# EPA Innovative Technology Verification Report  

Field Measurement Technology for Mercury in Soil and Sediment  

Ohio Lumex’s RA-915+/RP-91C Mercury Analyzer  

![](images/8e8fd53c72939de7dbb5f7f012b7b9ca711d5083d4fcc60d59f545cf5ebed952.jpg)  

# Innovative Technology Verification Report  

# Ohio Lumex’s RA-915+/RP-91C Mercury Analyzer  

Prepared by  

Science Applications International Corporation Idaho Falls, ID  

Contract No. 68-C-00-179  

Dr. Stephen Billets Characterization and Monitoring Branch Environmental Sciences Division Las Vegas, Nevada 89193-3478  

National Exposure Research Laboratory Office of Research and Development U.S. Environmental Protection Agency  

# Notice  

The U.S. Environmental Protection Agency through its Office of Research and Development funded and managed the research described here under contract to Science Applications International Corporation.  It has been subjected to the Agency’s peer and administrative review and has been approved for publication as an EPA document.  Mention of trade names or commercial products does not constitute endorsement or recommendation for use.  

# UNITED STATES ENVIRONMENTAL PROTECTION AGENCY  

Office of Research and Development Washington, DC 20460  

# MEASUREMENT AND MONITORING TECHNOLOGY PROGRAM VERIFICATION STATEMENT  

TECHNOLOGY TYPE: Field Measurement Device  

APPLICATION: Measurement for Mercury  

TECHNOLOGY NAME: Ohio Lumex Co.'s RA-915+/RP-91C Mercury Analyzer  

COMPANY: Ohio Lumex Co. ADDRESS: 9263 Ravenna Rd., Unit A-3 Twinsburg, OH 44087  

W EB SITE: http://www.ohiolumex.com  

TELEPHONE: (888) 876-2611  

# VERIFICATION PROGRAM DESCRIPTION  

The U.S. Environmental Protection Agency (EPA) created the Superfund Innovative Technology Evaluation (SITE) and Measurement and Monitoring Technology (MMT) Programs to facilitate deployment of innovative technologies through performance verification and information dissemination.  The goal of these programs is to further environmental protection by substantially accelerating the acceptance and use of improved and cost-effective technologies.  These programs assist and inform those involved in design, distribution, permitting, and purchase of environmental technologies. This document summ arizes results of a dem onstration of the RA-91 $^{5+}$ /RP-91C Mercury Analyzer developed by Ohio Lumex Co.  

# PROGRAM OPERATION  

Under the SITE and MMT Programs, with the full participation of the technology developers, the EPA evaluates and documents the performance of innovative technologies by developing demonstration plans, conducting field tests, collecting and analyzing demonstration data, and preparing reports.  The technologies are evaluated under rigorous quality assurance (QA) protocols to produce well-documented data of known quality.  The EPA National Exposure Research Laboratory, which dem onstrates field sampling, m onitoring, and m easurement technologies, selected Science Applications International Corporation as the verification organization to assist in field testing five field measurement devices for mercury in soil and sediment. This demonstration was funded by the SITE Program.  

# DEMONSTRATION DESCRIPTION  

In May 2003, the EPA conducted a field demonstration of the RA-91 $5+$ /RP-91C and four other field measurement devices for mercury in soil and sediment.  This verification statement focuses on the RA-915+/RP-91C; a similar statement has been prepared for each of the other four devices.  The performance of the RA-9 $15+$ /RP-91C was compared to that of an off-site laboratory using the reference method, “Test Methods for Evaluating Solid W aste” (SW - 846) Method 7471B (modified).  To verify a wide range of perform ance attributes, the demonstration had both primary and secondary objectives.  The primary objectives were:  

(1) Determining the instrument sensitivity with respect to the Method Detection Limit (MDL) and Practical Qua ntitation Limit (PQL);  

(2) Determining the analytical accuracy associated with the field measurement technologies;   
(3) Evaluating the precision of the field measurem ent technologies;   
(4) Measuring the amount of time required for mobilization and setup, initial calibration, daily calibration, sample analysis, and demobilization; and   
(5) Estimating the costs associated with mercury m easurements for the following four categories: capital, labor, supplies, and investigation-derived waste (IDW ).  

Secondary objectives for the demonstration included:  

(1) Documenting the ease of use, as well as skills and training required to properly operate the device;   
(2) Documenting potential health and safety concerns associated with operating the device;   
(3) Documenting the portability of the device;   
(4) Evaluating the device durability based on its materials of construction and engineering design; and (5) Documenting the availability of the device and associated spare parts.  

The RA- $915+/\mathsf{R P-91C}$ analyzed 56 field soil samples, 26 field sediment samples, 42 spiked field samples, and 73 performance evaluation (PE) standard reference material (SRM) sam ples in the demonstration.  The field sam ples were collected in four areas contam inated with mercury, the spiked samples were from these same locations, and the PE sam ples were obtained from  a com mercial provider.  

Collectively, the environmental and PE samples provided the different matrix types and the different concentrations of mercury needed to perform a com prehensive evaluation of the $\mathsf{R A}{-}915{+}/\mathsf{R P}{-}91\mathsf{C}$ .  A complete description of the demonstration and a summary of the results are available in the Innovative Technology Verification Report: “Field Measurement Technology for Mercury in Soil and Sediment—Ohio Lum ex Co.’s RA-9 $5+$ /RP-91C Mercury Analyzer" (EPA/600/R-03/147).  

# TECHNOLOGY DESCRIPTION  

The RA- $915+$ Mercury Analyzer is a portable AA spectrom eter with a 10-meter (m) multipath optical cell and Zeeman background correction.  Mercury is detected without preliminary accum ulation on a gold trap. Mercury sam ples are heated to $750{-}800^{\circ}{\mathsf C}$ , causing organic materials to be decomposed and m ercury to be vaporized in a carrier gas of ambient air.  The airflow carries the vaporized mercury to be carried to the analytical cell .  The RA-9 $15+$ includes a builtin test cell for field p erform an ce verific atio n.  T he op eratio n o f the R A- $915+$ is b as ed on the prin cip le o f dif ferentia l, Zeeman AA spectrometry combined with high-frequency modulation of polarized light.  This combination eliminates interferences and provides the highest sensitivity.  A mercury lamp is placed in a permanent magnetic field in which the 254-nm resonance line is split into three polarized components, two of which are circularly polarized in the opposite direction.  These two components (F- and $\upsigma+$ ) pass through a polarization modulator, while the third component (B) is removed.  One F component passes through the absorption cell; the other F component passes outside of the absorption cell and through the test cell.  In the absence of mercury vapors, the intensity of the two F com ponents are equal.  W hen mercury vapor is present in the absorption cell, mercury atoms cause a proportional, concentration-related difference in the intensity of the F components.  This difference in intensity is what is measured by the instrument.  The unit can be used with the optional RP-91C for an ultra-low mercury detection limit in water sam ples using the “cold vapor” technique.  For direct mercury determination in com plex m atrices without sam ple pretreatment, including liquids, soils and sediments, the instrument will be operated with the optional RP-91C accessory, as was done during the demonstration.  

During the demonstration, no extraction or sample digestion was required.  Individual samples were mixed m anually using a quartz injection spoon. This same spoon was used to transfer the sam ple directly to the RP-91C sample injection port after the sam ple was weighed on a digital balance.  The sample weight was m anually recorded.  The sample was analyzed, and the device displayed the m ercury concentration in parts per m illion, which is equivalent to a soil concentration in milligrams per kilogram.  

# ACTION LIMITS  

Action limits and concentrations of interest vary and are project specific.  There are, however, action limits which can be considered as potential reference points.  The EPA Region IX Preliminary Remedial Goals for mercury are $23\mathrm{~m}{\mathfrak{g}}/\upkappa{\mathfrak{g}}$ in re sidential soil and $310\mathrm{\mg/kg}$ in ind us tria l so il.  

# VERIFICATION OF PERFORMANCE  

To ensure data usability, data quality indicators for accuracy, precision, representativeness, completeness, comparability, and sensitivity were assessed for the reference method based on project-specific QA objectives. Key dem onstration findings are sum marized below for the primary objectives.  

Sensitivity:  The two primary sensitivity evaluations performed for this demonstration were the MDL and PQL.  Both will vary dependent upon whether the matrix is a soil, waste, or aqueous solution.  Only soils/sediments were tested during this demonstration, and therefore, MDL calculations and PQ L determ inations for this evaluation are limited to those matrices.  By definition, values m easured below the PQL should not be considered accurate or precise and those below the MDL are not distinguishable from background noise.  

Method Detection Lim it - The evaluation of an MDL requires seven different measurements of a low concentration standard or sample following the procedures established in the 40 Code of Federal Regulations (CFR) Part 136.  The MDL is estimated between 0.0053 and $0.042\:\mathrm{mg/kg}$ .  The equivalent MDL for the referee laboratory is $0.0026~\mathrm{mg/kg}$ .  

Practical Quantitation Lim it - The low standard calculations using MDL values suggest that a PQL for the Ohio Lumex field instrument may be as low as $0.027\mathrm{mg/kg}$ (5 tim es the lowest calculated MDL).  The $\%0$ for the average Ohio Lumex result for a tested sample with a referee laboratory value of $0.06\mathrm{~mg/kg}$ is $0.072\mathrm{~mg/kg}$ , w ith a $\%0$ of $20\%$ .  T his was the lowest sample concentration tested during the demonstration that is close to but not below, the calculated PQL noted above.  The referee laboratory PQL confirmed during the demonstration is $0.005~\mathrm{{mg/kg}}$ with a $\%0<10\%$ .  

Accuracy:  The results from the RA-915+/RP-91C  were compared to the $95\%$ pre diction interval for the SR M m aterials and to the referee laboratory results (Method 7471B).  The Ohio Lumex data were within SRM $95\%$ prediction intervals $93\%$ of the time, which suggests significant equivalence to certified standards.  The comparison between the Ohio Lumex field data and the referee laboratory results suggest that the two data sets are not the same.  When a unified hypothesis test is performed (which accounts for laboratory bias), this result is confirmed.  Ohio Lumex data were found to be both above and below referee laboratory concentrations, therefore there is no implied or suggested bias.  The number of Ohio Lumex average values less than $30\%$ different from the referee laboratory results or SRM reference values was significant – 19 of 33 different sample lots.  Ohio Lum ex results therefore, provide accurate estimates for field determination.  Because the Ohio Lumex data compare favorably to the SRM values, the differences between Ohio Lum ex and the referee laboratory are likely the result of reasons beyond the scope of this study.  

Precision:  The precision of the Ohio Lumex  field instrument is better than the referee laboratory precision.  The overall average RSD, is $22.3\%$ for the referee laboratory com pared to the Ohio Lumex average RSD of $16.1\%$ . T his is p rim arily because of the better precision obtained for the SRM analyses by Ohio Lumex. Both the laboratory precision and the Ohio Lumex precision goals of $25\%$ overall RSD were achieved.  

Measurement Time:  From the time of sample receipt, Ohio Lum ex required approximately 21 hours, 15 minutes, to prepare a draft data package containing mercury results for 197 samples.  One technician performed half of the equipment setup and demobilization, most of the sample preparation, and all of the analyses.  Individual analyses took 1 minute each, but the total time per analysis averaged 8.1 minutes per sample (based upon 1.25 analysts) when all field activities and data package preparation were included in the calculation because the vendor chose to analyze replicates of virtually every analysis.  

Measurement Costs:  The cost per analyses based upon 197 samples, when renting the RA-915+/RP-91C, is $\$23.44$ per sample.  The cost per analyses for the 197 samples, excluding rental fee, is $\$15.82$ per sample.  Based on a 3-day field demonstration, the total cost for equipment rental and necessary supplies is estimated at $\$4,617$ .  The cost by category is: capital costs, $32.5\%$ ; supplies, $10.8\%$ ; support equipment, $6.0\%$ ; labor, $19.5\%$ ; and IDW , $31.2\%$ .  

Key demonstration findings are summ arized below for the secondary objectives.  

Ease of Use:  Based on observations made during the dem onstration, the RA- $915+/\mathsf{R P-9}1\mathsf{C}$ is reasonably easy to operate; however, lack of automation somewhat impairs the ease of use.  Operation requires one field technician with a basic knowledge of chem istry acquired on the job or in a university and training on the instrument.  

Potential Health and Safety Concerns: No significant health and safety concerns were noted during the demonstration.  The only potential health and safety concerns identified were the generation of mercury vapors and the potential for burns with careless handling of hot quartz sample boats.  The vendor provides a mercury filter as standard equipment; exercising caution and good laboratory practices can mitigate the potential for burns.  

Portab ility:  The RA- $915+$ air analyzer was easily portable, although the device, even when carried in the canvas sling, was not considered light-weight.  The addition of the RP-91C and associated pum p unit preclude this from being a truly field portable instrument.  The device and attachments can be transported in carrying cases by two people, but must then be set up in a stationary location.  It was easy to set up, but the combined instrument is better characterized as mobile rather than field portable.  

Durability:  The RA-9 $\mid5+.$ /RP-91C was well designed and constructed for durability.  The outside of the RA- $915+$ is constructed of sturdy alum inum and the exterior of the RP-91C furnace is stainless steel.  

Availability of the Device:  The RA- $915+/\mathsf{R P-91C}$ is readily available for rental, lease, or purchase.  Spare parts and consum able supplies can be added to the original instrument order, or can be received within 24 to 48 hours of order placement.  Standards are readily available from laboratory supply firms or can be acquired through Ohio Lumex.  

# PERFORMANCE SUMMARY  

In summ ary, during the demonstration, the RA-91 $5+1$ RP-91C exhibited the following desirable characteristics of a field mercury measurem ent device: (1) good accuracy compared to SRMs, (2) good precision, (3) good sensitivity, (4) high sample throughput, (5) low measurement costs, and (6) ease of use.  During the demonstration the RA- $915+/\mathsf{R P-91C}$ was found to have the following limitations:  (1) lack of automation and (2) non-portable due to the instrument size and weight.  The demonstration findings collectively indicated that the RA-9 $15+$ /RP-91C is a reliable field measurement device for mercury in soil and sedim ent.  

NOTICE: EPA verifications are based on an evaluation of technology performance under specific, predetermined criteria and appropriate quality assurance procedures. The EPA makes no expressed or implied warranties as to the performance of the technology and does not certify that a technology will always operate as verified. The end user is solely responsible for complying with any and all applicable federal, state, and local requirements.  

# Foreword  

The U.S. Environmental Protection Agency (EPA) is charged by Congress with protecting the nation’s natural resources. Under the mandate of national environmental laws, the Agency strives to formulate and implement actions leading to a compatible balance between human activities and the ability of natural systems to support and nurture life. To m eet this mandate, the EPA’ s Office of Research and Development provides data and scientific support that can be used to solve environmental problems, build the scientific knowledge base needed to manage ecological resources wisely, understand how pollutants affect public health, and prevent or reduce environmental risks.  

The National Exposure Research Laboratory is the Agency’s center for investigation of technical and management approaches for identifying and quantifying risks to human health and the environment. Goals of the Laboratory’s research program are to (1) develop and evaluate methods and technologies for characterizing and monitoring air, soil, and water; (2) support regulatory and policy decisions; and (3) provide the scientific support needed to ensure effective implementation of environmental regulations and strategies.  

The EPA’s Superfund Innovative Technology Evaluation (SITE) Program evaluates technologies designed for characterization and remediation of contaminated Superfund and Resource Conservation and Recovery Act (RCRA) sites. The SITE Program was created to provide reliable cost and performance data in order to speed acceptance and use of innovative remediation, characterization, and m onitoring technologies by the regulatory and user com munity.  

Effective monitoring and measurement technologies are needed to assess the degree of contamination at a site, provide data that can be used to determine the risk to public health or the environment, and monitor the success or failure of a remediation process. One component of the EPA SITE Program, the Monitoring and Measurement Technology (MMT) Program, demonstrates and evaluates innovative technologies to meet these needs.  

Candidate technologies can originate within the federal governm ent or the private sector. Through the SITE Program, developers are given the opportunity to conduct a rigorous demonstration of their technologies under actual field conditions. By completing the demonstration and distributing the results, the Agency establishes a baseline for acceptance and use of these technologies. The MMT Program is m anaged by the Office of Research and Development’s Environmental Sciences Division in Las Vegas, NV.  

Gary Foley, Ph. D.   
Director   
National Exposure Research Laboratory Office of Research and Development  

vii  

# Abstract  

Ohio Lumex’s $\mathsf{R A915}\substack{+/91}\mathsf{C}$ mercury analyzer was demonstrated under the U.S. Environmental Protection Agency Superfund Innovative Technology Evaluation Program in May 2003, at the Oak Ridge National Laboratory (ORNL) in Oak Ridge, TN.  The purpose of the demonstration was to collect reliable performance and cost data for the RA91 $5+/910$ and four other field measurement devices for mercury in soil and sediment.  The key objectives of the demonstration were: 1) determine sensitivity of each instrum ent with respect to a vendor-generated m ethod detection limit (MDL) and practical quantitation limit (PQL); 2) determ ine analytical accuracy associated with vendor field m easurem ents using field samples and standard reference m aterials (SRMs); 3) evaluate the precision of vendor field m easurements; 4) m easure time required to perform mercury measurem ents; and 5) estim ate costs associated with mercury m easurements for capital, labor, supplies, and investigation-derived wastes.  

The demonstration also involved analysis of SRMs, field samples collected from four sites, and spiked field samples for mercury.  The performance results for a given field measurem ent device were compared to those of an off-site laboratory using reference method, “Test Methods for Evaluating Solid W aste” (SW -846) Method 7471B.  

The sensitivity, accuracy, and precision measurements were successfully completed.  Results of these measurement evaluations suggest that the Ohio Lumex field instrument can perform as well as the laboratory analytical method. Accuracy comparisons to standard reference materials showed statistical equivalence but field sample analysis suggested possible matrix interferences.  Field instrument precision was better than laboratory precision as determined by relative standard deviation calculations.  During the demonstration, Ohio Lumex required 21.25 hours (1,275 minutes) for analysis of 197 samples.  The cost per analysis, based on measurement of 197 samples, when incurring a minimum 1-m onth rental fee for the RA-9 $15+$ /RP-91C, was determined to be $\$23.44$ per sample.  Excluding the instrument rental cost, the cost for analyzing the 197 samples was determined to be $\$15.82$ per sample.  Based on the 3-day field demonstration, the total cost for equipm ent rental and necessary supplies was estimated at $\$4,617$ .  

The RA9 $15+$ /RP-91C exhibited good ease of use and durability, as well as no major health and safety concerns.  However, the device portability is somewhat limited by its size.  Additionally, the device is readily available for purchase or lease. The demonstration findings collectively indicated that the RA91 $5+$ /RP-91C is a reliable field mobile measurement device for m ercu ry in s oil.  

# Contents  

Verification Statement iii Foreword vii Abstract viii Contents . ix Tables xii Figures xiii Abbreviations, Acronym s, and Sym bols xiv Acknowledgm ents xvi  

# Chapter Page  

# Introduction  

1.1 Description of the SITE Program 1   
1.2 Scope of the Demonstration 2   
1.2.1 Phase I 2   
1.2.2 Phase II 2   
1.3 Mercury Chemistry and Analysis 3   
1.3.1 Mercury Chem istry 3   
1.3.2 Mercury Analysis 4  

# Technology Description  

2.1 Description of Atomic Absorption Spectroscopy 6   
2.2 Description of the RA-915+/RP-91C 6   
2.3 Developer Contact Information 8  

# Field Sample Collection Locations and Demonstration Site  

3.1.1 Site Description 10   
3.1.2 Sample Collection 10   
3.2 Y-12 National Security Complex 11   
3.2.1 Site Description 11   
3.2.2 Sample Collection 11   
3.3 Confidential Manufacturing Site 11   
3.3.1 Site Description . 11  

# Contents (Continued)  

# Chapter  

Page  

# 3.3.2 Sample Collection 12  

3.4 Puget Sound 12   
3.4.1 Site Description 12   
3.4.2 Sample Collection 12   
3.5 Demonstration Site 13   
3.6 SAIC GeoMechanics Laboratory 14  

# Demonstration Approach . 15  

4.1 Demonstration Objectives 15   
4.2 Demonstration Design 16   
4.2.1 Approach for Addressing Primary Objectives 16   
4.2.2 Approach for Addressing Secondary Objectives 20   
4.3 Sample Preparation and Management 21   
4.3.1 Sample Preparation . 21   
4.3.2 Sample Management 24   
4.4 Reference Method Confirmatory Process 25   
4.4.1 Reference Method Selection . 25   
4.4.2 Referee Laboratory Selection 25   
4.4.3 Summary of Analytical Methods 27   
4.5 Deviations from the Demonstration Plan 28  

# Assessm ent of Laboratory Quality Control Measurem ents 29  

5.1 Laboratory QA Sum mary 29   
5.2 Data Quality Indicators for Mercury Analysis 29   
5.3 Conclusions and Data Quality Limitations 30   
5.4 Audit Findings . 32  

# Performance of the RA-91 $5+$ /RP-91C 33  

6.1 Primary Objectives . 33  

6.1.1 Sensitivity 33   
6.1.2 Accuracy 35   
6.1.3 Precision 43   
6.1.4 Time Required for Mercury Measurement 46   
6.1.5 Cost 48   
.2 Secondary Objectives 48   
6.2.1 Ease of Use 48   
6.2.2 Health and Safety Concerns 51   
6.2.3 Portability of the Device 52   
6.2.4 Instrument Durability 53   
6.2.5 Availability of Vendor Instruments and Supplies 53  

# Econom ic Analysis 54  

7.1 Issues and Assumptions 54   
7.1.1 Capital Equipment Cost 54   
7.1.2 Cost of Supplies 54  

# Contents (Continued)  

Chapter Page  

7.1.3 Support Equipment Cost 55   
7.1.4 Labor Cost . 55   
7.1.5 Investigation-Derived W aste Disposal Cost 55   
7.1.6 Costs Not Included 56   
7.2 RA-915+/RP-91C Costs 56   
7.2.1 Capital Equipment Cost . 57   
7.2.2 Cost of Supplies 57   
7.2.3 Support Equipment Cost 57   
7.2.4 Labor Cost . 58   
7.2.5 Investigation-Derived W aste Disposal Cost 58   
7.2.6 Summary of RA-9 $15+$ /RP-91C Costs 58   
7.3 Typical Reference Method Costs 59  

# Summary of Demonstration Results 61  

8.1 Primary Objectives 61   
8.2 Secondary Objectives 62   
Bibliography 65   
Appendix A - Ohio Lum ex Comments 66   
Appendix B - Statistical Analysis 67  

# Tables  

# Table  

1-1 Physical and Chemical Properties of Mercury 4   
1-2 Methods for Mercury Analysis in Solids or Aqueous Soil Extracts 5   
3-1 Summary of Site Characteristics 10   
4-1 Demonstration Objectives 15   
4-2 Summary of Secondary Objective Observations Recorded During the Demonstration 20   
4-3 Field Samples Collected from the Four Sites 22   
4-4 Analytical Methods for Non-Critical Param eters 28   
5-1 MS/MSD Summary 30   
5-2 LCS Sum mary 30   
5-3 Precision Sum mary 31   
5-4 Low Check Standards 31   
6-1 Distribution of Sam ples Prepared for Ohio Lum ex and the Referee Laboratory . 33   
6-2 Ohio Lumex SRM Comparison 37   
6-3 ALSI SRM Com parison 37   
6-4 Accuracy Evaluation by Hypothesis Testing 38   
6-5 Number of Sample Lots W ithin Each %D Range 40   
6-6 Concentration of Non-Target Analytes 40   
6-7 Evaluation of Precision 44   
6-8 Time Measurements for Ohio Lumex 47   
7-1 Capital Cost Summ ary for the RA- $\beta\uparrow5+$ /RP-91C 57   
7-2 Labor Costs 58   
7-3 IDW  Costs 58   
7-4 Summary of Rental Costs for the RA-915+/RP-91C 59   
7-5 RA-915+/RP-91C Costs by Category 59   
8-1 Distribution of Sam ples Prepared for Ohio Lum ex and the Referee Laboratory 62   
8-2 Summary of RA- $\beta\uparrow5+$ /RP-91C Results for the Primary Objectives 63   
8-3 Summary of RA-9 $\mid15+$ /RP-91C Results for the Secondary Objectives 64   
B-1 Unified Hypothesis Test Summ ary Information . 69  

# Figures  

Figure  

2-1 RA- $915+$ instrument schematic. 7   
2-2 RA-915+/RP-91C shown setup in a van. 7   
3-1 Tent and field conditions during the demonstration at Oak Ridge, TN. 13   
3-2 Demonstration site and Building 5507. 13   
4-1 Test sample preparation at the SAIC GeoMechanics Laboratory. 23   
6-1 Data plot for low concentration sample results 41   
6-2 Data plot for high concentration sam ple results 42   
6-3 RA-915+/RP-91C peak screen. . 51   
7-1 Capital equipment costs. 57  

xiii  

# Abbreviations, Acronyms, and Symbols  

% Percent   
%D Percent difference   
°C Degrees Celsius   
µg/kg Microgram per kilogram   
AAS Atomic absorption spectroscopy   
ALSI Analytical Laboratory Services, Inc.   
bgs Below ground surface   
cm Centimeter   
CFR Code of Federal Regulations   
CI Confidence Interval   
COC Chain of custody   
DI Deionized (water)   
DOE Department of Energy   
EPA United States Environmental Protection Agency g Gram   
H&S Health and Safety   
Hg Mercury   
HgCl2 Mercury (II) chloride   
IDL Ins trum ent detec tion lim it   
IDW Investigation-derived waste   
ITVR Innovative Technology Verification Report kg Kilogram   
L Liter   
LCS Laboratory control sam ple   
LEFPC Lower East Fork Poplar Creek   
m Meter   
MDL Method detection limit   
mg M illigra m   
mg/kg Milligram per kilogram   
mL M illiliter   
mm Millimeter   
MS/MSD Matrix spike/m atrix spike duplicate   
MMT Monitoring and Measurement Technology NERL National Exposure Research Laboratory   
NiMH Nickel metal halide   
ng Nanogram   
nm Nanometer   
ORD Office of Research and Development   
ORNL Oak Ridge National Laboratory  

# Abbreviations, Acronyms, and Symbols (Continued)  

ORR Oak Ridge Reservation   
OSW ER Office of Solid Waste and Emergency Response   
PPE Personal protective equipment   
ppm Parts per million   
PQL Pr ac tica l qu an titat ion lim it   
QA Quality assurance   
QAPP Quality Assurance Project Plan   
QC Quality control   
RPD Relative percent difference   
RSD Relative standard deviation   
SAIC Science Applications International Corporation   
SITE Superfund Innovative Technology Evaluation   
SOP Standard operating procedure   
SRM Standard reference material   
SW -846 Test Methods for Evaluating Solid W aste; Physical/Chem ical Methods   
TOC Total Organic Carbon   
TOM Task Order Manager   
UL Underwriters Laboratory   
UEFPC Upper East Fork of Poplar Creek   
Y-12 Y-12 Oak Ridge Security Complex, Oak Ridge, TN  

# Acknowledgments  

The U.S. Environmental Protection Agency (EPA) Superfund Innovative Technology Evaluation wishes to acknowledge the support of the following individuals in perform ing the demonstration and preparing this document:  Elizabeth Phillips of the U.S. Department of Energy Oak Ridge National Laboratory (ORNL); Stephen Childs, Thomas Early, Roger Jenkins, and Monty Ross of the UT-Battelle ORNL; Dale Rector of the Tennessee Department of Environment and Conservation (TDEC) Department of Energy Oversight; Sergey Pogarev and Joseph Siperstein of Ohio Lumex; Leroy Lewis of the Idaho National Engineering and Environmental Laboratory, retired; Ishwar Murarka of the EPA Science Advisory Board, member; Danny Reible of Louisiana State University; Mike Bolen, Joseph Evans, Julia Gartseff, Sara Hartwell, Cathleen Hubbard, Kevin Jago, Andrew Matuson, Allen Motley, John Nicklas, Maurice Owens, Nancy Patti, Fernando Padilla, Mark Pruitt, James Rawe, Herb Skovronek, and Joseph Tillman of Science Applications International Corporation (SAIC); Scott Jacobs and Ann Vega of the EPA National Risk Management Research Laboratory’s Land Remediation and Pollution Control Division; and Brian Schum acher of the EPA National Exposure Research Laboratory.  

This document was QA reviewed by George Brilis of the EPA National Exposure Research Laboratory  

# Chapter 1 Introduction  

The U.S. Environmental Protection Agency (EPA) under the Office of Research and Development (ORD), National Exposure Research Laboratory (NERL), conducted a demonstration to evaluate the performance of innovative field measurem ent devices for their ability to measure mercury concentrations in soils and sedim ents.  This Innovative Technology Verification Report (ITVR) presents demonstration performance results and associated costs of Ohio Lumex’s Mercury Analyzer $(\mathsf{R A-}915+)$ w ith h eir so il attachment (RP-91C).  The vendor-prepared comments regarding the demonstration are presented in Appendix A.  

The dem onstration was conducted as part of the EPA Superfund Innovative Technology Evaluation (SITE) Monitoring and Measurement Technology (MMT) Program. Mercury contaminated soils and sediments, collected from four sites within the continental U.S., com prised the majority of samples analyzed during the evaluation.  Some soil and sediment samples were spiked with m ercury (II) chloride $(\mathsf{H}\mathsf{g C}\mathsf{l}_{2})$ to provide concentrations not occurring in the field samples.  Certified standard reference material (SRM) samples were also used to provide samples with certified mercury concentrations and to increase the m atrix variety.  

The demonstration was conducted at the Department of Energy (DOE) Oak Ridge National Laboratory (ORNL) in Oak Ridge, TN during the week of May 5, 2003.  The purpose of the dem onstration was to obtain reliable performance and cost data for field measurement devices in order to 1) provide potential users with a better understanding of the devices’ performance and operating costs under well-defined field conditions and 2) provide the instrument vendors with documented results that can assist them in promoting acceptance and use of their devices. The results obtained using the five field mercury measurement devices were compared to the mercury results obtained for identical sample sets (samples, spiked samples, and SRMs) analyzed at a referee laboratory.  The referee laboratory, which was selected prior to the demonstration, used a well-established EPA reference method.  

# 1.1 Description of the SITE Program  

Performance verification of innovative environmental technologies is an integral part of the regulatory and research mission of the EPA.  The SITE Program was established by EPA's Office of Solid Waste and Emergency Response (OSW ER) and ORD under the Superfund Amendments and Reauthorization Act of 1986.  

The overall goal of the SITE Program is to conduct performance verification studies and to promote the acceptance of innovative technologies that may be used to achieve long-term protection of human health and the environm ent.  The program  is designed to m eet three main objectives: 1) identify and remove obstacles to the development and commercial use of innovative technologies; 2) demonstrate promising innovative technologies and gather reliable performance and cost information to support site characterization and cleanup activities; and 3) develop procedures and policies that encourage the use of innovative technologies at Superfund sites, as well as at other waste sites or comm ercial facilities.  

The SITE Program includes the following elements:  

The MMT Program evaluates innovative technologies that sam ple, detect, monitor, or measure hazardous and toxic substances in soil, water, and sediment samples.  These technologies are expected to provide better, faster, or mor e cost-effective methods for producing real-time data during site characterization and rem edia tion stu dies than conventional technologies.  

The Remediation Technology Program  conducts demonstrations of innovative treatm ent technologies to provide reliable performance, cost, and applicability data for site cleanups.   
The Technology Transfer Program provides and disseminates technical information in the form of updates, brochures, and other publications that prom ote the SITE Program and participating technologies.  The Technology Transfer Program also offers technical assistance, training, and workshops in the support of the technologies.  A significant number of these activities are performed by EPA's Technology Innovation Office.  

The Field Analysis of Mercury in Soils and Sediments demonstration was performed under the MMT Program. The MMT Program provides developers of innovative hazardous waste sampling, detection, monitoring, and measurement devices with an opportunity to dem onstrate the perform ance of their devices under actual field conditions.  The main objectives of the MMT Program are as follows:  

Test and verify the perform ance of innovative field sampling and analytical technologies that enhance sampling, monitoring, and site characterization capabilities.   
Identify performance attributes of innovative technologies that address field sampling, monitoring, and characterization problems in a cost-effective and efficient manner.   
Prepare protocols, guidelines, methods, and other technical publications that enhance acceptance of these technologies for routine use.  

The MMT Program is administered by the Environmental Sciences Division of the NERL in Las Vegas, NV.  The NERL is the EPA center for investigation of technical and managem ent approaches for identifying and quantifying risks to human health and the environment.  The NERL mission components include 1) developing and evaluating methods and technologies for sampling, monitoring, and characterizing water, air, soil, and sediment; 2) supporting regulatory and policy decisions; and 3) providing technical support to ensure the effective implementation of environmental regulations and strategies.  

# 1.2 Scope of the Demonstration  

The demonstration project consisted of two separate phases: Phase I involved obtaining information on prospective vendors having viable mercury detection instrumentation. Phase II consisted of field and planning activities leading up to and including the demonstration activities.  The following subsections provide detail on both of these project phases.  

# 1.2.1 Phase I  

Phase I was initiated by m aking contact with knowledgeable sources on the subject of “m ercury in soil” detection devices.  Contacts included individuals within EPA, Science Applications International Corporation (SAIC), and industry where measurement of mercury in soil was known to be conducted.  Industry contacts included laboratories and private developers of mercury detection instrumentation.  In addition, the EPA Task Order Manager (TOM) provided contacts for "industry players" who had participated in previous MMT demonstrations.  SAIC also investigated university and other research-type contacts for knowledgeable sources within the subject area.  

These contacts led to additional knowledgeable sources on the subject, which in turn led to various Internet searches. The Internet searches were very successful in finding additional companies involved with mercury detection devices.  

All in all, these research activities generated an original list of approximately 30 companies potentially involved in the measurem ent of m ercury in soils.  The list included both international and U.S. companies.  Each of these companies was contacted by phone or email to acquire further information.  The contacts resulted in 10 companies that appeared to have viable technologies.  

Due to instrum ent d esig n (i.e., the instru m ent’s a bility to measure mercury in soils and sediments), business strategies, and stage of technology development, only 5 of those 10 vendors participated in the field demonstration portion of p has e II.  

# 1.2.2 Phase II  

Phase II of the demonstration project involved strategic planning, field-related activities for the demonstration, data analysis, data interpretation, and preparation of the ITVRs. Phase II included pre-demonstration and demonstration activities, as described in the following subsections.  

# 1.2.2.1 Pre-Demonstration Activities  

The pre-dem onstration activities were completed in the fall 2002.  There were six objectives for the pre-demonstration:  

Establish concentration ranges for testing vendors’ analytical equipment during the demonstration.   
Collect soil and sediment field samples to be used in the demonstration.   
Evaluate sample homogenization procedures.   
Determine mercury concentrations in homogenized soils and sedim ents.   
Select a reference method and qualify potential referee laboratories for the demonstration.   
Provide soil and sediment samples to the vendors for self-evaluation of their instrum ents, as a precursor to the demonstration.  

As an integral part of meeting these objectives, a predemonstration sam pling event was conducted in September 2002 to collect field samples of soils and sediments containing different levels of m ercury.  The field samples were obtained from the following locations:  

Carson River Mercury site - near Dayton, NV Y-12 National Security Complex - Oak Ridge, TN A confidential manufacturing facility - eastern U.S. Puget Sound - Bellingham  Bay, W A  

Immediately after collecting field sample material from the sites noted above, the general m ercury concentrations in the soils and sediments were confirmed by quick turnaround laboratory analysis of field-collected subsamples using method SW -7471B.  The field sample materials were then shipped to a soil preparation laboratory for homogenization.  Additional pre-demonstration activities are detailed in Chapter 4.  

# 1.2.2.2 Demonstration Activities  

Specific objectives for this SITE dem onstration were developed and defined in a Field Demonstration and Quality Assurance Project Plan (QAPP) (EPA Report # EPA/600/R-03/053).  The Field Demonstration QAPP is available t h ro u g h the EP A O RD we b s i t e (http://www.epa.gov/ORD/SITE) or from the EPA Project Manager.  The demonstration objectives were subdivided into two categories:  primary and secondary.  Primary objectives are goals of the demonstration study that need to be achieved for technology verification. The measurem ents used to achieve primary objectives are referred to as critical.  These measurements  typically produce quantitative results that can be verified using inferential and descriptive statistics.  

Secondary objectives are additional goals of the demonstration study developed for acquiring other information of interest about the technology that is not directly related to verifying the primary objectives. The measurem ents required for achieving secondary objectives are considered to be noncritical.  Therefore, the analysis of secondary objectives is typically more qualitative in nature and often uses observations and sometimes descriptive statistics.  

The field portion of the demonstration involved evaluating the capabilities of five m ercury-analyzing instrum ents to measure mercury concentrations in soil and sediment. During the demonstration, each instrument vendor received three types of samples 1) homogenized field samples referred to as “field samples”, 2) certified SRMs, and 3) spiked field sam ples (spikes).  

Spikes were prepared by adding known quantities of ${\mathsf{H}}{\mathsf{g C}}{\mathsf{l}}_{2}$ to field sam ples.  Together, the field samples, SRMs, and spikes are referred to as “demonstration samples” for the purpose of this ITVR.  All demonstration sam ples were independently analyzed by a carefully selected referee laboratory.  The experimental design for the demonstration is detailed in Chapter 4.  

# 1.3 Mercury Chemistry and Analysis  

# 1.3.1 Mercury Chemistry  

Elemental mercury is the only metal that occurs as a liquid at ambient temperatures. Mercury naturally occurs, primarily within the ore, cinnabar, as m ercury sulfide (HgS). Mercury easily forms am algams with many other metals, including gold.  As a result, mercury has historically been used to recover gold from ores.  

Merc ury is ionically stable; ho we ve r, it is very volatile for a metal.  Table 1-1 lists selected physical and chemical properties of elem ental m ercury.  

Table 1-1.  Physical and Chemical Properties of Mercury   


<html><body><table><tr><td>Properties</td><td>Data</td></tr><tr><td>Appearance</td><td>Silver-white, mobile, liquid.</td></tr><tr><td>Hardness</td><td>Liquid</td></tr><tr><td>Abundance</td><td>0.5% in Earth's crust</td></tr><tr><td>Density @ 25°C</td><td>13.53 g/mL</td></tr><tr><td>Vapor Pressure @ 25°C</td><td>0.002 mm</td></tr><tr><td>Volatilizes @</td><td>356°℃</td></tr><tr><td>Solidifies @</td><td>-39 °℃</td></tr></table></body></html>

Source: Merck Index, 1983  

Historically, mercury releases to the environment included a number of industrial processes such as chloralkali manufacturing, copper and zinc smelting operations, paint application, waste oil combustion, geothermal energy plants, municipal waste incineration, ink manufacturing, chemical manufacturing, paper mills, leather tanning, pharmaceutical production, and textile m anufacturing.  In addition, industrial and domestic mercury-containing products, such as thermom eters, electrical switches, and batteries, are disposed of as solid wastes in landfills (EPA, July 1995).  Mercury is also an indigenous compound at many abandoned mining sites and is, of course, found as a natural ore.  

At mercury-contaminated sites, mercury exists in m ercuric form $({\mathsf{H}}{\mathsf{g}}^{2+})$ , mercurous form $(\mathsf{H}\mathsf{g}_{2}^{2+})$ , elemental form $({\mathsf{H}}{\mathsf{g}}^{0})$ , and alk ylate d fo rm (e.g., m eth yl or e thyl m ercu ry). $\mathsf{H}\mathsf{g}_{2}^{2+}$ and ${\mathsf{H}}{\mathsf{g}}^{2+}$ are the more stable forms under oxidizing conditions. Under mildly reducing conditions, both organically bound mercury and inorganic mercury may be degraded to elemental mercury, which can then be converted readily to methyl or ethyl mercury by biotic and abiotic processes.  Methyl and ethyl mercury are the most toxic forms of mercury; the alkylated mercury compounds are volatile and soluble in water.  

Mercury (II) forms relatively strong complexes with Cl- and $\mathsf{C O}_{3}^{2-}$ .  Mercury (II) also forms complexes with inorganic ligands such as fluoride (F-), bromide (Br-), iodide (I-), sulfa te $(\mathsf{S O}_{4}^{2-})$ , sulfide $(\mathsf{S}^{2-})$ , and phosphate $(\mathsf{P O}_{4}^{3-})$ and forms strong complexes with organic ligands, such as sulfhydryl groups, amino acids, and humic and fulvic acids. The insoluble HgS is formed under mildly reducing conditions.  

# 1.3.2 Mercury Analysis  

There are several laboratory-based, EPA promulgated methods for the analysis of m ercury in solid and liquid hazardous waste matrices.  In addition, there are several performance-based methods for the determination of various mercury species. Table 1-2 summ arizes the commonly used methods for measuring m ercury in both solid and liquid matrices, as identified through a review of the EPA Test Method Index and SW -846.  A discussion of the choice of reference method is presented in Chapter 4.  

Table 1-2.  Methods for Mercury Analysis in Solids or Aqueous Soil Extracts   


<html><body><table><tr><td>Method</td><td>Analytical Technology</td><td>Type(s) of Mercury analyzed</td><td>Approximate Concentration Range</td><td></td><td>Comments</td></tr><tr><td>SW-7471B</td><td>CVAAS</td><td></td><td>inorganic mercury organo-mercury</td><td>10-2,000 ppb</td><td>Manual cold vapor technique widely used for total mercury determinations</td></tr><tr><td>SW-7472</td><td>ASV</td><td></td><td>inorganic mercury organo-mercury</td><td>0.1-10,000 ppb</td><td>Newer, less widely accepted method</td></tr><tr><td>SW-7473</td><td>TD, amalgamation, and AAS</td><td></td><td>inorganic mercury organo-mercury</td><td>0.2 - 400 ppb</td><td>Allows for total decomposition analysis</td></tr><tr><td>SW-7474</td><td>AFS</td><td></td><td>inorganic mercury organo-mercury</td><td>1 ppb - ppm</td><td>Allows for total decomposition analysis; less widely used/reference</td></tr><tr><td>EPA 1631</td><td>CVAFS</td><td></td><td>inorganic mercury organo-mercury</td><td>0.5 - 100 ppt</td><td>Requires "trace" analysis procedures; written for aqueous matrices; Appendix A of method written for sediment/soil samples</td></tr><tr><td>EPA 245.7</td><td>CVAFS</td><td></td><td>inorganic mercury organo-mercury</td><td>0.5 - 200 ppt</td><td>Requires “trace" analysis procedures; written for aqueous matrices; will require dilutions of high-concentration mercury samples</td></tr><tr><td>EPA 6200</td><td>FPXRF</td><td></td><td>inorganic mercury</td><td>>30 mg/kg</td><td>Considered a screening protocol</td></tr></table></body></html>

AAS $\mathbf{\tau}=\mathbf{\tau}$ Atomic Absorption Spectrometry AAF $\mathbf{\tau}=\mathbf{\tau}$ Atomic Fluorescence Spectrometry $\mathsf{A F S}=$ Atomic Fluorescence Spectrometry $\mathsf{A S V}=$ Anodic Stripping Voltammetry CVAAS $\mathbf{\tau}=\mathbf{\tau}$ Cold Vapor Atomic Absorption Spectrometry CVAFS $\mathbf{\tau}=\mathbf{\tau}$ Cold Vapor Atomic Fluorescence Spectrometry FPXRF $\mathbf{\tau}=\mathbf{\tau}$ Field Portable X-ray Fluorescence $\mathsf{E P A}=\mathsf{U}.\mathsf{S}$ . Environmental Protection Agency ${\sf m g}/{\sf k g}=$ milligram per kilogram ppb $\mathbf{\tau}=\mathbf{\tau}$ parts per billion ppm $\mathbf{\tau}=\mathbf{\tau}$ parts per million ppt $\mathbf{\tau}=\mathbf{\tau}$ parts per trillion $\mathsf{S W}=$ solid waste TD $\mathbf{\tau}=\mathbf{\tau}$ thermal decomposition  

# Chapter 2 Technology Description  

This chapter provides a detailed description of the thermal decomposition method of atomic absorption spectroscopy (AAS), which is the type of technology on which Ohio Lumex’s instrument is based, and a detailed description of the RA- $915+$ Mercury Analyzer with the RP-91C soil attachment.  

# 2.1 Description of Atomic Absorption Spectroscopy  

The principle of analysis used by the RA- $915+$ and RP-91C is thermal decomposition followed by AAS, with a 10-meter (m) multi-path optical cell and Zeeman background correction.  AAS uses the absorption of light to measure the concentration of gas-phase atoms.  Because samples are  liquids or solids, the analyte atoms or ions must be vaporized in a flame or graphite furnace.  The atoms absorb ultraviolet or visible light and make transitions to higher electronic energy levels.  The analyte concentration is determined from the amount of absorption. Concentration measurements are  determined from a working curve after calibrating the instrument with standards of known concentration.  

In reference to AAS, as a general analytical application, thermal decomposition is followed by  atomic absorption; however, the mechanism of chemical recovery for analysis may vary. Examples include cold vapor traps, amalgamation desorption, and direct detection.  

A sample of known mass is placed in the drying and decomposition furnace and heated to between 600-800 Celsius $(^{\circ}\mathsf{C})$ .  The liquid or solid sample is dried and organic materials are decomposed.  The amount   of light absorbed by an analyte (the product of decom position), in this case mercury vapor, is  com pared to a standard to quantify the m ass of that analyte present in a sample of known size.  The absorption of light is proportional to the mass of the analyte present.  The wavelength of the light source is specific to the analyte of interest.  For mercury, the wavelength is $254~\mathsf{n m}$ .  

# 2.2 Description of the RA-915+/RP-91C  

The RA- $915+$ Mercury Analyzer is a portable atomic absorption (AA) spectrometer with a $10-m$ m ultipath optical cell and Zeeman background correction.  Am ong its features is the direct detection of mercury without preliminary accumulation on a gold trap.  The RA- $915+$ includes a built-in test cell for field performance verification. The unit can be used with the optional RP-91C for an ultralow m ercury detection lim it in water sam ples using the “cold vapor” technique.  For direct mercury determination in complex matrices without sample pretreatment, including liquids, soils and sediments, the instrument is operated with the RP-91C accessory.  

The operation of the RA- $915+$ is based on the principle of differential, Zeeman AA spectrometry combined with highfrequency modulation of polarized light.  This combination eliminates interferences and provides the highest sensitivity.  A mercury lamp is placed in a permanent magnetic field in which the 254-nm resonance line is split into three polarized components, two of which are circularly polarized in the opposite direction.  These two components (F- and $\upsigma+$ ) pass through a polarization modulator, while the third com ponent (B) is removed (see Figure 1).  One F component passes through the absorption cell; the other F component passes outside of the absorption cell.  In the absence of m ercury vapors, the intensity of the two F com ponents are equal.  W hen m ercury vapor is present in the absorption cell, mercury atoms cause a proportional, concentration-related difference in the intensity of the F components. This difference in intensity is what is measured by the instrum ent.  

![](images/6a6869b9377fb35bb97a509ba3c1d12614cb32adfed758af0d659fa37c3788c9.jpg)  
Figure 2-1.  RA-915+ instrument schematic.  

The RP-91C attachment is intended to decompose a sample and to reduce the mercury using the pyrolysis technique.  The RP-91C attachment is a furnace heated to $800^{\circ}\mathsf{C}$ where m ercury is converted from a bound state to the atomic state by thermal decomposition, and reduced in a two-section furnace.  In the first section of the furnace, the “light” mercury compounds are preheated and burned. In the second section, a catalytic afterburner decomposes “heavy” compounds.  After the atomizer, the gas flow enters the analytical cell of the atta chm ent.  Am bient air is used as a carrier gas; no cylinders of  compressed gasses are required.  Zeeman correction eliminates interferences, thus, no gold amalgamation is required.  The instrument is controlled and the data are  acquired by software based on a Microsoft W indows $\textcircled{8}$ platform.  

Applications and Specifications - The RA- $915+$ is a portable spectrometer designed for interference-free analysis/monitoring of mercury content in ambient air, water, soil, natural and stack gases from chlor-alkali manufacturing, spill response, hazardous  waste, foodstuff, and biological materials.  The Ohio Lumex system  is fully operational in the field and could be set up in a van, as well as a helicopter, marine vessel, or hand-carried for continuous measurements.  The RP-91 and RP-91C attachm ents are used to convert the instrument into a liquid or solid sam ple analyzer, respectively. The instrument is suitab le for fie ld ope ration using a bu ilt-in battery.  

According to the RA- $915+$ Analyzer manual, the base unit has a dimension of 47 cm by $22\ {\mathsf{c m}}$ by 11 cm and weighs $7.57\mathsf{k g}$ .  The palm unit measures 13.5 cm by 8 cm by 2 cm and weighs $0.32\mathrm{~}\mathsf{k g}$ .  The power supply can be a built-in, 6- volt rechargeable battery, a power pack adapter, an external electric battery, or an optional rechargeable battery pack.  The RP-91C system includes a pumping unit that has a dimension of $34~{\mathsf{c m}}$ by $24\ c m$ by $12\mathsf{c m}$ and a power supply unit m easuring 14.5 cm by 15 cm by 8.5 cm (see Figure 2).  Site requirements cited in the manual include a temperature range of 5 to $40~^{\circ}\mathsf{C}$ , relative h um idity of up to $98\%$ , atmospheric pressures of 84 to 106.7 kilopascals, along with requirements for sinusoidal vibration and magnetic field tension.  Sensitivity of the instrument is reportedly not affected by up to a $95\%$ background absorption caused by interfering com ponents (dust, moisture, organic and inorganic gases).  

![](images/371f01d8136494285034806ae43a70814fbe4cb755072dcd8a478df6d5d495bc.jpg)  
Figure 2-2.  RA-915+/RP-91C shown setup in a van.  

Operation - The instrument calibration is performed by use of liquid or s olid, prim ary N ationa l Institute o f Sta ndard s and Technology (NIST)-traceable standards. The normal dynamic analytical range is from $1-100\ \upmu{\mathfrak{g}}/\upkappa{\mathfrak{g}}$ by direct determination without dilution.  No sam ple mineralization is needed, and the only waste generated is minimal residual sample residue, excess sample, and any personal protective equipment that may be used.  Sam ple throughput is up to 30 samples per hour without an auto sam pler.  

# 2.3 Developer Contact Information  

Additional information about the RA- $\mathfrak{915+}$ and PR-91C can be obtained from the following source:  

Joseph Siperstein   
Ohio Lumex Co.   
9263 Ravenna Rd., Unit A-3  

Twinsburg, OH 44087 Toll free: (888) 876-2611 Telephone: (330) 405-0837 Fax: (330) 405-0847 Email: mail@ohiolumex.com Internet: www.ohiolumex.com  

# Chapter 3 Field Sample Collection Locations and Demonstration Site  

As previously described in Chapter 1, the dem onstration in part tested th e ab ility of all five ve ndo r instru m ents to measure mercury concentrations in demonstration samples.  The demonstration samples consisted of fieldcollected samples, spiked field samples, and SRMs.  The field-collected samples comprised the majority of demonstration samples.  This chapter describes the four sites from which the field samples were collected, the demonstration site, and the sample homogenization laboratory.  Spiked samples were prepared from  these field samples.  

Screening of potential mercury-contaminated field sample sites was conducted during Phase I of the project.  Four sites were selected for acquiring mercury-contaminated samples that were diverse in appearance, consistency, and mercury concentration.  A key criterion was the  source of the contamination.  These sites included:  

Carson River Mercury site - near Dayton, NV The Y-12 National Security Complex (Y-12) - Oak Ridge, TN A confidential manufacturing facility - eastern U.S. Puget Sound - Bellingham  Bay, W A  

Site Diversity – Collectively, the four sites provided sampling areas with both soil and sediment, having variable physical consistencies and variable ranges of mercury contamination.  Two of the sites (Carson River and Oak Ridge) provided both soil and sediment samples. A third site (a ma nufacturing facility) provided just s oil samples and a fourth site (Puget Sound) provided only sediment samples.  

Access and Cooperation – Site representatives were instrumental in providing site access, and in some cases, guidance on the best areas to collect samples from relatively high and low mercury concentrations.  In addition, representatives from the host demonstration site (ORN L) provided a facility for conducting the demonstration.  

At three of the sites, the soil and/or sediment sample was collected, homogenized by hand in the field, and subsampled for quick turnaround analysis.  These subsamples were sent to analytical laboratories to determine the general range of mercury concentrations at each of the sites.  (The Puget Sound site did not require confirmation of m ercury contam ination due to recently acquired mercury analytical data from another, ongoing research project.)  The field-collected soil and sediment samples from all four sites were then shipped to SAIC’s GeoMechanics Laboratory for a m ore thorough sample homogenization (see Section 4.3.1) and subsampled for redistribution to vendors during the pre-demonstration vendor self-evaluations.  

All five of the technology vendors performed a selfevaluation on selected samples collected and homogenized during this pre-demonstration phase of the project.  For the self-evaluation, the laboratory results and SRM values were supplied to the vendor, allowing the vendor to determine how well it performed the analysis on the field samples.  The results were used to gain a preliminary understanding of the field samples collected and to prepare for the demonstration.  

Table 3-1 summ arizes key characteristics of samples collected at each of the four sites.  Also included are the sample matrix, sample descriptions, and sam ple depth intervals.  The analytical results presented in Table 3-1 are based on referee laboratory mercury results for the demonstration samples.  

Table 3-1. Summary of Site Characteristics   


<html><body><table><tr><td> Site Name</td><td> Sampling Area </td><td>Sample Matrix</td><td>Depth</td><td>Description</td><td>Hg Concentration Range</td></tr><tr><td>Carson River Mercury site</td><td>Carson River</td><td> Sediment </td><td>water/sediment interface</td><td>Sandy silt, with some organic debris present (plant stems and leaves)</td><td>10 ppb - 50 ppm</td></tr><tr><td></td><td> Six Mile Canyon</td><td>Soil</td><td>3-8 cm bgs</td><td>Silt with sand to sandy silt </td><td>10 ppb - 1,000 ppm</td></tr><tr><td>Y-12 National Security Complex</td><td>Old Hg Recovery Bldg.</td><td>Soil</td><td>0-1m bgs</td><td>Silty-clay to sandy-gravel</td><td>0.1 - 100 ppm</td></tr><tr><td></td><td> Poplar Creek </td><td> Sediment </td><td>0-0.5m bgs</td><td>Silt to coarse sandy gravel</td><td>0.1 - 100 ppm</td></tr><tr><td>Confidential manufacturing site</td><td>Former plant building</td><td>Soil</td><td>3.6 -9 m bgs </td><td>Silt to sandy silt </td><td>5 - 1,000 ppm</td></tr><tr><td>Puget Sound - Bellingham Bay</td><td>Sediment layer</td><td> Sediment </td><td>1.5 - 1.8 m thick</td><td>Clayey-sandy silt with various woody debris</td><td>10 - 400 ppm</td></tr><tr><td></td><td>Underlying Native Material </td><td>Sediment</td><td>0.3 m thick</td><td>Medium-fine silty sands</td><td>0.16 - 10 ppm</td></tr></table></body></html>

bgs $\mathbf{\tau}=\mathbf{\tau}$ below ground surface.  

# 3.1 Carson River  

# 3.1.1 Site Description  

The Carson River Mercury site begins near Carson City, NV, and extends downstream to the Lahontan Valley and the Carson Desert.  During the Comstock mining era of the late 1800s, mercury was imported to the area for processing gold and silver ore.  Ore mined from the Com stock Lode was transported to mill sites, where it was crushed and mixed with mercury to amalgamate the precious metals.  The Nevada mills were located in Virginia City, Silver City, Gold Hill, Dayton, Six Mile Canyon , G old Canyon, and adjacent to the Carson River between New Empire and Dayton.  During the mining era, an estimated 7,500 tons of mercury were discharged into the Carson R i v e r d r a i n a g e , p r i m a r i l y i n t h e f o r m o f mercury-contaminated tailings (EPA Region 9, 1994).  

Mercury contamination is present at Carson River as either elemental mercury and/or inorganic mercury sulfides with less than $1\%$ , if any, methylme rcury. Mercury contamination exists in soils present at the former gold and silver m inin g m ill sites; waterways adjacent to the mill sites; and sediment, fish, and wildlife over m ore than a 50-mile length of the Carson River.  Mercury is also present in the sediments and adjacent flood plain of the Carson River, and in the sediments of Lahontan Reservoir, Carson Lake, Stillwater W ildlife Refuge, and Indian La kes.  In addition, tailings with elevated mercury levels are still present at, and around, the his tor ic m ill sites , pa rtic ula rly in S ix M ile Canyon (EPA, 2002a).  

# 3.1.2 Sample Collection  

The Carson River Mercury site provided both soil and sediment sam ples across the range of contaminant concentrations desired for the demonstration.  Sixteen near-surface soil samples were collected between $3{-}8\ \mathsf{c m}$ below ground surface (bgs).  Two sediment samples were collected at the water-to-sediment interface.  All 18 samples were collected on September 23-24, 2002 with a hand shovel.  Samples were collected in Six Mile Canyon and along the Carson River.  

The sampling sites were selected based upon historical data from the site.  Specific sampling locations in the Six Mile Canyon were selected based upon local terrain and visible soil conditions (e.g., color and particle size).  The specific sites were selected to obtain soil sam ples with as much variety in mercury concentration as possible.  These sites included hills, run-off pathways, and dry river bed areas.  Sampling locations along the Carson River were selected based upon historical mine locations, local terrain, and river flow.  

W hen collecting the soil samples, approximately 3 cm of surface soil was scraped to the side.  The sample  was then collected with a shovel, screened through a 6.3-millimeter $(\mathsf{m m})$ (0.25-inch) sieve to remove larger material, and collected in 4-liter (L) sealable bags identified with a permanent marker. The sediment samples were also collected with a shovel, screened through a $_{6.3-m m}$ sieve to remove larger material, and collected in 4-L sealable bags identified with a perm anent marker.  Each of the 4-L sealable bags was placed into a second 4-L sealable bag, and the sample label was placed onto the outside bag.  The sediment samples were then placed into 10-L buckets, lidded, and identified with a sample label.  

# 3.2 Y-12 National Security Complex  

# 3.2.1 Site Description  

The Y-12 site is located at the DOE O RNL in Oak Ridge, TN.  The Y-12 site is an active manufacturing and developmental engineering facility that occupies approximately 800 acres on the northeast corner of the DOE Oak Ridge Reservation (ORR) adjacent to the city of Oak Ridge, TN.  Built in 1943 by the U.S. Army Corps of Engineers as part of the W orld W ar II Manhattan Project, the original mission of the installation was development of electrom agnetic separation of uranium isotopes and weapon components manufacturing, as part of the national effort to produce the atomic bomb.  Between 1950 and 1963, large quantities of elemental mercury were used at Y-12 during lithium isotope separation pilot studies and subsequent production processes in support of thermonuclear weapons programs.  

Soils at the Y-12 facility are contam inated with mercury in many areas.  One of the areas of known high levels of mercury-contaminated soils is in the vicinity of a former mercury use facility (the "Old Mercury Recovery Building" – Building 8110).  At this location, mercury-contaminated material and soil were processed in a Nicols-Herschoff roasting furnace to recover mercury.  Releases of mercury from this process, and from a building sump used to secure the mercury-contam inated materials and the recovered mercury, have contaminated the surrounding soils (Rothchild, et al., 1984).  Mercury contamination also occurred in the sediments of the East Fork of Poplar Creek (DOE, 1998).  The Upper East Fork of Poplar Creek (UEFPC) drains the entire Y-12 complex.  Releases of mercury via building drains connected to the storm sewer system, building basement dewatering sump discharges, and spills to soils, all contributed to contamination of UEFPC.  Recent investigations showed that bank soils containing mercury along the UEFPC were eroding and contributing to mercury loading.  Stabilization of the bank soils along this reach of the creek was recently completed.  

# 3.2.2 Sample Collection  

Two matrices were sam pled at Y-12 in Oak Ridge, TN, creek sediment and soil.  A total of 10 sediment samples was collected; one sediment sample was collected from the Lower East Fork of Poplar Creek (LEFPC) and nine sediment samples were collected from the UEFPC.  A total of six soil samples was collected from the Building 8110 area.  The sampling procedures that were used are summ arized below.  

Creek Sediments – Creek sediments were collected on September 24-25, 2002 from the East Fork of Poplar Creek.  Sediment samples were collected from various locations in a downstream  to upstream sequence (i.e., the downstream LEFPC sample was collected first and the most upstream point of the UEFPC was sam pled last).  

The sediment samples from Poplar Creek were collected using a comm ercially available clam-shell sonar dredge attached to a rope.  The dredge was slowly lowered to the creek bottom  surface, where it was pushed by foot into the sediment.  Several drops of the sampler (usually seven or more) were made to collect enough material for screening. On som e occasions, a shovel was used to remove overlying "hardpan" gravel to expose finer sediments at depth.  One creek sample consisted of creek bank sediments, which was collected using a stainless steel tro we l.  

The collected sediment was then poured onto a $_{6.3-m m}$ sieve to remove oversize sample material.  Sieved samples were then placed in 12-L sealable plastic buckets.  The sediment samples in these buckets were homogenized with a plastic ladle and subsamples were collected in 20- milliliter (mL) vials for quick turnaround analyses.  

Soil – Soil samples were collected from pre-selected boring locations September 25, 2002.  All samples were collected in the im mediate vicinity of the Building 8110 foundation using a comm ercially available bucket auger. Oversize material was hand picked from the excavated soil because the soil was too wet to be passed through a sieve. The soil was transferred to an aluminum pan, homogenized by hand, and subsam pled to a $20-\mathsf{m L}$ v ial. The rem aining soil was transferred to 4-L plastic containers.  

# 3.3 Confidential Manufacturing Site  

# 3.3.1 Site Description  

A confidential manufacturing site, located in the eastern U.S., was selected for participation in this demonstration. The site contains elemental mercury, mercury amalgams, and mercury oxide in shallow sedim ents (less than $0.3{\mathrm{~m}}$ deep) and deeper soils (3.65 to $9~\mathsf{m}$ bg s).  T his s ite provided soil with concentrations from $5{\cdot}1,000~\mathsf{m g/k g}$ .  

The site is the location of three former processes that resulted in mercury contamination.  The first process involved amalgamation of zinc with mercury.  The second process involved the manufacturing of zinc oxide.  The third process involved the reclamation of silver and gold from mercury-bearing materials in a retort furnace. Operations led to the dispersal of elem ental m ercury, mercury compounds such as chlorides and oxides, and zinc-m ercury amalgams.  Mercury values have been measured ranging from 0.05 to over $5,000\mathrm{~mg/kg}$ , with average values of approximately $100\mathrm{\mg/kg}$ .  

# 3.3.2 Sample Collection  

Eleven subsurface soil samples were collected on September 24, 2002.  All samples were collected with a Geoprobe® unit using plastic sleeves.  All sam ples were collected at the location of a former facility plant.  Drilling locations were determ ined based on historical data provided by the site operator.  The intention was to gather soil samples across a range of concentrations.  Because the surface soils were from relatively clean fill, the sampling device was pushed to a depth of $3.65~\mathsf{m}$ using a blank rod. Samples were then collected at pre-selected depths ranging from 3.65 to $\mathfrak{g}_{\mathfrak{m}}$ bgs.  Individual cores were 1-m long.  The plastic sleeve for each 1-m core was marked with a permanent marker; the depth interval and the bottom of each core was m arked.  The filled plastic tubes were transferred to a staging table where appropriate depth intervals were selected for m ixing.  Selected tubes were cut into $0.6\cdot\mathsf{m}$ intervals, which were emptied into a plastic container for premixing soils.  W hen feasible, soils were initially screened to remove materials larger than $6.3\mathsf{-m m}$ in diameter.  In many cases, soils were too wet and clayey to allow screening; in these cases, the soil was broken into pieces by hand and, by using a wooden spatula, oversize materials were manually removed.  These soils (screened or hand sorted) were then m ixed until the soil appeared visually uniform in color and texture.  The mixed soil was then placed into a 4-L sample container for each chosen sample interval.  A subsample of the mixed soil was transferred into a $20-m L$ vial, and it was sent for quick turnaround m ercury analysis.  This process was repeated for each subsequent sam ple interval.  

# 3.4 Puget Sound  

# 3.4.1 Site Description  

The Puget Sound site consists of contaminated offshore sediments.  The particular area of the site used for collecting demonstration samples is identified as the Georgia Pacific, Inc. Log Pond.  The Log Pond is located within the W hatcom W aterway in Bellingham  Bay, W A, a well-established heavy industrial land use area with a maritime shoreline designation.  Log Pond sediments measure approximately 1.5 to $1.8–m$ thick, and contain various contam inants including mercury, phenols, polyarom atic hydrocarbons, polychlorinated  biphenyls, and wood debris.  Mercury was used as a preservative in the logging industry.  The area was capped in late 2000 and early 2001 with an average of 7 feet of clean capping material, as part of a Model Toxics Control Act interim cleanup action.  The total thickness ranges from approximately $0.15\mathrm{m}$ along the site perim eter to $3\mathsf{m}$ with in the interior of the project area.  The restoration project produced 2.7 acres of shallow sub-tidal and 2.9 acres of low intertidal habitat, all of which had previously exceeded the Sediment Managem ent Standards cleanup criteria (Anchor Environmental, 2001).  

Mercury concentrations have been measured ranging from 0.16 to $400\mathrm{\mg/kg}$ (dry wt).  The m ajority $(98\%)$ of the mercury detected in near-shore ground waters and sediments of the Log Pond is believed to be comprised of complexed divalent $({\mathsf{H}}{\mathsf{g}}^{2+})$ forms such as mercuric sulfide (Bothner, et al., 1980 and Anchor Environmental, 2000).  

# 3.4.2 Sample Collection  

Science Applications International Corporation (SAIC ) is currently performing a SITE remedial technology evaluation in the Puget Sound (SAIC, 2002).  As part of ongoing work at that site, SAIC collected additional sediment for use during this MMT project.  Sediment samples collected on August 20-21, 2002 from the Log Pond in Puget Sound were obtained beneath approximately $3{-}6\mathsf{m}$ of water, using a vibra-coring system capable of capturing cores to $0.3~\mathsf{m}$ below the proposed dredging prism.  The vibra-corer consisted of a core barrel attached to a power head. Aluminum core tubes, equipped with a stainless steel "eggshell" core catcher to retain m aterial, were inserted into the core barrel.  The vibra-core was lowered into position on the bottom and advanced to the appropriate sampling depth.  Once sampling was completed, the vibra-core was retrieved and the core liner removed from the core barrel. The core sample was examined at each end to verify that sufficient sediment was retained for the particular sample.  The condition and quantity of material within the core was then inspected to determine acceptability.  

The following criteria were used to verify whether an acceptable core sample was collected:  

Target penetration depth (i.e., into native material) was achieved.  

Sedim ent recovery of at least $65\%$ of the penetration depth was achieved.   
Sample appeared undisturbed and intact without any evidence of obstruction/blocking within the core tube or catcher.  

The percent sediment recovery was determined by dividing the length of material recovered by the depth of core penetration below the mud line.  If the sam ple was deemed acceptable, overlying water was siphoned from the top of the core tube and each end of the tube capped and sealed with duct tape.  Following core collection, representative sam ples were collected from each core section representing a different vertical horizon. Sediment was collected from the center of the core that had not been smeared by, or in contact with, the core tube.  The volumes removed were placed in a decontaminated stainless steel bowl or pan and mixed until homogenous in texture and color (approximately 2 minutes).  

After all sediment for a vertical horizon composite was collected and homogenized, representative aliquots were placed in the appropriate pre-cleaned sample containers. Samples of both the sediment and the underlying native material were collected in a similar manner.  Distinct layers of sedim ent and native m aterial were easily recognizable within each core.  

# 3.5 Demonstration Site  

The demonstration was conducted in a natural environm ent, outdoors, in Oak Ridge, TN.  The area was a grass covered hill with some parking areas, all of which were surrounded by trees.  Building 5507, in the center of the demonstration area, provided facilities for lunch, break, and sam ple storage for the project and personnel.  

Most of the demonstration was performed during rainfall events ranging from steady to torrential.  Severe puddling of rain occurred to the extent that boards needed to be placed under chairs to prevent them from sinking into the ground.  Even when it was not raining, the relative hum idity was high, ranging from 70.6 to 98.3 percent.  Between two and four of the tent sides were used to keep rainfall from damaging the instruments.  The temperature in the afternoons ranged from 65-70 degrees Fahrenheit, and the wind speed was less than $10{\mathrm{~}}{\mathsf{m p h}}$ .  The latitude is $36^{\circ}\mathsf{N}$ , the longitude $35^{\circ}\mathsf{W}$ , and the elevation $275~\mathsf{m}$ .  (Figure 3-1 is a photograph of the site during the demonstration and Figure 3-2 is a photograph of the location.)  

![](images/4c3495414d3562b3d6e7370f83824d2cd1ed8c5c437e56fd730375e56db9d889.jpg)  
Figure 3-1.  Tent and field conditions during the demonstration at Oak Ridge, TN.  

![](images/4de91979f031ff5753ecd57ca255e0ffe994b0a424d83a4f04e6caf896c41c97.jpg)  
Figure 3-2.  Demonstration site and Building 5507.  

# 3.6 SAIC GeoMechanics Laboratory  

Sam ple homogenization was completed at the SAIC GeoMechanics Laboratory in Las Vegas, NV.  This facility is an ind us tria l-type building with separate facilities for personnel offices and m aterial handling.  The primary function of the laboratory is for rock mechanics studies. The laboratory has rock mechanics equipment, including sieves, rock crushers, and sample splitters.  The personnel associated with this laboratory are experienced in the areas of sam ple preparation and sam ple homogenization.  In addition to the sample homogenization equipment, the laboratory contains several benches, tables, and open space.  Mercury air monitoring equipment was used during the sample preparation activities for personnel safety.  

# Chapter 4 Demonstration Approach  

This chapter describes the demonstration approach that was used for evaluating the field mercury measurement technologies at ORNL in May 2003.  It presents the objectives, design, sample preparation and management procedures, and the reference m ethod confirmatory process used for the demonstration.  

# 4.1 Demonstration Objectives  

The primary goal of the SITE MMT Program is to develop reliable performance and cost data on innovative, field-ready measurement technologies. A SITE demonstration must provide detailed and reliable performance and cost data in order that potential technology users have adequate inform ation needed to make sound judgements regarding an innovative technology’s applicability to a specific site and to be able to compare the technology to conventional technologies.  

Table 4-1 summ arizes the project objectives for this demonstration.  In accordance with QAPP Requirements for Applied Research Projects (EPA,1998), the technical project objectives for the dem onstration were categorized as prim ary and secondary.  

Table 4-1. Demonstration Objectives   


<html><body><table><tr><td>Objective</td><td>Description</td><td>Method of Evaluation</td></tr><tr><td colspan="3">Primary Objectives</td></tr><tr><td>Primary Objective # 1</td><td>Determine sensitivity of each instrument with respect to vendor-generated MDL and PQL.</td><td>Independent laboratory confirmation of SRMs,</td></tr><tr><td>Primary Objective # 2</td><td>Determine potential analytical accuracy associated with vendor field measurements.</td><td>field samples, and spiked field samples.</td></tr><tr><td>Primary Objective # 3</td><td>Evaluate the precision of vendor field measurements.</td><td></td></tr><tr><td>Primary Objective # 4</td><td>Measure time required to perform five functions related to mercury measurements: 1) mobilization and setup, 2) initial calibration, 3) daily calibration, 4) sample </td><td>Documentation during demonstration; vendor-</td></tr><tr><td>Primary Objective # 5</td><td>analysis, and 5) demobilization. Estimate costs associated with mercury measurements for the following four categories: 1) capital, 2) labor, 3) supplies, and 4) investigation-derived wastes.</td><td> provided information.</td></tr><tr><td colspan="3">Secondary Objectives</td></tr><tr><td>Secondary Objective # 1</td><td>Document ease of use, skills, and training required to operate the device properly.</td><td>Documentation of</td></tr><tr><td>Secondary Objective # 2</td><td>Document potential H&S concerns associated with operating the device.</td><td>observations during</td></tr><tr><td>Secondary Objective # 3 Secondary Objective # 4</td><td>Document portability of the device. Evaluate durability of device based on materials of construction and engineering</td><td>demonstration;vendor- provided information.</td></tr><tr><td></td><td>design.</td><td></td></tr><tr><td>Secondary Objective # 5</td><td>Document the availability of the device and its spare parts.</td><td>Post-demonstration investigation.</td></tr></table></body></html>  

Critical data support primary objectives and noncritical data support secondary objectives. W ith the exception of the cost inform ation, primary objectives required the use of quantitative results to draw conclusions regarding technology performance.  Secondary objectives pertained to inform ation that was useful and did not necessarily require the use of quantitative results to draw conclusions regarding technology performance.  

# 4.2 Demonstration Design  

# 4.2.1 Approach for Addressing Primary Objectives  

The purpose of this demonstration was to evaluate the performance of the vendor's instrumentation against a standard laboratory procedure.  In addition, an overall average relative standard deviation (RSD) was calculated for all measurements made by the vendor and the referee laboratory.  RSD com parisons used descriptive statistics, not inferential statistics, between the vendor and laboratory results.  Other statistical com parisons (both inferential and descriptive) for sensitivity, precision, and accuracy were used, depending upon actual demonstration results.  

The approach for addressing each of the primary objectives is discussed in the following subsections. A detailed explanation of the precise statistical determination used for evaluating primary objectives No. 1 through No. 3 is presented in Chapter 6.  

# 4.2.1.1 Primary Objective #1: Sensitivity  

Se nsitivity is the ability of a m etho d or ins trum ent to discriminate between small differences in analyte concentration (EPA, 2002b).  It  can be discussed in terms of an instrum ent detection limit (IDL), a method detection lim it (MDL), and as a practical quantitation lim it (PQ L). MDL is not a measure of sensitivity in the same respect as an IDL or PQL.  It is a measure of precision at a predetermined, usually low, concentration. The IDL pertains to the a bility of the ins trum ent to dete rm ine w ith confidence the difference between a sample that contains the analyte of interest at a low concentration and a sample that does not contain that analyte.  T he IDL is generally considered to be the minimum true concentration of an analyte producing a non-zero signal that can be distinguished from the signals generated when no concentration of the analyte is present and with an adequate degree of certainty.  

The IDL is not rigidly defined in terms of m atrix, method, lab orato ry, or an alyst var iability, and it is no t us ua lly associated with a statistical level of confidence.  IDLs are, thus, usually lower than MDLs and rarely serve a purpose in terms of project objectives (EPA, 2002b).  The PQL defines a specific concentration with an associated level of accuracy.  The MDL defines a lower limit at which a method measurement can be distinguished from background noise. The PQL is a more meaningful estim ate of sensitivity.  The MDL and PQL were chosen as the two distinct parameters for evaluating sensitivity.  The approach for addressing each of these indicator param eters is discussed separately in the following paragraphs.  

# MDL  

MDL is the estimated measure of sensitivity as defined in 40 Code of Federal Regulations (CFR) Part 136.  The purpose of the MDL measurem ent is to estim ate the concentration at which an individual field instrument is able to detect a minimum concentration that is statistically different from instrument background or noise.  Guidance for the definition of the MDL is provided in EPA G-5i (EPA, 2002b).  

The determination of a MDL usually requires seven different measurements of a low concentration standard or sample.  Following procedures established in 40 CFR Part 136 for water matrices, the demonstration MDL definition is as follows:  

$$
\mu_{i}\vert\lbrack i\rbrack\mathsf{L}=\mathsf{t}_{i\lbrack n-1,\mathsf{L},\mathsf{L}\rbrack\varXi\rbrack}\mathsf{L}
$$  

where: $\mathbf{t}_{({\mathsf{n}}-1,0.99)}=$ $99^{\mathfrak{t h}}$ pe rcen tile of the t-distribution with n $^{-1}$ degrees of freedom n $\mathbf{\tau}=\mathbf{\tau}$ num ber of measurem ents s = standard deviation of replicate measurem ents  

# PQL  

The PQL is another important m easure of sensitivity.  The PQL is defined in EPA G-5i as the lowest level an instrument is capable of producing a result that has significance in term s of precision and bias.  (Bias is the difference between the measured value and the true value.)  It is generally considered the lowest standard on the instrument calibration curve.  It is often 5-10 times higher than the MDL, depending upon the analyte, the instrument being used, and the method for analysis; however, it should not be rigidly defined in this manner.  

During the demonstration, the PQL was to be defined by the vendor’s reported calibration or based upon lower concentration samples or SRMs. The evaluation of vendor-reported results for the PQL included a determination of the percent difference $(\%0)$ between their calculated value and true value. The true value is considered the value reported by the referee laboratory for field samples or spiked field samples, or, in the case of SRMs, the certified value provided by the supplier.  The equation used for the $\%0$ calculation is:  

$$
\sin[\pi=\frac{15\tan\tt{e}^{-i\sum_{i=1}\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt{e}_{i}\left|\tt\tt{e}_{i}\left|\tt{e}_{i}\left|\tt\tt{e}_{i}\left|\tt{e}_{i}\left|\tt\tt{e}_{i}\left|\tt\tt{e}_{i}\left|\tt\tt{e}_{i}\left|\tt\tt{e}_{i}\left|\tt\tt{e}_{i}\left|\tt\tt{e_{i}\left|\tt\tt{e}_{e}\left|\tt\tt{e}_{e}\left|\tt\tt{e}_{e}\left|\tt\tt{e}_{e\ u}_{e}\left|\tt{e\tt\tt{e}\ u_{e}\ u{e}_{e}\ u\ u{e}_{e}\ u{e}\ u_{e\ u}{e\ u}\ u{e\ u\ u\ u}{e\ u{e}\ u\ u\ u{e}\ u\ u{e}\ u\ u{e}\ u\ u{e}\ u\ u\ u{e}\ u\ u\ u{e}\ u\ u\ u{e}\ u\ u{e\ u\ u\ u}\ u\ u{e\ u\ u}\ u\ u\ u\ u\ u{e 
$$  

where: Ctrue = true concentration as determined by the referee laboratory or SRM reference value Ccalculated = c a l c u l a t e d t e s t  s a m p l e concentration  

The PQL and $\%0$ were reported for the vendor.  The $\%0$ for the referee laboratory, at the same concentration, was also reported for purposes of comparison.  No statistical comparison was m ade between these two values; only a descriptive comparison was made for purposes of this evaluation.  (The $\%0$ requirement for the referee laboratory was defined as $10\%$ or less.  The reference method PQL was approximately $10\ \upmu{\sf g}/\up k{\sf g}.$ )  

# 4.2.1.2 Primary Objective #2: Accuracy  

Accuracy was calculated by comparing the measured value to a known or true value.  For purposes of this demonstration, three separate standards were used to evaluate accuracy.  These included:  1) SRMs, 2) field samples collected from four separate mercurycontaminated sites, and 3) spiked field samples.  Four sites were used for evaluation of the Ohio Lumex field instrument.  Samples representing field samples and spiked field samples  were prepared at the SAIC GeoMechanics Laboratory.  In order to prevent cross contamination, SRMs were prepared in a separate location. Each of these standards is discussed separately in the following paragraphs.  

# SRMs  

The primary standards used to determine accuracy for this demonstration were SRMs.  SRMs provided very tight statistical comparisons, although they did not provide all matrices of interest nor all ranges of concentrations.  The  

SRMs were obtained from reputable suppliers, and had reported concentrations at associated $95\%$ confidence intervals (CIs) and $95\%$ prediction intervals. Prediction intervals were used for comparison because they represent a statistically infinite number of analyses, and therefore, would include all possible correct results $95\%$ of the time. All SRMs were analyzed by the referee laboratory and selected SRMs were analyzed by the vendor, based upon instrument capabilities and concentrations of SRMs that could be obtained.  Selected SRMs covered an appropriate range for each vendor.  Replicate SRMs were also analyzed by the vendor and the laboratory.  

The purpose for SRM analysis by the referee laboratory was to provide a check on laboratory accuracy.  During the pre-demonstration, the referee laboratory was chosen, in part, based upon the analysis of SRMs.  This was done to ensure a competent laboratory would be used for the demonstration.  Because of the need to provide confidence in laboratory analysis during the demonstration, the referee laboratory analyzed SRMs as an ongoing check for laboratory bias.  

Evaluation of vendor and laboratory analysis of SRMs was performed as follows. Accuracy was reported for individual sample concen t r at io n s o f r ep l ic a te measurements made at the same concentration.  

Two-tailed $95\%$ CIs were computed according to the following equation:  

$$
I_{i}=t_{(\sqrt{-1},\sqrt{2},\sqrt{7},5)}\cdot5^{1}\cdot\sqrt{17}
$$  

where: $\mathbf{{t}}_{({\mathsf{n}}-1,0.975)}=$ 9 7 . 5 t h p e r c e n t i l e  o f  t h e t-distribution with n-1 degrees of freedom n = num ber of measurem ents s = standard deviation of replicate measurem ents  

The number of vendor-reported SRM results and referee laboratory-reported SRM results that were within the associated $95\%$ prediction interval were evaluated. Prediction intervals were  com puted in a similar fashion to the CI, except that the Student’s “t” value use “n” equal to infinity and, because prediction intervals represented “n” approaching infinity, the square root of “n” was dropped from  the equation.  

A final measure of accuracy determined from SRMs is a frequency distribution that shows the percentage of vendorreported measurem ents that are within a specified window of the reference value.  For example, a distribution within a $30\%$ window of a reported concentration, within a $50\%$ window, and outside a $50\%$ window of a reported concentration.  This distribution aspect could be reported as average concentrations of replicate results from the vendor for a particular concentration and matrix, compared to the same collected sample from the laboratory.  These are descriptive statistics and are used to better describe comparisons, but they are not intended as inferential tests.  

# Field Samples  

The second accuracy standard used for this demonstration was actual field samples collected from four separate mercury-contaminated sites.  This accuracy determination consisted of a comparison of vendor-reported results for field samples to the referee laboratory results for the same field samples.  The field samples were used to ensure that "real-world" samples were tested for each vendor.  The field samples consisted of variable mercury concentrations within varying soil and sediment matrices. The referee laboratory results are considered the standard for comparison to each vendor.  

Vendor sample results for a given field sample were compared to replicates analyzed by the laboratory for the same field sample.  (A hypothesis test was use with alpha $\mathbf{\epsilon}=\mathbf{\epsilon}_{0.01}$ was performed.  The null hypothesis was that sa m ple results were similar.  Therefore, if th e n ull hypothesis is rejected, then the sample sets are considered differ ent.)  Com parisons for a specific matrix or concentration were made in order to provide additional information on that specific matrix or concentration. Comparison of the vendor values to laboratory values were sim ilar to the comparisons noted previously for SRMs, except that a more definitive or inferential statistical evaluation was used.  Alpha $\mathit{\Theta}=\ 0.01$ was used to help m itigate inte r-la bo rator y variability.  A dd itionally, an aggregate analysis was used to mitigate statistical anomalies (see Section 6.1.2).  

# Spiked Field Samples  

The third accuracy standard for this demonstration was spiked field samples.  These spiked field sam ples were analyzed by the vendors and by the referee laboratory in replicate, in order to provide additional measurement comparisons to a known value.  Spikes were prepared to cover additional concentrations not available from SRMs or the samples collected in the field. They were grouped with the field sample comparison noted above.  

# 4.2.1.3 Primary Objective #3:  Precision  

Precision can be defined as the degree of mutual agreement of independent measurements generated through repeated application of a process under specified conditions.  Precision is usually thought of as repeatability of a specific measurement, and it is often reported as RSD. The RSD is computed from a specified number of replicates.  The more replications of a measurement, the more confidence is associated with a reported RSD. Replication of a measurement may be as few as 3 separate measurements to 30 or more measurements of the same sample, dependent upon the degree of confidence desired in the specified result.   The precision of an analytical instrument may vary depending upon the matrix being measured, the concentration of the analyte, and whether the m easurem ent is made for an SRM or a field sample.  

The experimental design for this demonstration included a mechanism to evaluate the precision of the vendors’ technologies.  Field sam ples from the four m ercurycontam inated field sites were evaluated by each vendor's analytical instrument. During the demonstration, concentrations were predetermined only as low, medium, or high.  Ranges of test samples (field samples, SRMs, and spikes) were selected to cover the appropriate analytical ranges of the vendor’s instrumentation.  It was known prior to the demonstration that not all vendors were capable of measuring similar concentrations (i.e., some instrum ents were better at measuring low concentrations and others were geared toward higher concentration samples or had other attributes such as cost or ease of use that defined specific attributes of their technology). Because of this fact, not all vendors analyzed the same samples.  

During the demonstration, the vendor’s instrumentation was tested with samples from the four different sites, having different matrices when possible (i.e., depending upon available concentrations) and having different concentrations (high, medium, and low) using a variety of samples.  Sample concentrations for an individual instrument were chosen based upon vendor attributes in terms of expected low, medium, and high concentrations that the particular instrument was capable of measuring.  

The referee laboratory measured replicates of all samples. The results were used for  precision comparisons to the individual vendor. The RSD for the vendor and the laboratory were calculated individually, using the following equation:  

$$
\sin\angle B E=\frac{\Xi}{\Xi}\times1\pi\equiv
$$  

where: $\textsf{S}=$ standard deviation of replicate results $\bar{\times}=$ m ean value of replicate results  

Using descriptive statistics, differences between vendor RSD and referee laboratory RSD were determined. This included RSD com parisons based upon concentration, SRMs, field samples, and different sites.  In addition, an overall average RSD was calculated for all m easurem ents made by the vendor and the laboratory.  RSD com parisons were based upon descriptive statistical evaluations between the vendor and the laboratory, and results were compared accordingly.  

# 4.2.1.4 Primary Objective #4:  Time per Analysis  

The amount of time required for performing the analysis was measured and reported for five categories:  

Mobilization and setup Initial calibration Daily calibration Sample analyses Demobilization  

Mobilization and setup included the time needed to unpack and prepare the instrument for operation.  Initial calibration included the time to perform the vendor recommended on-site calibrations.  Daily calibration included the time to perform the vendor-recomm ended calibrations on subsequent field days.  (Note that this could have been the same as the initial calibration, a reduced calibration, or none.)  Sample analyses included the time to prepare, measure, and calculate the results for the demonstration and the necessary quality control (QC) sam ples performed by the vendor.  

The time per analysis was determined by dividing the total amount of time required to perform the analyses by the number of sam ples analyzed (197).  In the numerator, sample analysis time included preparation, measurem ent, and calculation of results for demonstration samples and necessary QC sam ples performed by the vendor.  In the denom inator, the total number of analyses included only demonstration samples analyzed by the vendor, not QC analyses nor reanalyses of samples.  

Downtim e that was required or that occurred between sample analyses as a part of operation and handling was considered a part of the sample analysis tim e.  Downtim e occurring due to instrument breakage or unexpected maintenance was not counted in the assessment, but it is noted in this final report as an additional time.  Any downtime caused by instrument saturation or memory effect was addressed, based upon its frequency and impact on the analysis.  

Unique time measurements are also addressed in this report (e.g., if soil samples were analyzed directly, and sedim ent samples required additional time to dry before the analyses started, then a statement was made noting that soil samples were analyzed in X amount of hours, and that sediment sam ples required drying time before analysis).  

Recorded times were rounded to the nearest $15-m$ inute interval.  The number of vendor personnel used was noted and factored into the time calculations.  No comparison on time per analysis is made between the vendor and the referee laboratory.  

# 4.2.1.5 Primary Objective #5:  Cost  

The following four cost categories were considered to estimate costs associated with mercury measurem ents:  

Capital costs   
Labor costs   
Supply costs   
Investigation-derived waste (IDW ) disposal costs  

Although both vendor and laboratory costs are presented, the calculated costs were not compared with the referee laboratory.  A summ ary of how each cost category was estimated for the measurement device is provided below.  

The capital cost was estimated based on published price lists for purchasing, renting, or leasing each field measurem ent device.  If the device was purchased, the capital cost estim ate did not  include salvage value for the device after work was completed. The labor cost was based on the num ber of people required to analyze samples during the demonstration. The labor rate was based on a standard hourly rate for a technician or other appropriate operator.  During the dem onstration, the skill level required was confirmed based on vendor input regarding the operation of the device to produce mercury concentration results and observations made in the field.  The labor costs were based on: 1) the actual num ber of hours required to complete all analyses, quality assurance (QA), and reporting; and 2) the assumption that a technician who worked for a portion of a day was paid for an entire 8-hour day.  

The supply costs were based on any supplies required to analyze the field and SRM sam ples during the demonstration.  Supplies consisted of items not included in the capital category, such as  extraction solvent, glassware, pipettes, spatulas, agitators, and similar materials.  The type and quantity of all supplies brought to the field and used during the demonstration were noted and documented.  

Any maintenance and repair costs during the demonstration were documented or provided by the vendor.  Equipment costs were estimated based on this information and standard cost analysis guidelines used in the SITE Program.  

The IDW  disposal costs included decontam ination fluids and equipment, mercury-contaminated soil and sediment samples, and used sample residues. Contaminated personal protective equipment (PPE) norm ally used in the laboratory was placed into a separate container.  The disposal costs for the IDW were included in the overall analytical costs for each vendor.  

After all of the cost categories were estimated, the cost per analysis was calculated.  This cost value was based on the number of analyses performed.  As the number of samples analyzed increased, the initial capital costs and certain other costs were distributed across a greater number of samples.  Therefore, the per unit cost decreased.  For this reason, two costs were reported:  1) the initial capital costs and 2) the operating costs per analysis.  No com parison to the referee laboratory’s method cost was m ade; however, a generic cost comparison was made.  Additionally, when determining laboratory costs, the associated cost for laboratory audits and data validation should be considered.  

# 4.2.2 Approach for Addressing Secondary Objectives  

Secondary objectives were evaluated based on observations made during the demonstration.  Because of the number of vendors involved, technology observers were required to m ake simultaneous observations of two vendors each during the demonstration.  Four procedures were implemented to ensure that these subjective observations made by the observers were as consistent as possible.  

First, forms were developed for each of the five secondary objectives.  These forms assisted in standardizing the observations.  Second, the observers m et each day before the evaluations began, at significant break periods, and after each day of work to discuss and com pare observations regarding each device. Third, an additional observer was assigned to independently evaluate only the secondary objectives in order to ensure that a consistent approach was applied in evaluating these objectives. Finally, the SAIC TOM circulated among the evaluation staff during the dem onstration to ensure that a consistent approach was being followed by all personnel.  Table 4-2 summ arizes the aspects observed during the demonstration for each secondary objective. The individual approaches to each of these objectives are detailed further in the following subsections.  

Table 4-2. Summary of Secondary Objective Observations Recorded During the Demonstration   
SECONDARY OBJECTIVE   


<html><body><table><tr><td>General Information</td><td>Secondary Objective # 1 Ease of Use</td><td>Secondary Objective # 2 H&S Concerns</td><td>Secondary Objective # 3 Instrument Portability</td><td>Secondary Objective # 4 Instrument Durability</td></tr><tr><td>- Vendor Name - Observer Name - Instrument Type - Instrument Name - Model No. - Serial No.</td><td>- No. of Operators - Operator Names/Titles - Operator Training - Training References -InstrumentSetupTime - Instrument Calibration Time - Sample Preparation Time - Sample Measurement Time</td><td>- Instrument Certifications - Electrical Hazards - Chemicals Used - Radiological Sources - Hg Exposure Pathways - Hg Vapor Monitoring - PPE Requirements - Mechanical Hazard - Waste Handling Issues </td><td>- Instrument Weight - Instrument Dimensions - Power Sources - Packaging - Shipping & Handling</td><td>-Materials of Construction - Quality of Construction - Max. Operating Temp. - Max. Operating Humidity - Downtime -Maintenance Activities - Repairs Conducted</td></tr></table></body></html>  

# 4.2.2.1 Secondary Objective #1:  Ease of Use  

The skills and training required for proper device operation were noted; these included any degrees or specialized training required by the operators.  This information was gathered by interviews (i.e., questioning) of the operators. The number of operators required was also noted.  This objective was also evaluated by subjective observations regarding the ease of equipment use and major peripherals required to measure m ercury concentrations in soils and sediments. The operating manual was evaluated to determine if it is easily useable and understandable.  

# 4.2.2.2 Secondary Objective #2:  Health and Safety Concerns  

Health and safety (H&S) concerns associated with device operation were noted during the dem onstration.  Criteria included hazardous materials used, the frequency and likelihood of potential exposures, and any direct exposures observed during the demonstration.  In addition, any potential for exposure to mercury during sample digestion and analysis was evaluated, based upon equipment design.  Other H&S concerns, such as basic electrical and mechanical hazards, were also noted.  Equipment certifications, such as Underwriters Laboratory (UL), were documented.  

# 4.2.2.3 Secondary Objective #3:  Portability of the Device  

The portability of the device was evaluated by observing transport, measuring setup and tear down time, determining the size and weight of the unit and peripherals, and assessing the ease with which the instrument was repackaged for movement to another location.  The use of battery power or the need for an AC outlet was also noted.  

# 4.2.2.4 Secondary Objective #4:  Instrument Durability  

The durability of each device and major peripherals was assessed by noting the quality of materials and construction. All device failures, routine m aintenance, repairs, and downtime were documented during the demonstration.  No specific tests were perform ed to evaluate durability; rather, subjective observations were made using a field form as guidance.  

# 4.2.2.5 Secondary Objective #5:  Availability of Vendor Instruments and Supplies  

The availability of each device was evaluated by determining whether additional units and spare parts are readily available from the vendor or retail stores.  The vendor's office (or a web page) and/or a retail store was contacted to identify and determine the availability of supplies of the tested measurem ent device and spare parts.  This portion of the evaluation was performed after the field demonstration, in conjunction with the cost estimate.  

# 4.3 Sample Preparation and Management 4.3.1 Sample Preparation  

# 4.3.1.1 Field Samples  

Field samples were collected during the pre-demonstration portion of the project, with the ultimate goal of producing a set of consistent test soils and sedim ents to be distributed among all participating vendors and the referee laboratory for analysis during the dem onstration.  Samples were collected from the following four sites:  

Carson River Mercury site (near Dayton, NV) Y-12 National Security Complex (Oak Ridge, TN) Manufacturing facility (eastern U.S.) Puget Sound (Bellingham, WA)  

The field samples collected during the pre-demonstration sampling events comprised a variety of matrices, ranging from m aterial having a high clay content, to material composed mostly of gravelly, coarse sand.  The field samples also differed with respect to m oisture content; several were collected as wet sediments.  Table 4-3 shows the number of distinct field samples that were collected from each of the four field sites.  

Prior to the s tart of the demonstration, the field samples selected for analysis during the dem onstration were processed at the SAIC GeoMechanics Laboratory in Las Vegas, NV.  The specific sample homogenization procedure used by this laboratory largely depended on the moisture content and physical consistency of the sample. Two specific sample homogenization procedures were developed and tested by SAIC at the GeoMechanics Laboratory during the pre-demonstration portion of the project.  The m ethods included a non-slurry sam ple procedure and a slurry sample procedure.  

A standard operating procedure (SOP) was developed detailing both methods.  The procedure was found to be satisfactory, based upon the results of replicate samples during the pre-demonstration. This SOP is included as Appendix A of the Field Demonstration Quality Assurance Project Plan (SAIC, August 2003,  EPA/600/R-03/053). Figure 4-1 summ arizes the homogenization steps of the SOP, beginning with sample mixing.  This procedure was used for preparing both pre-demonstration and demonstration sam ples.  Prior to the m ixing process (i.e., Step 1 in Figure 4-1), all field samples being processed were visually inspected to ensure that oversized m aterials were rem oved, and that there were no clum ps that would hinder homogenization.  Non-slurry samples were air-dried in accordance with the SOP, so that they could be passed m ultip le times through a riffle splitter.  Due to the high moisture content of many of the samples, they were not easily air-dried and could not be passed through a riffle splitter while wet.  Sam ples with very high m oisture contents, termed “slurries,” were not air-dried, and bypassed the riffle splitting step.  The homogenization steps for each type of matrix are briefly summ arized, as follows.  

Table 4-3.  Field Samples Collected from the Four Sites   


<html><body><table><tr><td>Field Site</td><td>No. of Samples / Matrices Collected </td><td>Areas For Collecting Sample Material</td><td>Volume Required</td></tr><tr><td>Carson River</td><td>12 Soil 6 Sediment</td><td>Tailings Piles (Six Mile Canyon) River Bank Sediments</td><td>4 L each for soil 12 L each for sediment</td></tr><tr><td rowspan="2">Y-12</td><td></td><td></td><td></td></tr><tr><td>10 Sediment 6 Soil</td><td>Poplar Creek Sediments Old Mercury Recovery Bldg. Soils</td><td>12 L each for sediment 4 L each for soil</td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td>Manufacturing Site</td><td>12 Soil</td><td> Subsurface Soils</td><td>4 L each</td></tr><tr><td> Puget Sound </td><td>4 Sediment</td><td>High-Level Mercury (below cap) Low-Level Mercury (native material)</td><td>12 L each</td></tr></table></body></html>  

# Preparing Slurry Matrices  

For slurries (i.e., wet sediments), the mixing steps were sufficiently thorough that the sample containers could be filled directly from the mixing vessel.  There were two separate mixing steps for the slurry-type samples.  Each slurry was initially m ixed m echanically within the sample container (i.e., bucket) in which the sample was shipped to the SAIC GeoMechanics Laboratory.  A subsample of this premixed sample was transferred to a second mixing vessel.  A mechanical drill equipped with a paint mixing attachment was used to mix the subsample.  As shown in Figure 4-1, slurry sam ples bypassed the sample riffle splitting step. To ensure all sample bottles contained the same material, the entire set of containers to be filled was submerged into the slurry as a group.  The filled vials were allowed to settle for a minimum of two days, and the standing water was removed using a Pasteur pipette.  The removal of the standing water from the slurry samples was the only change to the homogenization procedure between the pre-demonstration and the demonstration.  

# Preparing "Non-Slurry" Matrices  

Soils and sediments having no excess m oisture were initially mixed (Step 1) and then homogenized in the sa m ple riffle splitter (Step 2).  Prior to these steps, the material was air-dried and subsampled to reduce the volume of m aterial to a size that was easier to handle.  

As shown in Figure 4-1 (Step 1) the non-slurry subsample was manually stirred with a spoon or similar equipment until the material was visually uniform.  Immediately following manual mixing, the subsample was mixed and split six times for more com plete homogenization (Step 2). After the sixth and final split, the sample material was leveled to form a flattened, elongated rectangle and cut into transverse sections to fill the containers (Steps 3 and 4). After homogenization, 20-mL sample vials were filled and prepared for shipment (Step 5).  

For the demonstration, the vendor analyzed 197 samples, which included replicates of up to 7 samples per sample lot.  The majority of the samples distributed had concentrations within the range of the vendor’s technology. Some samples had expected concentrations at or below the estimated level of detection for each of the vendor instruments.  These samples were designed to evaluate the reported MDL and PQL and also to assess the prevalence of false positives.  Field samples distributed to the vendor included sediments and soils collected from all four sites and prepared by both the slurry and dry homogenization procedures.  The field samples were segregated into broad sample sets:  low, medium, and high mercury concentrations.  This gave the vendor the same general understanding of the sam ple to be analyzed as they would typically have for field application of their instrument.  

![](images/448ed1d9ddd1f870e27e2eb8f2dc9a35ca76b90db0b6554854fa92a1e4cec25d.jpg)  
Figure 4-1.  Test sample preparation at the SAIC GeoMechanics Laboratory.  

In addition, selected field sam ples were spiked with mercury (II) chloride to generate samples with additional concentrations and test the ability of the vendor’s instrumentation to measure the additional species of m ercury.  Specific information regarding the vendor’s sample distribution is included in Chapter 6.  

# 4.3.1.2 Standard Reference Materials  

Certified SRMs were analyzed by both the vendors and the referee laboratory.  These samples were homogenized matrices which had a known concentration of m ercury. Concentrations were certified values, as provided by the supplier, based on independent confirmation via multiple analyses of multiple lots and/or multiple analyses by different labor atorie s (i.e., rou nd ro bin tes ting).  These analytical results were then used to determine "true" values, as well as a statistically derived intervals (a $95\%$ prediction interval) that provided a range within which the true values were expected to fall.  

The SRMs selected were designed to encompass the same contam inant ranges indicated previously: low-, medium-, and high-level m ercury concentrations.  In addition, SRMs of varying matrices were included in the demonstration to challenge the vendor technology as well as the referee laboratory.  The referee laboratory analyzed all SRMs.  SRM samples were intermingled with site field samples and labeled in the same m anner as field samples.  

# 4.3.1.3 Spiked Field Samples  

Spiked field samples were prepared by the SAIC GeoMechanics Laboratory using mercury (II) chloride. Spikes were prepared using field samples from the selected sites.  Additional information was gained by preparing spikes at concentrations not previously obtainable.  The SAIC GeoMechanics Laboratory’s ability to prepare spikes was tested prior to the demonstration and evaluated in order to determine expected variability and accuracy of the spiked sample.  The spiking procedure was evaluated by preparing several different spikes using two different spiking procedures (dry and wet).  Based upon replicate analyses results, it was determined that the wet, or slurry, procedure was the only effective method of obtaining a homogeneous spiked sample.  

# 4.3.2 Sample Management  

# 4.3.2.1 Sample Volumes, Containers, and Preservation  

A subset from the pre-demonstration field samples was selected for use in the demonstration based on the sample’s mercury concentration range and sample type (i.e., sedim ent versus soil).  The SAIC GeoMechanics Laboratory prepared individual batches of field sample material to fill sample containers for each vendor.  Once all containers from a field sam ple were filled, each container was labeled and cooled to $4^{\circ}\mathsf C$ .  Because mercury analyses were to be performed both by the vendors in the field and by the referee laboratory, adequate sample size was taken into account. Minimum sample size requirem ents for the vendors varied from 0.1 g or less to $_{8-10~9}$ .  Only the referee laboratory analyzed separate sample aliquots for parameters other than mercury.  These additional parameters included arsenic, barium, cadmium, chromium, lead, selenium, silver, copper, zinc, oil and grease, and total organic carbon (TOC).  Since the m ercury method (SW -846 7471B) being used by the referee laboratory requires $\textsf{1g}$ for analysis, the sam ple size sent to all participants was a $20-m L$ vial (approxim ately $\displaystyle{10\ \mathfrak{g}},$ ), which ensured  a sufficient volume and m ass for analysis by all vendors.  

# 4.3.2.2 Sample Labeling  

The sample labeling used for the $20-m L$ vials consisted of an internal code developed by SAIC.  This "blind" code was used throughout the entire demonstration.  The only individuals who knew the key to the coding of the homogenized sam ples to the specific field sam ples were the SAIC TOM, the SAIC GeoMechanics Laboratory Manager, and the SAIC QA Manager.  

# 4.3.2.3 Sample Record Keeping, Archiving, and Custody  

Samples were shipped to the laboratory and the demonstration site the week prior to the dem onstration.  A third set of vials was archived at the SAIC GeoMechanics Laboratory as reserve samples.  

The sample shipment to Oak Ridge was retained at all times in the custody of SAIC at their Oak Ridge office until arrival of the dem onstration field crew.  Sam ples were shipped under chain-of-custody (COC) and with custody seals on both the coolers and the inner plastic bags.  Once the demonstration crew arrived, the coolers were retrieved from the SAIC office.  The custody seals on the plastic bags inside the cooler were broken by the vendor upon transfer.  

Upon arrival at the ORNL site, the vendor set up the instrumentation at the direction and oversight of SAIC.  At the start of sample testing, the vendor was provided with a sample set representing field samples collected from a particular field site, intermingled with SRM and spiked samples. Due to variability of vendor instrument measurem ent ranges for mercury detection, not all vendors received samples from the same field material.  All samples were stored in an ice cooler prior to demonstration startup and were stored in an on-site sample refrigerator during the demonstration.  Each sam ple set was identified and distributed as a set, with respect to the site from which it was collected.  This was done because, in any field application, the location and general type of the samples would be known.  

The vendor was responsible for analyzing all samples provided, performing any dilutions or reanalyses as needed, calibrating the instrument if applicable, performing any  necessary maintenance, and reporting all results.  Any samples that were not analyzed during the day were returned to the vendor for analysis at the beginning of the next day.  Once analysis of the samples from the first location were completed by the vendor, SAIC provided a set of sam ples from the second location.  Samples were provided at the time that they were requested by the vendor.  Once again, the transfer of samples was docum ented using a chain-of-custody (COC) form .  

This process was repeated for samples from each location. SAIC maintained custody of all rem aining sample sets until they were transferred to the vendor.  SAIC maintained custody of sam ples that already had been analyzed and followed the waste handling procedures in Section 4.2.2 of the Field Demonstration QAPP to dispose of these wastes.  

# 4.4 Reference Method Confirmatory Process  

The referee laboratory analyzed all samples that were analyzed by the vendor technologies in the field.  The following subsections provide information on the selection of the reference method, selection of the referee laboratory, and details regarding the performance of the reference method in accordance with EPA protocols. Other parameters that were analyzed by the referee laboratory are also discussed briefly.  

# 4.4.1 Reference Method Selection  

The selection of SW -846 Method 7471B as the reference method was based on several factors, predicated on information obtained from the technology vendors, as well as the expected contaminant types and soil/sediment mercury concentrations expected in the test m atrices. There are several laboratory-based, promulgated methods for the analysis of total mercury.  In addition, there are several performance-based methods for the determination of various mercury species. Based on the vendor technologies, it was determ ined that a reference method for total mercury would be needed (Table 1-2 summarizes the methods evaluated, as identified through a review of the EPA Test Method Index and SW -846).  

In selecting which of the potential methods would be suitable as a reference method, consideration was given to the following questions:  

W as the method widely used and accepted?  W as the method an EPA-recommended, or similar regulatory method?  The selected reference m ethod should be sufficiently used so that it could be cited as an acceptable method for monitoring and/or permit com pliance am ong regulatory authorities.   
Did the selected reference method provide QA/QC criteria that demonstrate acceptable performance characteristics over time?   
W as the m ethod suitable for the species of mercury that were expected to be encountered?  The reference method must be capable of determining, as total mercury, all form s of the contam inant known or likely to be present in the matrices.   
W ould the method achieve the necessary detection lim its to evaluate the sensitivity of each vendor technology adequately?   
W as the method suitable for the concentration range that was expected in the test matrices?  

Based on the above considerations, it was determined that SW -846 Method 7471B (analysis of mercury in solid samples by cold-vapor AAS) would be the best reference method.  SW -846 method 7474, (an atomic fluorescence spectrometry method using Method 3052 for microwave digestion of the solid) had also been considered a likely technical candidate; however, because this method was not as widely used or referenced, Method 7471B was considered the better choice.  

# 4.4.2 Referee Laboratory Selection  

During the planning of the pre-dem onstration phase of this project, nine laboratories were sent a statem ent of work (SOW ) for the analysis of mercury to be perform ed as part of the pre-demonstration.  Seven of the nine laboratories responded to the SOW  with appropriate bids.  Three of the seven laboratories were selected as candidate laboratories based upon technical merit, experience, and pricing. These laboratories received and analyzed blind samples and SRMs during pre-demonstration activities.  The referee laboratory to be used for the demonstration was selected from these three candidate laboratories.  Final selection of the referee laboratory was based upon: 1) the laboratory’s interest in continuing in the demonstration, 2) the laboratory-reported SRM results, 3) the laboratory MDL for the reference method selected, 4) the precision of the laboratory calibra tion curve, 5) the laborato ry’s ability to support the demonstration (scheduling conflicts, backup instrum entation, etc.), and 6) co st.  

One of the three candidate laboratories was eliminated from selection based on a technical consideration.  It was determined that this laboratory would not be able to meet demonstration quantitation limit requirements.  (Its lower calibration standard was approximately $50~\upmu\up g/\up k\up g$ , and the vendor comparison requirements were well below this value.)  Two candidates thus remained, including the eventual demonstration laboratory, Analytical Laboratory Services, Inc. (ALSI):  

Analytical Laboratory Services, Inc. Ray Martrano, Laboratory Manager 34 Dogwood Lane   
Middletown, PA 17057   
(717) 944-5541  

In order to make a final decision on selecting a referee laboratory, a preliminary audit was performed by the SAIC QA Manager at the remaining two candidate laboratories. Results of the SRM samples were compared for the two laboratories.  Each laboratory analyzed each sam ple (there were two SRMs) in triplicate.  B oth laboratories were within the $95\%$ prediction interval for each SRM.  In addition, the average result from the two SRMs was compared to the $95\%$ C I fo r th e S R M .  

Calibration curves from each laboratory were reviewed carefully.  This included calibration curves generated from previously performed analyses and those generated for other laboratory clients.  There were two QC requirements regarding calibration curves; the correlation coefficient had to be 0.995 or greater and the lowest point on the calibration curve had to be within $10\%$ of the predicted value.  Both laboratories were able to achieve these two requirem ents for all curves reviewed and for a lower standard of $10~\upmu\up g/\upkappa\up g$ , which was the lower standard required for the demonstration, based upon information received from each of the vendors.  In addition, an analysis of seven standards was reviewed for MDLs.  Both laboratories were able to achieve an MDL that was below $1~\upmu{\sf g}/\up k{\sf g}$ .  

It should be noted that vendor sensitivity claims impacted how low this lower quantitation standard should be.  These claims were somewhat vague, and the actual quantitation limit each vendor could achieve was uncertain prior to the demonstration (i.e., som e vendors claimed a sensitivity as low as $1\ \upmu{\sf g}/\up k{\sf g}$ , b ut it was uncertain at the tim e if t his lim it was actually a PQL or a detec tion lim it).  T herefore, it was determined that, if necessary, the laboratory actually should be able to achieve even a lower PQL than $10\upmu\up g/\up k\up g$ .  

For both laboratories, SOPs based upon SW-846 Method 7471B were reviewed.  Each SOP followed this reference method. In addition, interferences were discussed because there was som e concern that organic interferences may have been present in the samples previously analyzed by the laboratories.  Because these same matrices were expected to be part of the demonstration, there was some concern associated with how these interferences would be eliminated.  This is discussed at the end of this subsection.  

Sample throughput was somewhat important because the selected laboratory was to receive all demonstration samples at the same time (i.e., the samples were to be analyzed at the same time in order to eliminate any question of variability associated with loss of contaminant due to holding time).  This meant that the laboratory would receive approximately 400 samples for analysis over  the period of a few days.  It was also desirable for the laboratory to produce a data report within a 21-day turnaround time for purposes of the demonstration.  Both laboratories indicated that this was achievable. Instrumentation was reviewed and examined at both laboratories.  Each laboratory used a Leeman mercury analyzer for analysis.  One of the two laboratories had backup instrumentation in case of problems. Each laboratory indicated that its Leeman m ercury analyzer was relatively new and had not been a problem in the past.  

Previous SITE program experience was another factor considered as part of these pre-audits.  This is because the SITE program  generally requires a very high level of QC, such that most laboratories are not familiar with the QC required unless they have previously participated in the program.  A second aspect of the SITE program is that it generally requires analysis of relatively “dirty” samples and many laboratories are not use to analyzing such “dirty” samples. Both laboratories have been longtim e participants in this program.  

Other QC-related issues examined during the audits included:  1) analyses of other SRM sam ples not previously examined, 2) laboratory control charts, and 3) precision and accuracy results.  Each of these issues was closely examined.  Also, because of the desire to increase the representativeness of the samples for the demonstration, each laboratory was asked if sample aliquot sizes could be increased to 1 g (the method requirement noted 0.2 g). Based upon previous results, both laboratories routinely increased sample size to $_{0.5~\mathfrak{g}}$ , and each laboratory indicated that increasing the sample size would not be a problem.  Besides these QC issues, other less tangible QA elem ents were examined. This included analyst experience, managem ent involvem ent in th e demonstration, and internal laboratory QA m anagem ent. These elements were also factored into the final decision.  

# Selection Summary  

There were very few factors that separated the quality of these two laboratories.  Both were exemplary in performing mercury analyses.  There were, however, some minor differences based upon this evaluation that were noted by the auditor.  These were as follows:  

ALSI had backup instrum entation available.  Even though neither laboratory reported any problems with its primary instrument (the Leeman mercury analyzer), ALSI did have a backup instrument in case there were problems with the primary instrum ent, or in the event that the laboratory needed to perform other mercury analyses during the demonstration time. As noted, the low standard requirement for the calibration curve was one of the QC requirements specified for this demonstration in order to ensure that a lower quantitation could be achieved.  This low standard was $10~\upmu\mathfrak{g}/\upkappa\mathfrak{g}$ for both labor atorie s.  AL SI, however, was able to show experience in being able to calibrate much lower than this, using a second calibration curve.  In the event that the vendor was able to analyze at concentrations as low as $1\ \upmu{\sf g}/\up k{\sf g}$ with precise and accurate determinations, ALSI was able to perform analyses at lower concentrations as part of the demonstration.  ALSI used a second, lower calibration curve for any analyses required below 0.05 $\mathsf{m g}/\mathsf{k g}$ .  Very few vendors were able to analyze samples at concentrations at this low a level.  

Management practices and analyst experience were similar at both laboratories.  ALSI had participated in a few more SITE demonstrations than the other laboratory, but this difference was not significant because both laboratories had proven themselves capable of handling the additional QC requirements for the SITE program.  In addition, both laboratories had internal QA managem ent procedures to  provide the confidence needed to achieve SITE requirements.  

Interferences for the samples previously analyzed were discussed and data were reviewed.  ALSI performed two separate analyses for each sample.  This included analyses with and without stannous chloride. (Stannous chloride is the reagent used to release mercury into the vapor phase for analysis.  Sometimes organics can cause interferences in the vapor phase. Therefore, an analysis with no stannous chloride would provide information on organic interferences.)  The other laboratory did not routinely perform this analysis. Some samples were thought to contain organic interferences, based on previous sample results. The pre-demonstration results reviewed indicated that no organic interferences were present.  Therefore, while this was thought to be a possible discriminator between the two laboratories in terms of analytical method performance, it became m oot for the samples included in this demonstration.  

The factors above were considered in the final evaluation. Because there were only minor differences in the technical factors, cost of analysis was used as the discriminating factor.  (If there had been significant differences in laboratory quality, cost would not have been a factor.) ALSI was significantly lower in cost than the other laboratory.  Therefore, ALSI was chosen as the referee laboratory for the demonstration.  

# 4.4.3 Summary of Analytical Methods  

# 4.4.3.1 Summary of Reference Method  

The critical measurement for this study was the analysis of mercury in soil and sediment samples.  Samples analyzed by the laboratory included field samples, spiked field samples, and SRM sam ples.  Detailed laboratory procedures for subsampling, extraction, and analysis were provided in the SOPs included as Appendix B of the Field Demonstration QAPP.  These are briefly summarized below.  

Samples were analyzed for mercury using Method 7471B, a cold-vapor atomic absorption method, based on the absorption of  light at the 253.7-nm wavelength by mercury vapor.  The mercury is reduced to the elemental state and stripped/volatilized from solution in a closed system .  The mercury vapor passes through a cell positioned in the light path of the AA spectrophotometer.  Absorbance (peak height) is measured as a function of mercury concentration.  Potassium permanganate is added to eliminate possible interference from sulfide.  As per the method, concentrations as high as $20~\mathrm{mg/kg}$ of sulfide, as sodium sulfide, do not interfere with the recovery of added inorganic mercury in reagent water.  Copper has also been reported to interfere; however, the method states that copper concentrations as high as $10\mathrm{\mg/kg}$ had no effect on recovery of mercury from spiked samples.  Samples high in chlorides require additional permanganate (as much as $25~\mathrm{mL}$ ) because, during the oxidation step, chlorides are converted to free chlorine, which also absorbs radiation of $254~\mathsf{n m}$ .   Free chlorine is removed by using an excess (25 mL) of hydroxylamine sulfate reagent.  Certain volatile organic materials that absorb at this wavelength may also cause interference.  A preliminary analysis without reagents can determ ine if this type of interference is present.  

Prior to analysis, the contents of the sample container are stirred, and the sample mixed prior to removing an aliquot for the mercury analysis. An aliquot of soil/sediment (1 g) is placed in the bottom of a biochemical  oxygen demand bottle, with reagent water and aqua regia added.  The mixture is heated in a water bath at $95~^{\circ}\mathsf{C}$ for 2 minutes. The solution is cooled and reagent water and potassium permanganate solution are added to the sample bottle. The bottle contents are thoroughly m ixed, and the bottle is placed in the water bath for 30 minutes at $95~^{\circ}\mathsf{C}$ .  After cooling, sodium chloride-hydroxylam ine sulfate is added to reduce the excess permanganate.  Stannous chloride is then added and the bottle attached to the analyzer; the sample is aerated and the absorbance recorded.  An analysis without stannous chloride  is also included as an interference check when organic contam ination is suspected.  In the event of positive results of the nonstannous chloride analysis, the laboratory was to report those results to SAIC so that a determ ination of organic interferences could be made.  

# 4.4.3.2 Sum mary of Methods for Non-Critical Measurements.  

A selected set of non-critical parameters was also measured during the demonstration.  These parameters were measured to provide a better insight into the chemical constituency of the field samples, including the presence of potential interferents.  The results of the tests for potential interferents were reviewed to determine if a trend was apparent in the event that inaccuracy or low precision was observed.  Table 4-4 presents the analytical method reference and m ethod type for these non-critical parameters.  

Table 4-4.  Analytical Methods for Non-Critical Parameters   


<html><body><table><tr><td>Parameter</td><td>Method Reference</td><td>Method Type</td></tr><tr><td>Arsenic, barium, cadmium, chromium, lead, selenium, silver, copper, and zinc</td><td>SW-846 3050/6010</td><td>Acid digestion, ICP</td></tr><tr><td>Oil and Grease</td><td>EPA 1664</td><td>n-Hexane extraction, Gravimetric</td></tr><tr><td>TOC</td><td>SW-846 9060</td><td>analysis Carbonaceous analyzer</td></tr><tr><td>Total Solids</td><td>EPA2540G</td><td>Gravimetric</td></tr></table></body></html>  

# 4.5 Deviations from the Demonstration Plan  

There was one deviation to the demonstration plan.  The sam ples were distributed to Ohio Lumex by site (Carson River, Oak Ridge, etc.) as planned; however, due to the potential for memory effects, Ohio Lumex analyzed the high concentration samples from all sites prior to analyzing the low concentration samples for any of the sites.  

Additionally, Ohio Lumex was able to complete all analyses during the demonstration; however, they were unable to locate the results for one data point, and therefore, provided data for 196 samples prior to leaving the demonstration site.  

# Chapter 5 Assessment of Laboratory Quality Control Measurements  

# 5.1 Laboratory QA Summary  

QA may be defined as a system of activities, the purpose of which is to provide assurance that defined standards of quality are met with a stated level of confidence.  A QA program is a means of integrating the quality planning, quality assessment, QC, and quality improvem ent efforts to meet user requirements.  The objective of the QA program is to reduce measurem ent errors to agreed-upon limits, and to produce results of acceptable and known quality.  The QAPP specified the necessary guidelines to ensure that the measurement system for laboratory analysis was in control, and provided detailed information on the analytical approach to ensure that data of high quality could be obtained to achieve project objectives. The laboratory analyses were critical to project success, as the laboratory results were used as a standard for comparison to the field method results. The field methods are of unknown quality, and therefore, for comparison purposes the laboratory analysis  needed to be a known quantity.  The following sections provide information on the use of data quality indicators, and a detailed sum mary of the QC analyses associated with project objectives.  

# 5.2 Data Quality Indicators for Mercury Analysis  

To assess the quality of the data generated by the referee laboratory, two im portant data quality indicators of primary concern are precision and accuracy.  Precision can be defined as the degree of mutual agreement of independent measurem ents generated through repeated application of the process under specified conditions.  Accuracy is the degree of agreement of a measured value with the true or expected value.  Both accuracy and precision were measured by the analysis of matrix spike/matrix spike duplicates (MS/MSDs).  The precision of the spiked duplicates is evaluated by expressing, as a percentage, the difference between results of the sample and sam ple duplicate results.  The relative percent difference (RPD) is calculated as:  

$$
\mathsf{R P D}=\frac{\left(\mathsf{M a x i m u l e r v`{s}d u e}-\mathsf{M i n i m u l e r v a l u e}\right)}{\left(\mathsf{M i a x i m u l e r v a l u e i s s`{s}d u e}+\mathsf{M i n i m i m u l e r v a l u e}\right)/\bar{\mathsf{T}}}\times1\bar{\mathsf{U D}}
$$  

To determine and evaluate accuracy, known quantities of the target analytes were spiked into selected field samples. All spikes were post-digestion spikes because of the high sam ple concentrations encountered during the demonstration. Pre-digestion spikes, on highconcentration samples would either have been diluted or would have required additional studies to determine the effect of spiking more analyte and subsequent recovery values.  To determine matrix spike recovery, and hence measure accuracy, the following equation was applied:  

$$
\sin\beta=\frac{E--E-\frac{E}{2}}{E-\frac{\cos}{2}}\times1\sqrt{10}
$$  

where,  

Laboratory control samples (LCSs) were used as an additional measure of accuracy in the event of significant  

matrix interference.  To determine the percent recovery of LCS analyses, the equation below was used:  

$$
\sin\theta=\frac{N\sin\theta-\exists S\cup\gamma\theta,\theta\in\mathbb{Z}\mathrm{~C~D~in~E.~p~i~f~a~ti~o~n~}}{\mathsf{T}\cap\mathsf{e}\cup\gamma\in\{1,\ldots\}\mathrm{~C.~D~i~n~E.~e~n~t~r\'\exists~ti~o~n~}}\times1\bar{\mathsf{U}}\bar{\mathsf{U}}
$$  

W hile several precautions were taken to generate data of known quality through control of the measurement system, the data must also be representative of true conditions and c o m p a r a b l e  t o  s e p a r a t e  s a m p l e  a l i q u o t s . Representativeness refers to the degree with which analytical results accurately and precisely reflect actual conditions present at the locations chosen for sample collection.  Representativeness was evaluated as part of the pre-demonstration and combined with the precision measurement in relation to sam ple aliquots.  Sample aliquoting by the SAIC GeoMechanics Laboratory tested the ability of the procedure to produce homogeneous, representative, and com parable samples.  All samples were carefully homogenized in order to ensure com parability between the laboratory and the vendor. Therefore, the RSD measurement objective of $25\%$ or less for replicate sample lot analysis was intended to assess not only precision but representativeness and com parability.  

Sensitivity was another critical factor assessed for the laboratory method of analysis.  This was measured as a practical quantitation limit and was determined by the low standard on the calibration curve.  Two separate calibration curves were run by the laboratory when necessary.  The higher calibration curve was used for the majority of the samples and had a lower calibration limit of $25\upmu\up g/\upkappa\up g$ .  The lower calibration curve was used when sam ples were below this lower calibration standard.  The lower calibration curve had a lower limit standard of $5~{\upmu\up g}/{\upk\up g}$ .  T he low er lim it standard of the calibration curve was run with each sample batch as a check standard and was required to be within $10\%$ of the true value (Q APP Q C requirem ent).  This additional check on analytical sensitivity was performed to ensure that this lower limit standard was truly representative of the instrument and method practical qua ntitation lim it.  

# 5.3 Conclusions and Data Quality Limitations  

Critical sample data and associated QC analyses were reviewed  to determine whether the data collected were of adequate quality to provide proper evaluation of the project’s technical objectives.  The results of  this review are summ arized below.  

Accuracy objectives for mercury analysis by Method 7471B were assessed by the evaluation of 23 spiked duplicate pairs, analyzed in accordance with standard procedures in the same m anner as the samples.  Recovery values for the critical compounds were well within objectives specified in the QAPP, except for two spiked samples summarized in Table 5-1.  The results of these sam ples, however, were only slightly outside specified limits, and given the number of total samples (46 or 23 pairs), this is an insignificant number of results that did not fall within specifications.  The MS/MSD results therefore, are supportive of the overall accuracy objectives.  

Table 5-1.  MS/MSD Summary   


<html><body><table><tr><td>Parameter</td><td>Value</td></tr><tr><td>QC Limits</td><td>80%- 120%</td></tr><tr><td>Recovery Range</td><td>85.2% -126%</td></tr><tr><td>Number of Duplicate Pairs</td><td>23</td></tr><tr><td>Average Percent Recovery</td><td>108%</td></tr><tr><td>No. of Spikes Outside QC Specifications</td><td>2</td></tr></table></body></html>  

An additional measure of accuracy was LCSs.  These were analyzed with every sample batch (1 in 20 samples) and results are presented in Table 5-2.  All results were within specifications, thereby supporting the conclusion that QC assessment  m et project accuracy objectives.  

Table 5-2.  LCS Summary   


<html><body><table><tr><td>Parameter</td><td>Value</td></tr><tr><td>QC Limits</td><td>90%- 110%</td></tr><tr><td>Recovery Range</td><td>90% -100%</td></tr><tr><td>Numberof LCSs</td><td>24</td></tr><tr><td>AveragePercent Recovery</td><td>95.5%</td></tr><tr><td>No.of LCSs Outside QC Specifications</td><td>0</td></tr></table></body></html>  

Precision was assessed through the analysis of 23 duplicate spike pairs for mercury.  Precision specifications were established prior to the demonstration as a RPD less than $20\%$ .  All b ut tw o s am ple pa irs we re with in specifications, as noted in Table 5-3.  The results of these samples, however, were only slightly outside specified limits, and given the num ber of total samples (23 pairs), this is an insignificant numb er of results tha t did no t fall within specifications.  Therefore, laboratory analyses met precision specifications.  

Table 5-3.  Precision Summary   


<html><body><table><tr><td>Parameter</td><td>Value</td></tr><tr><td>QC Limits</td><td>RPD<20%</td></tr><tr><td>MS/MSD RPD Range</td><td>0.0% to 25%</td></tr><tr><td>Number of Duplicate Pairs</td><td>23</td></tr><tr><td>Average MS/MSD RPD</td><td>5.7%</td></tr><tr><td>No.of Pairs Outside QC Specifications</td><td>2</td></tr></table></body></html>  

Sensitivity results were within specified project objectives. The sensitivity objective was evaluated as the PQL, as assessed by the low standard on the calibration curve.  For the majority of samples, a calibration curve of $25{\cdot}500{\upmu}9/{\upmu}{\mathfrak{g}}$ was used.  This is because the majority of sam ples fell within this calibration range (samples often required dilution).  There were, however, some sam ples below this range and a second curve was used.  The calibration range for this lower curve was $5{-}50\upmu\mathfrak{g}/\upkappa\mathfrak{g}$ .  In order to ensure that the lower concentration on the calibration curve was a true PQL, the laboratory ran a low check standard (lowest concentration on the calibration curve) with every batch of samples.  This standard was required to be within $10\%$ of the specified value.  The results of this low check standard are summarized in Table 5-4.  

Table 5-4.  Low Check Standards   


<html><body><table><tr><td> Parameter</td><td>Value</td></tr><tr><td>QC Limits</td><td>Recovery 90% - 110%</td></tr><tr><td>Recovery Range</td><td>88.6% - 111%</td></tr><tr><td>Number of Check Standards Analyzed</td><td>23</td></tr><tr><td>Average Recovery</td><td>96%</td></tr></table></body></html>  

There were a few occasions where this standard did not meet specifications. The results of these samples, however, were only slightly outside specified limits, and given the number of total samples (23), this is an insignificant num ber o f res ults that did no t fall with in specifications.  In addition, the laboratory reanalyzed the standard when specifications were not achieved, and the second determination always fell within the required limits. Therefore laboratory objectives for sensitivity were achieved according to QAPP specifications.  

As noted previously, comparability and representativeness were assessed through the analysis of replicate samples. Results of these replicates are presented in the discussion on primary project objectives for precision.  These results show that data were within project and QA objectives.  

Com pleteness objectives were achieved for the project.  All samples were analyzed and data were provided for $100\%$ of the samples received by the laboratory.  No sam ple bottles were lost or broken.  

Other measures of data quality included method blanks, calibration checks, evaluation of linearity of the calibration curve, holding time specifications, and an independent standard verification included with each sample batch. These results were reviewed for every sample batch run by ALSI, and were within specifications.  In addition, $10\%$ of the reported results were checked against the raw data. Raw data  were reviewed to ensure that sample results were within the calibration range of the instrument, as defined by the calibration curve.  A 6-point calibration curve was generated at the start of each sample batch of 20.  A few data points were found to be incorrectly reported. Recalculations were performed for these data, and any additional data points that were suspected outliers were checked to ensure correct results were reported.  Very few calculation or dilution erro rs w ere f oun d.  All errors were corrected so that the appropriate data were reported.  

Another measure of compliance were the non-stannous chloride runs performed by the laboratory for every sample analyzed.  This was done to check for organic interference. There were no samples that were found to have any organic interference by this method.  Therefore, these results met expected QC specifications and data were not qualified in any fashion.  

Total solids data were also reviewed to ensure that calculations were performed appropriately and dry weights reported when required.  All of  these QC checks met  

QAPP specifications. In sum mary, all data quality indicators and QC specifications were reviewed and found to be well within project specifications.  Therefore, the data are considered suitable for purposes of this evaluation.  

# 5.4 Audit Findings  

The SAIC SITE QA Manager conducted audits of both field activities and of the subcontracted laboratory as part of the QA measures for this project.  The results of these technical system reviews are discussed below.  

The field audit resulted in no findings or nonconformances.  The audit performed at the subcontract laboratory was conducted during the time of project sam ple analysis. One non-conformance was identified and corrective action was initiated.  It was discovered that the laboratory  PQL was not meeting specifications due to a reporting error.  The analyst was generating the calibration curves as specified above; however, the lower limit on the calibration curve was not being reported.  This was immediately rectified and no other findings or nonconformances were identified.  

# Chapter 6 Performance of the RA-915+/RP-91C  

Ohio Lumex analyzed 197 samples from May 5-8, 2003 in Oak Ridge, TN.  Results for these samples were reported by Ohio Lumex, and a statistical evaluation was performed. Additionally, the observations made during the demonstration were reviewed, and the remaining prim ary and secondary objectives were completed.  The results of the primary and secondary objectives, identified in Chapter 1, are discussed in Sections 6.1 and 6.2, respectively.  

The distribution of the samples prepared for Ohio Lumex and the referee laboratory is presented in Table 6-1.  From the four sites, Ohio Lumex received samples at 36 different concentrations for a total of 197 samples.  These 197 samples consisted of 22 concentrations in replicates of 7, 1 concentration in replicate of 4, and 13 concentrations in replicates of 3.  

Table 6-1.  Distribution of Samples Prepared for Ohio Lumex and the Referee Laboratory   


<html><body><table><tr><td rowspan="2">Site</td><td rowspan="2">Concentration Range</td><td colspan="4">Sample Type</td></tr><tr><td>Soil</td><td>Sediment</td><td>Spiked Soil</td><td>SRM</td></tr><tr><td>Carson River</td><td>Low (1-500 ppb)</td><td>3</td><td>10</td><td>7</td><td>7</td></tr><tr><td rowspan="3">(Subtotal = 62)</td><td>Mid (0.5-50 ppm)</td><td></td><td>0</td><td>?</td><td>28</td></tr><tr><td>High (50->1,000 ppm)</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>Low (1 ppb - 10 ppm)</td><td>30</td><td>0</td><td>14</td><td>13</td></tr><tr><td>Puget Sound (Subtotal = 67)</td><td>High (10-500 ppm)</td><td>..</td><td>3</td><td>7</td><td>0</td></tr><tr><td>Oak Ridge</td><td>Low (0.1-10 ppm)</td><td>10</td><td>?</td><td>?</td><td>14</td></tr><tr><td>(Subtotal = 51)</td><td>High (10-800 ppm)</td><td>3</td><td>6</td><td>0</td><td>4</td></tr><tr><td>Manufacturing.</td><td>General (5-1,000 ppm)</td><td>10</td><td>0</td><td>0</td><td>7</td></tr><tr><td>(Subtotal = 17) Subtotal</td><td></td><td>56</td><td>26</td><td>42</td><td>73</td></tr></table></body></html>  

# 6.1 Primary Objectives  

# 6.1.1 Sensitivity  

Sensitivity objectives are explained in Chapter 4.  The two primary sensitivity evaluations perform ed for this demonstration were the MDL and PQL.  Determinations of these two measurements are explained in the paragraphs below, along with a com parison to the referee laboratory. These determinations set the standard for the evaluation of accuracy and precision for the Ohio Lum ex field instrument.  Any sample analyzed by Ohio Lumex and subsequently reported as below their level of detection was not used as part of any additional evaluations.  This was done because of the expectation that values below the lower lim it of instrument sensitivity would not reflect the true instrument accuracy and precision.  

The sensitivity measurem ents of MDL and PQL are both dependent upon the matrix and method.  Hence, the MDL and PQL will vary, depending upon whether the matrix is a soil, waste, or water.  Only soils and sediments were tested during this demonstration and therefore, MDL calculations for this evaluation reflect soil and sediment m atrices.  PQL determinations are not independent calculations, but are dependent upon results provided by the vendor for the sam ples tested.  

Com parison of the MDL and PQ L to laboratory sensitivity required that a standard evaluation be performed for all instruments tested during this demonstration.  PQL, as previously noted, is defined in EPA G-5i as the lowest level of method and instrum ent performance with a specified accuracy and precision.  This is often defined by the lowest point on the calibration curve.  Our approach was to let the vendor provide the lower limit of quantitation as determined by their particular standard operating procedure, and then test this limit by comparing results of samples analyzed at this low concentration to the referee laboratory results, or comparing the results to a standard reference m aterial, if available.  Com parison of these data are, therefore, presented for the lowest concentration  sample results, as provided by the vendor.  If the vendor provided “non-detect” results, then no formal evaluation of that sample was presented.  In addition, the sample(s) was not used in the evaluation of precision and accuracy.  

Method Detection Limit – The standard procedure for determining MDLs is to analyze a low standard or reference material seven tim es, calculate the standard deviation and multiply the standard deviation by the “t” value for seven measurements at the 99th percentile (alpha $=0.01$ ).  (This value is 3.143 as determined from a standard statistics table.)  This procedure for determination of an MDL is defined in 40 CFR Part 136, and while determinations for MDLs may be defined differently for other instruments, this method was previously noted in the demonstration QAPP and is intended to provide a comparison to other similar MDL evaluations.  The purpose is to p rovide a low er level o f de tec tion with a statistical confidence at which the instrum ent will detect the presence of a substance above its noise level.  There is no associated accuracy or precision provided or implied.  

Several blind standards and field samples were provided to O hio Lum ex a t their es tim ate d lo we r lim it of se ns itivity. The Ohio Lumex lower lim it of sensitivity was previously estimated at $0.005\:\mathrm{\mg/kg}$ .  Because there are several different SRM s and field sam ples at concentrations close to the MDL, evaluation of the MDL was performed using more than a single concentration.  Samples chosen for calculation were based upon: 1) concentration and how close it was to the estimated MDL, 2) number of analyses performed for the same sam ple (e.g., more than 4), and 3) if non-detects were reported by Ohio Lumex for a sam ple used to calculate the MDL.  Then the next highest concentration sample was selected based upon the premise that a non-detect result reported for one of several samples indicates the selected sample is on the “edge” of the instrum ents detection capability.  

Seven replicates were analyzed by Ohio Lum ex for a sample that had a reported average concentration by the referee laboratory of $0.06~\mathrm{mg/kg}$ .  (Sample lot 02 from the Puget Sound site.)  The average concentration reported by Ohio Lumex for this sample was $0.072\mathrm{\mg/kg}$ and the standard deviation was $0.0135\mathrm{~mg/kg}$ .  An SRM with a reference value of $0.017\:\mathrm{\mg/kg}$ (sample lot 35) was analyzed seven tim es by Ohio Lumex with a reported average concentration of $0.0067~\mathrm{mg/kg}$ and a standard deviation of $0.0017~\mathrm{mg/kg}$ .  Calculations of the respective MDLs based upon each of these standards are 0.042 and $0.0053\mathrm{\mg/kg}$ .  

As a further check of the MDL, sample lot 37 (SRM) had a reference value of $0.158\mathrm{~m~g/kg}$ .  Seven samples analyzed by Ohio Lumex for this sample lot had a reported average concentration of $0.196{\mathrm{~mg/kg}}$ and a standard deviation of $0.0098~\mathrm{{mg/kg}}$ .  This results in a calculated MDL of 0.031 ${\sf m g/k g}$ , which falls between the values noted above.  

Based upon these results it appears that the MDL for this instrument is somewhere between 0.0053 and 0.042 $\mathsf{m g}/\mathsf{k g}$ .  The lowest standard analyzed by Ohio Lumex was the SRM noted above (sample lot 35) with a reference value of $0.017~\mathrm{mg/kg}$ (which is close to the average MDL) with a reported average concentration by Ohio Lumex of $0.0067~\mathrm{mg/kg}$ .  W hile the averag e re su lt for this s am ple has a percent difference $(\%0)$ o f $-63.5\%$ , the sample was easily detected by the Ohio Lumex field instrument, and is, therefore, by definition within the range of the MDL. Consequently, the estimated sensitivity provided by Ohio Lumex of $0.005~\mathrm{mg/kg}$ is a reasonable estimation of the MDL for aqueous samples, assuming that some sam ples will likely have matrix interferences and may result in a slightly higher MDL.  The calculated MDL for soils and sediments is somewhere between 0.0053 and 0.042 ${\sf m g}/{\sf k g}$ . The equivalent MDL for the referee laboratory is $0.0026\mathrm{~mg/kg}$ .  The calculated result is only intended as a statistical estimation and not a true test of instrument sen sitivity.  

Practical Quantitation Lim it – This value is usually calculated by determining a low standard on the instrument calibration curve, and it is estimated as the lowest standard at which the instrument will accurately and precisely determine a given concentration within specified QC limits. The PQL is often around 5-10 times the MDL.  This PQL estimation, however, is method- and m atrix-dependent.   In order to determine the PQL, several low standards were provided to Ohio Lum ex, and subsequent %Ds were calculated.  

The lower lim it of sensitivity previously provided by the vendor $(0.005\mathsf{m g}/\mathsf{k g})$ appears to be close to their MDL, but this would likely result in a higher instrument and method PQL.  The PQL should have a precision and accuracy that matches the instrument capabilities within a certain operating range of analysis.  The relationship between sensitivity and precision is such that the lower the concentration, the higher the variation in reported sample results.  Five times the estimated MDL (estimated PQL) would result in a value of 0.027 to $0.21~\mathrm{mg/kg}$ .  Therefore, values in this range were chosen for estimating the PQL and associated $\%0$ between the Ohio Lumex reported average and the reference value if it is an SRM, or the average value reported by the referee laboratory.  Also compared are the $95\%$ CIs for additional descriptive information.  

The Ohio Lumex average result for the $0.017\mathrm{mg/kg}$ SRM noted above (sample lot 35) was $0.0067\mathrm{\mg/kg}$ .  The standard deviation was $0.0017~\mathrm{{mg/kg}}$ and the $95\%$ CI is 0.0051 to $0.0083\mathsf{m g/k g}$ .  The $\%0$ for this sample is $-63.5\%$ and therefore this is clearly below the instrument PQL.  

The Ohio Lumex average result for the $0.158~\mathrm{mg/kg}$ SRM (sam ple lot 37) was $0.196~\mathrm{mg/kg}$ .  The standard deviation was $0.0098\mathrm{mg/kg}$ and the $95\%$ C I is $0.187\cdot0.205~\mathrm{mg/kg}.$ The $\%0$ fo r this sa m ple is $24.1\%$ .  This is a reasonable $\%0$ for most analytical instrumentation and therefore within the instrument’s PQL.  

The average result reported by the referee laboratory for sample lot 02 was $0.06\mathrm{mg/kg}$ .  The result reported by Ohio Lumex for this same sample was $0.072\:\mathrm{\mg/kg}$ .  The standard deviation was $0.0135\mathrm{~mg/kg}$ .  T he $\%0$ for this sam ple is $20\%$ .  

# Sensitivity Summ ary  

The low standard calculations using MDL values suggest that a PQL for the Ohio Lumex field instrument may be as low as $0.027~\mathrm{\mg/kg}$ .  The referee laboratory PQL confirmed during the demonstration is $0.005~\mathrm{{mg/kg}}$ with a $\%0$ of $<10\%$ .  The $\%0$ for the average Ohio Lumex result for the average referee laboratory value of $0.06\mathrm{~mg/kg}$ is $0.072\mathrm{~mg/kg}$ , with a $\%0$ of $20\%$ .  This was the lowest sample concentration tested during the demonstration that is close to the calculated PQL noted above.  

The range for the calculated MDL is between 0.0053 and $0.042\mathrm{\mg/kg}$ , based on the results of seven replicate analyses for low standards.  The equivalent MDL for the referee laboratory is 0.0026 mg/kg.  The MDL determination, however, is only a statistical calculation that has been used in the past by EPA, and is currently not considered a “true” MDL by SW -846 methodology. SW -846 is suggesting that performance-based methods be used, and that PQLs be determined using low standard calculations.  

# 6.1.2 Accuracy  

Accuracy is the instrum ent measurement compared to a standard, or “true” value.  For this demonstration, three separate standards were used for determining accuracy. The primary standard is SRMs.  The SRMs are traceable to national systems.  These were obtained from reputable suppliers with reported concentration and an associated $95\%$ CI and $95\%$ prediction interval.  The CI from the reference material is used as a measure of comparison with CI calculated from replicate analyses for the same sample analyzed by the laboratory or vendor.  Results are considered com parable if CIs of the SRM overlap with the CIs computed from the replicate analyses by the vendor. W hile this is not a definitive m easure of c om parison, it provides som e assurance that the two values are equivalent.  

Prediction intervals are intended as a measure of comparison for a single laboratory or vendor result with the SRM.  W hen computing a prediction interval, the equation assumes an infinite number of analyses, and it is used to com pare individual sample results.  A $95\%$ prediction interval would, therefore, predict the correct result from a single analysis $95\%$ of the time for an infinite number of samples, if the result is comparable to that of th e S R M .  It should be noted that the corollary to this statem ent is that $5\%$ of the time a result will be outside the prediction interval if determined for an infinite number of samples.  If several samples are analyzed, the percentage of results within the prediction interval will be slightly above or below $95\%$ .  The more samples analyzed, the more likely the percentage of correct results will be close to $95\%$ i f th e result for the method being tested is comparable to the SRM.  

All SRMs were analyzed in replicates of three, four, or seven by both the vendor and the referee laboratory.  In some instances, analyses performed by the vendor were determined to be invalid measurements and were, therefore, not included with the reported results.   There were nine  different SRMs analyzed by both the vendor and the laboratory, for a total of 57 data points by the vendor and 62 data points by the laboratory.  One specially prepared SRM (sample lot 55) was not included, because analyses performed by the vendor and the laboratory suggested that the SRM value was in question.  Because this was a specially prepared SRM, and had somewhat less documentation in regards to the reference value, and because both the referee laboratory and vendor results, wh ile sta tistic ally equivalent were statistically different from the SRM value, this SRM was not included in the evaluation.  

The second accuracy determination used a comparison of vendor results of field samples and SRMs to the referee laboratory results for these same samples.  Field samples were used to ensure that "real-world" samples were tested by the vendor.  The referee laboratory result is considered as the standard for comparison to the vendor result.  T his comparison is in the form of a hypothesis test with alpha $\mathbf{\sigma}=\mathbf{\sigma}$ 0.01.  (Detailed equations along with additional information about this statistical comparison is included in Appendix B.)  

It should be noted that there is evidence of a laboratory bias.  This bias was determined by comparing average laboratory values to SRM reference values, and is discussed below.  The laboratory bias is low in comparison to the reference value.  A bias correction was not made when comparing individual samples (replicate analyses) between the laboratory and vendor; however, setting alpha $=0.01$ helps mitigate for this possible bias by widening the range of acceptable results between the two data sets.  

An aggregate analysis, or unified hypothesis test, was also performed for all 33 sam ple lots.  (A detailed discussion of this statistical com parison is included in Appendix B.)  This analysis provides additional statistical evidence in relation to the accuracy evaluation.  A bias term is included in this calculation in order to account for any data bias.  

The third measure of accuracy is obtained by the analysis of spiked field samples.  These were analyzed by the vendor and the laboratory in replicate in order to provide additional measurement comparisons and are treated the same as the other field sam ples.  Spikes were prepared to cover additional concentrations not available from SRMs or field samples.  There is no comparison to the spiked concentration, only a comparison between the vendor and the laboratory reported value.  

The purpose for SRM analyses by the referee laboratory is to provide a check on laboratory accuracy.  During the pre-demonstration, the referee laboratory was chosen, in part, based upon the analysis of SRMs.  This was done to ensure that a competent laboratory would be used for the demonstration. The pre-demonstration laboratory qualification showed that the laboratory was within prediction intervals for all SRMs analyzed.  Because of the need to provide confidence in laboratory analysis during the demonstration, the referee laboratory also analyzed SRMs as an ongoing check of  laboratory bias.  As noted in Table 6-3, not all laboratory results were within the prediction interval.  This is discussed in more detail below.  All laboratory QC checks, however, were found to be within compliance (see Chapter 5).  

Evaluation of vendor and laboratory analysis of SRMs is performed in the following manner.  Accuracy was determined by com paring the $95\%$ CI of the sample analyzed by the vendor and laboratory to the $95\%$ CI for the S R M .  ( $95\%$ CIs around the true value are provided by the SRM supplier.)  This information is provided in Tables 6-2 and 6-3, with notations when the CIs overlap, suggesting com parable results.  In addition, the number of SRM results for the vendor's analytical instrumentation and the referee laboratory that are within the associated $95\%$ prediction interval are reported.  This is a m ore definitive evaluation of laboratory and vendor accuracy.  The percentage of total res ults within the prediction interval for the vendor and laboratory are reported in Tables 6-2 and 6-3, respectively.  

The single most important number from these tables  is the percentage of samples within the $95\%$ pre dic tion inte rva l. As noted for the Ohio Lumex data, this percentage is $93\%$ , with $n=57$ .  This suggests that the Ohio Lum ex data are within expected accuracy accounting for statistical variation.  For five of the nine determinations, Ohio Lumex average results are above the reference value.  This would suggest that there is no bias associated with the Ohio Lumex data.    Six of the nine sam ple groups overlap with the $95\%$ CIs calculated from the Ohio Lumex data, compared to values provided by the supplier of the SRM. This number is also suggestive of a reasonable comparison to the SRM value, accounting for statistical variation.  

The percentage of sam ples within the $95\%$ prediction interval for the laboratory data is $87\%$ .  F o r 7 of the 9 determinations, ALSI average results are below the reference value.  This suggests that  the ALSI data are potentially biased low.  Because of this bias, the percentage of samples outside the prediction interval is slightly below the anticipated number of results, given that the num ber of samples analyzed (62) is relatively high. Nonetheless, the referee laboratory data should be considered accurate and not significantly different from the SRM value.  Because there is no bias correction term in the individual hypothesis tests (Table 6-4), alpha is set at 0.01 to help mitigate for laboratory bias.  This in effect widens the scope of vendor data that would fall within an acceptable range of the referee laboratory. Six of the nine sample groups overlap with the $95\%$ CIs calculated from the ALSI data, compared to values provided by the supplier of the SRM.  This num ber is also suggestive of a reasonable comparison to the SRM value accounting for statistical variation.  

Table 6-2.  Ohio Lumex SRM Comparison   


<html><body><table><tr><td>Sample Lot No.</td><td>SRM Value/ 95% CI</td><td>Ohio Lumex Avg./ 95% CI</td><td>CI Overlap (yes/no)</td><td>No. of Samples Analyzed</td><td>95% Prediction Interval</td><td>Ohio Lumex No. w/in Prediction</td></tr><tr><td>37</td><td>0.158 / 0.132 - 0.184</td><td>0.196 / 0.187-0.205</td><td>no</td><td>7</td><td>0-0.357</td><td>Interval ？</td></tr><tr><td>44</td><td>4.7/ 4.3 - 5.1</td><td>4.88 / 4.72- 5.03</td><td>yes</td><td>6</td><td>3.0 -6.4</td><td>6</td></tr><tr><td>35</td><td>0.017/0.010 -0.024</td><td>0.0067 /0.0051 -0.0083</td><td>no</td><td>?</td><td>0-0.0358 b</td><td>?</td></tr><tr><td>36</td><td>0.082/ 0.073-0.091</td><td>0.071/ 0.062-0.080</td><td>yes</td><td>3</td><td>0.035-0.13 b</td><td>3</td></tr><tr><td>38</td><td>0.62/ 0.61- 0.63 a</td><td>0.627/ 0.607-0.647</td><td>yes</td><td>?</td><td>0.545 - 0.695</td><td></td></tr><tr><td>39</td><td>1.09 / 1.06 - 1.12</td><td>1.07 / 1.01-1.13</td><td>yes</td><td>6</td><td>0.94 - 1.24</td><td>5</td></tr><tr><td>41</td><td>2.42 / 2.16 - 2.46</td><td>2.01 / 1.68 -2.37</td><td>yes</td><td>?</td><td>1.3 -3.3</td><td>7</td></tr><tr><td>43</td><td>3.80 / 3.50 - 4.11</td><td>3.64 / 3.33- 3.95</td><td> yes</td><td></td><td>2.41 - 5.20</td><td>7</td></tr><tr><td>45</td><td>6.45 / 6.06 - 6.84</td><td>8.14 / 8.02 - 8.26</td><td>no</td><td>7</td><td>4.83 - 8.06</td><td>4</td></tr><tr><td colspan="2">Total Samples % of samples w/in</td><td></td><td></td><td>57</td><td></td><td>53 93%</td></tr></table></body></html>

ab CI is estimated based upon $n=30$ .   A $95\%$ prediction interval was provided by the SRM supplier but no CI was given. Prediction interval is estimated based upon $\scriptstyle\mathtt{n}=30$ .   A $95\%$ CI was provided by the SRM supplier but no prediction interval was given.  

Table 6-3.  ALSI SRM Comparison   


<html><body><table><tr><td>Sample Lot No.</td><td>SRM Value/ 95% CI</td><td>ALSI Avg./ 95% CI</td><td>CI Overlap</td><td>No. of Samples</td><td>95% Prediction Interval</td><td>ALSI No. w/in Prediction</td></tr><tr><td>37</td><td>0.158/ 0.132-0.184</td><td>0.139/ 0.093-0.185</td><td>(yes/no) yes</td><td>Analyzed ？</td><td>0-0.357</td><td>Interval 7</td></tr><tr><td>44</td><td>4.7 / 4.3 - 5.1</td><td>2.33/1.05- 3.61</td><td>no</td><td></td><td>3.0 -6.4</td><td>2</td></tr><tr><td>35</td><td>0.017/0.010-0.024</td><td>0.0087/ 0.0078 -0.0096</td><td>no</td><td>7</td><td>0 -0.0358 b</td><td>?</td></tr><tr><td>36</td><td>0.082/ 0.073-0.091</td><td>0.073 /0.068 - 0.078</td><td>yes</td><td>7</td><td>0.035 - 0.13 b</td><td>7</td></tr><tr><td>38</td><td>0.62/0.61- 0.63 a</td><td>0.628 / 0.606 - 0.650</td><td>yes</td><td></td><td>0.545 - 0.695</td><td>?</td></tr><tr><td>39</td><td>1.09 / 1.06 - 1.12b</td><td>1.24 / 0.634 -1.85</td><td>yes</td><td>7</td><td>0.94 - 1.24</td><td>6</td></tr><tr><td>41</td><td>2.42 / 2.16 - 2.46</td><td>1.79 / 1.29 - 2.29</td><td>yes</td><td></td><td>1.3 - 3.3</td><td>6</td></tr><tr><td>43</td><td>3.80 / 3.50 - 4.11</td><td>2.76 / 2.51- 3.01</td><td>no</td><td>?</td><td>2.41 - 5.20</td><td>7</td></tr><tr><td>45</td><td>6.45 / 6.06 - 6.84</td><td>5.44 / 4.10 - 6.78</td><td>yes</td><td>6</td><td>4.83 - 8.06</td><td>5.</td></tr><tr><td></td><td>Total Samples</td><td></td><td></td><td>62</td><td></td><td>54</td></tr><tr><td></td><td>% of samples w/in prediction interval</td><td></td><td></td><td></td><td></td><td>87%</td></tr></table></body></html>

ab CI is estimated based upon $n=30$ .   A $95\%$ prediction interval was provided by the SRM supplier but no CI was given. Prediction interval is estimated based upon $\scriptstyle\mathtt{n}=30$ .   A $95\%$ CI was provided by the SRM supplier but no prediction interval was given.  

# Hypothesis Testing  

Sample results from field and spiked field samples for the vendor com pared to similar tests by the referee laboratory are used as another accuracy check.  Spiked samples were used to cover concentrations not found in the field samples, and they are considered the sam e as the field samples for purposes of comparison.  Because of the limited data available for determining the accuracy of the spiked value, these were not considered the same as reference standards.  Therefore, these samples were evaluated in the same fashion as field samples, but they were not com pared to individual spiked concentrations.  

Using a hypothesis test with alpha $=0.01$ , vendor results for all sam ples were com pared to laboratory results to determine if sample populations are the same or significantly different.  This was performed for each sample lot separately.  Because this test does not separate precision from bias, if Ohio Lumex’s or ALSI’s computed standard deviation was large due to a highly variable result (indication of poor precision), the two CIs could overlap. Therefore, the fact that there was no significant difference between the two results could be due to high sam ple variability.  Accordingly, associated RSDs have also been reported in Table 6-4 along with results of the hypothesis testing for each sam ple lot.  

Table 6-4. Accuracy Evaluation by Hypothesis Testing   


<html><body><table><tr><td>Sample Lot No./ Site</td><td>Avg. Conc. mg/kg</td><td>RSD or CV</td><td>Number of Measurements</td><td>Significantly Different at Alpha = 0.01</td><td>Relative Percent Difference (Ohio</td></tr><tr><td>03/ Oak Ridge</td><td></td><td></td><td></td><td>yes</td><td>Lumex to ALSI) 19.8%</td></tr><tr><td> Ohio Lumex</td><td>0.317</td><td>4.8%</td><td>3</td><td></td><td></td></tr><tr><td>ALSI</td><td>0.260</td><td>3.8%</td><td>3</td><td></td><td></td></tr><tr><td> 09/ Oak Ridge</td><td></td><td></td><td></td><td>no</td><td>6.4% </td></tr><tr><td> Ohio Lumex</td><td>0.497</td><td>23.2%</td><td>?</td><td></td><td></td></tr><tr><td>ALSI</td><td>0.466</td><td>34.2%</td><td>7</td><td></td><td></td></tr><tr><td>14/ Oak Ridge</td><td></td><td></td><td></td><td>yes</td><td>49.3%</td></tr><tr><td>Ohio Lumex</td><td>7.86</td><td>32.0%</td><td></td><td></td><td></td></tr><tr><td>ALSI</td><td>4.75</td><td>27.5%</td><td>7</td><td></td><td></td></tr><tr><td> 21/ Oak Ridge</td><td></td><td></td><td></td><td>no</td><td>42.8%</td></tr><tr><td>Ohio Lumex</td><td>17.3</td><td>23.3%</td><td>3</td><td></td><td></td></tr><tr><td>ALSI</td><td>11.2</td><td>23.8%</td><td>3</td><td></td><td></td></tr><tr><td> 24/ Oak Ridge</td><td></td><td></td><td></td><td>no</td><td>-11.5%</td></tr><tr><td> Ohio Lumex</td><td>197</td><td>28.0%</td><td>3</td><td></td><td></td></tr><tr><td>ALSI</td><td>221</td><td>44.8%</td><td>7</td><td></td><td></td></tr><tr><td> 26/ Oak Ridge</td><td></td><td></td><td></td><td>yes</td><td>23.7%</td></tr><tr><td>Ohio Lumex</td><td>97.7</td><td>2.6%</td><td>3</td><td></td><td></td></tr><tr><td>ALSI</td><td>77.0</td><td>13.2%</td><td>7</td><td></td><td></td></tr><tr><td> 37/ Oak Ridge</td><td></td><td></td><td></td><td>no</td><td>34.0%</td></tr><tr><td> Ohio Lumex</td><td>0.196</td><td> 5.0%</td><td>?</td><td></td><td></td></tr><tr><td>ALSI</td><td>0.139</td><td>36.4%</td><td>7</td><td></td><td></td></tr><tr><td>44/ Oak Ridge</td><td></td><td></td><td></td><td>no</td><td>70.7%</td></tr><tr><td>Ohio Lumex</td><td>4.88</td><td>3.0%</td><td>6</td><td></td><td></td></tr><tr><td>ALSI</td><td>2.33</td><td>59.4%</td><td>7</td><td></td><td></td></tr><tr><td>60/ Oak Ridge</td><td></td><td></td><td></td><td>no</td><td>-10.2%</td></tr><tr><td>Ohio Lumex </td><td>149</td><td>23.8%</td><td>?</td><td></td><td></td></tr><tr><td>ALSI</td><td>165</td><td>30.9%</td><td>7</td><td></td><td></td></tr><tr><td> 02/ Puget Sound</td><td></td><td></td><td></td><td>no</td><td>3.3 %</td></tr><tr><td>Ohio Lumex </td><td>0.062</td><td>43.9%</td><td>7</td><td></td><td></td></tr><tr><td>ALSI</td><td>0.06</td><td>23.6%</td><td>4</td><td></td><td></td></tr><tr><td>05/ Puget Sound</td><td></td><td></td><td></td><td>no</td><td>23.9%</td></tr><tr><td>Ohio Lumex</td><td>0.267</td><td>9.4%</td><td>3</td><td></td><td></td></tr><tr><td>ALSI</td><td>0.21</td><td>33.3 % </td><td>3</td><td></td><td></td></tr><tr><td>08/ Puget Sound</td><td></td><td></td><td></td><td>yes</td><td>36.4%</td></tr><tr><td>Ohio Lumex </td><td>0.52</td><td>14.2%</td><td>?</td><td></td><td></td></tr><tr><td>ALSI</td><td>0.36</td><td>13.4%</td><td>7</td><td></td><td></td></tr><tr><td>10/ Puget Sound</td><td></td><td></td><td></td><td>no</td><td>105%</td></tr><tr><td>Ohio Lumex </td><td>1.76</td><td>120%</td><td>3</td><td></td><td></td></tr><tr><td>ALSI</td><td>0.55</td><td>20.5%</td><td>3</td><td></td><td></td></tr><tr><td>11/ Puget Sound</td><td></td><td></td><td></td><td>yes</td><td>47.2%</td></tr><tr><td>Ohio Lumex </td><td>1.31</td><td>14.2%</td><td>?</td><td></td><td></td></tr><tr><td>ALSI</td><td>0.81</td><td>32.7%</td><td>7</td><td></td><td></td></tr><tr><td>12/ Puget Sound</td><td></td><td></td><td></td><td>no</td><td>25.8%</td></tr><tr><td>Ohio Lumex</td><td>1.4</td><td>7.2%</td><td>3</td><td></td><td></td></tr><tr><td>ALSI</td><td>1.08</td><td>2.8%</td><td>3</td><td></td><td></td></tr><tr><td> 25/ Puget Sound</td><td></td><td></td><td></td><td>yes</td><td>85.3%</td></tr><tr><td>Ohio Lumex</td><td>41.3</td><td>12.4%</td><td>3</td><td></td><td></td></tr><tr><td>ALSI</td><td>16.6</td><td>12.3%</td><td>3</td><td></td><td></td></tr><tr><td>34/ Puget Sound</td><td></td><td></td><td></td><td>no</td><td>165%</td></tr><tr><td>Ohio Lumex</td><td>117</td><td>24.7%</td><td>3 7</td><td></td><td></td></tr><tr><td>ALSI 36/ Puget Sound</td><td>11.3</td><td>23.4%</td><td></td><td></td><td>1.4%</td></tr><tr><td></td><td></td><td></td><td></td><td>no</td><td></td></tr><tr><td>Ohio Lumex</td><td>0.071</td><td>4.9%</td><td>3</td><td></td><td></td></tr><tr><td>ALSI</td><td>0.07</td><td>6.7%</td><td>7</td><td></td><td></td></tr><tr><td> 57/ Puget Sound </td><td></td><td></td><td></td><td>yes</td><td>34.1%</td></tr><tr><td>Ohio Lumex </td><td>1.03</td><td>11.2%</td><td>?</td><td></td><td></td></tr><tr><td>ALSI</td><td>0.73</td><td>16.2%</td><td>7</td><td></td><td></td></tr></table></body></html>  

Table 6-4.  Continued   


<html><body><table><tr><td>Table6-4.Continued Sample Lot No./ Site</td><td>Avg. Conc. mg/kg </td><td>RSD or CV</td><td>Number of Measurements</td><td>Significantly Different at Alpha = 0.01</td><td>Relative Percent Difference (Ohio</td></tr><tr><td>61/ Puget Sound</td><td></td><td></td><td></td><td>no</td><td>Lumex to ALSI) -26.0%</td></tr><tr><td> Ohio Lumex</td><td>154</td><td>47.0%</td><td>?</td><td></td><td></td></tr><tr><td>ALSI</td><td>200</td><td>10.9%</td><td>7</td><td></td><td></td></tr><tr><td> 62/ Puget Sound</td><td></td><td></td><td></td><td>yes</td><td>47.5%</td></tr><tr><td> Ohio Lumex</td><td>23.7</td><td>13.0%</td><td></td><td></td><td></td></tr><tr><td>ALSI</td><td>14.6</td><td>28.3%</td><td>7</td><td></td><td></td></tr><tr><td> 01/ Carson River</td><td></td><td></td><td></td><td>no</td><td>21.5%</td></tr><tr><td>Ohio Lumex</td><td>0.29</td><td>30.5%</td><td>？</td><td></td><td></td></tr><tr><td>ALSI</td><td>0.24</td><td>37.8%</td><td>7</td><td></td><td></td></tr><tr><td> 04/ Carson River</td><td></td><td></td><td></td><td>no</td><td>18.9%</td></tr><tr><td>Ohio Lumex </td><td>0.13</td><td>18.9%</td><td>3</td><td></td><td></td></tr><tr><td>ALSI</td><td>0.11</td><td>9.1%</td><td>7</td><td></td><td></td></tr><tr><td> 06/ Carson River</td><td></td><td></td><td></td><td>no</td><td>10.3%</td></tr><tr><td>Ohio Lumex</td><td>0.29</td><td>7.3%</td><td>3</td><td></td><td></td></tr><tr><td>ALSI</td><td>0.26</td><td>15.7%</td><td>7</td><td></td><td></td></tr><tr><td>38/ Carson River</td><td></td><td></td><td></td><td>no</td><td>-0.2%</td></tr><tr><td>Ohio Lumex</td><td>0.63</td><td>3.5%</td><td></td><td></td><td></td></tr><tr><td>ALSI</td><td>0.63</td><td>3.8%</td><td>7</td><td></td><td></td></tr><tr><td>39/ Carson River</td><td></td><td></td><td>？</td><td>no</td><td>-14.7%</td></tr><tr><td>Ohio Lumex</td><td>1.07</td><td>6.5%</td><td></td><td></td><td></td></tr><tr><td>ALSI</td><td>1.24</td><td>52.9%</td><td>7</td><td></td><td></td></tr><tr><td>41/ Carson River</td><td></td><td>17.5%</td><td>？</td><td>no</td><td>11.6%</td></tr><tr><td> Ohio Lumex </td><td>2.01</td><td>30.5%</td><td>7</td><td></td><td></td></tr><tr><td>ALSI 43/ Carson River</td><td>1.79</td><td></td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>9.1%</td><td></td><td>yes</td><td>27.5%</td></tr><tr><td>ALSI</td><td>3.64 2.76</td><td>9.6%</td><td>7</td><td></td><td></td></tr><tr><td>56/ Carson River</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td>0.22</td><td>8.0%</td><td>?</td><td>no</td><td>5.2%</td></tr><tr><td>ALSI</td><td>0.23</td><td>12.6%</td><td>7</td><td></td><td></td></tr><tr><td>59/ Carson River</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td>1.91</td><td>10.2%</td><td></td><td>no</td><td>11.1%</td></tr><tr><td>ALSI</td><td>1.71</td><td>7.9%</td><td>7</td><td></td><td></td></tr><tr><td>13/Manufacturing Site</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td>10.2</td><td> 51.9%</td><td>7</td><td>no</td><td>53.3%</td></tr><tr><td>ALSI</td><td>5.91</td><td>15.4%</td><td>7</td><td></td><td></td></tr><tr><td>17/ Manufacturing Site</td><td></td><td></td><td></td><td>no</td><td>39.7%</td></tr><tr><td>Ohio Lumex</td><td>15.7</td><td>24.2%</td><td>3</td><td></td><td></td></tr><tr><td>ALSI</td><td>10.5</td><td>14.6%</td><td>7</td><td></td><td></td></tr><tr><td>45/ Manufacturing Site</td><td></td><td></td><td></td><td>no</td><td>39.8%</td></tr><tr><td> Ohio Lumex</td><td>8.14</td><td>1.6% </td><td>?</td><td></td><td></td></tr><tr><td>ALSI</td><td>5.44</td><td>23.4%</td><td>6</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr></table></body></html>

CV = Coefficient of variance  

Of the 33 sample lots, 9 results are significantly different based upon the hypothesis test noted above.  Most of the relative percent differences are positive, which indicates that the Ohio Lumex result is generally higher than the laboratory result.  This is indicative of the previously noted low bias associated with the laboratory data.  There are some Ohio Lumex results that are less than the laboratory result, therefore, no overall Ohio Lumex high or low bias is apparent.  It appears that Ohio Lum ex data are subject to m ore random variability.  

In determining the number of results significantly above or below the value reported by the referee laboratory, 19 of 33 Ohio Lumex average results were found to have RPDs less than $30\%$ for sample concentrations above the estimated PQL.  Only two of 33 Ohio Lumex average results have RPDs greater than $100\%$ for this same group of samples (see Table 6-5).  Interferences m ay be a problem but, because of the random variability associated with the data, no interferences are specifically apparent from the data collected.  Table 6-6 shows the results of additional data collected for these same samples.  

Table 6-5.  Number of Sample Lots Within Each %D Range   


<html><body><table><tr><td></td><td><30%</td><td>>30%, <50%</td><td>>50%, <100%</td><td>>100%</td><td>Total</td></tr><tr><td>Positive %D</td><td>14</td><td>9</td><td>3</td><td>2</td><td>28</td></tr><tr><td>Negative %D</td><td>5</td><td>0</td><td>0</td><td>0</td><td>5</td></tr><tr><td>Total</td><td>19</td><td>9</td><td>3</td><td>2</td><td>33</td></tr></table></body></html>

Only those sample lots with the average result greater than the PQL are tabulated.  

Table 6-6.  Concentration (in mg/kg) of Non-Target Analytes   


<html><body><table><tr><td>Lot #.</td><td>Site</td><td>TOC</td><td>O&G</td><td>Ag</td><td>As</td><td>Ba</td><td>Cd</td><td>Cr</td><td>Cu</td><td>Pb</td><td>Se</td><td>Sn</td><td>Zn</td><td>Hg</td></tr><tr><td>1</td><td> Carson River</td><td>870</td><td>190</td><td><0.5</td><td>9</td><td>210</td><td><0.5</td><td>19</td><td>13</td><td>3</td><td><2</td><td><5</td><td>60</td><td>0.19</td></tr><tr><td>2</td><td> Puget Sound </td><td>3500</td><td>290</td><td><0.5</td><td>3</td><td>23</td><td><0.5</td><td>16</td><td>10</td><td>1</td><td><2</td><td><5</td><td>24</td><td>0.04</td></tr><tr><td></td><td>3Oak Ridge</td><td>2300</td><td>530</td><td>1.8</td><td>4</td><td>150</td><td><0.5</td><td>46</td><td>20</td><td>15</td><td><2</td><td><5</td><td>55</td><td>0.31</td></tr><tr><td></td><td>4  Carson River</td><td>2400</td><td>200</td><td><0.5</td><td>8</td><td>240</td><td><0.5</td><td>17</td><td>32</td><td>12</td><td><2</td><td><5</td><td>66</td><td>0.10</td></tr><tr><td>5</td><td> Puget Sound</td><td>3500</td><td>210</td><td><0.5</td><td>3</td><td>28</td><td><0.5</td><td>18</td><td>11</td><td>3</td><td><2</td><td><5</td><td>28</td><td>0.16</td></tr><tr><td></td><td>6  Carson River</td><td>7200</td><td>200</td><td><0.5</td><td>4</td><td>32</td><td><0.5</td><td>16</td><td>9</td><td>1</td><td><2</td><td><5</td><td>24</td><td>0.23</td></tr><tr><td></td><td>8Puget Sound</td><td>8100</td><td>200</td><td><0.5</td><td>3</td><td>27</td><td>1.0</td><td>17</td><td>23</td><td>99</td><td>2</td><td><5</td><td>37</td><td>0.37</td></tr><tr><td></td><td>9  Oak Ridge</td><td>3300</td><td>150</td><td>1.9</td><td>5</td><td>160</td><td>0.5</td><td>70</td><td>49</td><td>24</td><td><2</td><td><5</td><td>100</td><td>0.66</td></tr><tr><td>10</td><td>Puget Sound</td><td>4200</td><td>130</td><td><0.5</td><td>3</td><td>24</td><td><0.5</td><td>18</td><td>8</td><td>1</td><td><2</td><td><5</td><td>24</td><td>0.62</td></tr><tr><td></td><td>11  Puget Sound</td><td>3800</td><td>130</td><td><0.5</td><td>4</td><td>20</td><td><0.5</td><td>18</td><td>8</td><td>1</td><td><2</td><td><5</td><td>24</td><td>0.63</td></tr><tr><td>12</td><td>Puget Sound</td><td>3500</td><td>290</td><td><0.5</td><td>3</td><td>23</td><td>0.8</td><td>16</td><td>7</td><td>2</td><td><2</td><td><5</td><td>23</td><td>1.1</td></tr><tr><td>13</td><td> Manufacturing Site</td><td>3200</td><td>100</td><td><0.5</td><td>2</td><td>110</td><td><0.5</td><td>42</td><td>51</td><td>7</td><td><2</td><td><5</td><td>61</td><td>5.5</td></tr><tr><td>14</td><td> Oak Ridge</td><td>7800</td><td>180</td><td>0.32</td><td>2</td><td>41</td><td>0.4</td><td>16</td><td>9</td><td>11</td><td><2</td><td><4</td><td>74</td><td>78</td></tr><tr><td>17</td><td> Manufacturing Site</td><td>2400</td><td>90</td><td><0.5</td><td><2</td><td>180</td><td><0.5</td><td>48</td><td>20</td><td>15</td><td><2</td><td><5</td><td>120</td><td>10</td></tr><tr><td>21</td><td> Manufacturing Site</td><td>7800</td><td>320</td><td>1.9</td><td>4</td><td>150</td><td>2.8</td><td>22</td><td>40</td><td>23</td><td><2</td><td><4</td><td>340</td><td>14</td></tr><tr><td>24</td><td> Oak Ridge</td><td>6600</td><td>250</td><td><0.5</td><td>5</td><td>89</td><td><0.5</td><td>6.3</td><td>7</td><td>10</td><td><2</td><td><5</td><td>31</td><td>220</td></tr><tr><td>25</td><td> Puget Sound</td><td>46000</td><td>1200</td><td><0.5</td><td>2</td><td>46</td><td>0.7</td><td>35</td><td>33</td><td>31</td><td><2</td><td>6</td><td>98</td><td>35</td></tr><tr><td>26</td><td>Oak Ridge</td><td>88000</td><td>340</td><td>9.1</td><td>10</td><td>140</td><td>1.9</td><td>47</td><td>73</td><td>82</td><td><2</td><td>5</td><td>250</td><td>100</td></tr><tr><td>34</td><td>SRM CRM-204 (web)</td><td>NR</td><td>NR</td><td><0.5</td><td>0.82</td><td>0.04</td><td>14</td><td>4.5</td><td>NR</td><td>11</td><td>NR</td><td>NR</td><td>NR</td><td>0.002</td></tr><tr><td>35</td><td>SRM Canmet S0-3</td><td>NR</td><td>NR</td><td>NR</td><td>NR</td><td>300</td><td>NR</td><td>26</td><td>17</td><td>14</td><td>NR</td><td>NR</td><td>52</td><td>0.02</td></tr><tr><td>36</td><td>SRM Canmet S0-2</td><td>NR</td><td>NR</td><td>NR</td><td>NR</td><td>970</td><td>NR</td><td>16</td><td>7</td><td>21</td><td>NR</td><td>NR</td><td>120</td><td>0.08</td></tr><tr><td>37</td><td>SRM CRM-016</td><td>NR</td><td>NR</td><td>0.7</td><td>7.8</td><td>79</td><td>0.47</td><td>14</td><td>16</td><td>14</td><td>1</td><td>NR</td><td>70</td><td>0.16</td></tr><tr><td>38</td><td>SRM NWRI TH-2</td><td>NR</td><td>NR</td><td>5.8</td><td>8.7</td><td>570</td><td>5.2</td><td>120</td><td>120</td><td>190</td><td>0.83</td><td>NR</td><td>900</td><td>0.62</td></tr><tr><td>39</td><td>SRM NWRI WQB-1</td><td>NR</td><td>NR</td><td>1</td><td>23</td><td>600</td><td>2</td><td>89</td><td>80</td><td>84</td><td>1</td><td>3.9</td><td>275</td><td>1.09</td></tr><tr><td>41</td><td>SRM CRM 026</td><td>NR</td><td>NR</td><td>0.57</td><td>5.4</td><td>210</td><td>12</td><td>27</td><td>19</td><td>26</td><td>1.9</td><td>NR</td><td>140</td><td>2.4</td></tr><tr><td>43</td><td>SRM CRM 027</td><td>NR</td><td>NR</td><td>6</td><td>12</td><td>170</td><td>12</td><td>27</td><td>9.9</td><td>52</td><td>14</td><td>NR</td><td>51</td><td>3.8</td></tr><tr><td>44</td><td>SRM CRM 021</td><td>NR</td><td>NR</td><td>6.5</td><td>25</td><td>590</td><td>1.2</td><td>11</td><td>4800</td><td>6500</td><td>NR</td><td>300</td><td>550</td><td>4.7</td></tr><tr><td>45</td><td>SRM CRM 033</td><td>NR</td><td>NR</td><td>0.78 130</td><td></td><td>220 120</td><td>89</td><td>100</td><td>96</td><td>61</td><td>89</td><td>390</td><td>230</td><td>6.4</td></tr><tr><td>46</td><td>SRM CRM 032 SRM RTC spec.</td><td>NR NR</td><td>NR NR</td><td>81 NR</td><td>370</td></table></body></html>

CRM $\mathbf{\tau}=\mathbf{\tau}$ Canadian Reference Material RTC $\mathbf{\tau}=\mathbf{\tau}$ Resource Technology Corporation NR $\mathbf{\tau}=\mathbf{\tau}$ Not Reported by Standard Supplier  

# Discussion of Interferences  

The RSDs for Ohio Lumex are small, suggesting that precision is good and is not simply random  variation causing the differences noted above.  (This will be discussed in m ore detail in Section 6.1.3)  As noted previously, it would appear that interference is the cause of the inaccurate analyses, but it is not readily apparent as to the interferent causing the problem.  Specifically, there is no apparent significant difference between reported values and associated sites from which the sam ples were collected.  There are  possible exceptions, however, noted for the Puget Sound samples but only descriptive observations.  For example, discounting SRMs, for the Puget Sound site, only 6 of the 11 results reported by Ohio Lumex are considered the same as those from the referee laboratory.  Therefore, there m ay be a significant interference in the Puget Sound samples not present in the other samples.  Upon exam ination of additional data collected for these samples (see Table 6-6), no apparent differences were noted.  For example, a high organic content may cause interference, but not all the Puget Sound samples necessarily have a higher organic content than other samples tested.  In addition, the Method 7471B mercury analysis requires that a non-stannous chloride analysis be conducted with each sample analyzed, in order to test for organic interferences.  Upon examination of the referee laboratory data for the sample sets mentioned above, there was no apparent interference noted in the non-stannous chloride analyses.  

Puget Sound samples also had a higher percentage of moisture for some of the samples analyzed which may help explain these differences.  But this does not explain all differences or all similarities.  There are not enough samples to suggest that this difference is statistically significant.  Other interferences caused by additional elem ents were also not found to be significant.  Of course, there could be interferences that were not tested, and therefore, while it may be an interference (or likely a combination of interferences) particular to a sample lot, the exact cause rem ains unknown.  The reason(s) for these similarities and differences and the reason(s) for the difference between the Ohio Lum ex and referee laboratory results is only specu lative.  In addition to the statistical summary presented above, data plots (Figures 6-1 and 6- 2) are included in order to present a visual interpretation of the accuracy.  

![](images/09659353fd1528baf4fc79a9c28e9562149e01b9fa43af439b21ad48dc3d4379.jpg)  
Figure 6-1.  Data plot for low concentration sample results.  

![](images/177bb6a012b3b5bc89f8e39178c3d167c0c3dc83749e998c50dd23bedaea7f68.jpg)  
Figure 6-2.  Data plot for high concentration sample results.  

Two separate plots have been included for the Ohio Lumex data.  These two plots are divided based upon sam ple concentration in order to provide a more detailed presentation.  Concentrations of samples analyzed by Ohio Lumex ranged approximately from  0.01 to over $200\mathrm{mg/kg}$ . The previous statistical summ ary eliminated some of these data based upon whether concentrations were interpreted to be in the analytical range of the Ohio Lumex field instrument.  This graphical presentation presents all data points.  It shows Ohio Lum ex data com pared to ALSI data plotted against concentration.  Sam ple groups are shown by connecting lines.  Breaks between groups indicate a different set of samples at a different concentration. Sample groups were arranged from lowest to highest concentration.  

As can be seen by this presentation, samples analyzed by Ohio Lumex appear to match well with the ALSI results, with some notable exceptions.  This is only a visual interpretation and does not provide statistical significance. It does however, provide a visual interpretation that supports the previous statistical results for accuracy, as presented above.  

# Unified Hypothesis Test  

SAIC performed a unified hypothesis test analysis to assess the comparability of analytical results provided by Ohio Lumex and those provided by ALSI.   (See Appendix B for a detailed description of this test.)  Ohio Lumex and ALSI both supplied multiple assays on replicates derived from a total o f 33 diff eren t sa m ple lots , wh eth er field materials or reference materials.  The Ohio Lumex and ALSI data from these assays formed the basis of this assessment.  

Results from this analysis suggest that the two data sets are not the same.   The null hypothesis tested was that, on average, Ohio Lumex and ALSI produce the same results within a given sam ple lot.  The null hypothesis is rejected in part because Ohio Lumex results tended to exceed those from ALSI for the same sample lot.  Even when a bias term is used to correct this discrepancy, the null hypothesis is still rejected.  Additional information about this statistical evaluation is included in Appendix B.  

# Accuracy Summary  

In summ ary, Ohio Lumex data were within SRM $95\%$ prediction intervals $93\%$ of t he tim e, w hic h is sta tistic ally equivalent.  ALSI data also compared favorably to SRM values and were within the $95\%$ prediction interval $87\%$ of the time indicating statistical parity found to be biased low.  

The comparison between the Ohio Lumex field data and the ALSI results suggest that the two data sets are not the same.  W hen a unified hypothesis test is perform ed, this result is confirmed.  Ohio Lumex data were found to be both above and below referee laboratory concentrations. The number of Ohio Lumex average values less than $30\%$ different from the referee laboratory results or SRM reference values was 19 of 33 different sam ple lots.  Ohio Lumex results therefore, provide accurate estimates for field determination, and may be affected by interferences not identified by this dem onstration.  Because the Ohio Lumex data compare favorably to the SRM values, the differences between Ohio Lumex and the referee labo rator y are like ly the res ult of m atrix inte rfere nce s.  

# 6.1.3 Precision  

Precision is usually thought of as repeatability of a specific measurement, and it is often reported as RSD.  The RSD is computed from a specified number of replicates.  The more replications of a measurem ent, the higher confidence associated with a reported RSD. Replication of a measurem ent may be as few as 3 separate measurements, to 30 or more measurements of the same sample, depending upon the degree of confidence desired in the specified result.  Most samples were analyzed seven times by both Ohio Lumex and the referee laboratory.  In some cases, samples may have been analyzed as few as three times.  This was often the situation when it was believed that the chosen sample, or SRM, was likely to be below the vendor quantitation limit.  The precision goal for the referee laboratory, based upon pre-demonstration results, is an RSD of $25\%$ or less.  A descriptive evaluation for differences between Ohio Lumex RSDs and the referee laboratory RSDs was  determined.  In Table 6-7, the RSD for each separate sam ple lot is shown for Ohio Lumex compared to the referee laboratory.  The average RSD was then computed for all measurements m ade by Ohio Lumex, and this value was compared to the average RSD for the la bo rator y.  

In addition, the precision of an analytical instrument may vary depending upon the matrix being measured, the concentration of the analyte, and whether the measurement is made for an SRM or a field sample.  To evaluate precision for clearly different matrices, an overall average RSD for the SRMs is calculated and com pared to the average RSD for the field samples.  This comparison is also included in Table 6-7 and shown for both Ohio Lum ex and the referee laboratory.  

The purpose of this evaluation is to determine the field instrument’s capability to precisely measure analyte concentrations under real-life conditions.  Instrument repeatability was measured using samples from each of four different sites.  W ithin each site, there may be two separate matrices, soil and sedim ent.  Not all sites have both soil and sediment matrices, nor are there necessarily high, medium , and low concentrations for each sample site.  Therefore, spiked samples were included to cover additional ranges.  

Table 6-7 shows results from Oak Ridge, Puget Sound, Carson River, and the m anufacturing site.  It was thought that because these four different field sites represented different matrices, measures of precision may vary from site to site.  The average RSD for each site is shown in Table 6-7 and compared between Ohio Lumex  and the referee laboratory.  SRM RSDs are not included in this comparison because SRMs, while grouped with different sites for purposes of ensuring that the samples remained blind during the demonstration, were not actually samples from that site, and were, therefore, com pared separately.  

The RSDs of various concentrations are compared by noting the RSD of the individual sample lots.  The ranges of test samples (field, SRMs, and spikes) were selected to cover the appropriate analytical ranges of Ohio Lumex’s instrumentation.  Average referee laboratory values for sample concentrations are included in the table, along with SRM values, when appropriate.  These are discussed in detail in Section 6.1.2, describing the accuracy evaluation and are included here for purposes of precision comparison.  Sample concentrations were separated into approximate ranges:  low, medium, and high, as noted in Table 6-7 and Table 6-1.  Samples reported by Ohio Lumex as below their approximated PQL were not included in Table 6-7.  There appears to be no correlation between concentration (low, medium, or high) and RSD; therefore, no other formal evaluations of this comparison were perform ed.  

Table 6-7.  Evaluation of Precision   


<html><body><table><tr><td>Sample Lot No. Ohio Lumex and Lab</td><td>Avg. Conc. or Reference SRM Value</td><td>RSD</td><td>Number of </td><td>w/in 25% RSD Goal?</td></tr><tr><td></td><td></td><td>OAK RIDGE</td><td> Samples</td><td></td></tr><tr><td>Lot no. 03</td><td>0.26 (low)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex </td><td></td><td>4.8% </td><td>3</td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>3.8%</td><td>3</td><td>yes</td></tr><tr><td>Lot no. 09</td><td>0.47 (low)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>23.2%</td><td>？</td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>34.2%</td><td>7</td><td>no</td></tr><tr><td>Lot no. 14 </td><td>4.75 (medium)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>32.0% </td><td></td><td>no</td></tr><tr><td>ALSI</td><td></td><td>27.5%</td><td>7</td><td>no</td></tr><tr><td>Lot no. 21</td><td>11.2 (medium)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>23.3%</td><td>3</td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>23.8%</td><td>3</td><td>yes</td></tr><tr><td>Lot no. 24</td><td>221 (high)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>28.0%</td><td>3</td><td>no</td></tr><tr><td>ALSI</td><td></td><td>44.8%</td><td>7</td><td>no</td></tr><tr><td>Lot no. 26</td><td>77.0 (high)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>2.6%</td><td>3</td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>13.2%</td><td>7</td><td>yes</td></tr><tr><td>Lot no. 37</td><td>0.14 (low)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>5.0%</td><td></td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>36.4%</td><td>7</td><td>no</td></tr><tr><td>Lot no. 44</td><td>2.33 (medium)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>3.0% </td><td></td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>59.4%</td><td>7</td><td>no</td></tr><tr><td>Lot no. 60 </td><td>165 (high)</td><td></td><td></td><td></td></tr><tr><td> Ohio Lumex</td><td></td><td>23.8%</td><td></td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>30.9%</td><td>7</td><td>no</td></tr><tr><td>Oak Ridge Avg. RSD</td><td></td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>19.7%</td><td></td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>25.5%</td><td></td><td>no</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td>PUGETSOUND</td><td></td><td></td></tr><tr><td>Lot no. 02</td><td>0.06 (low)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>43.9%</td><td>?</td><td>no</td></tr><tr><td>ALSI</td><td></td><td>23.6%</td><td>7</td><td>yes</td></tr><tr><td>Lot no. 05</td><td>0.21 (low)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>9.4%</td><td>3</td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>33.3%</td><td>3</td><td>no</td></tr><tr><td>Lot no. 08</td><td>0.36 (low)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>14.2%</td><td></td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>13.4%</td><td>7</td><td>yes</td></tr><tr><td>Lot no. 10</td><td>0.55 (low)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>120%</td><td>3</td><td>no</td></tr><tr><td>ALSI</td><td></td><td>20.5%</td><td>3</td><td>yes</td></tr><tr><td>Lot no. 11 </td><td>0.81 (low)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>14.2%</td><td></td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>32.7%</td><td>7</td><td>no</td></tr><tr><td>Lot no. 12</td><td>1.08 (medium)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex </td><td></td><td>7.1% </td><td>3</td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>2.8%</td><td>3</td><td>yes</td></tr><tr><td>Lot no. 25</td><td>16.6 (high)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex </td><td></td><td>12.4%</td><td>3</td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>12.3%</td><td>3</td><td>yes</td></tr><tr><td>Lot no. 34</td><td>11.3 (medium)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex </td><td></td><td>24.7%</td><td>3</td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>22.4%</td><td>7</td><td>yes</td></tr></table></body></html>  

<html><body><table><tr><td>Table 6-7. Continued Sample Lot No. Ohio Lumex</td><td>Avg. Conc. or Reference</td><td>RSD</td><td>Number of </td><td>w/in 25% RSD Goal?</td></tr><tr><td>and Lab Lot no. 36</td><td>SRM Value 0.073 (low)</td><td></td><td>Samples</td><td></td></tr><tr><td>Ohio Lumex </td><td></td><td>4.9%</td><td></td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>6.7%</td><td>3７</td><td>yes</td></tr><tr><td>Lot no. 57</td><td>0.73 (low)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>11.2% </td><td></td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>16.2%</td><td>7７</td><td>yes</td></tr><tr><td>Lot no. 61</td><td>154 (high)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>47.0%</td><td></td><td>no</td></tr><tr><td>ALSI</td><td></td><td>10.9%</td><td>7</td><td>yes</td></tr><tr><td>Lot no.62</td><td>14.6 (high)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>13.0% </td><td></td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>28.3%</td><td>7７</td><td>no</td></tr><tr><td>Puget Sound/ Avg. RSD</td><td></td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex </td><td></td><td>28.8%</td><td></td><td>no</td></tr><tr><td>ALSI</td><td></td><td>19.7%</td><td></td><td>yes</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td>CARSONRIVER</td><td></td><td></td></tr><tr><td>Lot no. 01</td><td>0.24 (low)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>30.5%</td><td>7</td><td>no</td></tr><tr><td>ALSI</td><td>0.11 (low)</td><td>37.7%</td><td>7</td><td>no</td></tr><tr><td>Lot no. 04</td><td></td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>18.9% </td><td>3</td><td>yes</td></tr><tr><td>ALSI</td><td>0.26 (low)</td><td>9.1%</td><td>7</td><td>yes</td></tr><tr><td>Lot no. 06</td><td></td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>7.3%</td><td>3</td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>15.7%</td><td>7</td><td>yes</td></tr><tr><td>Lot no. 38</td><td>0.63 (low)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>3.5%</td><td>?</td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>3.8%</td><td>7</td><td>yes</td></tr><tr><td>Lot no. 39</td><td>1.24 (medium)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>6.5%</td><td>7</td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>52.9%</td><td>7</td><td>no</td></tr><tr><td>Lot no. 41</td><td>1.79 (medium)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>17.5%</td><td>7</td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>30.5%</td><td>7</td><td>no</td></tr><tr><td>Lot no. 43</td><td>2.76 (medium)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex </td><td></td><td>9.1% </td><td>7</td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>9.6%</td><td>7</td><td>yes</td></tr><tr><td>Lot no. 56</td><td>0.23 (low)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex ALSI</td><td></td><td>8.0%</td><td>7</td><td>yes</td></tr><tr><td>Lot no. 59</td><td>1.71 (medium)</td><td>12.6% </td><td>7</td><td>yes</td></tr><tr><td>Ohio Lumex</td><td></td><td></td><td>?</td><td></td></tr><tr><td>ALSI</td><td></td><td>10.2%</td><td></td><td>yes</td></tr><tr><td>Carson River/ Avg. RSD</td><td></td><td>7.9%</td><td>7</td><td>yes</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>15.0%</td><td></td><td>yes</td></tr><tr><td>ALSI</td><td></td><td>16.6%</td><td></td><td>yes</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td colspan="2">MANUFACTURINGSITE</td><td></td><td></td></tr><tr><td>Lot no. 13</td><td>5.91 (medium)</td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex</td><td></td><td>51.9%</td><td>7</td><td>no</td></tr></table></body></html>



<html><body><table><tr><td>Lot no. 13</td><td colspan="4">5.91 (medium)</td></tr><tr><td> Ohio Lumex</td><td></td><td>51.9%</td><td>7</td><td>no</td></tr><tr><td>ALSI</td><td></td><td>15.4%</td><td>7</td><td>yes</td></tr><tr><td>Lot no. 17</td><td>10.5 (high)</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex ALSI</td><td></td><td>24.2%</td><td>3 7</td><td>yes</td></tr><tr><td>Lot no. 45</td><td>5.44 (medium)</td><td>14.6%</td><td></td><td>yes</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td> Ohio Lumex</td><td></td><td></td><td></td><td></td></tr><tr><td>ALSI</td><td></td><td>1.6% 23.4%</td><td>7 6</td><td>yes yes</td></tr></table></body></html>  

<html><body><table><tr><td>Table 6-7. Continued Sample Lot No. Ohio Lumex and Lab</td><td>Avg. Conc. or Reference SRMValue</td><td>RSD</td><td>Number of Samples</td><td>w/in 25% RSD Goal?</td></tr><tr><td>Manufacturing Site/ Avg. RSD Ohio Lumex ALSI</td><td></td><td>38.0 % 15.0%</td><td></td><td>no yes</td></tr><tr><td></td><td colspan="4">SUMMARYSTATISTICS</td></tr><tr><td>Overall Avg. RSD</td><td></td><td></td><td></td><td></td></tr><tr><td>Ohio Lumex ALSI</td><td></td><td>16.1% 22.3%</td><td></td><td>yes yes</td></tr><tr><td>Field Samples/ Avg. RSD Ohio Lumex ALSI</td><td></td><td>24.3% 20.3%</td><td></td><td>yes yes</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td>SRMs/ Avg.RSD Ohio Lumex ALSI</td><td></td><td>8.0% 24.3%</td><td></td><td>yes yes</td></tr></table></body></html>  

The referee laboratory analyzed replicates of all samples analyzed by Ohio Lumex.  This was used for purposes of precision comparison to Ohio Lumex.  RSD for the vendor and the laboratory were calculated individually and shown in Table 6-7.  

As noted from Table 6-7, Ohio Lumex precision is similar to that of the referee laboratory.  The single most important measure of precision provided in Table 6-7, overall average RSD, is $22.3\%$ for the referee laboratory compared to the Ohio Lumex average RSD of $16.1\%$ .  The laboratory and Ohio Lumex RSD are both within the $25\%$ RSD objective for precision expected from both analytical and sampling variance.  

In addition, field sample precision compared to SRM precision shows that there may be some difference between these two sample lots; field sam ple RSD is $20.3\%$ for ALSI and $24.3\%$ for Ohio Lumex;  SRM RSD is $24.3\%$ for ALSI and $8.0\%$ for Ohio Lumex.  This is similar to the results for the accuracy comparison.  Ohio Lum ex appears to have better precision for the SRM analyses than for the field sam ple analyses.  For purposes of this analysis, spiked samples are considered the same as field samples because these were similar field matrices and the resulting variance was expected to be equal to that of field samples. The replicate sample RSDs also confirm the predem onstra t io n r e s u lt s , s h o w i n g t h a t s a m p l e homogenization procedures met their originally stated objectives.  

There appears to be no significant site variation between Oak Ridge, Puget Sound, and the m anufacturing site samples.  (See Table 6-7 showing average RSDs for each of these sample lots.  These average RSDs are computed using only the results of the field samples and not the SRMs.)  The Carson River site had a lower average RSD for both the vendor and the laboratory, but this difference may not be significant because this same result was not evident in the data comparisons perform ed for other data sets.  

# Precision Summary  

The precision of the Ohio Lumex  field instrument is better than the referee laboratory precision.  The overall average RSD is $22.3\%$ for the referee laboratory, compared to the Ohio Lumex average RSD of $16.1\%$ . T his is p rim ar ily because of the better precision obtained for the SRM analyses by Ohio Lumex.  Both the laboratory precision and the Ohio Lumex precision goals of $25\%$ overall RSD were achieved.  

# 6.1.4 Time Required for Mercury Measurement  

During the demonstration, the time required for mercury measurem ent activities was measured.  Specific activities that were timed included: instrument setup, sample analysis, and instrum ent disassembly.  One field technician performed all operations during the demonstration, with the exception of instrum ent setup and tear down, plus a sm all amount of sample preparation activities. A second operator assisted with these items.  

Setup and disassemble times were measured one time. Analytical time was m easured each day, beginning when the first blank was started, and continuing until the last blank was completed at the end of the day.  Any downtime was noted and then subtracted from the total daily operational time.  The total of the op eratio na l tim e fr om  all four days was divided by the total number of analyses performed.  For this calculation, analyses of blanks and calibration standards, and reanalyses of samples were not included in the total number of samples.  

Setup time for the RA-91 $5+$ /RA-91C consisted of removing the instrument from the shipping container, placement on a level working surface, establishment of all electrical and gas tubing connections, and instrument warm-up.  The time required to remove the RA-91 $^{5+}$ /RA-91C from the shipping container could not be m easured precisely because the device was removed from the shipping container before the evaluation team could time these activities; however, the vendor did replicate the majority of this process at the request of the evaluator, so that a tim e estim ate could be made.  Based on these observations, it is estimated that one person could remove the device from the shipping container in 15 minutes.  Setup time for other peripheral devices, such as the computer/m onitor and analytical balance, was accomplished during the instrument warm-up time. Leveling of the balance, depending on field conditions, took between 5 and 10 minutes.  Setup of the computer/monitor took less than 5 minutes.  

After all devices were set in place, remaining electrical and gas f lo w connections had to be made. The RA- $915+/\mathsf{R P-91C}$ was connected to a power source and to the com puter/monitor.  The balance was also connected to the power source, but not to the computer/monitor.  Gas connections had to be made from the auxiliary pump, through a flip-up flow gauge, and then to the instrument. A mercury trap came pre-assembled and already inserted in the vent line which was attached to the instrum ent. Overall, the electrical and gas flow connections required 10 minutes.  

After initial setup of the RA-915+/RP-91C was com plete, the instrument required approximately 45 to 60 minutes to warm to $800^{\circ}\mathsf{C}$ .  It is worth noting that setup of the balance and computer/monitor were performed during this tim e period.  

O ve rall, the tim e req uired to rem ove the ins trum ent fro m its shipping container, setup the device, allow the instrument to reach operating temperature, and setup peripheral devices during instrument warm-up is estimated at approximately 60 to 75 minutes.  

Individual sample analysis times were not measured for the duration of the demonstration. Analysis time was estimated by recording start and stop times each day, and accounting for any instrument downtime due to operator breaks or device failure and m aintenance activities. Therefore, the total time for analyses included blanks, calibration standards, and any sample reanalyses; however, the total number of analyses performed includes only demonstration samples (sam ples, spikes, and SR Ms), not vendor blanks, calibration standards, or reanalyses. Table 6-8 presents the time m easurements recorded for each of the four days of operation of the RA- $915+/\mathsf{R P-91C}$ . It should be noted that the second technician was required approximately $25\%$ of the tim e in order to achieve the sample throughput observed during the dem onstration, and that the times in Table 6-8 are lapse times not labor times.  

Table 6-8.  Time Measurements for Ohio Lumex   


<html><body><table><tr><td>Day</td><td>Day 1</td><td>Day 2</td><td>Day 3</td><td>Day 4</td><td>Total 4-Day</td></tr><tr><td>Run Time (minutes)</td><td>195</td><td>540</td><td>540</td><td>0</td><td>1,275</td></tr></table></body></html>  

# Analysis Time Summary  

In total, Ohio Lumex analyzed 197 samples during the demonstration.  The turnaround time on individual sample analyses was 1 minute; however, the vendor chose to analyze replicates of virtually every sample.  Using the total analytical time reported in Table 6-8 and factoring in the second analyst (1275 m inutes x 1.25 analysts), 8.1 minutes per analysis is a better approxim ation of real world operating conditions (assuming that replicate analyses are performed).  The vendor claims that 25 samples can be processed in an hour over an 8-hour day, an average of 2.4 minutes per sample, if replicates are not performed.  Field observations support this claim .  

The number of blanks, standards, and reanalysis of samples outside of the calibration range will vary from site to site, depending on project goals (e.g., are “greater than” results acceptable or must all samples be quantified) and site conditions (e.g., high concentration samples or very heterogeneous samples).  If project goals require all samples to be quantified, the number of reanalyses and blanks required could be higher and, therefore, the tim e per analysis could be greater.  If on the other hand, sample results can be reported as “greater than” values (as was generally done during the dem onstration), then 6.5 minutes per analysis is a reasonable average time.  

Instrument disassembly was m easured from  the time that the last sample or blank analysis ended until the instrument was disassembled and placed in the original shipping container.  Disassembly involved turning off power, disconnecting the power source and interface cables to the com puter/monitor, and removal of the auxiliary pum p unit. Packaging involved placing these components in wheeled shipping cases.  It is estim ated that this complete process would take one person approximately 30 minutes to complete.  

# 6.1.5 Cost  

Background inform ation, assum ptions used in the cost analysis, demonstration results, and a cost estimate are provided in Chapter 7.  

# 6.2 Secondary Objectives  

This section discusses the performance results for the RA- $915+$ , along with the RP-91C attachment for soils, in terms of the secondary objectives described in Section 4.1. These secondary objectives were addressed based on observations of the RA- $915+$ and RP-91C combination and inform ation provided by Ohio Lumex.  

# 6.2.1 Ease of Use  

Documents the ease of use, as well as the skills and training required to properly operate the device.  

Based on observations made during the d e m o n s t ra t io n , t h e $\mathsf{R A}{-}915{+}/\mathsf{R P}{-}91\mathsf{C}$ is reasonably easy to operate; lack of automation somew hat impairs the ease of use.  Operation requires one field technician with a basic knowledge of chemistry acquired on the job or in a university and training on the instrument.  

Six major elements were addressed in evaluating the ease of use:  

Usefulness of Standard Operating Practices (SOPs)  

Operator training and experience required   
Ease of equipment setup   
Ease of calibration   
Ease of sample preparation   
Ease of measurement  

Each of these is described, in sequence, in the following paragraphs.  Five of the six elements were given a subjective rating - excellent, good, fair, and poor - based on observations made by the instrument evaluator.  Operator training and experience in merely discussed.  

The vendor provided two SOPs, one entitled “RA-915+ Mercury Analyzer” and the other entitled “RP-91C Attachment.”  These procedures were evaluated during the dem onstration.  

The RA- $915+$ procedure provides the following information:  

Comprehensive safety guidelines   
Equipment list with corresponding images   
Equipment application, including applicable media,   
detection limits, sample parameters, and detection   
technique   
Technical specifications and operating conditions   
Design and operation of the analyzer, including a   
schematic   
Description of the appearance and functions of the   
equipment from all angles   
Pre-operational procedures such as setup and   
selection of operational mode   
Operational procedures for the display unit and for   
connection to a personal computer   
Detailed equipment test and maintenance procedures   
Troubleshooting guide  

The SOP was well-organized, covered major information requirements, and was easy to understand.  The safety precautions were thorough and well-documented.  The parts and equipment list covered all required parts for use of the $\mathsf{R A-}915+$ .  The table clearly presented various applications and related data, including the need for ancillary equipment for water and soil analyses.  Equipment specifications matched those documented during the demonstration.  The schematics and discussion of system design and operational principles were well written.  They provided a thorough description of the operational principle for the technology, easily understood by someone unfamiliar with the technology.  The description of appearance and functional controls was also useful for novices with the equipment.  Similarly,  the detailed preoperational procedures were generally clear and comprehensive, allowing an operator with training on the basics of the equipment to setup and operate the RA- $915+$ . A step-by-step evaluation of the procedure could not be performed without impacting  the evaluation of analytical throughput (see Section 6.1.4).  Finally, the troubleshooting table was easy to follow; however, there was no opportunity to evaluate the table, for accuracy or completeness, during the demonstration.  

The SOP for the RP-91C was written in a  manner similar to the SOP for the RA- $915+$ .  The RP-91C SOP was equally clear and thorough.  Adequate detail was provided to assist an inexperienced operator in equipment setup, calibration, operation, troubleshooting, and maintenance. The only maintenance activity that was performed during the demonstration was replacement of the optical lense. The procedure provides adequate information for a technician to perform  this m aintenance activity.  

There were two crucial operational elem ents encountered during the demonstration that were not adequately addressed in the RP-91C SOP.  The first was the selection of sample size such that the results remain within the calibration range.  The SOP instructs the user to use a sample mass such that the mass of m ercury is less than 1 :g; however, selection of sample size requires an estim ate of the expected mercury concentration. This problem is not unique to the RA- $915+/\mathsf{R P-91C}$ ; any AA instrument requires an estimate of sam ple concentration to obtain sam ple results within a specified calibration range. Second, no information was provided on how to handle samples that were outside of the calibration range. Procedures implemented during the demonstration included analyzing a blank sample after a sample was above the calibration range (to purge the system of mercury) and reducing sample size on subsequent reanalyses (if quantitative results are reported).  These procedures were not described in the SOP; however, the software provided the following prompt: “OUT OF RANGE”. It is not known whether the analyst is trained to analyze a clean-out blank following this prompt.  The specific content of the training course is not known.  

Ohio Lumex provides a 1-day training course for an additional cost of $\$600$ to anyone who purchases, rents, or leases the RA- $915+/\mathsf{R P-9}1\mathsf{C}$ .  The vendor asserts that this is a 6-hour, com prehensive course covering software and hardware installation, and operational training on use of the instrument for soil analysis.  The training course was not evaluated during the demonstration.  It may supplement the SOPs.  Overall, the SOPs were good, but could use additional detail related to sample size selection and results outside of the calibration curve.  

Ohio Lumex chose to operate the $\mathsf{R A}{-}915{+}/\mathsf{R P}{-}91\mathsf{C}$ with one chemist during the demonstration.  The chem ist held a Ph.D . in chemistry.  Ohio Lumex claims that a laboratory or field technician with a high school diploma and basic computer knowledge can operate the equipment after a 1-day training course on the instrument.  Field observations support this claim.  Most operations required either use of a keyboard or mouse with a Microsoft W indows-based system.  The prompts were clear and easy to understand.  

The operator performed equipment setup with ease.  The RP-91C connected rapidly and easily to the RA- $915+$ .  The unit plugged into a power supply and an interface with the PC.  The external air pump and flow meter (used with the RP-91C) were encased in a metal box with a hinged lid. The lid was opened, the flow meter (rotometer) was hinged upward into a vertical position, and the pump was connected to the rotom eter with plastic tubing that comes with the unit.  The self-standing balance was easily setup and leveled.  

It was difficult to determine exactly how much time was required for setup because a second vendor representative helped with setup to expedite the process.  Typically, the two vendor representatives setup the equipment in 5 minutes (the instrument was already unpacked from its shipping case).  Field observations indicate that one person could setup all required equipment, starting with shipping containers, in approximately 30 minutes, perhaps less in some cases.  It should be noted that once instrument setup is complete, furnace warm-up requires 45-60 minutes to reach the operating temperature of 800 $^{\circ}\mathsf{C}$ .  There was no display indicating actual furnace temperature; the operator merely observed the inner lining of the furnace.  W hen it achieved a red glow, the furnace was deemed hot enough for operation.  Overall, the ease of setup was good, with the only drawback being the extended warm-up tim e for the instrum ent.  

Calibration was performed by the operator alone.  A blank was analyzed and a 2-point calibration performed in less than five minutes.  The RP-91C SOP (p13) recommended three to four calibration points.  Calibration consisted of weighing the standard(s) and analyzing them  according to the steps in the SOP.  A calibration curve was plotted and, if acceptable, the calibration coefficients were accepted. Overall, the ease of calibration was good.  

The operator was able to perform sample preparation and analysis on a continuous basis.  Sample preparation took less than one minute per sample, on average, although some minor assistance was performed by a second vendor representative.  In general, sample preparation was unwieldy, increasing the potential for lost sample or weighing errors.  

Sample preparation consisted of preparing small pieces of aluminum foil (approximately 5-8 cm squares) for weighing soil samples.  Several times during the dem onstration, a second vendor representative assisted with this task.  The samples were initially mixed in the original container, using a clean quartz weigh boat.  Approximately one half of the sample was transferred to the aluminum foil, which was then placed on the digital balance.  The balance was zeroed with the sample and foil, which were then removed from the balance.  A sm all amount of sample was then transferred to a clean, quartz weigh boat.  Sample transfer was completed by dipping the quartz cup of the weigh boat into the soil and scooping a small quantity into the bowl. Each weigh boat was equipped with an insulated plastic handle to allow safe handling of the weigh boat immediately after heating.  

The balance was placed at ground level, inside a cardboard box (a standard file storage box with dimensions of $30~\mathsf{c m}$ wide by $40\ \mathsf{c m}$ long by 30 cm deep) to shield the balance from wind effects.  The balance had a hinged top cover with a 5-cm , transparent portal for convenient viewing of the sample; however, each time a sam ple was inserted or removed, the lid had to be opened and then closed.  The operator sat in a chair alm ost continuously during the demonstration so as to be able to reach the balance and the sam ple injection port in alternating steps. The location of the balance on the ground was required because of the top-opening mechanism on the balance. Inserting and removing samples through the hinged top and the box opening required great care.  Each time the operator took a short break, it was clear that he was stiff from working in a sitting position on a continuous basis.  

An aluminum foil square with soil sample was placed on the balance (the balance is not part of the system, but can be provided), the balance was zeroed (tare weight), the aluminum foil with sample was removed from the balance, and a sm all amount of the sam ple was placed in the weigh boat.  The alum inum foil and residual sample were placed on the balance again (gross weight).  The difference between the tare weight (zero) and the gross weight (a negative number) was the net weight used for the analysis. This weight was m anually calculated and recorded in the instrument data entry panel using the keyboard. This operation was relatively easy to understand and could be performed by a trained technician.  However, there were opportunities for spilling residual sample after weighing or improperly calculating or entering net weight data.  Sample weights can be determined by recording a tare weight for the weigh boat, adding sample, and recording a gross weight (the difference being the net weight).  In this way, use of alum inum foil can be eliminated.  The same issues remain with manual calculations and data recording.  

Sample analysis took less than 1 minute per sample. Because of the lack of automation in the process, the operator was constantly busy weighing samples, recording and entering weights, inserting and rem oving weigh boats from the RP-91C, or recording analytical results.  It should be noted that the operator always analyzed duplicate samples and, oftentim es, analyzed triplicates to ensure good analytical precision.  

As samples were analyzed, vendor-proprietary software screens allowed the user to track the sample adsorption curve on the screen and know when the analysis was completed (see Figure 6-3).  The software is compatible with W indows 95, 98, or 2000, and can export data to Microsoft Excel.  Sample analysis consisted of inserting the pre-weighed sample boat in the small opening in the furnace, watching the adsorption curve to show the analysis was completed, and removing the sample weigh boat.  Sample analysis was easy to understand and could be performed by a trained technician.  

During the demonstration, samples with concentrations outside of the equipment calibration range were encountered.  These samples would result in a peak that was above the top end of the calibration range. The operator was required to analyze a blank to demonstrate that excess mercury had been purged from the system; an “OUT OF RANGE” screen prompt advised the operator that the sam ple was not in the calibration range.  

The digital balance was the major peripheral item.  The vendor will supply a balance, or the user can supply his/her own balance.  Though the balance is not part of the required vendor equipment, a balance is a necessary peripheral.  Therefore, the balance was evaluated during the dem onstration.  The reader should note that other brands and models of balances may be used and these may not perform in the same m anner as the balance used during the demonstration.  The balance itself was easy to use, but the lack of an automatic interface with the monitor/software made the overall system  more difficult to operate and increased the potential for error.  

![](images/b85924bb015dc2353137c5c176895dfb6845a213d81abb321729ae338ff8badd.jpg)  
Figure 6-3.  RA-915+/RP-91C peak screen.  

# 6.2.2 Health and Safety Concerns  

Documents potential health and safety concerns associated with operating the device.  

No significant health and safety concerns were noted during the demonstration. The only potential health and safety concerns identified were the generation of mercury vapors and the potential for burns with careless handling of hot quartz sample boats.  The vendor provides a mercury filter as standard equipment; exercising caution and good laboratory practices can mitigate the potential for burns.  

Health and safety concerns, including chemical hazards, radiation sources, electrical shock, explosion, and mechanical hazards were evaluated.  

No chem icals were used in the preparation or processing of samples, except for analytical standards.  During this demonstration, the analytical standards were soil SRMs for mercury.  These were handled with gloves, and the operator wore safety glasses at all times.  Such standard laboratory precautions mitigate the potential for dermal exposure.  Sim ilar procedures were also used for soil samples which contained mercury.  Because the RP-91C attachment is designed to thermally convert m ercury compounds to mercury vapors as part of the analytical process, and no fume hood was present to exhaust mercury vapors after analysis, inhalation of mercury was a concern.  The vendor installs a proprietary mercury trap in the exhaust line from  the RP-91C attachment. Measurem ents were taken with a Jerom e 431-x gold film mercury vapor analyzer manufactured by Arizona Instruments Corporation.  The instrument has a range of 0.000 to $0.999\mathrm{~}\dot{\mathsf{m}}\mathsf{g}/\mathsf{m}^{3}$ .  In all cases, readings were 0.000 $\mathsf{m g}/\mathsf{m}^{3}$ in the breathing zone of the operator.  

In looking at electrical shock potential, two factors were evaluated: 1) obvious areas where electrical wires are exposed and 2) safety certifications. No obviously exposed wires were noted during the demonstration. All connections between equipment were made using standard electrical power cords, modem  interface lines, and 8-pin cords.  Power cords were grounded and a surge protector (provided by EPA) was utilized.  The RA- $915+$ line voltage (110 volts AC) was stepped down to 12 volts (DC) at 2.5 amps using a power transformer.  The RA- $915+$ was UL, SA, and CE certified, among other certifications marked on the transformer.  The balance utilized during the demonstration was a KND 1-microgram, digital balance, model FX-320.  It operated on a 12-volt DC (at 0.3amps) power source that was stepped down from 110 volts and 7.5 am ps.  This device had no visible certifications.  A standard laptop computer was used (Hewlett Packard Pavilion, model HP F145A). This computer had UL, CE, and numerous other certifications.  

No obvious explosion hazards were noted.  The use of ambient air as a carrier gas eliminates the possibility of explosion associated with the use of oxygen as a carrier gas in the presence of ignition sources.  

No serious mechanical hazards were noted during the demonstration.  All equipment edges were smooth, minimizing any chance of cuts or scrapes.  The hinged lid on the RP-91C pump/rotometer housing presents the possibility of a pinch hazard, as would any hinged device; however, the lid is very light weight, remained opened throughout the demonstration, and is designed to rem ain securely in place when the lid is open.  

# 6.2.3 Portability of the Device  

# Documents the portability of the device.  

The RA- $\bullet15+$ air analyzer was easily portable, although the device, even w hen carried in the canvas sling, was not considered light-weight. The addition of the RP-91C and associated pump unit preclude this from being a truly field portable instrum ent. The device and attachm ents can be transported in carrying cases by two people, but must then be setup in a stationary location.  It was easy to setup, but the combined instrument is better characterized as mobile rather than field portable.  

The RA- $915+$ measured 46 cm (L) by 11 cm (W ) by 21 cm (H).  The weight was reported as $7.5~\mathsf{k g}$ .  The RP-91C attachment measures 32 cm by $24\ c m$ by 12 cm and weighs $5.5~\mathsf{k g}$ .  Also included as a standard feature with the RP-91C were a monitor,  keyboard and mouse; and the pump/rotometer case.  All were light weight and easily portable, with the pump and rotometer enclosed in a metal carry case with a handle.  Remote locations also require the use of a generator or 12-volt battery.  

The RA-915+/RP-91C was not easily portable from the standpoint of being a handheld instrument.  Movement and setup of the equipment generally took two people about 10 minutes, with the equipment already unpacked.  It is estimated that one person would require approximately 30 minute to unpack the instrument from the carrying case and complete setup.  The RA- $915+$ air analyzer was easily portable, although the device, even when carried in the canvas sling, was not lightweight.  The addition of the RPD91, pump unit, and battery preclude this from being a truly field portable instrument.  The device and attachments can be transported by carrying two containers with handles, plus the RP-91C attachment, the monitor/mouse, power cords/transformers, and data cables (plus an analytical balance).  Even when placed in wheeled shipping containers, the device is only portable in the sense that it can be managed in a manner similar to wheeled luggage. Transport in paved areas is easy; transport up a rocky incline would be difficult.  The device is, however, easily transportable in  any size vehicle, and can be moved to any location where a vehicle can go.  Therefore, it would be practical for many field applications.  It should not be characterized as a handheld instrument.  During the demonstration, the complete soil analytical unit, including the monitor and air pump, easily fit on a table measuring 30 inches wide by 72 inches long, with adequate space for sample staging and preparation.  

The balance required a flat, stable surface.  Because the balance was top loaded, the vendor chose to place the balance on the ground near the chair in which the operator sat.  The balance was placed inside of a cardboard box to eliminate the effects of wind on the enclosed balance.  This setup required the operator to repeatedly bend over to tare the sample (on aluminum foil) and again after the analytical sam ple was removed in the sam ple boat.  

The RA-91 $5+$ /RP-91C was operated using a 12-volt battery during the Visitors’ Day.  The unit appeared to operate well, although no samples were being processed for evaluation and no evaluation was made of the amount of time the battery lasted.  The vendor reports a battery life of approximately 3.5 hours.  Alternatively, a standard electrical source of 110 volts can be utilized. Power can be supplied by any standard 2,000 watt generator.  

For the demonstration, the vendor was supplied with a folding table, two chairs, and a tent to provide shelter from inclement weather.  In addition, one 1-gallon container each was provided for waste soil and decontamination water utilized to clean weigh boats.  A 2-gallon zip-lock bag was furnished for disposal of used gloves, wipes, and other wastes which were contaminated during the demonstration. Finally, a large trash bag was supplied for disposal on noncontaminated wastes.  

# 6.2.4 Instrument Durability  

Evaluates the durability of the device based on its materials of construction and engineering design.  

The RA-915+/RP-91C was well designed and constructed for durability.  

The outside of the $\mathsf{R A-}\mathsf{9}15+$ is constructed of sturdy aluminum ( $2\mathsf{m m}$ thickness) that was painted to prevent corrosion.  The exterior of the RP-91C furnace is stainless steel; the interior is quartz.  The furnace is covered by a painted metal guard to prevent burns.  The auxiliary air pump and rotometer were housed in a sturdy, painted aluminum box $2{\mathsf{m m}}$ thickness).  The lid of this container was secured with hinges, and was opened when the rotometer was setup for operation.  No environm ental (e.g., corrosion) or m echanical (e.g., shear stress or im pact) tests were perform ed; however, the outer shell of the instrument was well-designed and constructed, indicating that the device would likely be durable under field conditions.  

No evaluation could be made regarding the long-term dura bility of the furnace , an alytic al c ell, o r circuitr y. External visual inspection did not indicate that any problems were likely, although many parts were obscured from view.  The vendor offers a standard 1-year warranty, and will provide a 1-year extended warranty and maintenance plan at the owner’s cost.  This warranty cost $\$2,400$ , and covers all parts and labor except consumable items (lam p, rechargeable battery for the RA- $915+$ , and filters).  T he o nly m ec ha nic al p art with the po ten tial to fail over time is the air pump.  Long term operation could result in the need for repair or replacement of the air pump.  The heating element of the furnace is the other part with some potential for long term failu re, alth ough it worked pro perly during the dem onstration.  Plastic tubing for the rotometer may also be subject to long term failure due to the effects of sun and tem perature or m echanical failure.  Overall, however, the design and construction of the instrument support the vendor claim  that this instrument is durable. The vendor asserts that life expectancy of the furnace and air pump is 3-5 years with heavy use.  

Finally, most of the demonstration was performed during rainfall events ranging from steady to torrential.  The instrument was located under a tent with side flaps to protect it from ra inf all.  Even when it was not raining, the relative humidity was high.  The high humidity and rainfall had no apparent impact on the reliability of the instrument operation.  

# 6.2.5 Availability of Vendor Instruments and Supplies  

Documents the availability of the device and spare parts.  

The RA-915+/RP-91C is readily available for rental, lease, or purchase.  Spare parts and consumable supplies can be added to the original instrument order or can be received within 24-48 hours of order placement. Standards are readily available from laboratory supply firms or can be acquired through Ohio Lumex.  

EPA representatives contacted Ohio Lumex regarding the ava ilability of the $\mathsf{R A}{-}915{+}/\mathsf{R P}{-}91\mathsf{C}$ and supplies. According to Ohio Lumex, such system s are available within a few weeks of order placement, but can be expedited.  The RA- $915+/\mathsf{R P-91C}$ also is available for rental or leasing and lead time is subject to availability.  

The instrument comes standard with four quartz-sam ple injectors; no other parts or consumable supplies are provided standard with the equipment.  Spare parts, such as the furnace, furnace lenses, the air pump, or additional sample injectors, can be ordered individually.  These and any other parts are available within 24-48 hours. Standards can be provided by Ohio Lumex or can be purchased from a laboratory supply firm.  

# Chapter 7 Economic Analysis  

The purpose of the economic analysis was to estimate the total cost of mercury measurem ent at a hypothetical site. The cost per analysis was estim ated; however, because the cost per analysis would decrease as the number of samples analyzed increased, the total capital cost was also estimated and reported.  Because unit analytical costs are dependent upon the total number of analyses, no attempt was made to compare the cost of field analyses with the RA- $915+/\mathsf{R P-91C}$ to the costs associated with the referee laboratory.  “Typical” unit cost results gathered from analytical laboratories were reported to provide a context in which to review the RA-91 $5+$ /RP-91C costs.  No attempt was made to make a direct comparison between these costs because of differences in sample throughput, overhead factors, total equipment utilization factors, and other issues that make a head-to-head comparison im practical.  

This chapter describes the issues and assumptions involved in the econom ic analysis, presents the costs associated with field use of the RA $.915+/\mathsf{R P-91C}$ , and presents a cost sum mary for a “typical” laboratory performing sample analyses using the reference method.  

# 7.1 Issues and Assumptions  

Several factors can affect mercury measurement costs. W herever possible in this chapter, these factors are identified in such a way that decision-makers can independently com plete a project-specific economic analysis.  Ohio Lum ex offers three options for potential RA- $915+/\mathsf{R P-91C}$ users: 1) purchase of the instrument, 2) weekly rental, and 3) equipment leasing with an option to purchase. Because site and user requirements vary significantly, all three of these options are discussed to provide each user with the inform ation to make a case-bycase decision.  

A more detailed cost analysis was performed on the equipment rental option because this case represents the most frequently encountered field scenario.  The results of that cost analysis are provided in Section 7.2  

# 7.1.1 Capital Equipment Cost  

The RA-91 $5+1$ RP-91C com es com plete with the analytical instrument $(\mathsf{R A-915+})$ , furnace attachment and auxiliary air pump/flow meter (RP-91C), a set of 4 quartz injection spoons with ceramic handles, and software, regardless of whether the instrument is purchased, rented, or leased.  An optional digital balance is available for purchase, rental, or lease from Ohio Lumex, but not included in the base cost of any of these three options because the user may provide his/her own balance.  Because there is no output signal link between the balance and the system, any balance can be used.  A laptop computer with display screen can be purchased, rented, or leased from Ohio Lumex or can be provided by the user.   A user-supplied printer can also be attached to the system using a standard printer cable; no purchase, lease, or rental option is available for the printer.  

The cost quoted by Ohio Lumex does not include packaging or freight costs to ship the instrument to the user location.  No deposit is required for rental and lease agreements.  A user m anual is provided at no cost.  A 6-hour training session is available for an additional fee.  

# 7.1.2 Cost of Supplies  

The cost of supplies was estimated based on the supplies required to analyze demonstration samples and discussions with Ohio Lumex. Requirements vary depending on whether solid or liquid samples are being analyzed.  For purposes of this cost estimate, only supplies required to analyze solid samples are factored into the cost estim ate because only solid samples were analyzed during the demonstration.  Supplies required for liquid samples are not noted because a different analytical attachment is used.  Supplies consisted of consumable items (e.g., calibration standards, mercury trap) and non-consumables that could not be returned because they were contaminated or the remainder of a set (e.g., quartz injection spoons). The purchase prices and supply sources were obtained from Ohio Lumex, and confirmed by contacting those sources.  Because the user cannot return unused or remaining portions of supplies, no salvage value was included in the cost of supplies.  PPE supplies were assumed to be part of the overall site investigation or remediation costs; therefore, no PPE costs were included as supplies.  

# 7.1.3 Support Equipment Cost  

During the demonstration, the RA- $915+$ /RP-91C, air pump, laptop computer, and balance were operated using AC power.  The costs associated with providing the power supply and electrical energy were not included in the econom ic analysis; the demonstration site provided AC power at no cost.  During Visitors’ Da y, all of the items mentioned were operated using a 12-volt DC battery.  

Because of the large number of samples expected to be analyzed during the demonstration, EPA provided support equipment, including tables and chairs for the two field technician’s comfort.  In addition, EPA provided a tent to ensure that there were no delays in the project due to inclement weather.  These costs may not be incurred in all cases.  However, such equipment is frequently needed in field situations, so these costs were included in the overall cost analysis.  

# 7.1.4 Labor Cost  

The labor cost was estimated based on the time required for RA- $915+/\mathsf{R P-91C}$ setup, sample preparation, sample analysis, summ ary data preparation, and instrument packaging at the end of the day.  Setup time covered the time required to take the instrument out of its packaging, set up all components, and ready the device for operation. However, the RA-9 $15+$ /RP-91C was already removed from the original shipping container.  Therefore, this time was estimated rather than measured.  Sample preparation involved mixing samples with the injection spoon.  Sample preparation was generally completed while previous samples were being analyzed.  Sample analysis comprised the time required to analyze all sam ples and submit a data summary.  The data summary was strictly a tabulation of results in whatever form the vendor chose to provide.  In this case, the vendor transcribed results from the electronic database to the field COC forms (no printer was available in the field).  The time required to perform all tasks was rounded to the nearest hour.  However, for the economic analysis, it was assumed that a field technician who had worked for a fraction of a day would be paid for an entire 8- hour day.  Based on this assum ption, a daily rate for a field technician was used in the analysis.  

During the demonstration, EPA representatives evaluated the skill level required for the field technician to analyze and report results for mercury samples.  Based on these field observations, a field technician with basic chem istry skills acquired on the job or in a university setting, and a 1-day training course specific to the RA- $915{+}/{\mathsf{R P-91C}}$ , was considered qualified to operate the instrument.  For the economic analysis, an hourly rate of $\$15$ was used for a field technician.  A multiplication factor of 2.5 was applied to labor costs to account for overhead costs.  Based on this hourly rate and multiplication factor, and an 8-hour day, a da ily rate of $\$300$ was used for the economic analysis. Monthly labor rates are based on the assumption of an average of 21 work days per month.  This assumes 365 days per year, and non work days totaling 113 days per year (104 weekend days and 9 holidays; vacation days are discounted assuming vacations will be scheduled around short-term wor k o r staf f will be ro tated during long projects).  Therefore, 252 total annual work days are assumed.  

# 7.1.5 Investigation-Derived Waste Disposal Cost  

Ohio Lum ex was instructed to segregate its waste into three categories during the dem onstration: 1) general trash; 2) lightly contaminated PPE and wipes; and 3) contaminated soil (both analyzed and unanalyzed) and other highly contaminated wastes.  General trash was not included as IDW  and is not discussed in this docum ent.  A separate container was provided for each waste category.  

Lightly contaminated wastes consisted primarily of used surgical gloves, wipes, and aluminum foil.  The surgical gloves were discarded for one of three reasons: 1) they posed a risk of cross contam ination (noticeably soiled), 2) they posed a potential health and safety risk (holes or tears), or 3) the operator needed to perform other tasks or take a break.  The rate of waste generation was in excess of what would be expected in a typical application of this instrument.  In addition, the EPA evaluators occasionally contributed used gloves to this waste accum ulation point. W ipes were used primarily to clean injection spoons (after cooling) between samples.  In cases where cross contamination is not a major concern (e.g., field screening or all sam ples are in the same concentration range), lesser amounts of waste would likely be generated.  Aluminum foil contained the soil while it was being weighed.  In the case of soils, the foil contained virtually no residual soil, and was discarded in this container.  Foil used to weigh wet sedim ents was considered highly contaminated, and was discarded with the soil.  

Contaminated soils consisted primarily of soil placed in the injection spoon and then removed because the weight was above the target weight.  Soil that was analyzed was also placed in this waste container as a precaution, even though it is expected that such soils would be free of mercury after being heated to high temperatures in the analytical instrument.  In some cases, these sample residuals may not need to be handled as hazardous waste.  

The contaminated soil, excess sample material, and lightly contaminated gloves and wipes were considered hazardous wastes for purposes of this cost analysis.  

# 7.1.6 Costs Not Included  

Items for which costs were not included in the econom ic analysis are discussed in the following subsections, along with the rationale for exclusion of each.  

Oversight of Sample Analysis Activities.  A typical user of the RA- $915+$ /RP-91C would not be required to pay for customer oversight of sam ple analysis. EPA representatives observed and documented all activities associated with sample analysis during the demonstration. Costs for this oversight were not included in the economic analysis because they were project specific.  For the same reason, costs for EPA oversight of the referee laboratory were also not included in the analysis.  

Travel and Per Diem for Field Technician.  Field technicians may be available locally. Because the ava ilability of f ield tec hn icia ns is p rim arily a function of the location of the project site, travel and per diem costs for field technicians were not included in the economic analysis.  

Sample Collection and M anagement.  Costs for sample collection and m anagem ent activities, including sam ple homogenization and labeling, are site specific and, therefore, not included in the economic analysis.  

Furthermore, these activities were not dependent upon the selected reference method or field analytical tool. Likewise, sample shipping, COC activities, preservation of samples, and distribution of sam ples were specific requirem ents of this project that applied to all vendor technologies and may vary from site to site.  None of these costs was included in the economic analysis.  

Items Costing Less than $\$10$ .  The costs of inexpensive items, such as paper towels, was not included in the economic analysis.  

Documentation Supplies.  The costs for digital cameras used to document field activities were not included in project costs.  These were considered project-specific costs that would not be needed in all cases.  In addition, these items can be used for multiple projects.  Sim ilarly, the cost of supplies (logbooks, copies, etc.) used to document field activities was not included in the analysis because such supplies  are project specific.  

Health and Safety Equipment. Costs for rental of the mercury vapor analyzer and the purchase of PPE were considered site specific and, therefore, not included as costs in the economic analysis.  Safety glasses and disposable gloves were required for sample handlers and would likely be required in m ost cases.  However, these costs are not specific to any one vendor or technology.  As a result, these costs were not included in the econom ic analysis.  

Mobilization and Demobilization.  Costs for mobilization and dem obilization were considered site specific, and not factored into the econom ic analysis.  Mobilization and demobilization costs actually impact laboratory analysis more than field analysis. W hen a field econom ic analysis is perform ed, it may be possible to perform a single mobilization and demobilization.  During cleanup or r e m e d i a t io n a c t i v i t i e s , s e v e r a l m o b i l i z a t i o n s , demobilizations, and associated downtime costs may be necessary  when an off-site laboratory is used because of the w ait for a nalytical re sults .  

# 7.2 RA-915+/RP-91C Costs  

This section presents inform ation on the individual costs of capital equipment, supplies, support equipment, labor, and IDW disposal for the RA-91 $^{5+,}$ /RP-91C. Table 7-1 summ arizes the RA- $915+1$ /RP-91C costs.  

Table 7-1. Capital Cost Summary for the RA-91 $5+$ /RP-91C   


<html><body><table><tr><td rowspan="2">Item </td><td rowspan="2">Quantity</td><td rowspan="2">Unit Cost ($)</td><td colspan="5">Total Cost for Selected Project Duration</td></tr><tr><td>1-Month</td><td>3-Month</td><td>6-Month</td><td>12-Month</td><td>24-Month</td></tr><tr><td>Purchase RA-915+/RP-91C</td><td>1</td><td>$29,000</td><td>$29,000</td><td>$29,000</td><td>$29,000</td><td>$29,000</td><td>$29,000</td></tr><tr><td>Monthly Rental of RA-915+/RP-91C</td><td>1</td><td>$3,500</td><td>$3,500</td><td>$10,500</td><td>$21,000</td><td>$42,000</td><td>$84,000</td></tr><tr><td>Monthly Lease of RA-915+/RP-91C</td><td>1</td><td>$3,500</td><td>$3,500</td><td>$10,500</td><td>$21,000</td><td>$42,000</td><td>$84,000</td></tr><tr><td>Purchase Balance (Optional) a</td><td>1</td><td>$600</td><td>$600</td><td>$600</td><td>$600</td><td>$600</td><td>$600</td></tr><tr><td>Purchase Printer (Optional) a</td><td>1</td><td>$150</td><td>$150</td><td>$150</td><td>$150</td><td>$150</td><td>$150</td></tr></table></body></html>

a A balance is required, but may be provided by the user.  A printer is optional; it may also be provided by the user.  

# 7.2.1 Capital Equipment Cost  

During the demonstration, the RA- $915+/\mathsf{R P-91C}$ was operated for approximately two and one-half days and was used to analyze 197 samples.  

Figure 7-1 summarizes the RA- $915+/\mathsf{R P-9}1\mathsf{C}$ capital  costs for the three procurement options: rental, lease, and purchase.   These costs reflect the basic RA- $915+/\mathsf{R P-91C}$ system, with the optional com puter.  No other options (e.g., balance or printer) and no supply or shipping costs are included.  As would be expected, this chart clearly shows that either rental or leasing is the most cost-effective option for short-term projects (less than 8 months).  W hen  project duration (or use on multiple projects) exceeds eight months, the purchase option is the most cost-effective. These scenarios cover only capital cost, not the cost of supplies, support equipment, labor, and IDW  disposal.  

![](images/bcafef120efd0bbe5205060be277e13f08b880b378e4f2496118d3389832c223.jpg)  
Figure 7-1.  Capital equipment costs.  

The RA-9 $15+1$ RP-91C, including the auxiliary air pump and flow meter, and related electrical connections, sells for $\$29,000$ .  Also included are four quartz injection spoons, plastic tubing for air connections, and an instruction manual.  The portable computer/monitor is not included in the cost, but the software is included.  A balance is also required and can be purchased from Ohio Lumex for $\$600$ , or rented or leased for $\$150$ per week.  However, the user can supply any existing balance.  The costs presented in Figure 7-1 do not include  the cost of the balance.  

# 7.2.2 Cost of Supplies  

Supplies used during the dem onstration included solid SRMs and a mercury trap.  NIST soil SRMs sell for $\$250$ each; typically both a high and a low standard will be required for many applications, for a total cost of $\$500$ .  If sediments are analyzed, a NIST sediment SRM may be obtained for $\$150$ .  No costs for a sediment SRM are included in this analysis.  These standards have a lifeexpectancy of one to three years (one year is assumed for this cost analysis).  A mercury trap was also required during the demonstration and would likely be needed for most field applications.  The proprietary trap costs $\$250$ and comes pre-assembled.  The trap is good for approximately 1,000 samples.  Based on the sample throughput achieved during the demonstration, the trap should last three weeks if running one shift per day and one week if running three shifts per day.  

# 7.2.3 Support Equipment Cost  

Ohio Lumex was provided with a $10\times10$ foot tent for protection from inclement weather during the demonstration.  It was also provided with one table and two chairs for use during sample preparation and analytical activities.  The rental cost for the tent (including detachable sides, ropes, poles, and pegs) was $\$270$ per week.  The rental cost for the table and two chairs for one week totaled $\$6$ .  Total support equipment costs were $\$276$ per week for renta l.  

For longer projects, purchase of support equipment should be considered. Two folding chairs would cost approximately $\$40$ .  A $10\times10$ foot tent would cost between $\$260$ and $\$1,000$ , depending on the construction m aterials and the need for sidewalls and other accessories (e.g., sand stakes, counter weights, storage bag, etc.).  A cost of $\$800$ was used for this cost analysis.  A folding table would cost between $\$80$ and $\$250$ , depending on the supplier. For purposes of this cost analysis, $\$160$ was used.  Total purchase costs for support equipment are estimated at $\$1,000$ .  

The RA- $915+,$ /RP-91C requires an electrical source: either 110/220 volts $50/60~\mathsf{H z}$ AC at 1.2 amps or 12 volts DC at 18 amps.  No cost was calculated for the DC electrical source used during the demonstration because any instrument will require a power source.  The Ohio Lumex instrument reportedly can be operated on a rechargeable 12-volt battery for 3.5 hours. (Ohio Lumex, 2003)  The battery can be purchased for less than $\$100$ . Alt er na tive ly, a standard 2,000 watt generator can be used to power the instrument.  The estim ated cost for a locally-supplied generator is $\$500$ ; Ohio Lumex will also rent a generator for $\$200$ per week, or one can be rented from  a local tool renta l firm .  

# 7.2.4 Labor Cost  

One field technician was required for 3 days during the demonstration to complete sample analyses and prepare a data summary.  Based on a labor rate of $\$300$ per day, total labor cost for application of the RA-9 $15+$ /RP-91C was $\$900$ for the 2.5-day period (assumes the technician was payed for a complete day on the third day).  Labor costs assume qualified technicians are available locally, and that no hotel or per diem costs are applicable.  Table 7-2 summ arizes labor costs for various operational periods. The costs presented do not include supervision and quality assurance because these would be associated with the use of any analytical instrument and are a portion of the overhead multiplier built into the labor rate.  

# 7.2.5 Investigation-Derived Waste Disposal Cost  

Ohio Lum ex generated waste personal protective equipment, contaminated wipes and aluminum foil, and excess soil waste. The PPE waste was charged to the overall project due to project constraints.  The minimum waste volume is a 5-gallon container.  Mobilization and container drop-off fees were $\$1,040$ ; disposal of a 5-gallon soil waste container was $\$400$ .  (This cost was based on a listed waste stream with a hazardous waste num ber U151.) The total IDW  disposal cost was $\$1,440$ . These costs may vary significantly from site to site, depending on whether the waste is classified as hazardous or nonhazardous and whether excess sample material requiring disposal is generated.  Table 7-3 presents IDW costs for various operational periods, assuming that waste generation rates were sim ilar to those encountered during the demonstration.  

Table 7-2.  Labor Costs   


<html><body><table><tr><td rowspan="2">Item</td><td colspan="5">Months</td></tr><tr><td>1</td><td>3</td><td>6</td><td>12</td><td>24</td></tr><tr><td>Technician</td><td>$6,300</td><td>$18,900</td><td>$37,800</td><td>$75,600</td><td>$151,200</td></tr><tr><td>Supervisor</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr><tr><td>Quality Control</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr><tr><td>Total</td><td>$6,300</td><td>$18,900</td><td>$37,800</td><td>$75,600</td><td>$151,200</td></tr></table></body></html>  

Table 7-3.  IDW Costs   


<html><body><table><tr><td rowspan="2">Item</td><td colspan="5">Months</td></tr><tr><td>1</td><td>3</td><td>6</td><td>12</td><td>24</td></tr><tr><td>Drop Fee</td><td>$1,040</td><td>$3,120</td><td>$6,240</td><td>$12,480</td><td>$24,960</td></tr><tr><td>Disposal</td><td>$400</td><td>$1,200</td><td>$2,400</td><td>$4,800</td><td>$9,600</td></tr><tr><td>Total</td><td>$1,440</td><td>$4,320</td><td>$8,640</td><td>$17,280</td><td>$34,560</td></tr></table></body></html>  

# 7.2.6 Summary of RA-915+/RP-91C Costs  

The total cost for performing m ercury analysis is summ arized in Table 7-4.   This table reflects costs for projects ranging from 1-24 months.  The rental option was used for estimating the equipment cost.  Table 7-5 summ arizes total costs and the percentage of total costs for the actual dem onstration.  

Table 7-4.  Summary of Rental Costs for the RA-915+/RP-91C   


<html><body><table><tr><td>Item</td><td>Quantity</td><td>Unit</td><td>Unit Cost</td><td colspan="5">Months</td></tr><tr><td>Capital Equipment</td><td></td><td></td><td>($)</td><td>1</td><td>3</td><td>6</td><td>12</td><td>24</td></tr><tr><td> Monthly Rental</td><td>1</td><td>NA</td><td>$3,500</td><td>$3,500</td><td>$10,500</td><td>$21,000</td><td>$42,000</td><td>$84,000</td></tr><tr><td>Supplies</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td> Quartz Injectors a</td><td>1</td><td>each</td><td>$150</td><td>$O</td><td>$O</td><td>$150</td><td>$300</td><td>$600</td></tr><tr><td>Solid SRM b</td><td>2</td><td>each</td><td>$250</td><td>$500</td><td>$500</td><td>$500</td><td>$1,000</td><td>$1,500</td></tr><tr><td>Mercury Trap (all components)</td><td>1</td><td>each</td><td>NA</td><td>$65</td><td>$250</td><td>$500</td><td>$1,000</td><td>$2,000</td></tr><tr><td>Total Supply Cost </td><td></td><td></td><td></td><td>$565</td><td>$750</td><td>$1,150</td><td>$2,300</td><td>$4,100</td></tr><tr><td>Support Equipment c</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Table (optional) - weekly</td><td>1</td><td>each</td><td>$5</td><td>$20</td><td>$60</td><td>$120</td><td>$160</td><td>$160</td></tr><tr><td>Chairs (optional) - weekly</td><td>2</td><td>each</td><td>$1</td><td>$10</td><td>$25</td><td>$40</td><td>$40</td><td>$40</td></tr><tr><td>Tent (for inclement weather only) - weekly</td><td>1</td><td>each</td><td>$270</td><td>$800</td><td>$800</td><td>$800</td><td>$800</td><td>$800</td></tr><tr><td>Total Support Equipment Cost Labor</td><td></td><td></td><td></td><td>$830</td><td>$885</td><td>$960</td><td>$1,000</td><td>$1,000</td></tr><tr><td>Field Technician (person day)</td><td>1</td><td>hour</td><td>$38</td><td>$6,300</td><td>$18,900</td><td>$37,800</td><td>$75,600</td><td>$151,200</td></tr><tr><td>IDW Drop Fee</td><td>NA</td><td></td><td>$1,040</td><td>$1,040</td><td>$3,120</td><td>$6,240</td><td>$12,480</td><td>$24,960</td></tr><tr><td> Disposal</td><td>NA</td><td>week</td><td>$400</td><td>$400</td><td>$1,200</td><td>$2,400</td><td>$4,800</td><td>$9,600</td></tr><tr><td>Total IDW Costs</td><td></td><td></td><td></td><td>$1,440</td><td>$4,320</td><td>$8,640</td><td>$17,280</td><td>$34,560</td></tr><tr><td>Total Cost</td><td></td><td></td><td></td><td>$18,935</td><td>$32,645</td><td>$69,715</td><td>$138,630</td><td>$274,930</td></tr></table></body></html>

a For solid samples and SRMs; a set of 4 comes standard and is assumed to last 2 years, with breakage of one per 6 months b Only for use with solid samples; assumes two SRMs are required (a low and a high standard) with a life expectancy of 1 year (some standards will have longer shelf lives). c Rental costs were used through the 3-month period for chairs and the 6-month period for the table.  Purchase costs were used for longer periods. Purchase costs for the tent were used for all periods. d Other than unit costs, all costs are rounded to the nearest $\$5$ . e The instrument is available for weekly rentals at $\$1,500$ per week.  

Table 7-5.  RA-915+/RP-91C Costs by Category   


<html><body><table><tr><td>Category</td><td>Category Cost ($)</td><td>Percentage of Total Costs</td></tr><tr><td>Instrument</td><td>$1,500</td><td>32.5%</td></tr><tr><td>Supplies</td><td>$500</td><td>10.8%</td></tr><tr><td>Support Equipment</td><td>$277</td><td>6.0%</td></tr><tr><td>Labor</td><td>$900</td><td>19.5%</td></tr><tr><td>IDW Disposal</td><td>$1,440</td><td>31.2%</td></tr><tr><td>Total</td><td>$4,617</td><td>100.0%</td></tr></table></body></html>  

The cost per analysis based upon 197 samples, when renting the RA- $915+$ /RP-91C, is $\$23.44$ per sample.  The cost per analysis for the 197 samples, excluding nstrument cost, is $\$15.82$ per sample.  

# 7.3 Typical Reference Method Costs  

This section presents costs associated with the reference method used to analyze the demonstration samples for mercury.  Costs for other project analyses are not covered. The referee laboratory utilized SW -846  Method 7471B for all soil and sediment samples.  The referee laboratory performed 421 analyses over a 21-day time period.  

A typical m ercury analysis cost, along with percent moisture for dry-weight calculation, is approximately $\$35$ . This cost covers sample management and preparation, analysis, quality assurance, and preparation of a data package.  The total cost for 197 sam ples at $\$35$ would be $\$6,895$ .  This is based on a standard turnaround time of 21-calendar days.  The sample turnaround time from the laboratory can be reduced to 14, 7, or even fewer calendar da ys, with a cost multiplier of from $125\%$ to $300\%$ , depending on project needs and laboratory availability. This results in a cost range from $\$6,895$ to $\$20,685$ .  The laboratory cost does not include sample packaging, shipping, or downtime caused to the project while awaiting sample results.  

# Chapter 8 Summary of Demonstration Results  

As discussed previously in this ITVR, the Ohio Lum ex RA-91 $5+$ /RP-91C was evaluated by having the vendor analyze 197 soil and sediment samples.  These 197 samples consisted of high-, medium-, and lowconcentration field samples from four sites, SRMs, and spiked field samples.  Table 8-1 provides a breakdown of the numbers of these samples for each sample type, and concentration range or source.  Collectively, these samples provided the different matrices, concentrations, and types of mercury needed to perform a comprehensive evaluation of the RA-91 $5+1$ RP-91C.  

# 8.1 Primary Objectives  

The primary objectives of the demonstration were centered on evaluation of the field instrument and performance in relation to sensitivity, accuracy, precision, time for analysis, and cost.  Each of these objectives was discussed in detail in previous chapters and is summ arized in the following paragraphs.  The overall demonstration results suggest that the experimental design was successful for evaluation of the Ohio Lumex RA-9 $15+$ /RP-91C .  Quantitative results were reviewed.  The results from this field instrument were found to be comparable to standard analyses performed by the laboratory in terms of precision, and accuracy in comparison to SRMs.  Field sample analyses were not found to be com parable, however, to referee laboratory results.  The collected data provide evidence to support these statements.  

The two primary sensitivity evaluations performed for this demonstration were the MDL and PQL.  Following procedures established in 40 CFR Part 136, the MDL is between 0.0053 and $0.042~\mathrm{mg/kg}$ based on the results of seven replicate analyses for low standards.  The equivalent MDL for the referee laboratory is $0.0026~\mathrm{\mathfrak{mg/kg}}$ .  The calculated MDL is only intended as a statical estimation and not a true test of ins trum ent sensitivity.  

The low standard calculations using MDL values suggest that a PQL for the Ohio Lumex field instrument may be as low as $0.027\mathrm{mg/kg}$ (5 times the lowest calculated MDL). The referee laboratory PQL confirmed during the demonstration is $0.005~\mathrm{mg/kg}$ with a $\%0$ of $<10\%$ .  The $\%0$ for the average Ohio Lumex result for a tested sam ple with a referee laboratory value of $0.06\mathrm{~}\mathsf{m g/k g}$ is 0.072 $\mathsf{m g}/\mathsf{k g}$ , w ith a $\%0$ o f $20\%$ .  This was the lowest sample concentration tested during the demonstration that is close to, but not below, the calculated PQL noted above.  Both the MDL and PQL were determined for soils and sediments.  

Accuracy was evaluated by com parison to SRMs and comparison to the referee laboratory analysis for field samples.  This included spiked field samples for evaluation of additional concentrations not otherwise available.  In summary, Ohio Lumex data were within SRM $95\%$ prediction intervals $93\%$ of the time, which suggests significant equivalence to certified standards. The comparison between the Ohio Lumex field data and the ALSI results, however, suggest that the two data sets are not the same.  When a unified hypothesis test is performed (which accounts for laboratory bias), this result is confirmed.  Ohio Lum ex data were found to be both above and below referee laboratory concentrations, therefore there is no implied or suggested bias.  The num ber of Ohio Lumex average values less than $30\%$ different from the referee laboratory results or SRM reference values; however, was 19 of 33 different sam ple lots.  Ohio Lumex results, therefore, can often provide a reasonable estim ate of accuracy for field determination, and may be affected by interferences not identified by this demonstration.  Because the Ohio Lumex data compare favorably to the SRM values, the differences between Ohio Lumex and the referee labo rator y are like ly the res ult o f m atr ix interferences.  

The precision was determ ined by analysis of replicate samples.  The precision of the Ohio Lumex field instrument is better than the referee laboratory precision.  The overall average RSD, is $22.3\%$ for the referee laboratory compared to the Ohio Lumex average RSD of $16.1\%$ . This is primarily because of the better precision obtained for the SRM analyses by Ohio Lumex.  Both the laboratory precision and the Ohio Lumex precision goals of $25\%$ overall RSD were achieved.  

Time measurements were based on the length of time the operator spent performing all phases of the analysis, including setup, calibration, and sam ple analyses (including all reanalysis).  Ohio Lumex analyzed 197 samples in 1,275 minutes times 1.25 analysts over three days, which averaged to 8.1 minutes per sample result.  Based on this, an operator could be expected to analyze 59 samples (8 hours $\times60$ minutes $\div8.1$ minutes/sample) in a 8-hour day.  

Cost of the Ohio Lumex sample analyses included capital, supplies, labor, support equipment, and waste disposal. The cost per sample was calculated both with and without the cost of the instrument included.  This was perform ed because the first sample requires that the instrum ent is either purchased or rented, and as the sample number increases, the cost per sample would decrease.  A comparison of the field Ohio Lumex cost to off-site laboratory cost was not made.  To compare the field and laboratory costs correctly, it would be necessary to include the expense incurred to the project due to waiting for analysis results to return from the laboratory (potentially several mobilizations and dem obilizations, stand-by fees, and other aspects associated with field activities).  

Table 8-2 summ arizes the results of the primary objectives.  

# 8.2 Secondary Objectives  

Table 8-3 summ arizes the results of the secondary objectives.  

Table 8-1.  Distribution of Samples Prepared for Ohio Lumex and the Referee Laboratory   


<html><body><table><tr><td rowspan="2">Site</td><td rowspan="2">Concentration Range</td><td colspan="4">Sample Type</td></tr><tr><td>Soil</td><td>Sediment</td><td>Spiked Soil</td><td>SRM</td></tr><tr><td>Carson River</td><td>Low (1-500 ppb)</td><td>3</td><td>10</td><td></td><td>?</td></tr><tr><td rowspan="3">(Subtotal = 62)</td><td>Mid (0.5-50 ppm)</td><td>0</td><td>0</td><td>?</td><td>28</td></tr><tr><td>High (50->1,000 ppm)</td><td></td><td>0</td><td>0</td><td>0</td></tr><tr><td>Low (1 ppb - 10 ppm)</td><td>30</td><td>0</td><td>14</td><td>13</td></tr><tr><td>Puget Sound (Subtotal = 67)</td><td>High (10-500 ppm)</td><td>0</td><td>3</td><td>7</td><td>0</td></tr><tr><td>Oak Ridge</td><td>Low (0.1-10 ppm)</td><td>10</td><td>?</td><td>?</td><td>14</td></tr><tr><td>(Subtotal = 51)</td><td>High (10-800 ppm)</td><td>3</td><td>6</td><td></td><td>4</td></tr><tr><td>Manufacturing</td><td>General (5-1,000 ppm)</td><td>10</td><td>0</td><td>0</td><td>7</td></tr><tr><td>(Subtotal = 17) Subtotal</td><td></td><td>56</td><td>26</td><td>42</td><td>73</td></tr></table></body></html>  

Table 8-2.  Summary of RA-915+/RP-91C Results for the Primary Objectives   


<html><body><table><tr><td>Demonstration Objective</td><td>Evaluation Basis</td><td colspan="2">Performance Results RA-915+/RP-91C</td><td>Reference Method 0.0026 mg/kg</td></tr><tr><td rowspan="2">Instrument Sensitivity</td><td>MDL. Method from 40 CFR Part 136.</td><td>mg/kg </td><td colspan="2">Between 0.0053 and 0.042</td></tr><tr><td>PQL. Low concentration SRMs or samples.</td><td>< 0.06 mg/kg</td><td colspan="2">0.005mg/kg</td></tr><tr><td>Accuracy</td><td>Comparison to SRMs, field, and spiked samples covering the entire range of the instrument calibration.</td><td colspan="2">Ohio Lumex data were within SRM 95% prediction intervals 93% of the time. 19 of 33 different sample lots within 30% of referee laboratory value.</td><td></td></tr><tr><td> Precision</td><td>Determined by analysis of replicate samples at several concentrations.</td><td></td><td colspan="2">Ohio Lumex overall average RSD; 16.1% One technician performed half of the equipment setup</td></tr><tr><td>Time per Analysis</td><td>Timed daily operations for 2.5 days and divided the total time by the total number of analyses.</td><td></td><td colspan="2">and demobilization, most sample preparation, and all calibration checks and analyses. Individual analyses took 1 minute each, but the total time per analysis averaged approximately 8.1 minutes per sample. The cost per analyses based upon 197 samples, when</td></tr><tr><td>Cost</td><td>Costs were provided by Ohio Lumex and independent suppliers of support equipment and supplies. Labor costs were estimated based on a salary survey. IDw costs were estimated from the actual costs encountered at the Oak Ridge demonstration.</td><td>renting the RA-915+/RP-91C, is $23.44 per sample. The cost per analyses for the 197 samples, excluding capital cost, is $15.82 per sample. The total cost for equipment rental and necessary supplies during the demonstration is estimated at $4,6i7. The cost breakout by category is: capital costs, 32.5%; supplies, 10.8%; support equipment, 6.0%; labor, 19.5%; and IDw, 31.2%.</td><td colspan="2"></td></tr></table></body></html>  

Table 8-3. Summary of RA-915+/RP-91C Results for the Secondary Objectives   


<html><body><table><tr><td>Demonstration Objective</td><td>Evaluation Basis</td><td>Performance Results</td></tr><tr><td>Ease of Use</td><td> Field observations during the demonstration.</td><td>The RA-915+/RP-91C combination is reasonably easy to operate; lack of automation somewhat impairs the ease of use. Operation requires one field technician with a basic knowledge of chemistry acquired on the job or in a</td></tr><tr><td>Health and Safety Concerns</td><td>Observation of equipment, operating procedures, and equipment certifications during the demonstration.</td><td>university, and training on the instrument. No significant health and safety concerns were noted during the demonstration. The only potential health and safety concerns identified were the generation of mercury vapors and the potential for burns with careless handling of hot quartz sample boats. The vendor provides a mercury filter as standard equipment; exercising caution and good laboratory practices can mitigate the potential</td></tr><tr><td>Portability of the Device</td><td>Review of device specifications, measurement of key components, and observation of equipment setup and tear down before, during, and ater the demonstration.</td><td>for burns. The RA-915+ air analyzer was easily portable, although the device, even when carried in the canvas sling, was not considered light-weight. The addition of the RP-91C and associated pump unit preclude this from being a truly field portable instrument. The device and attachments can be transported in carrying cases by two people, but must then be set up in a stationary location. It was easy to set up, but the combined instrument is better</td></tr><tr><td>Instrument Durability</td><td>Observation of equipment design and construction, and evaluation of any necessary repairs or instrument downtime during the demonstration.</td><td>characterized as mobile rather than field portable. The RA-915+/RP-91C combination was well designed and constructed for durability.</td></tr><tr><td>Availability of Vendor Instruments and Supplies</td><td>Review of vendor website and telephone calls to the vendor after the demonstration.</td><td>The RA-915+/RP-91C combination is readily available for rental, lease, or purchase. Spare parts and consumable supplies can be added to the original instrument order or can be received within 24-48 hours of order placement. Standards are readily available from laboratory supply firms or can be acquired through Ohio</td></tr></table></body></html>  

# Section 9 Bibliography  

Anchor  Environm ental. 2000. Engineering Design Report, Interim Remedial Action Log Pond Cleanup/ Habitat Restoration Whatcom Waterway Site, Bellingham, W A. Prepared for Georgia Pacific West, Inc. by Anchor Environmental, L.L.C., Seattle, W A. July 31, 2000.   
Confidential Manufacturing Site.  2002.  Soil Boring Data from a Remedial Investigation Conducted in 2000.   
Ohio Lumex, 2001.  Portable Zeeman Mercury Anlyzer: RA-915+ Analyzer; RP-91 and RP-91C Attachments. 2001.   
Rothchild, E.R., R.R. Turner, S.H. Stow, M.A. Bogle, L.K. Hyder, O.M. Sealand, H.J. W yrick. 1984.  Investigation of Subsurface Mercury at the Oak Ridge Y-12 Plant. Oak Ridge National Laboratory, TN.  ORNL/TM-9092.   
U.S. Environmental Protection Agency. 1994. Region 9. Human Health Risk Assessment and Remedial Investigation Report - C arson River Mercury Site (Revised Draft).  Decem ber 1994.   
U.S. Environmental Protection Agency. 1995. Contaminants and Remedial Options at Selected Metal-Contaminated Sites. July 1995.  W ashington D.C.  EPA/540/R-95/512.   
U.S. Environm ental Protection Agency.  1996.  Test M e t h o d s  f o r E v a l u a t i n g  S o l i d  W a s t e , Physical/Chemical Methods, SW-846 CD ROM, which contains updates for 1986, 1992, 1994, and 1996. W ashington DC.   
U.S. Department of Energy.  1998.  Report on the Remedial Investigation of the Upper East Fork of Poplar Creek Characterization Area at the Oak Ridge Y-12 Plant, Oak Ridge, TN.  DOE/OR/01-1641&D2.   
U.S. Environmental Protection Agency. 1998. Unpublished. Quality Assurance Project Plan Requirements for Applied Research Projects, August 1998.   
U.S. Environmental Protection Agency. 2002a.  Region 9  Internet W eb Site, www.epa.gov/region9/index. htm l.   
U.S. Environm ental Protection Agency. 2002b. Guidance on Data Q uality Indicators.  EPA G -5i, W ashington D.C., July 2002.   
U.S. Environm ental Protection Agency. 2003. Field Demonstration Quality Assurance Project Plan - Field Analysis of Mercury in Soil and Sediment.  August 2003. Washington D.C., EPA/600/R-03/053.   
W ilcox, J.W ., Chairman. 1983.  Mercury at Y-12: A Summary of the 1983 UCC-ND Task Force Study. Report Y/EX-23, November 1983.  

www.OhioLumex.com, 2003.  

# Appendix A Ohio Lumex Comments  

# Accuracy and Precision  

The accuracy of the instrument was tested in field conditions and this may have caused a loss of one sample result data.  Also, one sam ple was entered in the data sheet as $0.16~{\mathrm{ug/kg}}$ instead of $160~{\mathsf{u g}}/{\mathsf{k g}}$ .  Nevertheless, the demonstrated accuracy ( $95\%$ for SRM) and precision (average RSD for reference laboratory was $22.3\%$ , the average RSD for Ohio Lumex was $16.1\%$ or $7.6\ \%$ for SRM) of the Ohio Lumex instrument was better than results obtained by a reference laboratory.  

# Method Detection and Practical Quantitation Limits  

The method detection limits (MDLs) and practical quantitation limits (PQLs) determined by the results of testing were obtained for conditions specifically set for the instrument to expand the upper (high concentration) range to $200~\mathrm{{mg/kg}}$ .  A simple change of instrument parameters will enable the operator to change the MDL and PQ L to $0.001\mathrm{mg/kg}$ and $0.005\mathrm{mg/kg}$ respectively.  A specifically developed Pyro 915 attachment for ultra low direct mercury measurem ents enables one to achieve MDL/PQL $0.0001\mathrm{mg/kg}$ and $0.0005~\mathrm{mg/kg}$ .  

# Automation  

Since the time of the testing, Ohio Lumex has developed a balance interface to autom atically enter sam ple size into a computer spread sheet.  

Auto Sampler-  The turnaround time to analyze an individual sample is 1 minute. $25+$ samples can be manually processed in an hour over an 8-hour day, an average of 2.4 minutes per sample.  The time required only to load an auto sampler will be up to 10 minutes per sample.  Also, addition of the auto sam pler will affec t the reliability and portability of the system.  

# Portab ility  

The instrument consist of two modules and can be easily packed in one rolling pelican case with total weight of the system not exceeding 60 pounds. No compressed gases are required. Set-up time from unpacking to operation is within 1 hour.  W e also have many customers using these settings in the field in remote locations while using portable power generators.  

# Appendix B Statistical Analysis  

Two separate hypothesis tests were used to compare the referee laboratory samples to the vendor tested samples. This appendix details the equations and information for both of these statistical analyses. For purposes of this appendix, we have chosen to call the test comparing sample populations using a separate calculation for each sample lot the “hypothesis test,” and the statistical comparison of the entire sam ple set (all 33 separate sample lots) analyzed by the vendor and the laboratory the “unified hypothesis test,” also known as an “aggregate analysis” for all of the sample lots.  

# Hypothesis Test  

A hypothesis test is used to determine if two sample populations are significantly different.  The analysis is performed based on standard statistical calculations for hypothesis testing.  This incorporates a comparison between the two sample populations assuming a specified level of significance.  For establishing the hypothesis test, it was assumed that both sample sets are equal. Therefore, if the null hypothesis is rejected, then the sample sets are not considered equal.  This test was performed on all sam ple lots analyzed by both Ohio Lumex and the referee laboratory. $\mathsf{H}_{0}$ and ${\sf H}_{\sf a}$ , null and alternative hypothesis respectively, were tested with a 0.01 level of significance (LOS). The concern related to this test is that, if two sample populations have highly variable data (poor precision), then the null hypothesis may be accepted because of the test’s inability to exclude poor precision as a m itigating fa ctor.  H ighly variab le data results in wider acceptance windows, and therefore, allows for acceptance of the null hypothesis.  Conclusions regarding  this analysis are presented in the main body of the report.  

To determ ine if the two sample sets are significantly different, the absolute value of the difference between the laboratory average $\bar{\mathsf{x}}_{\mathsf{L}}$ and the vendor average $\bar{\mathsf{x}}_{\mathsf{v}}$ is compared to a calculated $\upmu$ .  When the absolute value of the difference is greater than $\upmu$ , then the alterna te hypothesis is accepted, and the two sets (laboratory and vendor) are concluded to be different.  

To calculate $\upmu$ , the variances for the laboratory data set and the vendor data set are calculated by dividing their standard deviations by the num ber of sam ples in their data set.  The effective number of degrees of freedom is then calculated.  

$$
f=\frac{\left(\mathbf{\boldsymbol{\mathsf{F}}}_{\bar{X}}^{r}+\mathbf{\boldsymbol{\mathsf{F}}}_{\Psi}^{r}\right)^{\bar{\mathbf{Z}}}}{\left(\frac{\mathbf{\boldsymbol{\mathsf{F}}}_{\bar{X}}^{r}\bar{\mathbf{Z}}}{\hbar_{\bar{X}}+1}\right)+\left(\frac{\mathbf{\boldsymbol{\mathsf{F}}}_{\bar{Y}}^{r}\bar{\mathbf{Z}}}{\hbar_{\bar{X}}+1}\right)}-\bar{\mathbf{Z}}
$$  

W here:  

f $\mathbf{\tau}=\mathbf{\tau}$ effective number of degrees of freedom   
$V_{\ L}$ $\mathbf{\tau}=\mathbf{\tau}$ variance for the laboratory results   
$n_{\mathrm{L}}$ $\mathbf{\tau}=\mathbf{\tau}$ num ber of samples for the laboratory data set   
$\mathsf{V}_{\mathsf{V}}$ $\mathbf{\tau}=\mathbf{\tau}$ variance for the vendor results   
nV $\mathbf{\tau}=\mathbf{\tau}$ number of sam ples for the vendor data set.  

The degrees of freedom (f) is used to determine the appropriate “t” value and used to calculate $\upmu$ at the 0.01 level of significance using the following:  

$$
\mathbf{,}\mathbf{\vec{u}}=\mathbf{\vec{t}}_{1-\left\{\mathbf{\vec{I}}\cdot\mathbf{\vec{I}}\mathbf{\vec{I}}\right\}}\sqrt{\mathbf{\vec{V}}_{\vec{L}}+\mathbf{\vec{V}}_{\vec{V}}}
$$  

# Unified Hypothesis Test  

For a specified vendor, let $\mathsf{Y}_{i j}$ be the measured ${\mathsf{H}}{\mathsf{g}}$ concentration for the $j^{t h}$ rep licate of the $i^{t h}$ sample for $I=1,2,\ldots,1$ and $j=1,2,...,\mathsf{J}_{\mathrm{i}}$ .  Let $\mathsf X_{i j}=\mathsf{I o g}(\mathsf Y_{i j})$ , where log is the logarithm to the base 10.  Define $\bar{\boldsymbol{\times}}_{i\mathrm{log.}}$ . to be the average over all log replicates for the $i^{t h}$ sample given by:  

$$
\overline{{\vec{X}}}_{i\mathrm{lig}\equiv}\ =\ {\bf{J}}_{i}-1\ \mathrm{lig}\ \sum_{j=1}^{J_{i}}\ \bar{X}_{i j}
$$  

W here $\boldsymbol{x}_{\ I-1}^{2}$ is approxim ately a chi-square random variable with (I-1) degrees of freedom:  

$$
\bar{\mathcal{S}}\quad=\quad\bar{\mathcal{I}}^{\mathrm{~-1~}}\mathrm{l}\bar{\cup}\quad\sum_{i=1}^{\bar{\mathcal{I}}}\quad\left(\overline{{\bar{X_{\mathrm{~\tiny~i~ng~}}}}}-\overline{{\bar{X}^{-1}}}_{\mathrm{~\tiny~i~log~}}\right)
$$  

and  

Denote the estimate of the variance of the log replicates for the ${j^{t h}}$ sample to be:  

$$
\mathcal{S}^{\widehat{Z}}=\left(\sum_{i=1}^{f}\left(\mathcal{\bar{I}}_{\widehat{\mathbf{i}}}-1\right)\right)^{-1}\mathbb{I}\mathbb{g}\sum_{i=1}^{f}\sum_{j=1}^{J}\left(\sum_{i}^{\mathcal{I}_{\widehat{\mathbf{i}}}}\left(\mathcal{I}_{\widehat{\mathbf{i}}}\right)-\mathcal{F}_{i\mathrm{I}\widetilde{\mathbf{i}}}\right)^{\widehat{\mathbf{i}}}
$$  

Now for the reference laboratory, let $\textsf{Y}_{i j}^{\prime}$ be the measured Hg concentration for the $j^{t h}$ replicate of the $i^{t h}$ sample for $I=1,2,...,1^{\prime}$ and $j=1,2,\ldots,\mathsf{J}_{\mathrm{i}}^{\prime}$ .  Denote the reference laboratory quantities $\mathsf X_{\iota_{j}^{\flat}}^{\prime},\mathsf{\Pi}_{\bar{\iota}_{I}^{\flat}}^{\prime}$ , and $\mathsf{s}^{\prime2}$ defined in a manner similar to the corresponding quantities for the vendor.  

Assumptions:  Assume that the vendor measurem ents, $\mathsf{Y}_{\mathsf{\Omega}_{i j},}$ are independent and identically distributed according to a lognormal distribution with parameters ${\upmu}_{I}$ and $\upsigma^{2}$ .  That is, $\mathsf{X}_{i j}=\mathsf{I o g}(\mathsf{Y}_{i j})$ is distributed according to a normal distribution with expected value ${\upmu}_{I}$ and variance $\upsigma^{2}$ .  Further, assume that the reference laboratory measurements, $\mathsf{Y}_{\boldsymbol{j}\boldsymbol{j}}^{\prime},$ are independent and identically distributed according to a lognormal distribution with parameters $\boldsymbol{\upmu}_{\ I}^{\prime}$ and $\upsigma^{,2}$ .  

The null hypothesis to be tested is:  

$$
H_{0}:\mathcal{H}_{1}=\mathcal{L}_{1}^{t}+\widetilde{\mathcal{S}},\widetilde{f}\widetilde{\mathcal{Q}}\gamma^{s}\widetilde{\mathcal{Q}}\widetilde{\mathcal{H}}\widetilde{\mathcal{Q}}\widetilde{\mathcal{Q}}\widetilde{\mathcal{Q}}\widetilde{\mathcal{L}}\widetilde{\mathcal{Q}}=\widetilde{\mathcal{L}},\ldots,\widetilde{f}
$$  

against the alternative hypothesis that the equality does not hold for at least one value of $I.$  

The null hypothesis ${\sf H}_{\circ}$ is rejected for large values of:  

$$
\check{\chi}_{\tilde{\bar{f}}-1}^{\tilde{\bar{\lambda}}}=\frac{\displaystyle\sum_{i=1}^{\tilde{f}}\left(\overline{{\bar{\mathcal{X}}}}_{i1i\bar{\Theta}\bar{\Xi}}-\overline{{\bar{\mathcal{X}}}}_{i1i\bar{\Xi}}^{1}-\hat{\mathcal{X}}\right)^{2}\cdot\left(\int_{i}^{r-1}+\int_{i}^{r-1}\hat{\bar{\Big]}}^{1}\right)}{\displaystyle\bar{\mathcal{X}}_{p r o s}^{2}}
$$  

$$
s_{p o o l}^{2}=\frac{s^{2}\log\displaystyle\sum_{i=1}^{J}\left(f_{i}-1\right)+s^{1}^{2}\log\displaystyle\sum_{i=1}^{J}\left(f_{i}^{\scriptscriptstyle1}-1\right)}{\displaystyle\sum_{i=1}^{J}\left(f_{i}-1\right)+\displaystyle\sum_{i=1}^{J}\left(f_{i}^{\scriptscriptstyle1}-1\right)}
$$  

Critical values for the hypothesis test are the upper percentile of the chi-square distribution with (I-1) degrees of freedom obtained from a chi-square table.  

# Results of Unified Hypothesis Test for Ohio Lumex  

SAIC performed a unified hypothesis test analysis to assess the comparability of analytical results provided by Ohio Lumex and those provided by ALSI.   Ohio Lumex and ALSI both supplied multiple assays on replicates derived from a total of 33 different sample lots, be they field materials or reference materials with sample lots 35 and 55 excluded because these were below the instrument PQL.  The Ohio Lumex and ALSI data from these assays form ed the basis of this assessm ent.  

The statistical analysis is based on log-transformed (logarithm base 10) data and uses a chi-square test for equality of Ohio Lumex and ALSI population means for given sample lot.  Equality of variances is assumed.  

Initially, the null hypothesis tested was that, on average, Ohio Lumex and ALSI would produce the sam e results within a given sample lot.  This hypothesis is stated as  

$\mathsf{H}_{10}$ : (Ohio Lumex Lot log mean) $\mathbf{\tau}=\mathbf{\tau}$ (ALSI Lot log mean) $\mathsf{H}_{10}$ was rejected in that the chi-square statistic was 130.26, which exceeds the upper $99^{\mathfrak{t h}}$ percentile of the chi-square distribution with 33 degrees of freedom having a value of 54.78.  

The null hypothesis was rejected in part because Ohio Lumex results tended to exceed those from ALSI for the sam e sample lot.  To explore this effect, the null hypothesis was revised to included a bias term in the form of  

$\mathsf{H}_{20}$ : (Ohio Lumex Lot log mean) $\mathbf{\tau}=\mathbf{\tau}$ (ALSI Lot log mean) +(delta),  

where delta is a single value that does not change from one sample lot to another, unlike the lot log means. $\mathsf{H}_{20}$ was rejected strongly in that the chi-square statistic was 101.46, which exceeded the upper ${99}^{\mathfrak{t h}}$ percentile of the chi-square distribution with 32 degrees of freedom with a value of 53.49.  In this analysis, delta was estimated to be 0.133 in logarithmic (base 10) space, which indicates an average upward bias for Ohio Lumex of $10^{0.121}=1.358$ or about $36\%$ .  

For both hypotheses, the large values of the chi-square test statistics summarize the disagreement between the Ohio Lumex and ALSI analytical results.  Furthermore, a review of the statistical analysis details indicates that the overall discordance between Ohio Lumex and ALSI analytical results cannot be traced to the disagreem ent in results for one or two sam ple lots.  

Sum mary information on these analyses is provided in Table B-1.  The p-value can be considered as a significance level.  This is a calculated value and usually when one sets a p-value (e.g., $95\%$ confidence level which translates to a $\mathsf{p}$ -value of 0.05), this value is used to test the level of significance for comparison.  As noted in Table B-1 the $\mathsf{p}$ -value is calculated from the test statistics and therefore it can be seen that because the p-value is so small $\begin{array}{r l}{(<}&{{}0.0000000)}\end{array}$ the two sample populations are considered to be non-equivalent and hence the large chi-square value.  

Table B-1.  Unified Hypothesis Test Summary Information   


<html><body><table><tr><td>Hypothesis</td><td>Total Sample Lots</td><td>Excluded Lot </td><td>DF</td><td></td><td>Delta</td><td>Chi-square</td><td> P-value</td></tr><tr><td>H1o</td><td>33</td><td>35,55</td><td>33</td><td>0.03967</td><td>0.0000</td><td>130.26</td><td>0.000000</td></tr><tr><td>H20</td><td>33</td><td>35.55</td><td>32</td><td>0.03967</td><td>0.1329</td><td>101.46</td><td>0.000000</td></tr></table></body></html>  