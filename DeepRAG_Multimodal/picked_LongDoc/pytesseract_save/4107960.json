{
    "Page_1": "United Stat\nAgene\n\nOffice of\nironmen nal | Protectio: Resear\n\nwEPA innovative Technology\nVerification Report\n\nField Measurement Technology for\nMercury in Soil and Sediment\n\nOhio Lumex’s RA-915+/RP-91C\nMercury Analyzer\n\n   \n \n\n%,\nWace.\n\nY\n>\n7",
    "Page_2": "EPA/600/R-03/147\nMay 2004\n\nInnovative Technology\nVerification Report\n\nOhio Lumex’s RA-915+/RP-91C\nMercury Analyzer\n\nPrepared by\n\nScience Applications International Corporation\nIdaho Falls, ID\n\nContract No. 68-C-00-179\n\nDr. Stephen Billets\nCharacterization and Monitoring Branch\nEnvironmental Sciences Division\nLas Vegas, Nevada 89193-3478\n\nNational Exposure Research Laboratory\nOffice of Research and Development\nU.S. Environmental Protection Agency",
    "Page_3": "Notice\n\nThe U.S. Environmental Protection Agency through its Office of Research and Development funded\nand managed the research described here under contract to Science Applications International\nCorporation. It has been subjected to the Agency's peer and administrative review and has been\napproved for publication as an EPA document. Mention of trade names or commercial products does\nnot constitute endorsement or recommendation for use.",
    "Page_4": "UNITED STATES ENVIRONMENTAL PROTECTION AGENCY\n\nOffice of Research and Development\nWashington, DC 20460\n\nMEASUREMENT AND MONITORING TECHNOLOGY PROGRAM\nVERIFICATION STATEMENT\n\nTECHNOLOGY TYPE: Field Measurement Device\nAPPLICATION: Measurement for Mercury\n\nTECHNOLOGY NAME: Ohio Lumex Co.'s RA-915+/RP-91C Mercury Analyzer\n\nCOMPANY: Ohio Lumex Co.\nADDRESS: 9263 Ravenna Rd., Unit A-3\nTwinsburg, OH 44087\n\nWEB SITE: http://www.ohiolumex.com\nTELEPHONE: (888) 876-2611\nVERIFICATION PROGRAM DESCRIPTION\n\nThe U.S. Environmental Protection Agency (EPA) created the Superfund Innovative Technology Evaluation (SITE) and\nMeasurement and Monitoring Technology (MMT) Programs to facilitate deployment of innovative technologies through\nperformance verification and information dissemination. The goal of these programs is to further environmental\nprotection by substantially accelerating the acceptance and use of improved and cost-effective technologies. These\nprograms assist and inform those involved in design, distribution, permitting, and purchase of environmental\ntechnologies. This document summarizes results of a demonstration of the RA-915+/RP-91C Mercury Analyzer\ndeveloped by Ohio Lumex Co.\n\nPROGRAM OPERATION\n\nUnder the SITE and MMT Programs, with the full participation of the technology developers, the EPA evaluates and\ndocuments the performance of innovative technologies by developing demonstration plans, conducting field tests,\ncollecting and analyzing demonstration data, and preparing reports. The technologies are evaluated under rigorous\nquality assurance (QA) protocols to produce well-documented data of known quality. The EPA National Exposure\nResearch Laboratory, which dem onstrates field sampling, monitoring, and measurementtechnologies, selected Science\nApplications International Corporation as the verification organization to assist in field testing five field measurement\ndevices for mercury in soil and sediment. This demonstration was funded by the SITE Program.\n\nDEMONSTRATION DESCRIPTION\n\nIn May 2003, the EPA conducted a field demonstration of the RA-915+/RP-91C and four other field measurement\ndevices for mercury in soil and sediment. This verification statement focuses on the RA-915+/RP-91C; a similar\nstatement has been prepared for each of the other four devices. The performance of the RA-915+/RP-91C was\ncompared to that of an off-site laboratory using the reference method, “Test Methods for Evaluating Solid Waste” (SW-\n846) Method 7471B (modified). To verify a wide range of performance attributes, the demonstration had both primary\nand secondary objectives. The primary objectives were:\n\n(1) Determining the instrument sensitivity with respect to the Method Detection Limit (MDL) and Practical\nQuantitation Limit (PQL);",
    "Page_5": "(2) Determining the analytical accuracy associated with the field measurement technologies;\n\n(3) Evaluating the precision of the field measurement technologies;\n\n(4) Measuring the amount of time required for mobilization and setup, initial calibration, daily calibration, sample\nanalysis, and demobilization; and\n\n(5) Estimating the costs associated with mercury measurements for the following four categories: capital, labor,\nsupplies, and investigation-derived waste (IDW).\n\nSecondary objectives for the demonstration included:\n\n(1) Documenting the ease of use, as well as skills and training required to properly operate the device;\n\n(2) Documenting potential health and safety concerns associated with operating the device;\n\n(3) Documenting the portability of the device;\n\n(4) Evaluating the device durability based on its materials of construction and engineering design; and\n)\n\n(5) Documenting the availability of the device and associated spare parts.\n\nThe RA-915+/RP-91C analyzed 56 field soil samples, 26 field sediment samples, 42 spiked field samples, and 73\nperformance evaluation (PE) standard reference material (SRM) samples in the demonstration. The field samples were\ncollected in four areas contaminated with mercury, the spiked samples were from these same locations, and the PE\nsamples were obtained from a commercial provider.\n\nCollectively, the environmental and PE samples provided the different matrix types and the different concentrations of\nmercury needed to perform a comprehensive evaluation of the RA-915+/RP-91C. A complete description of the\ndemonstration and a summary of the results are available in the Innovative Technology Verification Report: “Field\nMeasurement Technology for Mercury in Soil and Sediment—Ohio Lumex Co.’s RA-915+/RP-91C Mercury Analyzer\"\n(EPA/600/R-03/147).\n\nTECHNOLOGY DESCRIPTION\n\nThe RA-915+ Mercury Analyzer is a portable AA spectrometer with a 10-meter (m) multipath optical cell and Zeeman\nbackground correction. Mercury is detected without preliminary accumulation on a gold trap. Mercury samples are\nheated to 750-800°C, causing organic materials to be decomposed and mercury to be vaporized in a carrier gas of\nambient air. The airflow carries the vaporized mercury to be carried to the analytical cell. The RA-915+ includes a built-\nin test cell for field performance verification. The operation of the RA-915+ is based on the principle of differential,\nZeeman AA spectrometry combined with high-frequency modulation of polarized light. This combination eliminates\ninterferences and provides the highest sensitivity. A mercury lamp is placed in a permanent magnetic field in which the\n254-nm resonance line is split into three polarized components, two of which are circularly polarized in the opposite\ndirection. These two components (o- and ot) pass through a polarization modulator, while the third component (11) is\nremoved. One o component passes through the absorption cell; the other o component passes outside of the\nabsorption cell and through the test cell. In the absence of mercury vapors, the intensity of the two o components are\nequal. When mercury vapor is presentin the absorption cell, mercury atoms cause a proportional, concentration-related\ndifference in the intensity of the o components. This difference in intensity is what is measured by the instrument. The\nunit can be used with the optional RP-91C for an ultra-low mercury detection limit in water samples using the “cold\nvapor” technique. For direct mercury determination in com plex matrices without sam ple pretreatment, including liquids,\nsoils and sediments, the instrument will be operated with the optional RP-91C accessory, as was done during the\ndemonstration.\n\nDuring the demonstration, no extraction or sample digestion was required. Individual samples were mixed manually\nusing a quartz injection spoon. This same spoon was used to transfer the sample directly to the RP-91C sample\ninjection port after the sample was weighed on a digital balance. The sample weight was manually recorded. The\nsample was analyzed, and the device displayed the mercury concentration in parts per million, which is equivalent to\na soil concentration in milligrams per kilogram.",
    "Page_6": "ACTION LIMITS\n\nAction limits and concentrations of interest vary and are project specific. There are, however, action limits which can\nbe considered as potential reference points. The EPA Region IX Preliminary Remedial Goals for mercury are 23 mg/kg\nin residential soil and 310 mg/kg in industrial soil.\n\nVERIFICATION OF PERFORMANCE\n\nTo ensure data usability, data quality indicators for accuracy, precision, representativeness, completeness,\ncomparability, and sensitivity were assessed for the reference method based on project-specific QA objectives. Key\ndemonstration findings are summarized below for the primary objectives.\n\nSensitivity: The two primary sensitivity evaluations performed for this demonstration were the MDL and PQL. Both\nwill vary dependent upon whether the matrix is a soil, waste, or aqueous solution. Only soils/sediments were tested\nduring this demonstration, and therefore, MDL calculations and PQL determinations for this evaluation are limited to\nthose matrices. By definition, values measured below the PQL should not be considered accurate or precise and those\nbelow the MDL are not distinguishable from background noise.\n\nMethod Detection Limit - The evaluation of an MDL requires seven different measurements of a low concentration\nstandard or sample following the procedures established in the 40 Code of Federal Regulations (CFR) Part 136. The\nMDL is estimated between 0.0053 and 0.042 mg/kg. The equivalent MDL for the referee laboratory is 0.0026 mg/kg.\n\nPractical Quantitation Limit - The low standard calculations using MDL values suggest that a PQL for the Ohio Lumex\nfield instrument may be as low as 0.027mg/kg (5 times the lowest calculated MDL). The %D for the average Ohio\nLumex result for a tested sample with a referee laboratory value of 0.06 mg/kg is 0.072 mg/kg, with a %D of 20%. This\nwas the lowest sample concentration tested during the demonstration that is close to but not below, the calculated PQL\nnoted above. The referee laboratory PQL confirmed during the demonstration is 0.005 mg/kg with a %D <10%.\n\nAccuracy: The results from the RA-915+/RP-91C were compared to the 95% prediction interval for the SRM materials\nand to the referee laboratory results (Method 7471B). The Ohio Lumex data were within SRM 95% prediction intervals\n93% of the time, which suggests significant equivalence to certified standards. The comparison between the Ohio\nLumex field data and the referee laboratory results suggest that the two data sets are not the same. When a unified\nhypothesis testis performed (which accounts for laboratory bias), this resultis confirmed. Ohio Lumex data were found\nto be both above and below referee laboratory concentrations, therefore there is no implied or suggested bias. The\nnumber of Ohio Lumex average values less than 30% different from the referee laboratory results or SRM reference\nvalues was significant — 19 of 33 different sample lots. Ohio Lumex results therefore, provide accurate estimates for\nfield determination. Because the Ohio Lumex data compare favorably to the SRM values, the differences between Ohio\nLumex and the referee laboratory are likely the result of reasons beyond the scope of this study.\n\nPrecision: The precision of the Ohio Lumex field instrument is better than the referee laboratory precision. The overall\naverage RSD, is 22.3% for the referee laboratory compared to the Ohio Lumex average RSD of 16.1%. This is primarily\nbecause of the better precision obtained for the SRM analyses by Ohio Lumex. Both the laboratory precision and the\nOhio Lumex precision goals of 25% overall RSD were achieved.\n\nMeasurement Time: From the time of sample receipt, Ohio Lumex required approximately 21 hours, 15 minutes, to\nprepare a draft data package containing mercury results for 197 samples. One technician performed half of the\nequipment setup and demobilization, most of the sample preparation, and all of the analyses. Individual analyses took\n1 minute each, but the total time per analysis averaged 8.1 minutes per sample (based upon 1.25 analysts) when all\nfield activities and data package preparation were included in the calculation because the vendor chose to analyze\nreplicates of virtually every analysis.\n\nMeasurement Costs: The cost per analyses based upon 197 samples, when renting the RA-915+/RP-91C, is $23.44\npersample. The cost per analyses for the 197 samples, excluding rental fee, is $15.82 per sample. Based on a 3-day\nfield demonstration, the total cost for equipment rental and necessary supplies is estimated at $4,617. The cost by\ncategory is: capital costs, 32.5%; supplies, 10.8%; support equipment, 6.0%; labor, 19.5%; and IDW, 31.2%.",
    "Page_7": "Key demonstration findings are summarized below for the secondary objectives.\n\nEase of Use: Based on observations made during the demonstration, the RA-915+/RP-91C is reasonably easy to\noperate; however, lack of automation somewhat impairs the ease of use. Operation requires one field technician with\na basic knowledge of chemistry acquired on the job or in a university and training on the instrument.\n\nPotential Health and Safety Concerns: No significant health and safety concerns were noted during the\ndemonstration. The only potential health and safety concerns identified were the generation of mercury vapors and the\npotential for burns with careless handling of hot quartz sample boats. The vendor provides a mercury filter as standard\nequipment; exercising caution and good laboratory practices can mitigate the potential for burns.\n\nPortability: The RA-915+ air analyzer was easily portable, although the device, even when carried in the canvas sling,\nwas not considered light-weight. The addition of the RP-91C and associated pump unit preclude this from being a truly\nfield portable instrument. The device and attachments can be transported in carrying cases by two people, but must\nthen be set up ina stationary location. It was easy to set up, but the combined instrument is better characterized as\nmobile rather than field portable.\n\nDurability: The RA-915+/RP-91C was well designed and constructed for durability. The outside of the RA-915+ is\nconstructed of sturdy aluminum and the exterior of the RP-91C furnace is stainless steel.\n\nAvailability of the Device: The RA-915+/RP-91C is readily available for rental, lease, or purchase. Spare parts and\nconsumable supplies can be added to the original instrument order, or can be received within 24 to 48 hours of order\nplacement. Standards are readily available from laboratory supply firms or can be acquired through Ohio Lumex.\n\nPERFORMANCE SUMMARY\n\nIn summary, during the demonstration, the RA-915+/RP-91C exhibited the following desirable characteristics of a field\nmercury measurement device: (1) good accuracy compared to SRMs, (2) good precision, (3) good sensitivity, (4) high\nsample throughput, (5) low measurement costs, and (6) ease of use. During the demonstration the RA-915+/RP-91C\nwas found to have the following limitations: (1) lack of automation and (2) non-portable due to the instrument size and\nweight. The demonstration findings collectively indicated that the RA-915+/RP-91C is a reliable field measurement\ndevice for mercury in soil and sediment.\n\n \n\nNOTICE: EPA verifications are based on an evaluation of technology performance under specific, predetermined criteria and appropriate\nquality assurance procedures. The EPA makes no expressed or implied warranties as to the performance of the technology and does not\ncertify that a technology will always operate as verified. The end user is solely responsible for complying with any and all applicable\nfederal, state, and local requirements.\n\n \n\n \n\nvi",
    "Page_8": "Foreword\n\nThe U.S. Environmental Protection Agency (EPA) is charged by Congress with protecting the nation’s natural resources.\nUnder the mandate of national environmental laws, the Agency strives to formulate and implement actions leading toa\ncompatible balance between human activities and the ability of natural systems to support and nurture life. To meet this\nmandate, the EPA’ s Office of Research and Development provides data and scientific support that can be used to solve\nenvironmental problems, build the scientific knowledge base needed to manage ecological resources wisely, understand\nhow pollutants affect public health, and prevent or reduce environmental risks.\n\nThe National Exposure Research Laboratory is the Agency’s center for investigation of technical and management\napproaches for identifying and quantifying risks to human health and the environment. Goals of the Laboratory's research\nprogram are to (1) develop and evaluate methods and technologies for characterizing and monitoring air, soil, and water;\n(2) support regulatory and policy decisions; and (3) provide the scientific support needed to ensure effective\nimplementation of environmental regulations and strategies.\n\nThe EPA’s Superfund Innovative Technology Evaluation (SITE) Program evaluates technologies designed for\ncharacterization and remediation of contaminated Superfund and Resource Conservation and Recovery Act (RCRA) sites.\nThe SITE Program was created to provide reliable cost and performance data in order to speed acceptance and use of\ninnovative remediation, characterization, and monitoring technologies by the regulatory and user community.\n\nEffective monitoring and measurement technologies are needed to assess the degree of contamination at a site, provide\ndata that can be used to determine the risk to public health or the environment, and monitor the success or failure of a\nremediation process. One component of the EPA SITE Program, the Monitoring and Measurement Technology (MMT)\nProgram, demonstrates and evaluates innovative technologies to meet these needs.\n\nCandidate technologies can originate within the federal government or the private sector. Through the SITE Program,\ndevelopers are given the opportunity to conduct a rigorous demonstration of their technologies under actual field\nconditions. By completing the demonstration and distributing the results, the Agency establishes a baseline for acceptance\nand use of these technologies. The MMT Program is managed by the Office of Research and Development's\nEnvironmental Sciences Division in Las Vegas, NV.\n\nGary Foley, Ph. D.\n\nDirector\n\nNational Exposure Research Laboratory\nOffice of Research and Development\n\nvii",
    "Page_9": "Abstract\n\nOhio Lumex’s RA915+/91C mercury analyzer was demonstrated under the U.S. Environmental Protection Agency\nSuperfund Innovative Technology Evaluation Program in May 2003, at the Oak Ridge National Laboratory (ORNL) in Oak\nRidge, TN. The purpose of the demonstration was to collect reliable performance and cost data for the RA915+/91C and\nfour other field measurement devices for mercury in soil and sediment. The key objectives of the demonstration were:\n1) determine sensitivity of each instrument with respect to a vendor-generated method detection limit (MDL) and practical\nquantitation limit (PQL); 2) determine analytical accuracy associated with vendor field measurements using field samples\nand standard reference materials (SRMs); 3) evaluate the precision of vendor field measurements; 4) measure time\nrequired to perform mercury measurements; and 5) estimate costs associated with mercury measurements for capital,\nlabor, supplies, and investigation-derived wastes.\n\nThe demonstration also involved analysis of SRMs, field samples collected from four sites, and spiked field samples for\nmercury. The performance results for a given field measurement device were compared to those of an off-site laboratory\nusing reference method, “Test Methods for Evaluating Solid Waste” (SW-846) Method 7471B.\n\nThe sensitivity, accuracy, and precision measurements were successfully completed. Results of these measurement\nevaluations suggest that the Ohio Lumex field instrument can perform as well as the laboratory analytical method.\nAccuracy comparisons to standard reference materials showed statistical equivalence but field sample analysis suggested\npossible matrix interferences. Field instrument precision was better than laboratory precision as determined by relative\nstandard deviation calculations. During the demonstration, Ohio Lumex required 21.25 hours (1,275 minutes) for analysis\nof 197 samples. The costper analysis, based on measurement of 197 samples, whenincurring a minimum 1-month rental\nfee for the RA-915+/RP-91C, was determined to be $23.44 per sample. Excluding the instrument rental cost, the cost for\nanalyzing the 197 samples was determined to be $15.82 per sample. Based on the 3-day field demonstration, the total\ncost for equipment rental and necessary supplies was estimated at $4,617.\n\nThe RA915+/RP-91C exhibited good ease of use and durability, as well as no major health and safety concerns. However,\nthe device portability is somewhat limited by its size. Additionally, the device is readily available for purchase or lease.\nThe demonstration findings collectively indicated that the RA915+/RP-91C is a reliable field mobile measurement device\nfor mercury in soil.\n\nviii",
    "Page_10": "Contents\n\n \n\n \n\n  \n\n \n\n  \n  \n\n \n\nNotice 2... ee eee ii\nVerification Statement ©... 0... ee eee iii\nForeword ii\nAbstract\nContents\nTables 0 eee eee eee\nFiQureS 2. nn en nent tee ee\nAbbreviations, Acronyms, and Symbols ....... 0... 0. ce teen xiv\nAcknowledgmentS ........ 00. c cent eee ee xvi\nChapter Page\n1 Introduction ........... 0.0.0.0... 0c eee eee 1\n1.1 Description of the SITE Program 1\n1.2 Scope of the Demonstration... 1... .. eee 2\n1.2.1 Phase] .. 0... eee eee 2\n1.2.2 Phase ll... 2. ee 2\n1.3 Mercury Chemistry and Analysis .......... 0.0 0c cece eee eee 3\n1.3.1 Mercury Chemistry 3\n1.3.2 Mercury Analysis 4\n2 Technology Description... 2... 0... eee eee 6\n2.1 Description of Atomic Absorption Spectroscopy 6\n2.2 Description of the RA-915+/RP-91C 1.1.0... eee 6\n2.3 Developer Contact Information ......... 0.0.00 eee eee 8\n3 Field Sample Collection Locations and Demonstration Site\n3.1 Carson River\n3.1.1 Site Description ....\n3.1.2 Sample Collection ............\n3.2 Y-12 National Security Complex\n3.2.1 Site Description ©... 0... eee eee\n3.2.2 Sample Collection ....... 0.0... eee\n3.3 Confidential Manufacturing Site 2... eee\n3.3.1 Site Description ©... 0... eee eee",
    "Page_11": "Contents (Continued)\n\nChapter Page\n\n3.3.2 | Sample Collection\n3.4 Puget Sound .... 0.2... 2c eee\n3.4.1 Site Description ....\n3.4.2 Sample Collection ....\n\n \n\n   \n\n \n\n  \n\n \n\n \n\n3.5 Demonstration Site.............. : : : .\n3.6 SAIC GeoMechanics Laboratory ..... 0.0.0... eee eee eee 14\n4 Demonstration Approach... ..... eee eee 15\n41 Demonstration Objectives ©... 0... eee 15\n4.2 Demonstration Design .... 0... .. ce eee eee 16\n4.2.1. Approach for Addressing Primary Objectives ....................0.00000- .. 16\n4.2.2 Approach for Addressing Secondary Objectives . . . 20\n4.3 Sample Preparation and Management ............... .\n4.3.1 Sample Preparation... 2.2.2... 2. cee eee\n4.3.2 Sample Management .......... 0.0... c cee eee\n4.4 Reference Method Confirmatory Process tee tee tee .e\n4.4.1 Reference Method Selection... 2.0.0... cee eee\n4.4.2 Referee Laboratory Selection ..... 0... 0.0... eee\n4.4.3. Summary of Analytical Methods ..\n4.5 Deviations from the Demonstration Plan\n5 Assessment of Laboratory Quality Control Measurements ......... 0.0.0.0. 00 cece eee 29\n5.1 Laboratory QA Summary ...... 0... 0c eee eee 29\n5.2 Data Quality Indicators for Mercury Analysis .. .. 29\n5.3 Conclusions and Data Quality Limitations ...... 0.0... 0... ee 30\n5.4 Audit Findings ..... 0... nee eee eee 32\n6 Performance of the RA-915+/RP-91C .. .. 33\n6.1 Primary Objectives ... 0.0... eee 2... 33\n6.1.1 Sensitivity 2... eee 33\n6.1.2  ACCUracy ... 6. eee 35\n6.1.3. Precision .......... 0.0.00 e ee eee . 43\n6.1.4 Time Required for Mercury Measurement .. 46\n6.1.5 Cost ....... 2. eee .. 48\n6.2 Secondary Objectives ..... 0... ee eee 48\n6.2.1 Ease of Use... eee 48\n6.2.2 Health and Safety Concerns .. .. 51\n6.2.3 Portability of the Device... 1... ee 52\n6.2.4 Instrument Durability... 2... tee 53\n6.2.5 Availability of Vendor Instruments and Supplies ........ 0.0.0... cece eee 53\n7 Economic Analysis ......0..0 0.0.00 ccc enn e eee 54\n7.1 Issues and Assumptions ..... 0.0.0... eee ee 54\n7.1.1 Capital Equipment Cost.... 20... 0... eee 54\n7.1.2  Costof Supplies ..... 0.0... eee eee 54",
    "Page_12": "Contents (Continued)\n\nChapter Page\n\n7.1.3. Support Equipment Cost ... 0... 0. eee eee\n7.1.4 Labor Cost... 0... eee\n7.1.5 Investigation-Derived Waste Disposal Cost ..\n7.1.6 Costs Not Included ...\n\n \n\n7.2 RA-915+/RP-91C Costs ....... ..\n7.2.1 Capital Equipment Cost.... 20... 0... eee\n7.2.2  Costof Supplies ..... 0.0... eee eee\n7.2.3. Support Equipment Cost .. .\n7.24 Labor Cost... 0.0... eee\n\n \n\n7.2.5 — Investigation-Derived Waste Disposal Cost\n7.2.6 Summary of RA-915+/RP-91C Costs\n7.3 Typical Reference Method Costs\n\n   \n\n8 Summary of Demonstration Results 2.0.0... eee 61\n8.1 Primary Objectives ... 0... 0. . eee 61\n8.2 Secondary Objectives ..... 0... ee eee 62\n9 Bibliography .. 0... eee ee 65\nAppendix A- Ohio Lumex Comments ... .. 66\nAppendix B- Statistical Analysis ..... 2.0.0... 00 cee eee 67\n\n \n\nxi",
    "Page_13": "Table\n\n4-4\n5-1\n5-2\n5-3\n5-4\n6-1\n6-2\n6-3\n6-4\n6-5\n\n6-7\n6-8\n7-1\n7-2\n7-3\n7-4\n7-5\n8-1\n8-2\n8-3\n\n \n\nTables\n\n \n \n\n \n\n \n  \n \n \n\n \n\n \n  \n\nPage\nPhysical and Chemical Properties of Mercury ..... 0.0.0.0... eee eee eee 4\nMethods for Mercury Analysis in Solids or Aqueous Soil Extracts 2.0.0... ee ee 5\nSummary of Site Characteristics .... 2... 0.0... eee eee eee .. 10\nDemonstration Objectives ... 0... eee eee .. 16\nSummary of Secondary Objective Observations Recorded During the Demonstration . .. 20\nField Samples Collected from the Four Sites ... 0... ce eee 22\nAnalytical Methods for Non-Critical Parameters .. 2.20... 0.00. eee 28\nMS/MSD Summary : : : .. 30\nLCS Summary ... 0.0... eee 30\nPrecision Summary ......0. 0.0.0 c cc ene e eee eee 31\nLow Check Standards ..... 0.0... 0.0 eee .. 31\nDistribution of Samples Prepared for Ohio Lumex and the Referee Laboratory .. . . 33\nOhio Lumex SRM Comparison ....... 0... 00.00 : .. 37\nALSI SRM Comparison ... 0.0.0.0 cc ee eee 37\nAccuracy Evaluation by Hypothesis Testing .... 0.0.0... eee eee eee 38\nNumber of Sample Lots Within Each %D Range .. .. 40\nConcentration of Non-Target Analytes ..... 0.0... cnn eee eee 40\nEvaluation of Precision ... 0... 0. eee eee 44\nTime Measurements for Ohio Lumex .... 0... eee 47\nCapital Cost Summary for the RA-915+/RP-91C 1.1... .. eee 57\nLabor Costs\nIDW Costs\nSummary of Rental Costs for the RA-915+/RP-91C 1.0... ee 59\nRA-915+/RP-91C Costs by Category ............. 0.00002 . 59\nDistribution of Samples Prepared for Ohio Lumex and the Referee Laboratory .. . . 62\nSummary of RA-915+/RP-91C Results for the Primary Objectives .......... .. 63\nSummary of RA-915+/RP-91C Results for the Secondary Objectives ................0 00000000000 ee 64\nUnified Hypothesis Test Summary Information .... 0... 0.0... teens 69\n\nxii",
    "Page_14": "Figures\n\nPage\nRA-915+ instrument schematic. ©... 0.0... eee 7\nRA-915+/RP-91C shown setup ina van... ...... eee eee eee 7\nTent and field conditions during the demonstration at Oak Ridge, TN............... 0.200000 e eee 13\nDemonstration site and Building 5507. ... 2... ee eee 13\nTest sample preparation at the SAIC GeoMechanics Laboratory.\nData plot for low concentration sample results .... 0... eee eee\nData plot for high concentration sample results 2... 0... eee eee\nRA-915+/RP-91C peak SCreen. 6. ete ee\nCapital equipment costs. .. 2.2... nee eee\n\n \n\nxiii",
    "Page_15": "%\n\n%D\n°C\nug/kg\nAAS\nALSI\nbgs\ncm\nCFR\nCl\ncoc\nDI\nDOE\nEPA\ng\n\nH&S\nHg\nHgCl,\nIDL\nIDW\nITVR\nkg\n\nL\n\nLCS\nLEFPC\nm\nMDL\nmg\nmg/kg\nmL\nmm\nMS/MSD\nMMT\nNERL\nNiMH\nng\n\nnm\nORD\nORNL\n\n \n\nAbbreviations, Acronyms, and Symbols\n\nPercent\n\nPercent difference\n\nDegrees Celsius\n\nMicrogram per kilogram\n\nAtomic absorption spectroscopy\nAnalytical Laboratory Services, Inc.\nBelow ground surface\n\nCentimeter\n\nCode of Federal Regulations\nConfidence Interval\n\nChain of custody\n\nDeionized (water)\n\nDepartment of Energy\n\nUnited States Environmental Protection Agency\nGram\n\nHealth and Safety\n\nMercury\n\nMercury (Il) chloride\n\nInstrument detection limit\nInvestigation-derived waste\nInnovative Technology Verification Report\nKilogram\n\nLiter\n\nLaboratory control sample\n\nLower East Fork Poplar Creek\n\nMeter\n\nMethod detection limit\nMilligram\n\nMilligram per kilogram\nMilliliter\n\nMillimeter\n\nMatrix spike/m atrix spike duplicate\nMonitoring and Measurement Technology\nNational Exposure Research Laboratory\nNickel metal halide\n\nNanogram\n\nNanometer\n\nOffice of Research and Development\nOak Ridge National Laboratory\n\nxiv",
    "Page_16": "ORR\nOSWER\nPPE\nppm\nPAL\nQA\nQAPP\nac\nRPD\nRSD\nSAIC\nSITE\nSOP\nSRM\nSW-846\nTOC\nTOM\nUL\nUEFPC\nY-12\n\n \n\nAbbreviations, Acronyms, and Symbols (Continued)\n\nOak Ridge Reservation\n\nOffice of Solid Waste and Emergency Response\nPersonal protective equipment\n\nParts per million\n\nPractical quantitation limit\n\nQuality assurance\n\nQuality Assurance Project Plan\n\nQuality control\n\nRelative percent difference\n\nRelative standard deviation\n\nScience Applications International Corporation\nSuperfund Innovative Technology Evaluation\nStandard operating procedure\n\nStandard reference material\n\nTest Methods for Evaluating Solid Waste; Physical/Chemical Methods\nTotal Organic Carbon\n\nTask Order Manager\n\nUnderwriters Laboratory\n\nUpper East Fork of Poplar Creek\n\nY-12 Oak Ridge Security Complex, Oak Ridge, TN\n\nXV",
    "Page_17": "Acknowledgments\n\nThe U.S. Environmental Protection Agency (EPA) Superfund Innovative Technology Evaluation wishes to acknowledge\nthe support of the following individuals in performing the demonstration and preparing this document: Elizabeth Phillips\nof the U.S. Department of Energy Oak Ridge National Laboratory (ORNL); Stephen Childs, Thomas Early, Roger Jenkins,\nand Monty Ross of the UT-Battelle ORNL; Dale Rector of the Tennessee Department of Environment and Conservation\n(TDEC) Department of Energy Oversight; Sergey Pogarev and Joseph Siperstein of Ohio Lumex; Leroy Lewis of the Idaho\nNational Engineering and Environmental Laboratory, retired; Ishwar Murarka of the EPA Science Advisory Board, member;\nDanny Reible of Louisiana State University; Mike Bolen, Joseph Evans, Julia Gartseff, Sara Hartwell, Cathleen Hubbard,\nKevin Jago, Andrew Matuson, Allen Motley, John Nicklas, Maurice Owens, Nancy Patti, Fernando Padilla, Mark Pruitt,\nJames Rawe, Herb Skovronek, and Joseph Tillman of Science Applications International Corporation (SAIC); Scott Jacobs\nand Ann Vega of the EPA National Risk Management Research Laboratory's Land Remediation and Pollution Control\nDivision; and Brian Schumacher of the EPA National Exposure Research Laboratory.\n\nThis document was QA reviewed by George Brilis of the EPA National Exposure Research Laboratory.\n\nxvi",
    "Page_18": "Chapter 1\nIntroduction\n\nThe U.S. Environmental Protection Agency (EPA) under\nthe Office of Research and Development (ORD), National\nExposure Research Laboratory (NERL), conducted a\ndemonstration to evaluate the performance of innovative\nfield measurement devices for their ability to measure\nmercury concentrations in soils and sediments. This\nInnovative Technology Verification Report (ITVR) presents\ndemonstration performance results and associated costs\nof Ohio Lumex’s Mercury Analyzer (RA-915+) with their soil\nattachment (RP-91C). The vendor-prepared comments\nregarding the demonstration are presented in Appendix A.\n\nThe demonstration was conducted as part of the EPA\nSuperfund Innovative Technology Evaluation (SITE)\nMonitoring and Measurement Technology(MMT)Program.\nMercury contaminated soils and sediments, collected from\nfour sites within the continental U.S., comprised the\nmajority of samples analyzed during the evaluation. Some\nsoil and sediment samples were spiked with mercury (Il)\nchloride (HgCl,) to provide concentrations not occurring in\nthe field samples. Certified standard reference material\n(SRM) samples were also used to provide samples with\ncertified mercury concentrations and to increase the matrix\nvariety.\n\nThe demonstration was conducted at the Department of\nEnergy (DOE) Oak Ridge National Laboratory (ORNL) in\nOak Ridge, TN during the week of May 5, 2003. The\npurpose of the demonstration was to obtain reliable\nperformance and cost data for field measurement devices\nin order to 1) provide potential users with a better\nunderstanding of the devices’ performance and operating\ncosts under well-defined field conditions and 2) provide the\ninstrument vendors with documented results thatcan assist\nthem in promoting acceptance and use of their devices.\nThe results obtained using the five field mercury\nmeasurement devices were compared to the mercury\n\nresults obtained for identical sample sets (samples, spiked\nsamples, and SRMs) analyzed ata referee laboratory. The\nreferee laboratory, which was selected prior to the\ndemonstration, used a well-established EPA reference\nmethod.\n\n1.1. Description of the SITE Program\n\nPerformance verification of innovative environmental\ntechnologies is an integral part of the regulatory and\nresearch mission of the EPA. The SITE Program was\nestablished by EPA's Office of Solid Waste and Emergency\nResponse (OSWER) and ORD under the Superfund\nAmendments and Reauthorization Act of 1986.\n\nThe overall goal of the SITE Program is to conduct\nperformance verification studies and to promote the\nacceptance of innovative technologies that may be used to\nachieve long-term protection of human health and the\nenvironment. The program is designed to meet three main\nobjectives: 1) identify and remove obstacles to the\ndevelopment and commercial use of _ innovative\ntechnologies; 2) demonstrate promising innovative\ntechnologies and gather reliable performance and cost\ninformation to support site characterization and cleanup\nactivities; and 3) develop procedures and policies that\nencourage the use of innovative technologies at Superfund\nsites, as well as at other waste sites or commercial\nfacilities.\n\nThe SITE Program includes the following elements:\n\n* The MMT Program evaluates innovative technologies\nthat sample, detect, monitor, or measure hazardous\nand toxic substances in soil, water, and sediment\nsamples. These technologies are expected to provide\nbetter, faster, or more cost-effective methods for",
    "Page_19": "producing real-time data during site characterization\nand remediation studies than conventional\ntechnologies.\n\n* The Remediation Technology Program conducts\ndemonstrations of innovative treatm ent technologies to\nprovide reliable performance, cost, and applicability\ndata for site cleanups.\n\n* The Technology Transfer Program provides and\ndisseminates technical information in the form of\nupdates, brochures, and other publications that\npromote the SITE Program and_ participating\ntechnologies. The Technology Transfer Program also\noffers technical assistance, training, and workshops in\nthe support of the technologies. A significant number\nof these activities are performed by EPA's Technology\nInnovation Office.\n\nThe Field Analysis of Mercury in Soils and Sediments\ndemonstration was performed under the MMT Program.\nThe MMT Program provides developers of innovative\nhazardous waste sampling, detection, monitoring, and\nmeasurement devices with an opportunity to demonstrate\nthe performance of their devices under actual field\nconditions. The main objectives of the MMT Program are\nas follows:\n\n+ Test and verify the performance of innovative field\nsampling and analytical technologies that enhance\n\nsampling, monitoring, and site characterization\ncapabilities.\n+ Identify performance attributes of innovative\n\ntechnologies that address field sampling, monitoring,\nand characterization problems in a cost-effective and\nefficient manner.\n\n. Prepare protocols, guidelines, methods, and other\ntechnical publications that enhance acceptance of\nthese technologies for routine use.\n\nThe MMT Program is administered by the Environmental\nSciences Division of the NERL in Las Vegas, NV. The\nNERL is the EPA center for investigation of technical and\nmanagement approaches for identifying and quantifying\nrisks to human health and the environment. The NERL\nmission components include 1) developing and evaluating\nmethods and technologies for sampling, monitoring, and\ncharacterizing water, air, soil, and sediment; 2) supporting\nregulatory and policy decisions; and 3) providing technical\nsupport to ensure the effective implementation of\nenvironmental regulations and strategies.\n\n1.2 Scope of the Demonstration\n\nThe demonstration project consisted of two separate\nphases: Phase | involved obtaining information on\nprospective vendors having viable mercury detection\ninstrumentation. Phase II consisted of field and planning\nactivities leading up to and including the demonstration\nactivities. The following subsections provide detail on both\nof these project phases.\n\n1.2.1 Phasel\n\nPhase | was_ initiated by making contact with\nknowledgeable sources on the subject of “mercury in soil”\ndetection devices. Contacts included individuals within\nEPA, Science Applications International Corporation\n(SAIC), and industry where measurement of mercury in soil\nwas known to be conducted. Industry contacts included\nlaboratories and private developers of mercury detection\ninstrumentation. In addition, the EPA Task Order Manager\n(TOM) provided contacts for \"industry players\" who had\nparticipated in previous MMT demonstrations. SAIC also\ninvestigated university and other research-type contacts for\nknowledgeable sources within the subject area.\n\nThese contacts led to additional knowledgeable sources on\nthe subject, which in turn led to various Internet searches.\nThe Internet searches were very successful in finding\nadditional companies involved with mercury detection\ndevices.\n\nAllin all, these research activities generated an original list\nof approximately 30 companies potentially involved in the\nmeasurement of mercury in soils. The list included both\ninternational and U.S. companies. Each of these\ncompanies was contacted by phone or email to acquire\nfurther information. The contacts resulted in 10 companies\nthat appeared to have viable technologies.\n\nDue to instrument design (i.e., the instrument’s ability to\nmeasure mercury in soils and sediments), business\nstrategies, and stage of technology development, only 5 of\nthose 10 vendors participated in the field demonstration\nportion of phase Il.\n\n1.2.2 Phase Il\n\nPhase II of the demonstration project involved strategic\nplanning, field-related activities for the demonstration, data\nanalysis, data interpretation, and preparation of the ITVRs.\nPhase II included pre-demonstration and demonstration\nactivities, as described in the following subsections.",
    "Page_20": "1.2.2.1 Pre-Demonstration Activities\n\nThe pre-demonstration activities were completed in the fall\n2002. There were six objectives for the pre-demonstration:\n\n+ Establish concentration ranges for testing vendors’\nanalytical equipment during the demonstration.\n\n* Collect soil and sediment field samples to be used in\nthe demonstration.\n\n+ Evaluate sample homogenization procedures.\n\n+ Determine mercury concentrations in homogenized\nsoils and sediments.\n\n+ Selecta reference method and qualify potential referee\nlaboratories for the demonstration.\n\n+ Provide soil and sediment samples to the vendors for\nself-evaluation of their instruments, as a precursor to\nthe demonstration.\n\nAs an integral part of meeting these objectives, a pre-\ndemonstration sampling event was conducted in\nSeptember 2002 to collect field samples of soils and\nsediments containing different levels of mercury. The field\nsamples were obtained from the following locations:\n\n* Carson River Mercury site - near Dayton, NV\n*  Y-12 National Security Complex - Oak Ridge, TN\n*  Acconfidential manufacturing facility - eastern U.S.\n\n+ Puget Sound - Bellingham Bay, WA\n\nImmediately after collecting field sample material from the\nsites noted above, the general mercury concentrations in\nthe soils and sediments were confirmed by quick\nturnaround laboratory analysis of _ field-collected\nsubsamples using method SW-7471B. The field sample\nmaterials were then shipped to a soil preparation laboratory\nforhomogenization. Additional pre-demonstration activities\nare detailed in Chapter 4.\n\n1.2.2.2 Demonstration Activities\n\nSpecific objectives for this SITE demonstration were\ndeveloped and defined in a Field Demonstration and\nQuality Assurance Project Plan (QAPP) (EPA Report #\nEPA/600/R-03/053). The Field Demonstration QAPP is\navailable through the EPA ORD _ web = site\n\n(http:/Awww.epa.gov/ORD/SITE) or from the EPA Project\nManager. The demonstration objectives were subdivided\ninto two categories: primary and secondary. Primary\nobjectives are goals of the demonstration study that need\nto be achieved for technology verification. The\nmeasurements used to achieve primary objectives are\nreferred to as critical. These measurements typically\nproduce quantitative results that can be verified using\ninferential and descriptive statistics.\n\nSecondary objectives are additional goals of the\ndemonstration study developed for acquiring other\ninformation of interest about the technology that is not\ndirectly related to verifying the primary objectives. The\nmeasurements required for achieving secondary objectives\nare considered to be noncritical. Therefore, the analysis of\nsecondary objectives is typically more qualitative in nature\nand often uses observations and sometimes descriptive\nstatistics.\n\nThe field portion of the demonstration involved evaluating\nthe capabilities of five mercury-analyzing instruments to\nmeasure mercury concentrations in soil and sediment.\nDuring the demonstration, each instrument vendor received\nthree types of samples 1) homogenized field samples\nreferred to as “field samples”, 2) certified SRMs, and 3)\nspiked field samples (spikes).\n\nSpikes were prepared by adding known quantities of HgCl,\nto field samples. Together, the field samples, SRMs, and\nspikes are referred to as “demonstration samples” for the\npurpose of this ITVR. All demonstration samples were\nindependently analyzed by a carefully selected referee\nlaboratory. The experimental design for the demonstration\nis detailed in Chapter 4.\n\n1.3. Mercury Chemistry and Analysis\n1.3.1 Mercury Chemistry\n\nElemental mercury is the only metal that occurs as a liquid\nat ambient temperatures. Mercury naturally occurs,\nprimarily within the ore, cinnabar, as mercury sulfide (HgS).\nMercury easily forms amalgams with many other metals,\nincluding gold. As a result, mercury has historically been\nused to recover gold from ores.\n\nMercury is ionically stable; however, it is very volatile for a\nmetal. Table 1-1 lists selected physical and chemical\nproperties of elemental mercury.",
    "Page_21": "Table 1-1. Physical and Chemical Properties of Mercury\n\n \n\nProperties Data\n\nAppearance Silver-white, mobile, liquid.\nHardness Liquid\n\nAbundance 0.5% in Earth’s crust\nDensity @ 25°C 13.53 g/mL\n\nVapor Pressure @ 25 °C 0.002 mm\n\nVolatilizes @ 356 °C\n\nSolidifies @ -39 °C\n\n \n\nSource: Merck Index, 1983\n\nHistorically, mercury releases to the environment included\na number of industrial processes such as _ chloralkali\nmanufacturing, copper and zinc smelting operations, paint\napplication, waste oil combustion, geothermal energy\nplants, municipal waste incineration, ink manufacturing,\nchemical manufacturing, paper mills, leather tanning,\npharmaceutical production, and textile manufacturing. In\naddition, industrial and domestic mercury-containing\nproducts, such as thermometers, electrical switches, and\nbatteries, are disposed of as solid wastes in landfills (EPA,\nJuly 1995). Mercury is also an indigenous compound at\nmany abandoned mining sites and is, of course, found as\na natural ore.\n\nAt mercury-contaminated sites, mercury exists in mercuric\nform (Hg”*), mercurous form (Hg,\"\"), elemental form (Hg?),\nand alkylated form (e.g., methyl or ethyl mercury). Hg,**\nand Hg?* are the more stable forms under oxidizing\nconditions. Under mildly reducing conditions, both\norganically bound mercury and inorganic mercury may be\ndegraded to elemental mercury, which can then be\nconverted readily to methyl or ethyl mercury by biotic and\nabiotic processes. Methyl and ethyl mercury are the most\ntoxic forms of mercury; the alkylated mercury compounds\nare volatile and soluble in water.\n\nMercury (Il) forms relatively strong complexes with Cl and\nco,”. Mercury (Il) also forms complexes with inorganic\nligands such as fluoride (F), bromide (Br), iodide (I),\nsulfate (SO,”), sulfide (S*), and phosphate (PO,*) and\nforms strong complexes with organic ligands, such as\nsulfhydryl groups, amino acids, and humic and fulvic acids.\nThe insoluble HgS is formed under mildly reducing\nconditions.\n\n1.3.2 Mercury Analysis\n\nThere are several laboratory-based, EPA promulgated\nmethods for the analysis of mercury in solid and liquid\nhazardous waste matrices. In addition, there are several\nperformance-based methods for the determination of\nvarious mercury species. Table 1-2 summarizes the\ncommonly used methods for measuring mercury in both\nsolid and liquid matrices, as identified through a review of\nthe EPA Test Method Index and SW-846. A discussion of\nthe choice of reference method is presented in Chapter 4.",
    "Page_22": "Table 1-2. Methods for Mercury Analysis in Solids or Aqueous Soil Extracts\n\nMethod Analytical Type(s) of\n\nTechnology Mercury analyzed\n\nSW-7471B CVAAS inorganic mercury\norgano-mercury\n\nSW-7472 ASV inorganic mercury\norgano-mercury\n\nSW-7473 TD, inorganic mercury\namalgamation, organo-mercury\n\nand AAS\n\nSW-7474 AFS inorganic mercury\norgano-mercury\n\nEPA 1631 CVAFS inorganic mercury\norgano-mercury\n\nEPA 245.7. CVAFS inorganic mercury\norgano-mercury\n\nEPA 6200 FPXRF inorganic mercury\n\nApproximate\nConcentration Range\n\n10-2,000 ppb\n\n0.1-10,000 ppb\n\n0.2 - 400 ppb\n\n1 ppb - ppm\n\n0.5 - 100 ppt\n\n0.5 - 200 ppt\n\n>30 mg/kg\n\nComments\n\nManual cold vapor technique widely\nused for total mercury determinations\n\nNewer, less widely accepted method\n\nAllows for total decomposition analysis\n\nAllows for total decomposition analysis;\nless widely used/reference\n\nRequires “trace” analysis procedures;\nwritten for aqueous matrices; Appendix\nA of method written for sediment/soil\nsamples\n\nRequires “trace” analysis procedures;\nwritten for aqueous matrices; will\nrequire dilutions of high-concentration\nmercury samples\n\nConsidered a screening protocol\n\n \n\nAAS = Atomic Absorption Spectrometry\n\nAAF = Atomic Fluorescence Spectrometry\n\nAFS = Atomic Fluorescence Spectrometry\n\nASV = Anodic Stripping Voltammetry\n\nCVAAS = Cold Vapor Atomic Absorption Spectrometry\nCVAFS = Cold Vapor Atomic Fluorescence Spectrometry\nFPXRF = Field Portable X-ray Fluorescence\n\nEPA = U.S. Environmental Protection Agency\n\nmg/kg = milligram per kilogram\n\nppb = parts per billion\n\nppm = parts per million\n\nppt = parts per trillion\n\nSW = solid waste\n\nTD = thermal decomposition",
    "Page_23": "Chapter 2\nTechnology Description\n\nThis chapter provides a detailed description of the thermal\ndecomposition method of atomic absorption spectroscopy\n(AAS), which is the type of technology on which Ohio\nLumex’s instrument is based, and a detailed description of\nthe RA-915+ Mercury Analyzer with the RP-91C soil\nattachment.\n\n2.1. Description of Atomic Absorption\nSpectroscopy\n\nThe principle of analysis used by the RA-915+ and RP-91C\nis thermal decomposition followed by AAS, with a 10-meter\n(m) multi-path optical cell and Zeeman background\ncorrection. AAS uses the absorption of light to measure\nthe concentration of gas-phase atoms. Because samples\nare liquids or solids, the analyte atoms or ions must be\nvaporized in a flame or graphite furnace. The atoms\nabsorb ultraviolet or visible light and make transitions to\nhigher electronic energy levels. The analyte concentration\nis determined from the amount of absorption.\nConcentration measurements are determined from a\nworking curve after calibrating the instrument with\nstandards of known concentration.\n\nIn reference to AAS, as a general analytical application,\nthermal decomposition is followed by atomic absorption;\nhowever, the mechanism of chemical recovery for analysis\nmay vary. Examples include cold vapor traps,\namalgamation desorption, and direct detection.\n\nA sample of known mass is placed in the drying and\ndecomposition furnace and heated to between 600-800\nCelsius (°C). The liquid or solid sample is dried and\norganic materials are decomposed. The amount of light\nabsorbed by an analyte (the product of decomposition), in\nthis case mercury vapor, is compared to a standard to\n\nquantify the mass of that analyte present in a sample of\nknown size. The absorption of light is proportional to the\nmass of the analyte present. The wavelength of the light\nsource is specific to the analyte of interest. For mercury,\nthe wavelength is 254 nm.\n\n2.2. Description of the RA-915+/RP-91C\n\nThe RA-915+ Mercury Analyzer is a portable atomic\nabsorption (AA) spectrometer with a 10-m multipath optical\ncell and Zeeman background correction. Among its\nfeatures is the direct detection of mercury without\npreliminary accumulation on a gold trap. The RA-915+\nincludes a built-in test cell for field performance verification.\nThe unit can be used with the optional RP-91C for an ultra-\nlow mercury detection limit in water samples using the\n“cold vapor” technique. For direct mercury determination\nin complex matrices without sample pretreatment, including\nliquids, soils and sediments, the instrument is operated\nwith the RP-91C accessory.\n\nThe operation of the RA-915+ is based on the principle of\ndifferential, Zeeman AA spectrometry combined with high-\nfrequency modulation of polarized light. This combination\neliminates interferences and provides the highest\nsensitivity. A mercury lamp is placed in a permanent\nmagnetic field in which the 254-nm resonance line is split\ninto three polarized components, two of which are circularly\npolarized in the opposite direction. These two components\n(o- and o+) pass through a polarization modulator, while\nthe third com ponent (m1) is removed (see Figure 1). One o\ncomponent passes through the absorption cell; the othero\ncomponent passes outside of the absorption cell. In the\nabsence of mercury vapors, the intensity of the two o\ncomponents are equal. When mercury vapor is present in\nthe absorption cell, mercury atoms cause a proportional,",
    "Page_24": "concentration-related difference in the intensity of the o\ncomponents. This difference in intensity is what is\nmeasured by the instrument.\n\nZeeman\nmercury triplet\n\n \n     \n \n   \n     \n\nMercury\nlamp\n\nAbsorption line envelope\n\nMulti-path cell\n\nPhotodetector\nFigure 2-1. RA-915+ instrument schematic.\n\nThe RP-91C attachment is intended to decompose a\nsample and to reduce the mercury using the pyrolysis\ntechnique. The RP-91C attachment is a furnace heated to\n800 °C where mercury is converted from a bound state to\nthe atomic state by thermal decomposition, and reduced in\na two-section furnace. In the first section of the furnace,\nthe “light” mercury compounds are preheated and burned.\nIn the second section, a catalytic afterburner decomposes\n“heavy” compounds. After the atomizer, the gas flow\nenters the analytical cell of the attachment. Ambient air is\nused as a carrier gas; no cylinders of compressed gasses\nare required. Zeeman correction eliminates interferences,\nthus, no gold amalgamation is required. The instrumentis\ncontrolled and the data are acquired by software based on\na Microsoft Windows® platform.\n\nApplications and Specifications - The RA-915+ is a\nportable spectrometer designed for interference-free\nanalysis/monitoring of mercury content in ambient air,\nwater, soil, natural and stack gases from chlor-alkali\nmanufacturing, spill response, hazardous waste, foodstuff,\nand biological materials. The Ohio Lumex system is fully\noperational in the field and could be set up in a van, as well\nas a helicopter, marine vessel, or hand-carried for\ncontinuous measurements. The RP-91 and RP-91C\nattachments are used to convert the instrument into a liquid\n\nor solid sample analyzer, respectively. The instrument is\nsuitable for field operation using a built-in battery.\n\nAccording to the RA-915+ Analyzer manual, the base unit\nhas a dimension of 47 cm by 22 cm by 11 cm and weighs\n7.57 kg. The palm unit measures 13.5 cm by 8cm by 2cm\nand weighs 0.32 kg. The power supply can be a built-in, 6-\nvolt rechargeable battery, a power pack adapter, an\nexternal electric battery, or an optional rechargeable\nbattery pack. The RP-91C system includes a pumping unit\nthat has a dimension of 34 cm by 24 cm by 12 cm and a\npower supply unit measuring 14.5 cm by 15 cm by 8.5 cm\n(see Figure 2). Site requirements cited in the manual\ninclude a temperature range of 5 to 40 °C, relative humidity\nof up to 98%, atmospheric pressures of 84 to 106.7\nkilopascals, along with requirements for sinusoidal vibration\nand magnetic field tension. Sensitivity of the instrument is\nreportedly not affected by up to a 95% background\nabsorption caused by interfering components (dust,\n\nmoisture, organic and inorganic gases).\n\n   \n\nFigure 2-2. RA-915+/RP-91C shown setup in a van.\n\nOperation - The instrument calibration is performed by use\nof liquid or solid, primary National Institute of Standards\nand Technology (NIST)-traceable standards. The normal\ndynamic analytical range is from 1-100 wg/kg by direct\ndetermination without dilution. No sample mineralization is\nneeded, and the only waste generated is minimal residual\nsample residue, excess sample, and any personal\nprotective equipment that may be used. Sample\nthroughput is up to 30 samples per hour without an auto\nsampler.",
    "Page_25": "2.3. Developer Contact Information\n\nAdditional information about the RA-915+ and PR-91C can\nbe obtained from the following source:\n\nJoseph Siperstein\nOhio Lumex Co.\n9263 Ravenna Rd., Unit A-3\n\nTwinsburg, OH 44087\n\nToll free: (888) 876-2611\nTelephone: (330) 405-0837\nFax: (330) 405-0847\n\nEmail: mail@ohiolumex.com\nInternet: www.ohiolumex.com",
    "Page_26": "Chapter 3\nField Sample Collection Locations and Demonstration Site\n\nAs previously described in Chapter 1, the demonstration in\npart tested the ability of all five vendor instruments to\nmeasure mercury concentrations in demonstration\nsamples. The demonstration samples consisted of field-\ncollected samples, spiked field samples, and SRMs. The\nfield-collected samples comprised the majority of\ndemonstration samples. This chapter describes the four\nsites from which the field samples were collected, the\ndemonstration site, and the sample homogenization\nlaboratory. Spiked samples were prepared from these field\nsamples.\n\nScreening of potential mercury-contaminated field sample\nsites was conducted during Phase | of the project. Four\nsites were selected for acquiring mercury-contaminated\nsamples thatwere diverse in appearance, consistency, and\nmercury concentration. A key criterion was the source of\nthe contamination. These sites included:\n\n* Carson River Mercury site - near Dayton, NV\n\n* The Y-12 National Security Complex (Y-12) - Oak\nRidge, TN\n\n+ Acconfidential manufacturing facility - eastern U.S.\n+ Puget Sound - Bellingham Bay, WA\n\nSite Diversity - Collectively, the four sites provided\nsampling areas with both soil and sediment, having\nvariable physical consistencies and variable ranges of\nmercury contamination. Two of the sites (Carson River\nand Oak Ridge) provided both soil and sediment samples.\nA third site (a manufacturing facility) provided just soil\nsamples and a fourth site (Puget Sound) provided only\nsediment samples.\n\nAccess and Cooperation - Site representatives were\ninstrumental in providing site access, and in some cases,\n\nguidance on the best areas to collect samples from\nrelatively high and low mercury concentrations. In addition,\nrepresentatives from the host demonstration site (ORNL)\nprovided a facility for conducting the demonstration.\n\nAt three of the sites, the soil and/or sediment sample was\ncollected, homogenized by hand in the field, and\nsubsampled for quick turnaround analysis. These\nsubsamples were sent to analytical laboratories to\ndetermine the general range of mercury concentrations at\neach of the sites. (The Puget Sound site did not require\nconfirmation of mercury contamination due to recently\nacquired mercury analytical data from another, ongoing\nresearch project.) The field-collected soil and sediment\nsamples from all four sites were then shipped to SAIC’s\nGeoMechanics Laboratory for a more thorough sample\nhomogenization (see Section 4.3.1) and subsampled for\nredistribution to vendors during the pre-demonstration\nvendor self-evaluations.\n\nAll five of the technology vendors performed a self-\nevaluation on selected samples collected and\nhomogenized during this pre-demonstration phase of the\nproject. For the self-evaluation, the laboratory results and\nSRM values were supplied to the vendor, allowing the\nvendor to determine how well it performed the analysis on\nthe field samples. The results were used to gain a\npreliminary understanding of the field samples collected\nand to prepare for the demonstration.\n\nTable 3-1 summarizes key characteristics of samples\ncollected at each of the four sites. Also included are the\nsample matrix, sample descriptions, and sample depth\nintervals. The analytical results presented in Table 3-1 are\nbased on referee laboratory mercury results for the\ndemonstration samples.",
    "Page_27": "Table 3-1. Summary of Site Characteristics\n\n \n\nSite Name Sampling Area Sample Depth Description Hg Concentration\nMatrix Range\nCarson River Carson River Sediment water/sediment Sandy silt, with some 10 ppb - 50 ppm\nMercury site interface organic debris present\n(plant stems and leaves)\n\nSix Mile Canyon Soil 3-8cm bgs Silt with sand to sandy silt 10 ppb - 1,000 ppm\nY-12 National Old Hg Recovery Bldg. Soil 0-1m bgs Silty-clay to sandy-gravel 0.1 - 100 ppm\nSecurity Complex\n\nPoplar Creek Sediment 0-0.5m bgs Silt to coarse sandy gravel 0.1 - 100 ppm\nConfidential Former plant building Soil 3.6 -9m bgs Silt to sandy silt 5 - 1,000 ppm\nmanufacturing site\nPuget Sound - Sediment layer Sediment 1.5 - 1.8 m thick Clayey-sandy silt with 10 - 400 ppm\nBellingham Bay various woody debris\n\nUnderlying Native Material | Sediment 0.3 m thick Medium-fine silty sands 0.16 - 10 ppm\n\n \n\nbgs = below ground surface.\n\n3.1\n3.1.1 Site Description\n\nThe Carson River Mercury site begins near Carson City,\nNV, and extends downstream to the Lahontan Valley and\nhe Carson Desert. During the Comstock mining era of the\nate 1800s, mercury was imported to the area for\nprocessing gold and silver ore. Ore mined from the\nComstock Lode was transported to mill sites, where it was\ncrushed and mixed with mercury to amalgamate the\nprecious metals. The Nevada mills were located in Virginia\nCity, Silver City, Gold Hill, Dayton, Six Mile Canyon, Gold\nCanyon, and adjacent to the Carson River between New\nEmpire and Dayton. During the mining era, an estimated\n7,500 tons of mercury were discharged into the Carson\nRiver drainage, primarily in the form of\nmercury-contaminated tailings (EPA Region 9, 1994).\n\nCarson River\n\nMercury contamination is present at Carson River as either\nelemental mercury and/or inorganic mercury sulfides with\ness than 1%, if any, methylmercury. Mercury\ncontamination exists in soils present at the former gold and\nsilver mining mill sites; waterways adjacentto the mill sites;\nand sediment, fish, and wildlife over more than a 50-mile\nlength of the Carson River. Mercury is also present in the\nsediments and adjacent flood plain of the Carson River,\nand in the sediments of Lahontan Reservoir, Carson Lake,\nStillwater Wildlife Refuge, and Indian Lakes. In addition,\nailings with elevated mercury levels are still present at, and\naround, the historic mill sites, particularly in Six Mile\nCanyon (EPA, 2002a).\n\n \n\n10\n\n3.1.2 Sample Collection\n\nThe Carson River Mercury site provided both soil and\nsediment samples across the range of contaminant\nconcentrations desired for the demonstration. Sixteen\nnear-surface soil samples were collected between 3-8 cm\nbelow ground surface (bgs). Two sediment samples were\ncollected at the water-to-sediment interface. All 18\nsamples were collected on September 23-24, 2002 witha\nhand shovel. Samples were collected in Six Mile Canyon\nand along the Carson River.\n\nThe sampling sites were selected based upon historical\ndata from the site. Specific sampling locations in the Six\nMile Canyon were selected based upon local terrain and\nvisible soil conditions (e.g., color and particle size). The\nspecific sites were selected to obtain soil samples with as\nmuch variety in mercury concentration as possible. These\nsites included hills, run-off pathways, and dry river bed\nareas. Sampling locations along the Carson River were\nselected based upon historical mine locations, local terrain,\nand river flow.\n\nWhen collecting the soil samples, approximately 3 cm of\nsurface soil was scraped to the side. The sample was\nthen collected with a shovel, screened through a\n6.3-millimeter (mm) (0.25-inch) sieve to remove larger\nmaterial, and collected in 4-liter (L) sealable bags identified\nwith a permanent marker. The sediment samples were\nalso collected with a shovel, screened through a 6.3-mm\nsieve to remove larger material, and collected in 4-L\nsealable bags identified with a permanent marker. Each of\nthe 4-L sealable bags was placed into a second 4-L",
    "Page_28": "sealable bag, and the sample label was placed onto the\noutside bag. The sediment samples were then placed into\n10-L buckets, lidded, and identified with a sample label.\n\n3.2\n\n3.2.1 Site Description\n\nThe Y-12 site is located at the DOE ORNL in Oak Ridge,\nTN. The Y-12 site is an active manufacturing and\ndevelopmental engineering facility that occupies\napproximately 800 acres on the northeast corner of the\nDOE Oak Ridge Reservation (ORR) adjacent to the city o\nOak Ridge, TN. Built in 1943 by the U.S. Army Corps o\nEngineers as part of the World War II Manhattan Project,\nthe original mission of the installation was development o\nelectromagnetic separation of uranium isotopes and\nweapon components manufacturing, as part of the nationa\neffort to produce the atomic bomb. Between 1950 and\n1963, large quantities of elemental mercury were used at\nY-12 during lithium isotope separation pilot studies and\nsubsequent production processes in support o\nthermonuclear weapons programs.\n\nY-12 National Security Complex\n\nSoils at the Y-12 facility are contaminated with mercury in\nmany areas. One of the areas of known high levels o\nmercury-contaminated soils is in the vicinity of a former\nmercury use facility (the \"Old Mercury Recovery Building\"\n— Building 8110). At this location, mercury-contaminated\nmaterial and soil were processed in a Nicols-Herschof\nroasting furnace to recover mercury. Releases of mercury\nfrom this process, and from a building sump used to\nsecure the mercury-contaminated materials and the\nrecovered mercury, have contaminated the surrounding\nsoils (Rothchild, et al., 1984). Mercury contamination also\noccurred in the sediments of the East Fork of Poplar Creek\n(DOE, 1998). The Upper East Fork of Poplar Creek\n(UEFPC) drains the entire Y-12 complex. Releases of\nmercury via building drains connected to the storm sewer\nsystem, building basement dewatering sump discharges,\nand spills to soils, all contributed to contamination of\nUEFPC. Recent investigations showed that bank soils\ncontaining mercury along the UEFPC were eroding and\ncontributing to mercury loading. Stabilization of the bank\nsoils along this reach of the creek was recently completed.\n\n \n\n3.2.2 Sample Collection\n\nTwo matrices were sampled at Y-12 in Oak Ridge, TN,\ncreek sediment and soil. A total of 10 sediment samples\nwas collected; one sediment sample was collected from\nthe Lower East Fork of Poplar Creek (LEFPC) and nine\nsediment samples were collected from the UEFPC. A total\n\n11\n\nof six soil samples was collected from the Building 8110\narea. The sampling procedures that were used are\nsummarized below.\n\nCreek Sediments — Creek sediments were collected on\nSeptember 24-25, 2002 from the East Fork of Poplar\nCreek. Sediment samples were collected from various\nlocations in a downstream to upstream sequence (i.e., the\ndownstream LEFPC sample was collected first and the\nmost upstream point of the UEFPC was sampled last).\n\nThe sediment samples from Poplar Creek were collected\nusing a commercially available clam-shell sonar dredge\nattached to a rope. The dredge was slowly lowered to the\ncreek bottom surface, where it was pushed by foot into the\nsediment. Several drops of the sampler (usually seven or\nmore) were made to collect enough material for screening.\nOn some occasions, a shovel was used to remove\noverlying \"hardpan\" gravel to expose finer sediments at\ndepth. One creek sample consisted of creek bank\nsediments, which was collected using a stainless steel\ntrowel.\n\nThe collected sediment was then poured onto a 6.3-mm\nsieve to remove oversize sample material. Sieved samples\nwere then placed in 12-L sealable plastic buckets. The\nsediment samples in these buckets were homogenized\nwith a plastic ladle and subsamples were collected in 20-\nmilliliter (mL) vials for quick turnaround analyses.\n\nSoil — Soil samples were collected from pre-selected\nboring locations September 25, 2002. All samples were\ncollected in the immediate vicinity of the Building 8110\nfoundation using a commercially available bucket auger.\nOversize material was hand picked from the excavated soil\nbecause the soil was too wet to be passed through a sieve.\nThe soil was transferred to an aluminum pan,\nhomogenized by hand, and subsampled to a 20-mL vial.\n\nThe remaining soil was transferred to 4-L plastic\ncontainers.\n3.3. Confidential Manufacturing Site\n\n3.3.1 Site Description\n\nA confidential manufacturing site, located in the eastern\nU.S., was selected for participation in this demonstration.\nThe site contains elemental mercury, mercury amalgams,\nand mercury oxide in shallow sediments (less than 0.3 m\ndeep) and deeper soils (3.65 to 9 m bgs). This site\nprovided soil with concentrations from 5-1,000 mg/kg.\n\nThe site is the location of three former processes that\nresulted in mercury contamination. The first process",
    "Page_29": "involved amalgamation of zinc with mercury. The second\nprocess involved the manufacturing of zinc oxide. The\nthird process involved the reclamation of silver and gold\nfrom mercury-bearing materials in a retort furnace.\nOperations led to the dispersal of elemental mercury,\nmercury compounds such as chlorides and oxides, and\nzinc-mercury amalgams. Mercury values have been\nmeasured ranging from 0.05 to over 5,000 mg/kg, with\naverage values of approximately 100 mg/kg.\n\n3.3.2 Sample Collection\n\nEleven subsurface soil samples were collected on\nSeptember 24, 2002. All samples were collected with a\nGeoprobe® unit using plastic sleeves. All samples were\ncollected at the location of a former facility plant. Drilling\nlocations were determined based on historical data\nprovided by the site operator. The intention was to gather\nsoil samples across a range of concentrations. Because\nthe surface soils were from relatively clean fill, the sampling\ndevice was pushed to a depth of 3.65 m using a blank rod.\nSamples were then collected at pre-selected depths\nranging from 3.65 to 9 m bgs. Individual cores were 1-m\nlong. The plastic sleeve for each 1-m core was marked\nwith a permanent marker; the depth interval and the bottom\nof each core was marked. The filled plastic tubes were\ntransferred to a staging table where appropriate depth\nintervals were selected for mixing. Selected tubes were cut\ninto 0.6-m intervals, which were emptied into a plastic\ncontainer for premixing soils. When feasible, soils were\ninitially screened to remove materials larger than 6.3-mm\nin diameter. In many cases, soils were too wet and clayey\nto allow screening; in these cases, the soil was broken into\npieces by hand and, by using a wooden spatula, oversize\nmaterials were manually removed. These soils (screened\nor hand sorted) were then mixed until the soil appeared\nvisually uniform in color and texture. The mixed soil was\nthen placed into a 4-L sample container for each chosen\nsample interval. A subsample of the mixed soil was\ntransferred into a 20-mL vial, and it was sent for quick\nturnaround mercury analysis. This process was repeated\nfor each subsequent sample interval.\n\n3.4\n3.4.1 Site Description\n\nThe Puget Sound site consists of contaminated offshore\nsediments. The particular area of the site used for\ncollecting demonstration samples is identified as the\nGeorgia Pacific, Inc. Log Pond. The Log Pond is located\nwithin the Whatcom Waterway in Bellingham Bay, WA, a\n\nPuget Sound\n\n12\n\nwell-established heavy industrial land use area with a\nmaritime shoreline designation. Log Pond sediments\nmeasure approximately 1.5 to 1.8-m thick, and contain\nvarious contaminants including mercury, phenols,\npolyaromatic hydrocarbons, polychlorinated biphenyls, and\nwood debris. Mercury was used as a preservative in the\nlogging industry. The area was capped in late 2000 and\nearly 2001 with an average of 7 feet of clean capping\nmaterial, as part of a Model Toxics Control Act interim\ncleanup action. The total thickness ranges from\napproximately 0.15 m along the site perimeter to 3 m within\nthe interior of the project area. The restoration project\nproduced 2.7 acres of shallow sub-tidal and 2.9 acres of\nlow intertidal habitat, all of which had previously exceeded\nthe Sediment Management Standards cleanup criteria\n(Anchor Environmental, 2001).\n\nMercury concentrations have been measured ranging from\n0.16 to 400 mg/kg (dry wt). The majority (98%) of the\nmercury detected in near-shore ground waters and\nsediments of the Log Pond is believed to be comprised of\ncomplexed divalent (Hg?*) forms such as mercuric sulfide\n(Bothner, et al., 1980 and Anchor Environmental, 2000).\n\n3.4.2 Sample Collection\n\nScience Applications International Corporation (SAIC) is\ncurrently performing a SITE remedialtechnology evaluation\nin the Puget Sound (SAIC, 2002). As part of ongoing work\nat that site, SAIC collected additional sediment for use\nduring this MMT project. Sediment samples collected on\nAugust 20-21, 2002 from the Log Pond in Puget Sound\nwere obtained beneath approximately 3-6 m of water, using\na vibra-coring system capable of capturing cores to 0.3 m\nbelow the proposed dredging prism. The vibra-corer\nconsisted of a core barrel attached to a power head.\nAluminum core tubes, equipped with a stainless steel\n\"eggshell\" core catcher to retain material, were inserted\ninto the core barrel. The vibra-core was lowered into\nposition on the bottom and advanced to the appropriate\nsampling depth. Once sampling was completed, the\nvibra-core was retrieved and the core liner removed from\nthe core barrel. The core sample was examined at each\nend to verify that sufficient sediment was retained for the\nparticular sample. The condition and quantity of material\nwithin the core was then inspected to determine\nacceptability.\n\nThe following criteria were used to verify whether an\nacceptable core sample was collected:\n\n* Target penetration depth (i.e., into native material) was\nachieved.",
    "Page_30": "+ Sediment recovery of at least 65% of the penetration\ndepth was achieved.\n\n+ Sample appeared undisturbed and intact without any\nevidence of obstruction/blocking within the core tube or\ncatcher.\n\nThe percent sediment recovery was determined by dividing\nthe length of material recovered by the depth of core\npenetration below the mud line. Ifthe sample was deemed\nacceptable, overlying water was siphoned from the top of\nthe core tube and each end of the tube capped and sealed\nwith duct tape. Following core collection, representative\nsamples were collected from each core section\nrepresenting a different vertical horizon. Sediment was\ncollected from the center of the core that had not been\nsmeared by, or in contact with, the core tube. The volumes\nremoved were placed in a decontaminated stainless steel\nbowl or pan and mixed until homogenous in texture and\ncolor (approximately 2 minutes).\n\nAfter all sediment for a vertical horizon composite was\ncollected and homogenized, representative aliquots were\nplaced in the appropriate pre-cleaned sample containers.\nSamples of both the sediment and the underlying native\nmaterial were collected ina similar manner. Distinct layers\nof sediment and native material were easily recognizable\nwithin each core.\n\n3.5 Demonstration Site\n\nThe demonstration was conducted in a_ natural\nenvironment, outdoors, in Oak Ridge, TN. The area was\na grass covered hill with some parking areas, all of which\nwere surrounded by trees. Building 5507, in the center of\nthe demonstration area, provided facilities for lunch, break,\nand sample storage for the project and personnel.\n\nMost of the demonstration was performed during rainfall\nevents ranging from steady to torrential. Severe puddling\nof rain occurred to the extent that boards needed to be\nplaced under chairs to prevent them from sinking into the\nground. Even when it was not raining, the relative humidity\nwas high, ranging from 70.6 to 98.3 percent. Between two\nand four of the tent sides were used to keep rainfall from\ndamaging the instruments. The temperature in the\nafternoons ranged from 65-70 degrees Fahrenheit, and the\nwind speed was less than 10 mph. The latitude is 36°N,\nthe longitude 35°W, and the elevation 275 m. (Figure 3-1\nis a photograph of the site during the demonstration and\nFigure 3-2 is a photograph of the location.)\n\n13\n\n   \n\nFigure 3-1. Tent and field conditions during the\ndemonstration at Oak Ridge, TN.\n\n \n\nFigure 3-2. Demonstration site and Building 5507.",
    "Page_31": "3.6 SAIC GeoMechanics Laboratory\n\nSample homogenization was completed at the SAIC\nGeoMechanics Laboratory in Las Vegas, NV. This facility\nis an industrial-type building with separate facilities for\npersonnel offices and material handling. The primary\nfunction of the laboratory is for rock mechanics studies.\nThe laboratory has rock mechanics equipment, including\n\n14\n\nsieves, rock crushers, and sample splitters. The personnel\nassociated with this laboratory are experienced in the areas\nof sample preparation and sample homogenization. In\naddition to the sample homogenization equipment, the\nlaboratory contains several benches, tables, and open\nspace. Mercury air monitoring equipment was used during\nthe sample preparation activities for personnel safety.",
    "Page_32": "Chapter 4\nDemonstration Approach\n\nThis chapter describes the demonstration approach that\nwas used for evaluating the field mercury measurement\ntechnologies at ORNL in May 2003. It presents the\nobjectives, design, sample preparation and management\nprocedures, and the reference method confirmatory\nprocess used for the demonstration.\n\n4.1. Demonstration Objectives\nThe primary goal of the SITE MMT Program is to develop\n\ndemonstration must provide detailed and _ reliable\nperformance and cost data in order that potential\ntechnology users have adequate information needed to\nmake sound judgements regarding an_ innovative\ntechnology’s applicability to a specific site and to be able to\ncompare the technology to conventional technologies.\n\nTable 4-1 summarizes the project objectives for this\ndemonstration. In accordance with QAPP Requirements\nfor Applied Research Projects (EPA,1998), the technical\n\nproject objectives for the demonstration were categorized\n\nreliable performance and cost data on_ innovative, . d d\nfield-ready measurement technologies. A SITE as primary and secondary.\nTable 4-1. Demonstration Objectives\nObjective Description Method of Evaluation\n\n \n\nPrimary Objectives\n\n \n\nPrimary Objective # 1\n\nPrimary Objective # 2\nPrimary Objective # 3\n\nPrimary Objective # 4\n\nPrimary Objective #5\n\nSecondary Objectives\n\nDetermine sensitivity of each instrument with respect to vendor-generated MDL and\nPQL.\n\nDetermine potential analytical accuracy associated with vendor field measurements.\n\nEvaluate the precision of vendor field measurements.\n\nMeasure time required to perform five functions related to mercury measurements:\n1) mobilization and setup, 2) initial calibration, 3) daily calibration, 4) sample\nanalysis, and 5) demobilization.\n\nEstimate costs associated with mercury measurements for the following four\ncategories: 1) capital, 2) labor, 3) supplies, and 4) investigation-derived wastes.\n\nIndependent laboratory\nconfirmation of SRMs,\nfield samples, and\nspiked field samples.\n\nDocumentation during\ndemonstration; vendor-\nprovided information.\n\n \n\nSecondary Objective # 1\nSecondary Objective # 2\nSecondary Objective # 3\nSecondary Objective # 4\n\nSecondary Objective # 5\n\ninvestigation.\n\nDocument ease of use, skills, and training required to operate the device properly.\nDocument potential H&S concerns associated with operating the device.\nDocument portability of the device.\n\nEvaluate durability of device based on materials of construction and engineering\ndesign.\n\nDocument the availability of the device and its spare parts.\n\n15\n\nDocumentation of\nobservations during\ndemonstration; vendor-\nprovided information.\n\nPost-demonstration",
    "Page_33": "Critical data support primary objectives and noncritical data\nsupport secondary objectives. With the exception of the\ncost information, primary objectives required the use of\nquantitative results to draw conclusions regarding\ntechnology performance. Secondary objectives pertained\nto information that was useful and did not necessarily\nrequire the use of quantitative results to draw conclusions\nregarding technology performance.\n\n4.2\n\n4.2.1 Approach for Addressing Primary\nObjectives\n\nThe purpose of this demonstration was to evaluate the\nperformance of the vendor's instrumentation against a\nstandard laboratory procedure. In addition, an overall\naverage relative standard deviation (RSD) was calculated\nfor all measurements made by the vendor and the referee\nlaboratory. RSD comparisons used descriptive statistics,\nnotinferential statistics, between the vendor and laboratory\nresults. Other statistical comparisons (both inferential and\ndescriptive) for sensitivity, precision, and accuracy were\nused, depending upon actual demonstration results.\n\nDemonstration Design\n\nThe approach for addressing each of the primary\nobjectives is discussed in the following subsections. A\ndetailed explanation of the precise statistical determination\nused for evaluating primary objectives No. 1 through No. 3\nis presented in Chapter 6.\n\n4.2.1.1 Primary Objective #1: Sensitivity\n\nSensitivity is the ability of a method or instrument to\ndiscriminate between small differences in analyte\nconcentration (EPA, 2002b). It can be discussed in terms\nof an instrument detection limit (IDL), a method detection\nlimit (MDL), and as a practical quantitation limit (PQL).\nMDL is not a measure of sensitivity in the same respect as\nan IDL or PQL. It is a measure of precision at a\npredetermined, usually low, concentration. The IDL\npertains to the ability of the instrument to determine with\nconfidence the difference between a sample that contains\nthe analyte of interest at a low concentration and a sample\nthat does not contain that analyte. The IDL is generally\nconsidered to be the minimum true concentration of an\nanalyte producing a non-zero signal that can be\ndistinguished from the signals generated when no\nconcentration of the analyte is present and with an\nadequate degree of certainty.\n\n16\n\nThe IDL is not rigidly defined in terms of matrix, method,\nlaboratory, or analyst variability, and it is not usually\nassociated with a statistical level of confidence. IDLs are,\nthus, usually lower than MDLs and rarely serve a purpose\nin terms of project objectives (EPA, 2002b). The PQL\ndefines a specific concentration with an associated level of\naccuracy. The MDL defines a lower limit at which a\nmethod measurement can be _ distinguished from\nbackground noise. The PQL is a more meaningful\nestimate of sensitivity. The MDL and PQL were chosen as\nthe two distinct parameters for evaluating sensitivity. The\napproach for addressing each of these indicator\n\nparameters is discussed separately in the following\nparagraphs.\n\nMDL\n\nMDL is the estimated measure of sensitivity as defined in\n\n40 Code of Federal Regulations (CFR) Part 136. The\npurpose of the MDL measurement is to estimate the\nconcentration at which an individual field instrumentis able\nto detect a minimum concentration that is statistically\ndifferent from instrument background or noise. Guidance\nfor the definition of the MDL is provided in EPA G-5i (EPA,\n2002b).\n\nThe determination of a MDL usually requires seven\ndifferent measurements of a low concentration standard or\nsample. Following procedures established in 40 CFR Part\n136 for water matrices, the demonstration MDL definition\n\nis as follows:\n\n \n\nMDL = tat.0.99$\n\n99\" percentile of the t-distribution\nwith n —1 degrees of freedom\nnumber of measurements\nstandard deviation of replicate\nmeasurements\n\nwhere: tin-1,0.99) =\n\nn\nSs\n\nPQL\n\nThe PQL is another important measure of sensitivity. The\nPQL is defined in EPA G-5i as the lowest level an\ninstrument is capable of producing a result that has\nsignificance in terms of precision and bias. (Bias is the\ndifference between the measured value and the true\nvalue.) It is generally considered the lowest standard on\nthe instrument calibration curve. It is often 5-10 times\nhigher than the MDL, depending upon the analyte, the\ninstrument being used, and the method for analysis;\nhowever, it should not be rigidly defined in this manner.",
    "Page_34": "During the demonstration, the PQL was to be defined by\nthe vendor’s reported calibration or based upon lower\nconcentration samples or SRMs. The evaluation of\nvendor-reported results for the PQL included a\ndetermination of the percent difference (%D) between their\ncalculated value and true value. The true value is\nconsidered the value reported by the referee laboratory for\nfield samples or spiked field samples, or, in the case of\nSRMs, the certified value provided by the supplier. The\nequation used for the %D calculation is:\n\n%D = Etrue — caloulated | 4 0\n\ntrue\n\nwhere: Cine true concentration as determined\nby the referee laboratory or SRM\n\nreference value\nC calculated = calculated test sample\n\nconcentration\n\nThe PQL and %D were reported for the vendor. The %D\nfor the referee laboratory, at the same concentration, was\nalso reported for purposes of comparison. No statistical\ncomparison was made between these two values; only a\ndescriptive comparison was made for purposes of this\nevaluation. (The %D requirement for the referee laboratory\nwas defined as 10% or less. The reference method PQL\nwas approximately 10 ug/kg.)\n\n4.2.1.2 Primary Objective #2: Accuracy\n\nAccuracy was calculated by comparing the measured value\nto a known or true value. For purposes of this\ndemonstration, three separate standards were used to\nevaluate accuracy. These included: 1) SRMs, 2) field\nsamples collected from four separate mercury-\ncontaminated sites, and 3) spiked field samples. Foursites\nwere used for evaluation of the Ohio Lumex field\ninstrument. Samples representing field samples and\nspiked field samples were prepared at the SAIC\nGeoMechanics Laboratory. In order to prevent cross\ncontamination, SRMs were prepared in a separate location.\nEach of these standards is discussed separately in the\nfollowing paragraphs.\n\nSRMs\n\nThe primary standards used to determine accuracy for this\ndemonstration were SRMs. SRMs provided very tight\nstatistical comparisons, although they did not provide all\nmatrices of interest nor all ranges of concentrations. The\n\n17\n\nSRMs were obtained from reputable suppliers, and had\nreported concentrations at associated 95% confidence\nintervals (CIs) and 95% prediction intervals. Prediction\nintervals were used for comparison because they represent\na statistically infinite number of analyses, and therefore,\nwould include all possible correct results 95% of the time.\nAll SRMs were analyzed by the referee laboratory and\nselected SRMs were analyzed by the vendor, based upon\ninstrument capabilities and concentrations of SRMs that\ncould be obtained. Selected SRMs covered an appropriate\nrange for each vendor. Replicate SRMs were also\nanalyzed by the vendor and the laboratory.\n\nThe purpose for SRM analysis by the referee laboratory\nwas to provide a check on laboratory accuracy. During the\npre-demonstration, the referee laboratory was chosen, in\npart, based upon the analysis of SRMs. This was done to\nensure a competent laboratory would be used for the\ndemonstration. Because of the need to provide confidence\nin laboratory analysis during the demonstration, the referee\nlaboratory analyzed SRMs as an ongoing check for\nlaboratory bias.\n\nEvaluation of vendor and laboratory analysis of SRMs was\nperformed as follows. Accuracy was reported for\nindividual sample concentrations of replicate\nmeasurements made at the same concentration.\n\nTwo-tailed 95% Cls were computed according to the\nfollowing equation:\n\nAttanos7e ‘si dn\n\n97.5'\" percentile of the\nt-distribution with n-1 degrees of\nfreedom\n\nnum ber of measurements\nstandard deviation of replicate\nmeasurements\n\nwhere: tin-1, 0.975)\n\nThe number of vendor-reported SRM results and referee\nlaboratory-reported SRM results that were within the\nassociated 95% prediction interval were evaluated.\nPrediction intervals were computed in a similar fashion to\n\nthe Cl, except that the Student’s “t” value use “n” equal to\ninfinity and, because prediction intervals represented “n”\napproaching infinity, the square root of “n” was dropped\n\nfrom the equation.\n\nA final measure of accuracy determined from SRMs is a\nfrequency distribution that shows the percentage of vendor-\nreported measurements that are within a specified window",
    "Page_35": "of the reference value. For example, a distribution within\na 30% window of a reported concentration, within a 50%\nwindow, and outside a 50% window of a reported\nconcentration. This distribution aspect could be reported\nas average concentrations of replicate results from the\nvendor for a particular concentration and matrix, compared\nto the same collected sample from the laboratory. These\nare descriptive statistics and are used to better describe\ncomparisons, but they are notintended as inferential tests.\n\nField Samples\n\nThe second accuracy standard used for this demonstration\nwas actual field samples collected from four separate\nmercury-contaminated sites. This accuracy determination\nconsisted of a comparison of vendor-reported results for\nfield samples to the referee laboratory results for the same\nfield samples. The field samples were used to ensure that\n\"real-world\" samples were tested for each vendor. The\nfield samples consisted of variable mercury concentrations\nwithin varying soil and sediment matrices. The referee\nlaboratory results are considered the standard for\ncomparison to each vendor.\n\nVendor sample results for a given field sample were\ncompared to replicates analyzed by the laboratory for the\nsame field sample. (A hypothesis test was use with alpha\n= 0.01 was performed. The null hypothesis was that\nsample results were similar. Therefore, if the null\nhypothesis is rejected, then the sample sets are considered\ndifferent.) Comparisons for a_ specific matrix or\nconcentration were made in order to provide additional\ninformation on that specific matrix or concentration.\nComparison of the vendor values to laboratory values were\nsimilar to the comparisons noted previously for SRMs,\nexcept that a more definitive or inferential statistical\nevaluation was used. Alpha 0.01 was used to help\nmitigate inter-laboratory variability. Additionally, an\naggregate analysis was used to mitigate statistical\nanomalies (see Section 6.1.2).\n\nSpiked Field Samples\n\nThe third accuracy standard for this demonstration was\nspiked field samples. These spiked field samples were\nanalyzed by the vendors and by the referee laboratory in\nreplicate, in order to provide additional measurement\ncomparisons to a known value. Spikes were prepared to\ncover additionalconcentrations not available from SRMs or\nthe samples collected in the field. They were grouped with\nthe field sample comparison noted above.\n\n18\n\n4.2.1.3 Primary Objective #3: Precision\n\nPrecision can be defined as the degree of mutual\nagreement of independent measurements generated\nthrough repeated application of a process under specified\nconditions. Precision is usually thought of as repeatability\nof a specific measurement, anditis often reported as RSD.\nThe RSD is computed from a specified number of\nreplicates. The more replications of a measurement, the\nmore confidence is associated with a reported RSD.\nReplication of a measurement may be as few as 3\nseparate measurements to 30 or more measurements of\nthe same sample, dependent upon the degree of\nconfidence desired in the specified result. The precision\nof an analytical instrument may vary depending upon the\nmatrix being measured, the concentration of the analyte,\nand whether the measurement is made for an SRM ora\nfield sample.\n\nThe experimental design for this demonstration included a\nmechanism to evaluate the precision of the vendors’\ntechnologies. Field samples from the four mercury-\ncontaminated field sites were evaluated by each vendor's\nanalytical instrument. During the demonstration,\nconcentrations were predetermined only as low, medium,\nor high. Ranges of test samples (field samples, SRMs,\nand spikes) were selected to cover the appropriate\nanalytical ranges of the vendor’s instrumentation. It was\nknown prior to the demonstration that not all vendors were\ncapable of measuring similar concentrations (i.e., some\ninstruments were better at measuring low concentrations\nand others were geared toward higher concentration\nsamples or had other attributes such as costor ease of use\nthat defined specific attributes of their technology).\nBecause of this fact, not all vendors analyzed the same\nsamples.\n\nDuring the demonstration, the vendor’s instrumentation\nwas tested with samples from the four different sites,\nhaving different matrices when possible (i.e., depending\nupon available concentrations) and having different\nconcentrations (high, medium, and low) using a variety of\nsamples. Sample concentrations for an_ individual\ninstrument were chosen based upon vendor attributes in\nterms of expected low, medium, and high concentrations\nthat the particular instrument was capable of measuring.\n\nThe referee laboratory measured replicates of allsamples.\nThe results were used for precision comparisons to the\nindividual vendor. The RSD for the vendor and the\nlaboratory were calculated individually, using the following\nequation:",
    "Page_36": "5\n%RSD = —x 100\nx\n\nwhere: S = standard deviation of replicate results\nx = mean value of replicate results\n\nUsing descriptive statistics, differences between vendor\nRSD and referee laboratory RSD were determined. This\nincluded RSD comparisons based upon concentration,\nSRMs, field samples, and different sites. In addition, an\noverall average RSD was calculated for all measurements\nmade by the vendor and the laboratory. RSD comparisons\nwere based upon descriptive statistical evaluations\nbetween the vendor and the laboratory, and results were\ncompared accordingly.\n\n4.2.1.4 Primary Objective #4: Time per Analysis\n\nThe amount of time required for performing the analysis\nwas measured and reported for five categories:\n\n* Mobilization and setup\n+ — Initial calibration\n\n+ Daily calibration\n\n+ Sample analyses\n\n+ Demobilization\n\nMobilization and setup included the time needed to unpack\nand prepare the instrument for operation. Initial calibration\nincluded the time to perform the vendor recommended\non-site calibrations. Daily calibration included the time to\nperform the vendor-recommended calibrations on\nsubsequent field days. (Note that this could have been the\nsame as the initial calibration, a reduced calibration, or\nnone.) Sample analyses included the time to prepare,\nmeasure, and calculate the results for the demonstration\nand the necessary quality control (QC) samples performed\nby the vendor.\n\nThe time per analysis was determined by dividing the total\namount of time required to perform the analyses by the\nnumber of samples analyzed (197). In the numerator,\nsample analysis time included preparation, measurement,\nand calculation of results for demonstration samples and\nnecessary QC samples performed by the vendor. In the\ndenominator, the total number of analyses included only\ndemonstration samples analyzed by the vendor, not QC\nanalyses nor reanalyses of samples.\n\nDowntime that was required or that occurred between\nsample analyses as a part of operation and handling was\nconsidered a part of the sample analysis time. Downtime\noccurring due to instrument breakage or unexpected\nmaintenance was not counted in the assessment, but it is\n\n19\n\nnoted in this final report as an additional time. Any\ndowntime caused by instrument saturation or memory\neffect was addressed, based upon its frequency and\nimpact on the analysis.\n\nUnique time measurements are also addressed in this\nreport (e.g., if soil samples were analyzed directly, and\nsediment samples required additional time to dry before the\nanalyses started, then a statement was made noting that\nsoil samples were analyzed in X amount of hours, and that\nsediment samples required drying time before analysis).\n\nRecorded times were rounded to the nearest 15-minute\ninterval. The number of vendor personnel used was noted\nand factored into the time calculations. No comparison on\ntime per analysis is made between the vendor and the\nreferee laboratory.\n\n4.2.1.5 Primary Objective #5: Cost\n\nThe following four cost categories were considered to\nestimate costs associated with mercury measurements:\n\n* Capital costs\n\n+ Labor costs\n\n+ Supply costs\n\n+ Investigation-derived waste (IDW ) disposal costs\n\nAlthough both vendor and laboratory costs are presented,\nthe calculated costs were not compared with the referee\nlaboratory. A summary of how each cost category was\nestimated for the measurement device is provided below.\n\n+ The capital cost was estimated based on published\nprice lists for purchasing, renting, or leasing each field\nmeasurement device. If the device was purchased,\nthe capital cost estimate did not include salvage value\nfor the device after work was completed.\n\n* The labor cost was based on the number of people\nrequired to analyze samples during the demonstration.\nThe labor rate was based on a standard hourly rate for\na technician or other appropriate operator. During the\ndemonstration, the skill level required was confirmed\nbased on vendor input regarding the operation of the\ndevice to produce mercury concentration results and\nobservations made in the field. The labor costs were\nbased on: 1) the actual number of hours required to\ncomplete all analyses, quality assurance (QA), and\nreporting; and 2) the assumption that a technician who\nworked for a portion of a day was paid for an entire\n8-hour day.\n\n* The supply costs were based on any supplies required\nto analyze the field and SRM samples during the",
    "Page_37": "demonstration. Supplies consisted of items not\nincluded in the capital category, such as_ extraction\nsolvent, glassware, pipettes, spatulas, agitators, and\nsimilar materials. The type and quantity of all supplies\nbrought to the field and used during the demonstration\nwere noted and documented.\n\nAny maintenance and repair costs during the\ndemonstration were documented or provided by the\nvendor. Equipment costs were estimated based on\nthis information and standard cost analysis guidelines\nused in the SITE Program.\n\n+ The IDW disposal costs included decontamination\nfluids and equipment, mercury-contaminated soil and\nsediment samples, and used sample residues.\nContaminated personal protective equipment (PPE)\nnormally used in the laboratory was placed into a\nseparate container. The disposal costs for the IDW\nwere included in the overall analytical costs for each\nvendor.\n\nAfter allof the cost categories were estimated, the cost per\nanalysis was calculated. This cost value was based on the\nnumber of analyses performed. As the number of samples\nanalyzed increased, the initial capital costs and certain\nother costs were distributed across a greater number of\nsamples. Therefore, the per unit cost decreased. For this\nreason, two costs were reported: 1) the initial capital costs\nand 2) the operating costs per analysis. No comparison to\nthe referee laboratory's method cost was made; however,\na generic cost comparison was made. Additionally, when\n\ndetermining laboratory costs, the associated cost for\nlaboratory audits and data validation should be considered.\n\n4.2.2 Approach for Addressing Secondary\nObjectives\n\nSecondary objectives were evaluated based on\nobservations made during the demonstration. Because of\nthe number of vendors involved, technology observers\nwere required to make simultaneous observations of two\nvendors each during the demonstration. Four procedures\nwere implemented to ensure that these subjective\nobservations made by the observers were as consistent as\npossible.\n\nFirst, forms were developed for each of the five secondary\nobjectives. These forms assisted in standardizing the\nobservations. Second, the observers met each day before\nthe evaluations began, at significant break periods, and\nafter each day of work to discuss and compare\nobservations regarding each device. Third, an additional\nobserver was assigned to independently evaluate only the\nsecondary objectives in order to ensure that a consistent\napproach was applied in evaluating these objectives.\nFinally, the SAIC TOM circulated among the evaluation\nstaff during the demonstration to ensure that a consistent\napproach was being followed by all personnel. Table 4-2\nsummarizes the aspects observed during the\ndemonstration for each secondary objective. The\nindividual approaches to each of these objectives are\ndetailed further in the following subsections.\n\nTable 4-2. Summary of Secondary Objective Observations Recorded During the Demonstration\n\nSECONDARY OBJECTIVE\n\nGeneral\n\nInformation Secondary Objective # 1\n\nEase of Use\n\nSecondary Objective # 2\nH&S Concerns\n\nSecondary Objective # 3\nInstrument Portability\n\nSecondary Objective # 4\nInstrument Durability\n\n \n\n- Vendor Name\n\n- Observer Name\n- Instrument Type\n- Instrument Name\n\n- No. of Operators\n\n- Operator Names/Titles\n- Operator Training\n\n- Training References\n\n- Instrument Certifications\n- Electrical Hazards\n\n- Chemicals Used\n\n- Radiological Sources\n\n- Materials of Construction\n- Quality of Construction\n\n- Max. Operating Temp.\n\n- Max. Operating Humidity\n- Downtime\n\n- Maintenance Activities\n\n- Repairs Conducted\n\n- Instrument Weight\n\n- Instrument Dimensions\n- Power Sources\n\n- Packaging\n\n- Shipping & Handling\n\n- Model No. - Instrument Setup Time - Hg Exposure Pathways\n- Serial No. - Instrument Calibration Time — - Hg Vapor Monitoring\n- Sample Preparation Time - PPE Requirements\n- Sample Measurement Time —- Mechanical Hazard\n- Waste Handling Issues\nH&S Health and Safety\n\nPPE = Personal Protective Equipment\n\n20",
    "Page_38": "4.2.2.1 Secondary Objective #1: Ease of Use\n\nThe skills and training required for proper device operation\nwere noted; these included any degrees or specialized\ntraining required by the operators. This information was\ngathered by interviews (i.e., questioning) of the operators.\nThe number of operators required was also noted. This\nobjective was also evaluated by subjective observations\nregarding the ease of equipment use and major peripherals\nrequired to measure mercury concentrations in soils and\nsediments. The operating manual was evaluated to\ndetermine if it is easily useable and understandable.\n\n4.2.2.2 Secondary Objective #2: Health and Safety\nConcerns\n\nHealth and safety (H&S) concerns associated with device\noperation were noted during the demonstration. Criteria\nincluded hazardous materials used, the frequency and\nlikelihood of potential exposures, and any direct exposures\nobserved during the demonstration. In addition, any\npotential for exposure to mercury during sample digestion\nand analysis was evaluated, based upon equipment\ndesign. Other H&S concerns, such as basic electrical and\nmechanical hazards, were also noted. Equipment\ncertifications, such as Underwriters Laboratory (UL), were\ndocumented.\n\n4.2.2.3 Secondary Objective #3:\nDevice\n\nPortability of the\n\nThe portability of the device was evaluated by observing\ntransport, measuring setup and tear down time,\ndetermining the size and weight of the unit and peripherals,\nand assessing the ease with which the instrument was\nrepackaged for movement to another location. The use of\nbattery power or the need for an AC outlet was also noted.\n\n4.2.2.4 Secondary Objective #4: Instrument Durability\n\nThe durability of each device and major peripherals was\nassessed by noting the quality of materials and\nconstruction. All device failures, routine maintenance,\nrepairs, and downtime were documented during the\ndemonstration. No specific tests were performed to\nevaluate durability; rather, subjective observations were\nmade using a field form as guidance.\n\n4.2.2.5 Secondary Objective #5: Availability of Vendor\nInstruments and Supplies\n\nThe availability of each device was evaluated by\ndetermining whether additional units and spare parts are\nreadily available from the vendor or retail stores. The\nvendor's office (or a web page) and/or a retail store was\n\n21\n\ncontacted to identify and determine the availability of\nsupplies of the tested measurement device and spare\nparts. This portion of the evaluation was performed after\nthe field demonstration, in conjunction with the cost\nestimate.\n\n4.3\n\n4.3.1 Sample Preparation\n4.3.1.1 Field Samples\n\nSample Preparation and Management\n\nField samples were collected during the pre-demonstration\nportion of the project, with the ultimate goal of producing a\nset of consistent test soils and sediments to be distributed\namong all participating vendors and the referee laboratory\nfor analysis during the demonstration. Samples were\ncollected from the following four sites:\n\n* Carson River Mercury site (near Dayton, NV)\n\n*  Y-12 National Security Complex (Oak Ridge, TN)\n«Manufacturing facility (eastern U.S.)\n\n+ Puget Sound (Bellingham, WA)\n\nThe field samples collected during the pre-demonstration\nsampling events comprised a variety of matrices, ranging\nfrom material having a high clay content, to material\ncomposed mostly of gravelly, coarse sand. The field\nsamples also differed with respect to moisture content;\nseveral were collected as wet sediments. Table 4-3 shows\nthe number of distinct field samples that were collected\nfrom each of the four field sites.\n\nPrior to the start of the demonstration, the field samples\nselected for analysis during the demonstration were\nprocessed at the SAIC GeoMechanics Laboratory in Las\nVegas, NV. The specific sample homogenization\nprocedure used by this laboratory largely depended on the\nmoisture content and physical consistency of the sample.\nTwo specific sample homogenization procedures were\ndeveloped and tested by SAIC at the GeoMechanics\nLaboratory during the pre-demonstration portion of the\nproject. The methods included a non-slurry sample\nprocedure and a slurry sample procedure.\n\nA standard operating procedure (SOP) was developed\ndetailing both methods. The procedure was found to be\nsatisfactory, based upon the results of replicate samples\nduring the pre-demonstration. This SOP is included as\nAppendix A of the Field Demonstration Quality Assurance\nProject Plan (SAIC, August 2003, EPA/600/R-03/053).\nFigure 4-1 summarizes the homogenization steps of the\nSOP, beginning with sample mixing. This procedure was",
    "Page_39": "used for preparing both pre-demonstration and\ndemonstration samples. Prior to the mixing process (i.e.,\nStep 1 in Figure 4-1), all field samples being processed\nwere visually inspected to ensure that oversized materials\nwere removed, and that there were no clumps that would\nhinder homogenization. Non-slurry samples were air-dried\nin accordance with the SOP, so that they could be passed\nmultiple times through a riffle splitter. Due to the high\n\nTable 4-3. Field Samples Collected from the Four Sites\n\nNo. of Samples / Matrices\n\nmoisture content of many of the samples, they were not\neasily air-dried and could not be passed through a riffle\nsplitter while wet. Samples with very high moisture\ncontents, termed “slurries,” were not air-dried, and\nbypassed the riffle splitting step. The homogenization\nsteps for each type of matrix are briefly summarized, as\nfollows.\n\n \n\nField Site Collected Areas For Collecting Sample Material Volume Required\nCarson River 12 Soil Tailings Piles (Six Mile Canyon) 4 L each for soil\n6 Sediment River Bank Sediments 12 L each for sediment\nY-12 10 Sediment Poplar Creek Sediments 12 L each for sediment\n6 Soil Old Mercury Recovery Bldg. Soils 4 L each for soil\nManufacturing Site 12 Soil Subsurface Soils 4Leach\nPuget Sound 4 Sediment High-Level Mercury (below cap) 12 Leach\n\nLow-Level Mercury (native material)\n\nPreparing Slurry Matrices\n\nFor slurries (i.e., wet sediments), the mixing steps were\nsufficiently thorough that the sample containers could be\nfilled directly from the mixing vessel. There were two\nseparate mixing steps for the slurry-type samples. Each\nslurry was initially mixed mechanically within the sample\ncontainer (i.e., bucket) in which the sample was shipped to\nthe SAIC GeoMechanics Laboratory. A subsample of this\npremixed sample was transferred to a second mixing\nvessel. A mechanical drill equipped with a paint mixing\nattachment was used to mix the subsample. As shown in\nFigure 4-1, slurry samples bypassed the sample riffle\nsplitting step. To ensure all sample bottles contained the\nsame material, the entire set of containers to be filled was\nsubmerged into the slurry as a group. The filled vials were\nallowed to settle for a minimum of two days, and the\nstanding water was removed using a Pasteur pipette. The\nremoval of the standing water from the slurry samples was\nthe only change to the homogenization procedure between\nthe pre-demonstration and the demonstration.\n\nPreparing \"Non-Slurry\" Matrices\n\nSoils and sediments having no excess moisture were\ninitially mixed (Step 1) and then homogenized in the\nsample riffle splitter (Step 2). Prior to these steps, the\nmaterial was air-dried and subsampled to reduce the\nvolume of material to a size that was easier to handle.\n\n22\n\nAs shown in Figure 4-1 (Step 1) the non-slurry subsample\nwas manually stirred with a spoon or similar equipment\nuntil the material was visually uniform. Immediately\nollowing manual mixing, the subsample was mixed and\nsplit six times for more complete homogenization (Step 2).\nAfter the sixth and final split, the sample material was\neveled to form a flattened, elongated rectangle and cut into\nransverse sections to fill the containers (Steps 3 and 4).\nAfter homogenization, 20-mL sample vials were filled and\nprepared for shipment (Step 5).\n\nFor the demonstration, the vendor analyzed 197 samples,\nwhich included replicates of up to 7 samples per sample\nlot. The majority of the samples distributed had\nconcentrations within the range of the vendor’s technology.\nSome samples had expected concentrations at or below\nhe estimated level of detection for each of the vendor\ninstruments. These samples were designed to evaluate\nhe reported MDL and PQL and also to assess the\nprevalence of false positives. Field samples distributed to\nhe vendor included sediments and soils collected from all\nour sites and prepared by both the slurry and dry\nhomogenization procedures. The field samples were\nsegregated into broad sample sets: low, medium, and high\nmercury concentrations. This gave the vendor the same\ngeneral understanding of the sample to be analyzed as\nthey would typically have for field application of their\ninstrument.",
    "Page_40": "Test material mixed until\nvisually uniform\n\nFor non-slurries\nMix manually\n\nFor slurries\na) Mix mechanically the entire\nsample volume\n\nb) Subsample slurry, transfer to\nmixing vessel, and mix\nmechanically\n\n \n\nNon-slurries to\nriffle splitter\nSlurries transferred\n\ndirectly to 20 mL vials\n(vials submerged into slurry)\n\n   \n   \n \n\n  \n \n   \n\nare reintroduced\ninto splitter (6 X)\n\n     \n\nRIFFLE\nSPLITTER\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nElongated\nrectangular pile\n/ trom 6\" split)\nTransfer cut TEFLON SURFACE\nsections to\n20 mL vials 3 Sample aliquots made\n\nby transverse cuts\nacross sample piles\n\nv v\n[| [| [| 3 Samples shipped @ 4 °C to\nreferee lab and Oak Ridge\n\n(Container numbers will vary)\nFigure 4-1. Test sample preparation at the SAIC GeoMechanics Laboratory.\n\n \n\n23",
    "Page_41": "In addition, selected field samples were spiked with\nmercury (Il) chloride to generate samples with additional\nconcentrations and test the ability of the vendor’s\ninstrumentation to measure the additional species of\nmercury. Specific information regarding the vendor’s\nsample distribution is included in Chapter 6.\n\n4.3.1.2 Standard Reference Materials\n\nCertified SRMs were analyzed by both the vendors and the\nreferee laboratory. These samples were homogenized\nmatrices which had a known concentration of mercury.\nConcentrations were certified values, as provided by the\nsupplier, based on independent confirmation via multiple\nanalyses of multiple lots and/or multiple analyses by\ndifferent laboratories (i.e., round robin testing). These\nanalytical results were then used to determine \"true\"\nvalues, as well as a statistically derived intervals (a 95%\nprediction interval) that provided a range within which the\ntrue values were expected to fall.\n\nThe SRMs selected were designed to encompass the\nsame contaminant ranges indicated previously: low-,\nmedium-, and high-level mercury concentrations. In\naddition, SRMs of varying matrices were included in the\ndemonstration to challenge the vendor technology as well\nas the referee laboratory. The referee laboratory analyzed\nall SRMs. SRM samples were intermingled with site field\nsamples and labeled in the same manner as field samples.\n\n4.3.1.3 Spiked Field Samples\n\nSpiked field samples were prepared by the SAIC\nGeoMechanics Laboratory using mercury (Il) chloride.\nSpikes were prepared using field samples from the\nselected sites. Additional information was gained by\npreparing spikes at concentrations not previously\nobtainable. The SAIC GeoMechanics Laboratory’s ability\nto prepare spikes was tested prior to the demonstration\nand evaluated in order to determine expected variability\nand accuracy of the spiked sample. The spiking procedure\nwas evaluated by preparing several different spikes using\ntwo different spiking procedures (dry and wet). Based\nupon replicate analyses results, it was determined that the\nwet, or slurry, procedure was the only effective method of\nobtaining a homogeneous spiked sample.\n\n4.3.2 Sample Management\n4.3.2.1 Sample Volumes, Containers, and Preservation\n\nA subset from the pre-demonstration field samples was\nselected for use in the demonstration based on the\nsample’s mercury concentration range and sample type\n\n24\n\n(i.e., sediment versus soil). The SAIC GeoMechanics\nLaboratory prepared individual batches of field sample\nmaterial to fill sample containers for each vendor. Once all\ncontainers from a field sample were filled, each container\nwas labeled and cooled to 4 °C. Because mercury\nanalyses were to be performed both by the vendors in the\nfield and by the referee laboratory, adequate sample size\nwas taken into account. Minimum sample size\nrequirements for the vendors varied from 0.1 g or less to\n8-10 g. Only the referee laboratory analyzed separate\nsample aliquots for parameters otherthan mercury. These\nadditional parameters included arsenic, barium, cadmium,\nchromium, lead, selenium, silver, copper, zinc, oil and\ngrease, and total organic carbon (TOC). Since the mercury\nmethod (SW-846 7471B) being used by the referee\nlaboratory requires 1 g for analysis, the sample size sent to\nall participants was a 20-mL vial (approximately 10 g),\nwhich ensured a sufficient volume and mass for analysis\nby all vendors.\n\n4.3.2.2 Sample Labeling\n\nThe sample labeling used for the 20-mL vials consisted of\nan internal code developed by SAIC. This \"blind\" code was\nused throughout the entire demonstration. The only\nindividuals who knew the key to the coding of the\nhomogenized samples to the specific field samples were\nthe SAIC TOM, the SAIC GeoMechanics Laboratory\nManager, and the SAIC QA Manager.\n\n4.3.2.3 Sample\nCustody\n\nRecord Keeping, Archiving, and\n\nSamples were shipped to the laboratory and the\ndemonstration site the week prior to the demonstration. A\nthird set of vials was archived at the SAIC GeoMechanics\nLaboratory as reserve samples.\n\nThe sample shipment to Oak Ridge was retained at all\ntimes in the custody of SAIC at their Oak Ridge office until\narrival of the demonstration field crew. Samples were\nshipped under chain-of-custody (COC) and with custody\nseals on both the coolers and the inner plastic bags. Once\nthe demonstration crew arrived, the coolers were retrieved\nfrom the SAIC office. The custody seals on the plastic\nbags inside the cooler were broken by the vendor upon\ntransfer.\n\nUpon arrival at the ORNL site, the vendor set up the\ninstrumentation at the direction and oversight of SAIC. At\nthe start of sample testing, the vendor was provided with a\nsample set representing field samples collected from a\nparticular field site, intermingled with SRM and spiked\nsamples. Due to variability of vendor instrument",
    "Page_42": "measurementranges for mercury detection, not all vendors\nreceived samples from the same field material. All\nsamples were stored in an ice cooler prior to demonstration\nstartup and were stored in an on-site sample refrigerator\nduring the demonstration. Each sample set was identified\nand distributed as a set, with respect to the site from which\nit was collected. This was done because, in any field\napplication, the location and general type of the samples\nwould be known.\n\nThe vendor was responsible for analyzing all samples\nprovided, performing any dilutions or reanalyses as\nneeded, calibrating the instrument if applicable, performing\nany necessary maintenance, and reporting all results. Any\nsamples that were not analyzed during the day were\nreturned to the vendor for analysis at the beginning of the\nnext day. Once analysis of the samples from the first\nlocation were completed by the vendor, SAIC provided a\nset of samples from the second location. Samples were\nprovided at the time that they were requested by the\nvendor. Once again, the transfer of samples was\ndocumented using a chain-of-custody (COC) form.\n\n \n\nThis process was repeated for samples from each location.\nSAIC maintained custody of all remaining sample sets until\nthey were transferred to the vendor. SAIC maintained\ncustody of samples that already had been analyzed and\nfollowed the waste handling procedures in Section 4.2.2 of\nthe Field Demonstration QAPP to dispose of these wastes.\n\n4.4 Reference Method\n\nProcess\n\nConfirmatory\n\nThe referee laboratory analyzed all samples that were\nanalyzed by the vendor technologies in the field. The\nfollowing subsections provide information on the selection\nof the reference method, selection of the referee\nlaboratory, and details regarding the performance of the\nreference method in accordance with EPA protocols.\nOther parameters that were analyzed by the referee\nlaboratory are also discussed briefly.\n\n4.4.1 Reference Method Selection\n\nThe selection of SW-846 Method 7471B as the reference\nmethod was based on several factors, predicated on\ninformation obtained from the technology vendors, as well\nas the expected contaminant types and soil/sediment\nmercury concentrations expected in the test matrices.\nThere are several laboratory-based, promulgated methods\nfor the analysis of total mercury. In addition, there are\nseveral performance-based methods for the determination\n\n25\n\nof various mercury species. Based on the vendor\ntechnologies, it was determined that a reference method\nfor total mercury would be needed (Table 1-2 summarizes\nthe methods evaluated, as identified through a review of\nthe EPA Test Method Index and SW-846).\n\nIn selecting which of the potential methods would be\nsuitable as a reference method, consideration was given to\nthe following questions:\n\n+ Was the method widely used and accepted? Was the\nmethod an EPA-recommended, or similar regulatory\nmethod? The selected reference method should be\nsufficiently used so that it could be cited as an\nacceptable method for monitoring and/or permit\ncompliance among regulatory authorities.\n\n+ Did the selected reference method provide QA/QC\ncriteria that demonstrate acceptable performance\ncharacteristics over time?\n\n+ Was the method suitable for the species of mercury\nthat were expected to be encountered? The reference\nmethod must be capable of determining, as total\nmercury, all forms of the contaminant known or likely\nto be present in the matrices.\n\n \n\n+ Would the method achieve the necessary detection\nlimits to evaluate the sensitivity of each vendor\ntechnology adequately?\n\n+ Was the method suitable for the concentration range\nthat was expected in the test matrices?\n\nBased on the above considerations, it was determined that\nSW-846 Method 7471B (analysis of mercury in solid\nsamples by cold-vapor AAS) would be the best reference\nmethod. SW-846 method 7474, (an atomic fluorescence\nspectrometry method using Method 3052 for microwave\ndigestion of the solid) had also been considered a likely\ntechnical candidate; however, because this method was\nnot as widely used or referenced, Method 7471B was\nconsidered the better choice.\n\n4.4.2 Referee Laboratory Selection\n\nDuring the planning of the pre-demonstration phase of this\nproject, nine laboratories were sent a statement of work\n(SOW) for the analysis of mercury to be performed as part\nof the pre-demonstration. Seven of the nine laboratories\nresponded to the SOW with appropriate bids. Three of the\nseven laboratories were selected as candidate laboratories\nbased upon technical merit, experience, and pricing.\nThese laboratories received and analyzed blind samples\nand SRMs during pre-demonstration activities. The referee",
    "Page_43": "laboratory to be used for the demonstration was selected\nfrom these three candidate laboratories. Final selection of\nthe referee laboratory was based upon: 1) the laboratory's\ninterest in continuing in the demonstration, 2) the\nlaboratory-reported SRM results, 3) the laboratory MDL for\nthe reference method selected, 4) the precision of the\nlaboratory calibration curve, 5) the laboratory’s ability to\nsupport the demonstration (scheduling conflicts, backup\ninstrumentation, etc.), and 6) cost.\n\nOne of the three candidate laboratories was eliminated\nfrom selection based on a technical consideration. It was\ndetermined that this laboratory would not be able to meet\ndemonstration quantitation limit requirements. (Its lower\ncalibration standard was approximately 50 g/kg, and the\nvendor comparison requirements were well below this\nvalue.) Two candidates thus remained, including the\neventual demonstration laboratory, Analytical Laboratory\nServices, Inc. (ALSI):\n\nAnalytical Laboratory Services, Inc.\nRay Martrano, Laboratory Manager\n34 Dogwood Lane\n\nMiddletown, PA 17057\n\n(717) 944-5541\n\nIn order to make a final decision on selecting a referee\nlaboratory, a preliminary audit was performed by the SAIC\nQA Manager at the remaining two candidate laboratories.\nResults of the SRM samples were compared for the two\nlaboratories. Each laboratory analyzed each sample (there\nwere two SRMs) in triplicate. Both laboratories were within\nthe 95% prediction interval foreach SRM. In addition, the\naverage result from the two SRMs was compared to the\n95% Cl for the SRM.\n\nCalibration curves from each laboratory were reviewed\ncarefully. This included calibration curves generated from\npreviously performed analyses and those generated for\nother laboratory clients. There were two QC requirements\nregarding calibration curves; the correlation coefficient had\nto be 0.995 or greater and the lowest point on the\ncalibration curve had to be within 10% of the predicted\nvalue. Both laboratories were able to achieve these two\nrequirements for all curves reviewed and for a lower\nstandard of 10 wg/kg, which was the lower standard\nrequired for the demonstration, based upon information\nreceived from each of the vendors. In addition, an analysis\nof seven standards was reviewed for MDLs. Both\nlaboratories were able to achieve an MDL that was below\n\n1 ug/kg.\n\n26\n\nIt should be noted that vendor sensitivity claims impacted\nhow low this lower quantitation standard should be. These\nclaims were somewhat vague, and the actual quantitation\nlimit each vendor could achieve was uncertain prior to the\ndemonstration (i.e., some vendors claimed a sensitivity as\nlow as 1 g/kg, but it was uncertain at the time if this limit\nwas actually a PQL ora detection limit). Therefore, it was\ndetermined that, if necessary, the laboratory actually\nshould be able to achieve even alower PQL than 10 yg/kg.\n\nFor both laboratories, SOPs based upon SW-846 Method\n7471B were reviewed. Each SOP followed this reference\nmethod. In addition, interferences were discussed\nbecause there was some concern that organic\ninterferences may have been present in the samples\npreviously analyzed by the laboratories. Because these\nsame matrices were expected to be part of the\ndemonstration, there was some concern associated with\nhow these interferences would be eliminated. This is\ndiscussed at the end of this subsection.\n\nSample throughput was somewhat important because the\nselected laboratory was to receive all demonstration\nsamples at the same time (i.e., the samples were to be\nanalyzed at the same time in order to eliminate any\nquestion of variability associated with loss of contaminant\ndue to holding time). This meant that the laboratory would\nreceive approximately 400 samples for analysis over the\nperiod of a few days. It was also desirable for the\nlaboratory to produce a data report within a 21-day\nturnaround time for purposes of the demonstration. Both\nlaboratories indicated that this was achievable.\nInstrumentation was reviewed and examined at both\nlaboratories. Each laboratory used a Leeman mercury\nanalyzer for analysis. One of the two laboratories had\nbackup instrumentation in case of problems. Each\nlaboratory indicated that its Leeman mercury analyzer was\nrelatively new and had not been a problem in the past.\n\nPrevious SITE program experience was another factor\nconsidered as partof these pre-audits. This is because the\nSITE program generally requires a very high level of QC,\nsuch that most laboratories are not familiar with the QC\nrequired unless they have previously participated in the\nprogram. A second aspect of the SITE program is that it\ngenerally requires analysis of relatively “dirty” samples and\nmany laboratories are not use to analyzing such “dirty”\nsamples. Both laboratories have been longtime\nparticipants in this program.\n\nOther QC-related issues examined during the audits\nincluded: 1) analyses of other SRM samples not previously\nexamined, 2) laboratory control charts, and 3) precision",
    "Page_44": "and accuracy results. Each of these issues was closely\nexamined. Also, because of the desire to increase the\nrepresentativeness of the samples for the demonstration,\neach laboratory was asked if sample aliquot sizes could be\nincreased to 1 g (the method requirement noted 0.2 g).\nBased upon previous results, both laboratories routinely\nincreased sample size to 0.5 g, and each laboratory\nindicated that increasing the sample size would not be a\nproblem. Besides these QC issues, other less tangible QA\nelements were examined. This included analyst\nexperience, management involvement in the\ndemonstration, and internal laboratory QA management.\nThese elements were also factored into the final decision.\n\nSelection Summary\n\nThere were very few factors that separated the quality of\nthese two laboratories. Both were exemplary in performing\nmercury analyses. There were, however, some minor\ndifferences based upon this evaluation that were noted by\nthe auditor. These were as follows:\n\n+ ALSI had backup instrumentation available. Even\nthough neither laboratory reported any problems with\nits primary instrument (the Leeman mercury analyzer),\nALSI did have a backup instrument in case there were\nproblems with the primary instrument, or in the event\nthat the laboratory needed to perform other mercury\nanalyses during the demonstration time.\n\n. As noted, the low standard requirement for the\ncalibration curve was one of the QC requirements\nspecified for this demonstration in order to ensure that\na lower quantitation could be achieved. This low\nstandard was 10 ug/kg for both laboratories. ALSI,\nhowever, was able to show experience in being able to\ncalibrate much lower than this, using a second\ncalibration curve. In the event that the vendor was\nable to analyze at concentrations as low as 1 ug/kg\nwith precise and accurate determinations, ALSI was\nable to perform analyses at lower concentrations as\npart of the demonstration. ALSI used a second, lower\ncalibration curve for any analyses required below 0.05\nmg/kg. Very few vendors were able to analyze\nsamples at concentrations at this low a level.\n\n* Management practices and analyst experience were\nsimilar at both laboratories. ALSI had participated ina\nfew more SITE demonstrations than the other\nlaboratory, but this difference was not significant\nbecause both laboratories had proven themselves\ncapable of handling the additional QC requirements for\nthe SITE program. In addition, both laboratories had\n\n27\n\ninternal QA management procedures to provide the\nconfidence needed to achieve SITE requirements.\n\n+ Interferences for the samples previously analyzed were\ndiscussed and data were reviewed. ALSI performed\ntwo separate analyses for eachsample. This included\nanalyses with and without stannous. chloride.\n(Stannous chloride is the reagent used to release\nmercury into the vapor phase for analysis. Sometimes\norganics can cause interferences in the vapor phase.\nTherefore, an analysis with no stannous chloride would\nprovide information on organic interferences.) The\nother laboratory did not routinely perform this analysis.\nSome samples were thought to contain organic\ninterferences, based on previous sample results. The\npre-demonstration results reviewed indicated that no\norganic interferences were present. Therefore, while\nthis was thought to be a possible discriminator\nbetween the two laboratories in terms of analytical\nmethod performance, it became moot for the samples\nincluded in this demonstration.\n\nThe factors above were considered in the final evaluation.\nBecause there were only minor differences in the technical\nfactors, cost of analysis was used as the discriminating\nfactor. (lf there had been significant differences in\nlaboratory quality, cost would not have been a factor.)\nALSI was significantly lower in cost than the other\nlaboratory. Therefore, ALSI was chosen as the referee\nlaboratory for the demonstration.\n\n4.4.3, Summary of Analytical Methods\n4.4.3.1 Summary of Reference Method\n\nThe critical measurement for this study was the analysis of\nmercury in soiland sediment samples. Samples analyzed\nby the laboratory included field samples, spiked field\nsamples, and SRM _ samples. Detailed laboratory\nprocedures for subsampling, extraction, and analysis were\nprovided in the SOPs included as Appendix B of the Field\nDemonstration QAPP. These are briefly summarized\nbelow.\n\nSamples were analyzed for mercury using Method 7471B,\na cold-vapor atomic absorption method, based on the\nabsorption of light at the 253.7-nm wavelength by mercury\nvapor. The mercury is reduced to the elemental state and\nstripped/volatilized from solution in a closed system. The\nmercury vapor passes through a cell positioned in the light\npath of the AA spectrophotometer. Absorbance (peak\nheight) is measured as a_ function of mercury\nconcentration. Potassium permanganate is added to\neliminate possible interference from sulfide. As per the",
    "Page_45": "method, concentrations as high as 20 mg/kg of sulfide, as\nsodium sulfide, do not interfere with the recovery of added\ninorganic mercury in reagent water. Copper has also been\nreported to interfere; however, the method states that\ncopper concentrations as high as 10 mg/kg had no effect\non recovery of mercury from spiked samples. Samples\nhighin chlorides require additional permanganate (as much\nas 25 mL) because, during the oxidation step, chlorides are\nconverted to free chlorine, which also absorbs radiation of\n254 nm. Free chlorine is removed by using an excess (25\nmL) of hydroxylamine sulfate reagent. Certain volatile\norganic materials that absorb at this wavelength may also\ncause interference. A preliminary analysis without\nreagents can determine if this type of interference is\npresent.\n\nPrior to analysis, the contents of the sample container are\nstirred, and the sample mixed prior to removing an aliquot\nfor the mercury analysis. An aliquot of soil/sediment (1 g)\nis placed in the bottom of a biochemical oxygen demand\nbottle, with reagent water and aqua regia added. The\nmixture is heated in a water bath at 95 °C for 2 minutes.\nThe solution is cooled and reagent water and potassium\npermanganate solution are added to the sample bottle.\nThe bottle contents are thoroughly mixed, and the bottle is\nplaced in the water bath for 30 minutes at 95 °C. After\ncooling, sodium chloride-hydroxylamine sulfate is added to\nreduce the excess permanganate. Stannous chloride is\nthen added and the bottle attached to the analyzer; the\nsample is aerated and the absorbance recorded. An\nanalysis without stannous chloride is also included as an\ninterference check when organic contamination is\nsuspected. In the event of positive results of the non-\nstannous chloride analysis, the laboratory was to report\nthose results to SAIC so that a determination of organic\ninterferences could be made.\n\n4.4.3.2 Summary of Methods’ for Non-Critical\n\nMeasurements.\n\nA selected set of non-critical parameters was also\nmeasured during the demonstration. These parameters\nwere measured to provide a better insightinto the chemical\n\n28\n\nconstituency of the field samples, including the presence of\npotential interferents. The results of the tests for potential\ninterferents were reviewed to determine if a trend was\napparent in the event that inaccuracy or low precision was\n\nobserved. Table 4-4 presents the analytical method\nreference and method type for these non-critical\nparameters.\n\nTable 4-4. Analytical Methods for Non-Critical Parameters\n\nParameter Method Reference Method Type\n\nArsenic, barium, SW-846 3050/6010\ncadmium,\n\nchromium, lead,\n\nselenium, silver,\n\ncopper, and zinc\n\nAcid digestion, ICP\n\n \n\nOil and Grease EPA 1664 n-Hexane\nextraction,\nGravimetric\nanalysis\n\nTOC SW-846 9060 Carbonaceous\nanalyzer\n\nTotal Solids EPA 2540G Gravimetric\n\n4.5 Deviations from the Demonstration\n\nPlan\n\nThere was one deviation to the demonstration plan. The\nsamples were distributed to Ohio Lumex by site (Carson\nRiver, Oak Ridge, etc.) as planned; however, due to the\npotential for memory effects, Ohio Lumex analyzed the\nhigh concentration samples from all sites prior to analyzing\nthe low concentration samples for any of the sites.\n\nAdditionally, Ohio Lumex was able to complete allanalyses\nduring the demonstration; however, they were unable to\nlocate the results for one data point, and therefore,\nprovided data for 196 samples prior to leaving the\ndemonstration site.",
    "Page_46": "Chapter 5\nAssessment of Laboratory Quality Control Measurements\n\n5.1 Laboratory QA Summary\n\nQA may be defined as a system of activities, the purpose\nof which is to provide assurance that defined standards of\nquality are met with a stated level of confidence. A QA\nprogram is a means of integrating the quality planning,\nquality assessment, QC, and quality improvement efforts\nto meet user requirements. The objective of the QA\nprogram is to reduce measurement errors to agreed-upon\nlimits, and to produce results of acceptable and known\nquality. The QAPP specified the necessary guidelines to\nensure that the measurement system for laboratory\nanalysis was in control, and provided detailed information\non the analytical approach to ensure that data of high\nquality could be obtained to achieve project objectives.\nThe laboratory analyses were critical to project success, as\nthe laboratory results were used as a standard for\ncomparison to the field method results. The field methods\nare of unknown quality, and therefore, for comparison\npurposes the laboratory analysis needed to be a known\nquantity. The following sections provide information on the\nuse of data quality indicators, and a detailed summary of\nthe QC analyses associated with project objectives.\n\n5.2 Data Quality Indicators for Mercury\n\nAnalysis\n\nTo assess the quality of the data generated by the referee\nlaboratory, two important data quality indicators of primary\nconcern are precision and accuracy. Precision can be\ndefined as the degree of mutual agreement of independent\nmeasurements generated through repeated application of\nthe process under specified conditions. Accuracy is the\ndegree of agreement of a measured value with the true or\nexpected value. Both accuracy and precision were\nmeasured by the analysis of matrix spike/matrix spike\n\n29\n\nduplicates (MS/MSDs). The precision of the spiked\nduplicates is evaluated by expressing, as apercentage, the\ndifference between results of the sample and sample\nduplicate results. The relative percent difference (RPD) is\ncalculated as:\n\n(Maximum Value - Minimum Value)\n\nRPD = 100\n\n(Maximum Value +Minimum Value) /2 *\n\nTo determine and evaluate accuracy, known quantities of\nthe target analytes were spiked into selected field samples.\nAll spikes were post-digestion spikes because of the high\nsample concentrations encountered during the\ndemonstration. Pre-digestion spikes, on_ high-\nconcentration samples would either have been diluted or\nwould have required additional studies to determine the\neffect of spiking more analyte and subsequent recovery\nvalues. To determine matrix spike recovery, and hence\nmeasure accuracy, the following equation was applied:\n\nR= Cse- Cus,\n\nsa\n\n100\n\nwhere,\nCoy = Analyte concentration in spiked\nsample\nCus = Analyte concentration in unspiked\nsample\nCy, = Analyte concentration added to\nsample\n\nLaboratory control samples (LCSs) were used as an\nadditional measure of accuracy in the event of significant",
    "Page_47": "matrix interference. To determine the percent recovery of\nLCS analyses, the equation below was used:\n\nMeasured Concentration\n\n9, =\noR Theoretical Concentration »\n\nWhile several precautions were taken to generate data of\nknown quality through control of the measurement system,\nthe data must also be representative of true conditions and\ncomparable to separate sample aliquots.\nRepresentativeness refers to the degree with which\nanalytical results accurately and precisely reflect actual\nconditions present at the locations chosen for sample\ncollection. Representativeness was evaluated as part of\nthe pre-demonstration and combined with the precision\nmeasurement in relation to sample aliquots. Sample\naliquoting by the SAIC GeoMechanics Laboratory tested\nthe ability of the procedure to produce homogeneous,\nrepresentative, and comparable samples. All samples\nwere carefully homogenized in order to ensure\ncomparability between the laboratory and the vendor.\nTherefore, the RSD measurement objective of 25% or less\nforreplicate sample lotanalysis was intended to assess not\nonly precision but representativeness and comparability.\n\nSensitivity was another critical factor assessed for the\nlaboratory method of analysis. This was measured as a\npractical quantitation limit and was determined by the low\nstandard on the calibration curve. Two separate calibration\ncurves were run by the laboratory when necessary. The\nhigher calibration curve was used for the majority of the\nsamples and had a lower calibration limit of 25 g/kg. The\nlower calibration curve was used when samples were\nbelow this lowercalibration standard. The lower calibration\ncurve had a lower limit standard of 5 ug/kg. The lower limit\nstandard of the calibration curve was run with each sample\nbatch as a check standard and was required to be within\n10% of the true value (QAPP QC requirement). This\nadditional check on analytical sensitivity was performed to\nensure that this lower limit standard was _ truly\nrepresentative of the instrument and method practical\nquantitation limit.\n\n5.3. Conclusions and Data\n\nLimitations\n\nQuality\n\nCritical sample data and associated QC analyses were\nreviewed to determine whether the data collected were of\nadequate quality to provide proper evaluation of the\nproject’s technical objectives. The results of this review\nare summarized below.\n\nAccuracy objectives for mercury analysis by Method 7471B\nwere assessed by the evaluation of 23 spiked duplicate\npairs, analyzed in accordance with standard procedures in\nthe same manner as the samples. Recovery values for the\ncritical compounds were well within objectives specified in\nthe QAPP, except for two spiked samples summarized in\nTable 5-1. The results of these samples, however, were\nonly slightly outside specified limits, and given the number\nof total samples (46 or 23 pairs), this is an insignificant\nnumber of results that did not fall within specifications. The\nMS/MSD results therefore, are supportive of the overall\naccuracy objectives.\n\nTable 5-1. MS/MSD Summary\n\nParameter Value\n\n \n\nQC Limits 80%- 120%\n\nRecovery Range 85.2% - 126%\n\nNumber of Duplicate Pairs 23\nAverage Percent Recovery 108%\nNo. of Spikes Outside QC 2\n\nSpecifications\n\n \n\nAn additional measure of accuracy was LCSs. These were\nanalyzed with every sample batch (1 in 20 samples) and\nresults are presented in Table 5-2. All results were within\nspecifications, thereby supporting the conclusion that QC\nassessment met project accuracy objectives.\n\nTable 5-2. LCS Summary\n\nParameter Value\n\nQC Limits 90%- 110%\n\nRecovery Range 90% - 100%\n\nNumber of LCSs 24\nAverage Percent Recovery 95.5%\nNo. of LCSs Outside QC 0\n\nSpecifications\n\n \n\nPrecision was assessed through the analysis of 23\nduplicate spike pairs for mercury. Precision specifications\nwere established prior to the demonstration as a RPD less\n\n30",
    "Page_48": "than 20%. All but two sample pairs were within\nspecifications, as noted in Table 5-3. The results of these\nsamples, however, were only slightly outside specified\nlimits, and given the number of total samples (23 pairs),\nthis is an insignificant number of results that did not fall\nwithin specifications. Therefore, laboratory analyses met\nprecision specifications.\n\nTable 5-3. Precision Summary\n\nParameter Value\n\nQC Limits RPD< 20%\n\nMS/MSD RPD Range 0.0% to 25%\n\nNumber of Duplicate Pairs 23\nAverage MS/MSD RPD 5.7%\nNo. of Pairs Outside QC 2\n\nSpecifications\n\n \n\nSensitivity results were within specified project objectives.\nThe sensitivity objective was evaluated as the PQL, as\nassessed by the low standard on the calibration curve. For\nthe majority of samples, a calibration curve of 25-500 ug/kg\nwas used. This is because the majority of samples fell\nwithin this calibration range (samples often required\ndilution). There were, however, some samples below this\nrange and a second curve was used. The calibration range\nfor this lower curve was 5-50 ug/kg. In order to ensure that\nthe lower concentration on the calibration curve was a true\nPQL, the laboratory ran a low check standard (lowest\nconcentration on the calibration curve) with every batch of\nsamples. This standard was required to be within 10% of\nthe specified value. The results of this low check standard\nare summarized in Table 5-4.\n\nTable 5-4. Low Check Standards\n\nParameter Value\n\n \n\nQC Limits Recovery 90% - 110%\n\nRecovery Range 88.6% - 111%\n\nNumber of Check Standards 23\nAnalyzed\nAverage Recovery 96%\n\n \n\n31\n\nThere were a few occasions where this standard did not\nmeet specifications. The results of these samples,\nhowever, were only slightly outside specified limits, and\ngiven the number of total samples (23), this is an\ninsignificant number of results that did not fall within\nspecifications. In addition, the laboratory reanalyzed the\nstandard when specifications were not achieved, and the\nsecond determination always fell within the required limits.\nTherefore laboratory objectives for sensitivity were\nachieved according to QAPP specifications.\n\nAs noted previously, comparability and representativeness\nwere assessed through the analysis of replicate samples.\nResults of these replicates are presented in the discussion\non primary project objectives for precision. These results\nshow that data were within project and QA objectives.\n\nCompleteness objectives were achieved for the project. All\nsamples were analyzed and data were provided for 100%\nof the samples received by the laboratory. No sample\nbottles were lost or broken.\n\nOther measures of data quality included method blanks,\ncalibration checks, evaluation of linearity of the calibration\ncurve, holding time specifications, and an independent\nstandard verification included with each sample batch.\nThese results were reviewed for every sample batch run by\nALSI, and were within specifications. In addition, 10% of\nthe reported results were checked against the raw data.\nRaw data were reviewed to ensure that sample results\nwere within the calibration range of the instrument, as\ndefined by the calibration curve. A6-point calibration curve\nwas generated at the start of each sample batch of 20. A\nfew data points were found to be incorrectly reported.\nRecalculations were performed for these data, and any\nadditional data points that were suspected outliers were\nchecked to ensure correct results were reported. Very few\ncalculation or dilution errors were found. All errors were\ncorrected so that the appropriate data were reported.\n\nAnother measure of compliance were the non-stannous\nchloride runs performed by the laboratory for every sample\nanalyzed. This was done tocheck for organic interference.\nThere were no samples that were found to have any\norganic interference by this method. Therefore, these\nresults met expected QC specifications and data were not\nqualified in any fashion.\n\nTotal solids data were also reviewed to ensure that\ncalculations were performed appropriately and dry weights\nreported when required. All of these QC checks met",
    "Page_49": "QAPP specifications. In summary, all data quality\nindicators and QC specifications were reviewed and found\nto be well within project specifications. Therefore, the data\nare considered suitable for purposes of this evaluation.\n\n5.4 Audit Findings\n\nThe SAIC SITE QA Manager conducted audits of both field\nactivities and of the subcontracted laboratory as part of the\nQA measures for this project. The results of these\ntechnical system reviews are discussed below.\n\n32\n\nThe field audit resulted in no findings or non-\nconformances. The audit performed at the subcontract\nlaboratory was conducted during the time of project sample\nanalysis. One non-conformance was identified and\ncorrective action was initiated. It was discovered that the\nlaboratory PQL was not meeting specifications due to a\nreporting error. The analyst was generating the calibration\ncurves as specified above; however, the lower limit on the\ncalibration curve was not being reported. This was\nimmediately rectified and no other findings or non-\nconformances were identified.",
    "Page_50": "Chapter 6\nPerformance of the RA-915+/RP-91C\n\nOhio Lumex analyzed 197 samples from May 5-8, 2003 in\nOak Ridge, TN. Results for these samples were reported\nby Ohio Lumex, and a statistical evaluation was performed.\nAdditionally, the observations made during the\ndemonstration were reviewed, and the remaining primary\nand secondary objectives were completed. The results of\nthe primary and secondary objectives, identified in Chapter\n1, are discussed in Sections 6.1 and 6.2, respectively.\n\nThe distribution of the samples prepared for Ohio Lumex\nand the referee laboratory is presented in Table 6-1. From\nthe four sites, Ohio Lumex received samples at 36 different\nconcentrations for a total of 197 samples. These 197\nsamples consisted of 22 concentrations in replicates of 7,\n1 concentration in replicate of 4, and 13 concentrations in\nreplicates of 3.\n\nTable 6-1. Distribution of Samples Prepared for Ohio Lumex and the Referee Laboratory\n\n \n\n \n\n; ; Sample Type\nSite Concentration Range Soil Sediment Spiked Soil SRM\n\nCarson River Low (1-500 ppb) 3 10 7 7\n\n(Subtotal = 62) Mid (0.5-50 ppm) 0 0 7 28\nHigh (50->1,000 ppm) 0 0 0 0\n\nPuget Sound Low (1 ppb - 10 ppm) 30 0 14 13\n\n(Subtotal = 67) High (10-500 ppm) 0 3 7 0\n\nOak Ridge Low (0.1-10 ppm) 10 7 7 14\n\n(Subtotal = 51) High (10-800 ppm) 3 6 0 4\n\nManufacturing General (5-1,000 ppm) 10 0 0 7\n\n(Subtotal = 17)\n\nSubtotal 56 26 42 73\n\n(Total = 197)\n\n6.1 Primary Objectives done because of the expectation that values below the\n\n6.1.1 Sensitivity\n\nSensitivity objectives are explained in Chapter 4. The two\nprimary sensitivity evaluations performed for this\ndemonstration were the MDL and PQL. Determinations of\nthese two measurements are explained in the paragraphs\nbelow, along with a comparison to the referee laboratory.\nThese determinations set the standard for the evaluation of\naccuracy and precision for the Ohio Lumex field\ninstrument. Any sample analyzed by Ohio Lumex and\nsubsequently reported as below their level of detection was\nnot used as part of any additional evaluations. This was\n\n33\n\nlower limit of instrument sensitivity would not reflect the true\ninstrument accuracy and precision.\n\nThe sensitivity measurements of MDL and PQL are both\ndependent upon the matrix and method. Hence, the MDL\nand PQL will vary, depending upon whether the matrix is a\nsoil, waste, or water. Only soils and sediments were tested\nduring this demonstration and therefore, MDL calculations\nfor this evaluation reflect soil and sediment matrices. PQL\ndeterminations are not independent calculations, but are\ndependent upon results provided by the vendor for the\nsamples tested.",
    "Page_51": "Comparison of the MDL and PQL to laboratory sensitivity\nrequired that a standard evaluation be performed for all\ninstruments tested during this demonstration. PQL, as\npreviously noted, is defined in EPA G-5i as the lowest level\nof method and instrument performance with a specified\naccuracy and precision. This is often defined by the lowest\npoint on the calibration curve. Our approach was to let the\nvendor provide the lower limit of quantitation as determined\nby their particular standard operating procedure, and then\ntest this limit by comparing results of samples analyzed at\nthis low concentration to the referee laboratory results, or\ncomparing the results to a standard reference material, if\navailable. Comparison of these data are, therefore,\npresented for the lowest concentration sample results, as\nprovided by the vendor. If the vendor provided “non-detect”\nresults, then no formal evaluation of that sample was\npresented. In addition, the sample(s) was not used in the\nevaluation of precision and accuracy.\n\nMethod Detection Limit — The standard procedure for\ndetermining MDLs is to analyze a low standard or\nreference material seven times, calculate the standard\ndeviation and multiply the standard deviation by the “t”\nvalue for seven measurements at the 99th percentile\n(alpha = 0.01). (This value is 3.143 as determined from a\nstandard statistics table.) This procedure for determination\nof an MDL is defined in 40 CFR Part 136, and while\ndeterminations for MDLs may be defined differently for\nother instruments, this method was previously noted in the\ndemonstration QAPP and is intended to provide a\ncomparison to other similar MDL evaluations. The purpose\nis to provide a lower level of detection with a statistical\nconfidence at which the instrument will detect the presence\nof a substance above its noise level. There is no\nassociated accuracy or precision provided or implied.\n\nSeveral blind standards and field samples were provided to\nOhio Lumex at their estimated lower limit of sensitivity.\nThe Ohio Lumex lower limit of sensitivity was previously\nestimated at 0.005 mg/kg. Because there are several\ndifferent SRMs and field samples at concentrations close\nto the MDL, evaluation of the MDL was performed using\nmore than a single concentration. Samples chosen for\ncalculation were based upon: 1) concentration and how\nclose it was to the estimated MDL, 2) number of analyses\nperformed for the same sample (e.g., more than 4), and 3)\nif non-detects were reported by Ohio Lumex for a sample\nused to calculate the MDL. Then the next highest\nconcentration sample was selected based upon the\npremise that a non-detect result reported for one of several\nsamples indicates the selected sample is on the “edge” of\nthe instruments detection capability.\n\n34\n\nSeven replicates were analyzed by Ohio Lumex for a\nsample that had a reported average concentration by the\nreferee laboratory of 0.06 mg/kg. (Sample lot 02 from the\nPuget Sound site.) The average concentration reported by\nOhio Lumex for this sample was 0.072 mg/kg and the\nstandard deviation was 0.0135 mg/kg. An SRM with a\nreference value of 0.017 mg/kg (sample lot 35) was\nanalyzed seven times by Ohio Lumex with a reported\naverage concentration of 0.0067 mg/kg and a standard\ndeviation of 0.0017 mg/kg. Calculations of the respective\nMDLs based upon each of these standards are 0.042 and\n0.0053 mg/kg.\n\nAs a further check of the MDL, sample lot 37 (SRM) hada\nreference value of 0.158 mg/kg. Seven samples analyzed\nby Ohio Lumex for this sample lot had a reported average\nconcentration of 0.196 mg/kg and a standard deviation of\n0.0098 mg/kg. This results in a calculated MDL of 0.031\nmg/kg, which falls between the values noted above.\n\nBased upon these results it appears that the MDL for this\ninstrument is somewhere between 0.0053 and 0.042\nmg/kg. The lowest standard analyzed by Ohio Lumex was\nthe SRM noted above (sample lot 35) with a reference\nvalue of 0.017 mg/kg (which is close to the average MDL)\nwith a reported average concentration by Ohio Lumex of\n0.0067 mg/kg. While the average result for this sample\nhas a percent difference (%D) of -63.5%, the sample was\neasily detected by the Ohio Lumex field instrument, and is,\ntherefore, by definition within the range of the MDL.\nConsequently, the estimated sensitivity provided by Ohio\nLumex of 0.005 mg/kg is a reasonable estimation of the\nMDL for aqueous samples, assuming that some samples\nwill likely have matrix interferences and may result in a\nslightly higher MDL. The calculated MDL for soils and\nsediments is somewhere between 0.0053 and 0.042\nmg/kg. The equivalent MDL for the referee laboratory is\n0.0026 mg/kg. The calculated resultis only intended as a\nstatistical estimation and not a true test of instrument\nsensitivity.\n\nPractical Quantitation Limit — This value is usually\ncalculated by determining a low standard on the instrument\ncalibration curve, and itis estimated as the lowest standard\nat which the instrument will accurately and precisely\ndetermine a given concentration within specified QC limits.\nThe PQL is often around 5-10 times the MDL. This PQL\nestimation, however, is method- and matrix-dependent. In\norder to determine the PQL, several low standards were\nprovided to Ohio Lumex, and subsequent %Ds were\ncalculated.",
    "Page_52": "The lower limit of sensitivity previously provided by the\nvendor (0.005 mg/kg) appears to be close to their MDL, but\nthis would likely result in a higher instrument and method\nPQL. The PQL should have a precision and accuracy that\nmatches the instrument capabilities within a certain\noperating range of analysis. The relationship between\nsensitivity and precision is such that the lower the\nconcentration, the higher the variation in reported sample\nresults. Five times the estimated MDL (estimated PQL)\nwould result in a value of 0.027 to 0.21 mg/kg. Therefore,\nvalues in this range were chosen for estimating the PQL\nand associated %D between the Ohio Lumex reported\naverage and the reference value if it is an SRM, or the\naverage value reported by the referee laboratory. Also\ncompared are the 95% Cls for additional descriptive\ninformation.\n\nThe Ohio Lumex average result for the 0.017 mg/kg SRM\nnoted above (sample lot 35) was 0.0067 mg/kg. The\nstandard deviation was 0.0017 mg/kg and the 95% Cl is\n0.0051 to 0.0083 mg/kg. The %D for this sample is -63.5%\nand therefore this is clearly below the instrument PQL.\n\nThe Ohio Lumex average result for the 0.158 mg/kg SRM\n(sample lot 37) was 0.196 mg/kg. The standard deviation\nwas 0.0098 mg/kg and the 95% Cl is 0.187 - 0.205 mg/kg.\nThe %D for this sample is 24.1%. This is a reasonable %D\nfor most analytical instrumentation and therefore within the\ninstrument’s PQL.\n\nThe average result reported by the referee laboratory for\nsample lot 02 was 0.06 mg/kg. The result reported by Ohio\nLumex for this same sample was 0.072 mg/kg. The\nstandard deviation was 0.0135 mg/kg. The %D for this\nsample is 20%.\n\nSensitivity Summary\n\nThe low standard calculations using MDL values suggest\nthat a PQL for the Ohio Lumex field instrument may be as\nlow as 0.027 mg/kg. The referee laboratory PQL\nconfirmed during the demonstration is 0.005 mg/kg with a\n%D of <10%. The %D for the average Ohio Lumex result\nfor the average referee laboratory value of 0.06 mg/kg is\n0.072 mg/kg, with a %D of 20%. This was the lowest\nsample concentration tested during the demonstration that\nis close to the calculated PQL noted above.\n\nThe range for the calculated MDL is between 0.0053 and\n0.042 mg/kg, based on the results of seven replicate\nanalyses for low standards. The equivalent MDL for the\nreferee laboratory is 0.0026 mg/kg. The MDL\ndetermination, however, is only a statistical calculation that\nhas been used in the past by EPA, and is currently not\n\n35\n\nconsidered a “true” MDL by SW-846 methodology.\nSW -846 is suggesting that performance-based methods be\nused, and that PQLs be determined using low standard\ncalculations.\n\n6.1.2 Accuracy\n\nAccuracy is the instrument measurement compared to a\nstandard, or “true” value. For this demonstration, three\nseparate standards were used for determining accuracy.\nThe primary standard is SRMs. The SRMs are traceable\nto national systems. These were obtained from reputable\nsuppliers with reported concentration and an associated\n95% Cl and 95% prediction interval. The Cl from the\nreference material is used as a measure of comparison\nwith Cl calculated from replicate analyses for the same\nsample analyzed by the laboratory or vendor. Results are\nconsidered comparable if Cls of the SRM overlap with the\nCls computed from the replicate analyses by the vendor.\nWhile this is not a definitive measure of comparison, it\nprovides some assurance that the two values are\nequivalent.\n\nPrediction intervals are intended as a measure of\ncomparison fora single laboratory or vendor result with the\nSRM. When computing a prediction interval, the equation\nassumes an infinite number of analyses, and it is used to\ncompare individual sample results. A 95% prediction\ninterval would, therefore, predict the correct result from a\nsingle analysis 95% of the time for an infinite number of\nsamples, if the result is comparable to that of the SRM. It\nshould be noted that the corollary to this statement is that\n5% of the time a result will be outside the prediction interval\nif determined for an infinite number of samples. If several\nsamples are analyzed, the percentage of results within the\nprediction interval will be slightly above or below 95%. The\nmore samples analyzed, the more likely the percentage of\ncorrect results will be close to 95% if the result for the\nmethod being tested is comparable to the SRM.\n\nAll SRMs were analyzed in replicates of three, four, or\nseven by both the vendor and the referee laboratory. In\nsome instances, analyses performed by the vendor were\ndetermined to be invalid measurements and were,\ntherefore, not included with the reported results. There\nwere nine different SRMs analyzed by both the vendor and\nthe laboratory, for a total of 57 data points by the vendor\nand 62 data points by the laboratory. One specially\nprepared SRM (sample lot 55) was not included, because\nanalyses performed by the vendor and the laboratory\nsuggested that the SRM value was in question. Because\nthis was a specially prepared SRM, and had somewhat",
    "Page_53": "less documentation in regards to the reference value, and\nbecause both the referee laboratory and vendor results,\nwhile statistically equivalentwere statistically different from\nthe SRM value, this SRM was not included in the\nevaluation.\n\nThe second accuracy determination used a comparison of\nvendor results of field samples and SRMs to the referee\nlaboratory results for these same samples. Field samples\nwere used to ensure that \"real-world\" samples were tested\nby the vendor. The referee laboratory result is considered\nas the standard for comparison to the vendor result. This\ncomparison is in the form of a hypothesis test with alpha =\n0.01. (Detailed equations along with additional information\nabout this statistical comparison is included in Appendix B.)\n\nIt should be noted that there is evidence of a laboratory\nbias. This bias was determined by comparing average\nlaboratory values to SRM reference values, and is\ndiscussed below. The laboratory bias is low in comparison\nto the reference value. A bias correction was not made\nwhen comparing individual samples (replicate analyses)\nbetween the laboratory and vendor; however, setting alpha\n= 0.01 helps mitigate for this possible bias by widening the\nrange of acceptable results between the two data sets.\n\nAn aggregate analysis, or unified hypothesis test, was also\nperformed for all 33 sample lots. (A detailed discussion of\nthis statistical comparison is included in Appendix B.) This\nanalysis provides additional statistical evidence in relation\nto the accuracy evaluation. A bias term is included in this\ncalculation in order to account for any data bias.\n\nThe third measure of accuracy is obtained by the analysis\nof spiked field samples. These were analyzed by the\nvendor and the laboratory in replicate in order to provide\nadditional measurement comparisons and are treated the\nsame as the other field samples. Spikes were prepared to\ncover additional concentrations not available from SRMs or\nfield samples. There is no comparison to the spiked\nconcentration, only a comparison between the vendor and\nthe laboratory reported value.\n\nThe purpose for SRM analyses by the referee laboratory is\nto provide a check on laboratory accuracy. During the\npre-demonstration, the referee laboratory was chosen, in\npart, based upon the analysis of SRMs. This was done to\nensure that a competent laboratory would be used for the\ndemonstration. The pre-demonstration laboratory\nqualification showed that the laboratory was_ within\nprediction intervals for all SRMs analyzed. Because of the\nneed to provide confidence in laboratory analysis during the\ndemonstration, the referee laboratory also analyzed SRMs\n\n36\n\nas an ongoing check of laboratory bias. As noted in Table\n6-3, not all laboratory results were within the prediction\ninterval. This is discussed in more detail below. All\njaboratory QC checks, however, were found to be within\ncompliance (see Chapter 5).\n\nEvaluation of vendor and laboratory analysis of SRMs is\nperformed in the following manner. Accuracy was\ndetermined by comparing the 95% Cl of the sample\nanalyzed by the vendor and laboratory to the 95% Cl for\nhe SRM. (95% Cls around the true value are provided by\nhe SRM supplier.) This information is provided in Tables\n6-2 and 6-3, with notations when the Cls overlap,\nsuggesting comparable results. In addition, the number of\nSRM results for the vendor's analytical instrumentation and\nhe referee laboratory that are within the associated 95%\nprediction interval are reported. This is a more definitive\nevaluation of laboratory and vendor accuracy. The\npercentage of total results within the prediction interval for\nhe vendor and laboratory are reported in Tables 6-2 and\n6-3, respectively.\n\nThe single most important number from these tables is the\npercentage of samples within the 95% prediction interval.\nAs noted for the Ohio Lumex data, this percentage is 93%,\nwith n = 57. This suggests that the Ohio Lumex data are\nwithin expected accuracy accounting for statistical\nvariation. For five of the nine determinations, Ohio Lumex\naverage results are above the reference value. This would\nsuggest that there is no bias associated with the Ohio\nLumex data. Six of the nine sample groups overlap with\nthe 95% Cls calculated from the Ohio Lumex data,\ncompared to values provided by the supplier of the SRM.\nThis number is also suggestive of a reasonable\ncomparison to the SRM value, accounting for statistical\nvariation.\n\n \n\nThe percentage of samples within the 95% prediction\ninterval for the laboratory data is 87%. For 7 of the 9\ndeterminations, ALSI average results are below the\nreference value. This suggests that the ALSI data are\npotentially biased low. Because of this bias, the\npercentage of samples outside the prediction interval is\nslightly below the anticipated number of results, given that\nthe number of samples analyzed (62) is relatively high.\nNonetheless, the referee laboratory data should be\nconsidered accurate and not significantly different from the\nSRM value. Because there is no bias correction term in\nthe individual hypothesis tests (Table 6-4), alpha is set at\n0.01 to help mitigate for laboratory bias. This in effect\nwidens the scope of vendor data that would fall within an\nacceptable range of the referee laboratory. Six of the nine",
    "Page_54": "sample groups overlap with the 95% Cls calculated from\nthe ALSI data, compared to values provided by the supplier\nof the SRM. This number is also suggestive of a\n\nTable 6-2. Ohio Lumex SRM Comparison\n\nreasonable comparison to the SRM value accounting for\nstatistical variation.\n\n \n\n \n\nSample SRM Value/ 95% Cl Ohio Lumex Avg./ 95% Cl cl No. of 95% Prediction Ohio Lumex No.\nLot No. Overlap Samples Interval w/in Prediction\n(yes/no) Analyzed Interval\n37 0.158 / 0.132 - 0.184 0.196 / 0.187- 0.205 no 7 0- 0.357 7\n44 4.714.3-5.1 4.88 /4.72- 5.03 yes 6 3.0 -6.4 6\n35 0.017 / 0.010 - 0.024 0.0067 / 0.0051 - 0.0083 no 7 0 - 0.0358 ° 7\n36 0.082 / 0.073 - 0.091 0.071 / 0.062 - 0.080 yes 3 0.035 - 0.13° 3\n38 0.62 / 0.61 - 0.63 0.627 / 0.607- 0.647 yes 7 0.545 - 0.695 7\n39 1.09 / 1.06-1.12° 1.07 / 1.01-1.13 yes 6 0.94 - 1.24 5\n41 2.42 / 2.16 - 2.46 2.01 / 1.68 -2.37 yes 7 1.3-3.3 7\n43 3.80 / 3.50 - 4.11 3.64 / 3.33 - 3.95 yes 7 2.41 - 5.20 7\n45 6.45 / 6.06 - 6.84 8.14 / 8.02 - 8.26 no 7 4.83 - 8.06 4\nTotal Samples 57 53\n% of samples w/in 93%\n\nprediction interval\n\nTable 6-3. ALS] SRM Comparison\n\nCl is estimated based upon n=30. A 95% prediction interval was provided by the SRM supplier but no Cl was given.\nPrediction interval is estimated based upon n=30. A 95% Cl was provided by the SRM supplier but no prediction interval was given.\n\n \n\n \n\nSample SRM Value/ 95% Cl ALSI Avg./ 95% Cl cl No. of 95% Prediction ALSI No. w/in\nLot No. Overlap Samples Interval Prediction\n(yes/no) Analyzed Interval\n37 0.158 / 0.132 - 0.184 0.139 / 0.093 - 0.185 yes 7 0- 0.357 7\n44 4.714.3-5.1 2.33 / 1.05 - 3.61 no 7 3.0 -6.4 2\n35 0.017 / 0.010 - 0.024 0.0087 / 0.0078 - 0.0096 no 7 0 - 0.0358\" 7\n36 0.082 / 0.073 - 0.091 0.073 / 0.068 - 0.078 yes 7 0.035 - 0.13 ° 7\n38 0.62 / 0.61 - 0.63° 0.628 / 0.606 - 0.650 yes 7 0.545 - 0.695 7\n39 1.09 / 1.06-1.12° 1.24 / 0.634 - 1.85 yes 7 0.94 - 1.24 6\n41 2.42 / 2.16 - 2.46 1.79 / 1.29 - 2.29 yes 7 1.3-3.3 6\n43 3.80 / 3.50- 4.11 2.76 / 2.51 - 3.01 no 7 2.41 - 5.20 7\n45 6.45 / 6.06 - 6.84 5.44 /4.10- 6.78 yes 6 4.83 - 8.06 5\nTotal Samples 62 54\n% of samples w/in 87%\n\nprediction interval\na\nb\n\nHypothesis Testing\n\nSample results from field and spiked field samples for the\nvendor compared to similar tests by the referee laboratory\nare used as another accuracy check. Spiked samples\nwere used to cover concentrations not found in the field\nsamples, and they are considered the same as the field\nsamples for purposes of comparison. Because of the\nlimited data available for determining the accuracy of the\nspiked value, these were not considered the same as\nreference standards. Therefore, these samples were\nevaluated in the same fashion as field samples, but they\nwere not compared to individual spiked concentrations.\n\n37\n\nCl is estimated based upon n=30. A 95% prediction interval was provided by the SRM supplier but no Cl was given.\nPrediction interval is estimated based upon n=30. A 95% Cl was provided by the SRM supplier but no prediction interval was given.\n\nUsing a hypothesis test with alpha = 0.01, vendor results\nfor all samples were compared to laboratory results to\ndetermine if sample populations are the same or\nsignificantly different. This was performed for each sample\nlot separately. Because this test does not separate\nprecision from bias, if Ohio Lumex’s or ALSI’s computed\nstandard deviation was large due to a highly variable result\n(indication of poor precision), the two Cls could overlap.\nTherefore, the fact that there was no significant difference\nbetween the two results could be due to high sample\nvariability. Accordingly, associated RSDs have also been\nreported in Table 6-4 along with results of the hypothesis\ntesting for each sample lot.",
    "Page_55": "Table 6-4. Accuracy Evaluation by Hypothesis Testing\n\n \n\nSample Lot No/ Site Avg. Conc. RSD or CV Significantly Different at Relative Percent\nmg/kg Measurements Alpha = 0.01 Difference (Ohio\nLumex_to ALSI)\n03/ Oak Ridge yes 19.8%\nOhio Lumex 0.317 4.8%\nALSI 0.260 3.8%\n09/ Oak Ridge no 6.4%\nOhio Lumex 0.497 23.2%\nALSI 0.466 34.2%\n14/ Oak Ridge yes 49.3%\nOhio Lumex 7.86 32.0%\nALSI 4.75 27.5%\n21/ Oak Ridge no 428%\nOhio Lumex 17.3 23.3%\nALSI 11.2 23.8%\n24/ Oak Ridge no -11.5%\nOhio Lumex 197 28.0%\nALSI 221 44.8%\n26/ Oak Ridge yes 23.7%\nOhio Lumex 97.7 2.6%\nALSI 77.0 13.2%\n37/ Oak Ridge no 34.0%\nOhio Lumex 0.196 5.0%\nALSI 0.139 36.4%\n44/ Oak Ridge no 70.7%\nOhio Lumex 4.88 3.0%\nALSI 2.33 59.4%\n60/ Oak Ridge no -10.2%\nOhio Lumex 149 23.8%\nALSI 165 30.9%\n02/ Puget Sound no 3.3 %\nOhio Lumex 0.062 43.9%\nALSI 0.06 23.6%\n05/ Puget Sound no 23.9%\nOhio Lumex 0.267 9.4%\nALSI 0.21 33.3 %\n08/ Puget Sound yes 36.4%\nOhio Lumex 0.52 14.2%\nALSI 0.36 13.4%\n10/ Puget Sound no 105%\nOhio Lumex 1.76 120%\nALSI 0.55 20.5%\n11/ Puget Sound yes 47.2%\nOhio Lumex 1.31 14.2%\nALSI 0.81 32.7%\n12/ Puget Sound no 25.8%\nOhio Lumex 1.4 7.2%\nALSI 1.08 2.8%\n25/ Puget Sound yes 85.3%\nOhio Lumex 41.3 12.4%\nALSI 16.6 12.3%\n34/ Puget Sound no 165%\nOhio Lumex 117 24.7%\nALSI 11.3 23.4%\n36/ Puget Sound no 1.4%\nOhio Lumex 0.071 4.9%\nALSI 0.07 6.7%\n57/ Puget Sound yes 34.1%\nOhio Lumex 1.03 11.2%\nALSI 0.73 16.2%\n\n38",
    "Page_56": "Table 6-4. Continued\n\n \n\nSample Lot No/ Site Avg. Conc. RSD or CV Number of Significantly Different at Relative Percent\nmg/kg Measurements Alpha = 0.01 Difference (Ohio\nLumex_to ALSI)\n61/ Puget Sound no -26.0%\nOhio Lumex 154 47.0% 7\nALSI 200 10.9% 7\n62/ Puget Sound yes 47.5%\nOhio Lumex 23.7 13.0% 7\nALSI 14.6 28.3% 7\n01/ Carson River no 21.5%\nOhio Lumex 0.29 30.5% 7\nALSI 0.24 37.8% 7\n04/ Carson River no 18.9%\nOhio Lumex 0.13 18.9% 3\nALSI 0.11 9.1% 7\n06/ Carson River no 10.3%\nOhio Lumex 0.29 7.3% 3\nALSI 0.26 15.7% 7\n38/ Carson River no -0.2%\nOhio Lumex 0.63 3.5% 7\nALSI 0.63 3.8% 7\n39/ Carson River no -14.7%\nOhio Lumex 1.07 6.5% 7\nALSI 1.24 52.9% 7\n41/ Carson River no 11.6%\nOhio Lumex 2.01 17.5% 7\nALSI 1.79 30.5% 7\n43/ Carson River yes 27.5%\nOhio Lumex 3.64 9.1% 7\nALSI 2.76 9.6% 7\n56/ Carson River no 5.2%\nOhio Lumex 0.22 8.0% 7\nALSI 0.23 12.6% 7\n59/ Carson River no 11.1%\nOhio Lumex 1.91 10.2% 7\nALSI 1.71 7.9% 7\n13/ Manufacturing Site no 53.3%\nOhio Lumex 10.2 51.9% 7\nALSI 5.91 15.4% 7\n17/ Manufacturing Site no 39.7%\nOhio Lumex 15.7 24.2% 3\nALSI 10.5 14.6% 7\n45/ Manufacturing Site no 39.8%\nOhio Lumex 8.14 1.6% 7\nALSI 5.44 23.4% 6\n\n \n\nCV = Coefficient of variance\n\nOf the 33 sample lots, 9 results are significantly different\nbased upon the hypothesis test noted above. Most of the\nrelative percent differences are positive, which indicates\nthat the Ohio Lumex result is generally higher than the\nlaboratory result. This is indicative of the previously noted\nlow bias associated with the laboratory data. There are\nsome Ohio Lumex results that are less than the laboratory\nresult, therefore, no overall Ohio Lumex high or low bias\nis apparent. It appears that Ohio Lumex data are subject\nto more random variability.\n\n39\n\nIn determining the number of results significantly above or\nbelow the value reported by the referee laboratory, 19 of 33\nOhio Lumex average results were found to have RPDs less\nthan 30% for sample concentrations above the estimated\nPQL. Only two of 33 Ohio Lumex average results have\nRPDs greater than 100% for this same group of samples\n(see Table 6-5). Interferences may be a problem but,\nbecause of the random variability associated with the data,\nno interferences are specifically apparent from the data\ncollected. Table 6-6 shows the results of additional data\ncollected for these same samples.",
    "Page_57": "Table 6-5. Number of Sample Lots Within Each %D Range\n\n \n\n \n\n<30% >30%, <50% >50%, <100% >100% Total\nPositive %D 14 9 3 2 28\nNegative %D 5 0 0 0 5\nTotal 19 9 3 2 33\nOnly those sample lots with the average result greater than the PQL are tabulated.\nTable 6-6. Concentration (in mg/kg) of Non-Target Analytes\nLot # Site TOC _O0&G Ag As Ba Cd Cr Cu Pb Se Sn Zn Hg\n1 Carson River 870 190 <0.5 9 210 <0.5 19 13 3 <2 <5 60 0.19\n2 Puget Sound 3500 290 <0.5 3 23 <0.5 16 10 1 <2 <5 24 0.04\n3 Oak Ridge 2300 530 1.8 4 150 <0.5 46 20 15 <2 <5 55 0.31\n4 Carson River 2400 200 <0.5 8 240 <0.5 17 32 12 <2 <5 66 0.10\n5 Puget Sound 3500 210 <0.5 3 28 <0.5 18 11 3 <2 <5 28 0.16\n6 Carson River 7200 200 <0.5 4 32 <0.5 16 9 1 <2 <5 24 0.23\n8 Puget Sound 8100 200 <0.5 3 27 1.0 17 23 99 2 <5 37 0.37\n9 Oak Ridge 3300 150 1.9 5 160 0.5 70 49 24 <2 <5 100 0.66\n10 Puget Sound 4200 130 <0.5 3 24 <0.5 18 8 1 <2 <5 24 0.62\n11 Puget Sound 3800 130 <0.5 4 20 <0.5 18 8 1 <2 <5 24 0.63\n12 Puget Sound 3500 290 <0.5 3 23 0.8 16 7 2 <2 <5 23 1.1\n13 Manufacturing Site 3200 100 <0.5 2 110 <0.5 42 51 7 <2 <5 61 5.5\n14 Oak Ridge 7800 180 0.32 2 41 0.4 16 9 11 <2 <4 74 78\n17 Manufacturing Site 2400 90 <0.5 <2 180 <0.5 48 20 15 <2 <5 120 10\n21 Manufacturing Site 7800 320 1.9 4 150 2.8 22 40 23 <2 <4 340 14\n24 Oak Ridge 6600 250 <0.5 5 89 <0.5 6.3 7 10 <2 <5 31 220\n25 Puget Sound 46000 1200 <0.5 2 46 0.7 35 33 31 <2 6 98 35\n26 Oak Ridge 88000 340 9.1 10 140 1.9 47 73 82 <2 5 250 100\n34 SRM CRM-204 (web) NR NR <0.5 0.82 0.04 14 45 NR 11 NR NR NR 0.002\n35 SRM Canmet SO-3 NR NR NR NR 300 NR 26 17 14 NR NR 52 0.02\n36 SRM Canmet SO-2 NR NR NR NR 970 NR 16 7 21 NR NR 120 0.08\n37 SRM CRM-016 NR NR 0.7 7.8 79 0.47 14 16 14 1 NR 70 0.16\n38 SRM NWRI TH-2 NR NR 5.8 8.7 570 5.2 120 120 190 0.83 NR 900 0.62\n39 SRM NWRI WQB-1 NR NR 1 23 600 2 89 80 84 1 3.9 275 1.09\n41 SRM CRM 026 NR NR 0.57 54 210 12 27 19 26 1.9 NR 140 24\n43 SRM CRM 027 NR NR 6 12 170 12 27 9.9 52 14 NR 51 3.8\n44 SRM CRM 021 NR NR 6.5 25 590 1.2 11 4800 6500 NR 300 550 47\n45 SRM CRM 033 NR NR 0.78 130 220 89 100 96 61 89 390 230 6.4\n46 SRM CRM 032 NR NR 81 370 120 130 15 590 4600 170 1300 2600 21\n55 SRM RTC spec. NR NR NR NR NR NR NR NR NR NR NR NR 0.01\n56 Spiked Lot 1 870 190 <0.5 9 210 <0.5 19 13 3 <2 <5 60 0.19\n57 Spiked PS- X1,X4 3500 290 <0.5 3 23 <0.5 16 10 1 <2 <5 24 0.61\n59 Spiked CR-SO-14 870 190 <0.5 9 210 <0.5 19 13 3 <2 <5 60 1.6\n60 Spiked Lot 7 5100 150 1.1 5 120 <0.5 50 28 15 <2 <5 61 72\n61 Spiked Lot 10 4200 130 <0.5 3 24 <0.5 18 8 1 <2 <5 24 220\n62_ Spiked Lot 5 3500 210 <0.5 3 28 <0.5 18 11 3 <2 <5 28 23\nCRM = _ Canadian Reference Material\nRTC = Resource Technology Corporation\nNR= Not Reported by Standard Supplier\n\n40",
    "Page_58": "Discussion of Interferences\n\nThe RSDs for Ohio Lumex are small, suggesting that\nprecision is good and is not simply random variation\ncausing the differences noted above. (This will be\ndiscussed in more detail in Section 6.1.3) As noted\npreviously, it would appear that interference is the cause of\nthe inaccurate analyses, butitis not readily apparent as to\nthe interferent causing the problem. Specifically, there is\nno apparentsignificant difference between reported values\nand associated sites from which the samples were\ncollected. There are possible exceptions, however, noted\nfor the Puget Sound samples but only descriptive\nobservations. For example, discounting SRMs, for the\nPuget Sound site, only 6 of the 11 results reported by Ohio\nLumex are considered the same as those from the referee\nlaboratory. Therefore, there may be a_ significant\ninterference in the Puget Sound samples not presentin the\nother samples. Upon examination of additional data\ncollected for these samples (see Table 6-6), no apparent\ndifferences were noted. For example, a high organic\ncontent may cause interference, but not all the Puget\nSound samples necessarily have a higher organic content\nthan other samples tested. In addition, the Method 7471B\n\nmercury analysis requires that a non-stannous chloride\nanalysis be conducted with each sample analyzed, in order\nto test for organic interferences. Upon examination of the\nreferee laboratory data for the sample sets mentioned\nabove, there was no apparent interference noted in the\nnon-stannous chloride analyses.\n\nPuget Sound samples also had a higher percentage of\nmoisture for some of the samples analyzed which may help\nexplain these differences. But this does not explain all\ndifferences or all similarities. There are not enough\nsamples to suggest that this difference is statistically\nsignificant. Other interferences caused by additional\nelements were also not found to be significant. Of course,\nthere could be interferences that were not tested, and\ntherefore, while it may be an interference (or likely a\ncombination of interferences) particular to a sample lot, the\nexact cause remains unknown. The reason(s) for these\nsimilarities and differences and the reason(s) for the\ndifference between the Ohio Lumex and referee laboratory\nresults is only speculative. In addition to the statistical\n\nsummary presented above, data plots (Figures 6-1 and 6-\n2) are included in order to present a visual interpretation of\nthe accuracy.\n\n—— Ohio Lum ex\n—m ALS\n\n \n\nCenaningen inguin\n\n \n\n \n\n \n\nFigure 6-1. Data plot for low concentration sample results.\n\n41",
    "Page_59": "I. ad\npo\n: chess Sytedhy wettess be STN: |\n\n \n\n \n\nFigure 6-2. Data plot for high concentration sample results.\n\nTwo separate plots have been included for the Ohio Lumex\ndata. These two plots are divided based upon sample\nconcentration in order to provide a more detailed\npresentation. Concentrations of samples analyzed by Ohio\nLumex ranged approximately from 0.01 to over 200 mg/kg.\nThe previous statisticalsummary eliminated some of these\ndata based upon whether concentrations were interpreted\nto be in the analytical range of the Ohio Lumex field\ninstrument. This graphical presentation presents all data\npoints. It shows Ohio Lumex data compared to ALSI data\nplotted against concentration. Sample groups are shown\nby connecting lines. Breaks between groups indicate a\ndifferent set of samples at a different concentration.\nSample groups were arranged from lowest to highest\nconcentration.\n\nAs can be seen by this presentation, samples analyzed by\nOhio Lumex appear to match well with the ALSI results,\nwith some notable exceptions. This is only a visual\ninterpretation and does not provide statistical significance.\nIt does however, provide a visual interpretation that\n\n42\n\n \n\nsupports the previous statistical results\npresented above.\n\nUnified Hypothesis Test\n\nSAIC performed a unified hypothesis test analysis to\nassess the comparability of analytical results provided by\nOhio Lumex and those provided by ALSI. (See Appendix\nB for a detailed description of this test.) Ohio Lumex and\nALSI both supplied multiple assays on replicates derived\nfrom a total of 33 different sample lots, whether field\nmaterials or reference materials. The Ohio Lumex and\nALSI data from these assays formed the basis of this\nassessment.\n\nor accuracy, as\n\nResults from this analysis suggest that the two data sets\nare notthe same. The null hypothesis tested was that, on\naverage, Ohio Lumex and ALSI produce the same results\nwithin a given sample lot. The null hypothesis is rejected\nin part because Ohio Lumex results tended to exceed\nthose from ALSI for the same sample lot. Even when a\nbias term is used to correct this discrepancy, the null",
    "Page_60": "hypothesis is still rejected. Additional information about\nhis statistical evaluation is included in Appendix B.\n\nAccuracy Summary\n\nIn summary, Ohio Lumex data were within SRM 95%\nprediction intervals 93% of the time, which is statistically\nequivalent. ALSI data also compared favorably to SRM\nvalues and were within the 95% prediction interval 87% of\nhe time indicating statistical parity found to be biased low.\n\nThe comparison between the Ohio Lumex field data and\nhe ALSI results suggest that the two data sets are not the\nsame. When a unified hypothesis test is performed, this\nresult is confirmed. Ohio Lumex data were found to be\nboth above and below referee laboratory concentrations.\nThe number of Ohio Lumex average values less than 30%\ndifferent from the referee laboratory results or SRM\nreference values was 19 of 33 different sample lots. Ohio\nLumex results therefore, provide accurate estimates for\nield determination, and may be affected by interferences\nnot identified by this demonstration. Because the Ohio\nLumex data compare favorably to the SRM values, the\ndifferences between Ohio Lumex and the referee\naboratory are likely the result of matrix interferences.\n\n \n\n6.1.3 Precision\n\nPrecision is usually thought of as repeatability of a specific\nmeasurement, and it is often reported as RSD. The RSD\nis computed from a specified number of replicates. The\nmore replications ofa measurem ent, the higher confidence\nassociated with a reported RSD. Replication of a\nmeasurement may be as few as 3_ separate\nmeasurements, to 30 or more measurements of the same\nsample, depending upon the degree of confidence desired\nin the specified result. Most samples were analyzed seven\ntimes by both Ohio Lumex and the referee laboratory. In\nsome cases, samples may have been analyzed as few as\nthree times. This was often the situation when it was\nbelieved that the chosen sample, or SRM, was likely to be\nbelow the vendor quantitation limit. The precision goal for\nthe referee laboratory, based upon pre-demonstration\nresults, isan RSD of 25% orless. A descriptive evaluation\nfor differences between Ohio Lumex RSDs and the referee\nlaboratory RSDs was determined. In Table 6-7, the RSD\nfor each separate sample lot is shown for Ohio Lumex\ncompared to the referee laboratory. The average RSD was\nthen computed for all measurements made by Ohio\nLumex, and this value was compared to the average RSD\nfor the laboratory.\n\n43\n\nIn addition, the precision of an analytical instrument may\nvary depending upon the matrix being measured, the\nconcentration of the analyte, and whether the\nmeasurement is made for an SRM or a field sample. To\nevaluate precision for clearly different matrices, an overall\naverage RSD for the SRMs is calculated and compared to\nthe average RSD for the field samples. This comparison\nis also included in Table 6-7 and shown for both Ohio\nLumex and the referee laboratory.\n\nThe purpose of this evaluation is to determine the field\ninstrument's capability to precisely measure analyte\nconcentrations under real-life conditions. Instrument\nrepeatability was measured using samples from each of\nfour different sites. Within each site, there may be two\nseparate matrices, soil and sediment. Not all sites have\nboth soil and sediment matrices, nor are there necessarily\nhigh, medium, and low concentrations for each sample\nsite. Therefore, spiked samples were included to cover\nadditional ranges.\n\nTable 6-7 shows results from Oak Ridge, Puget Sound,\nCarson River, and the manufacturing site. It was thought\nthat because these four different field sites represented\ndifferent matrices, measures of precision may vary from\nsite to site. The average RSD for each site is shown in\nTable 6-7 and compared between Ohio Lumex and the\nreferee laboratory. SRM RSDs are not included in this\ncomparison because SRMs, while grouped with different\nsites for purposes of ensuring that the samples remained\nblind during the demonstration, were not actually samples\nfrom that site, and were, therefore, compared separately.\n\nThe RSDs of various concentrations are compared by\nnoting the RSD of the individual sample lots. The ranges\nof test samples (field, SRMs, and spikes) were selected to\ncover the appropriate analytical ranges of Ohio Lumex’s\ninstrumentation. Average referee laboratory values for\nsample concentrations are included in the table, along with\nSRM values, when appropriate. These are discussed in\ndetail in Section 6.1.2, describing the accuracy evaluation\nand are included here for purposes of precision\ncomparison. Sample concentrations were separated into\napproximate ranges: low, medium, and high, as noted in\nTable 6-7 and Table 6-1. Samples reported by Ohio\nLumex as below their approximated PQL were not included\nin Table 6-7. There appears to be no correlation between\nconcentration (low, medium, or high) and RSD; therefore,\nno other formal evaluations of this comparison were\nperformed.",
    "Page_61": "Table 6-7. Evaluation of Precision\n\n \n\n \n\n \n\nSample Lot No. Ohio Lumex Avg. Conc. or Reference RSD Number of wilin 25% RSD Goal?\nand Lab SRM Value Samples\nOAK RIDGE\nLot no. 03 0.26 (low)\nOhio Lumex 4.8% 3 yes\nALSI 3.8% 3 yes\nLot no. 09 0.47 (low)\nOhio Lumex 23.2% 7 yes\nALSI 34.2% 7 no\nLot no. 14 4.75 (medium)\nOhio Lumex 32.0% 7 no\nALSI 27.5% 7 no\nLot no. 21 11.2 (medium)\nOhio Lumex 23.3% 3 yes\nALSI 23.8% 3 yes\nLot no. 24 221 (high)\nOhio Lumex 28.0% 3 no\nALSI 44.8% 7 no\nLot no. 26 77.0 (high)\nOhio Lumex 2.6% 3 yes\nALSI 13.2% 7 yes\nLot no. 37 0.14 (low)\nOhio Lumex 5.0% 7 yes\nALSI 36.4% 7 no\nLot no. 44 2.33 (medium)\nOhio Lumex 3.0% 7 yes\nALSI 59.4% 7 no\nLot no. 60 165 (high)\nOhio Lumex 23.8% 7 yes\nALSI 30.9% 7 no\nOak Ridge Avg. RSD\nOhio Lumex 19.7% yes\nALSI 25.5% no\nPUGET SOUND\nLot no. 02 0.06 (low)\nOhio Lumex 43.9% 7 no\nALSI 23.6% 7 yes\nLot no. 05 0.21 (low)\nOhio Lumex 9.4% 3 yes\nALSI 33.3% 3 no\nLot no. 08 0.36 (low)\nOhio Lumex 14.2% 7 yes\nALSI 13.4% 7 yes\nLot no. 10 0.55 (low)\nOhio Lumex 120% 3 no\nALSI 20.5% 3 yes\nLot no. 11 0.81 (low)\nOhio Lumex 14.2% 7 yes\nALSI 32.7% 7 no\nLot no. 12 1.08 (medium)\nOhio Lumex 7.1% 3 yes\nALSI 2.8% 3 yes\nLot no. 25 16.6 (high)\nOhio Lumex 12.4% 3 yes\nALSI 12.3% 3 yes\nLot no. 34 11.3 (medium)\nOhio Lumex 24.7% 3 yes\nALSI 22.4% 7 yes\n\n44",
    "Page_62": "Table 6-7. Continued\n\n \n\n \n\n \n\nSample Lot No. Ohio Lumex Avg. Conc. or Reference RSD Number of wilin 25% RSD Goal?\nand Lab SRM Value Samples\nLot no. 36 0.073 (low)\nOhio Lumex 4.9% 3 yes\nALSI 6.7% 7 yes\nLot no. 57 0.73 (low)\nOhio Lumex 11.2% 7 yes\nALSI 16.2% 7 yes\nLot no. 61 154 (high)\nOhio Lumex 47.0% 7 no\nALSI 10.9% 7 yes\nLot no. 62 14.6 (high)\nOhio Lumex 13.0% 7 yes\nALSI 28.3% 7 no\nPuget Sound/ Avg. RSD\nOhio Lumex 28.8% no\nALSI 19.7% yes\nCARSON RIVER\nLot no. 01 0.24 (low)\nOhio Lumex 30.5% 7 no\nALSI 37.7% 7 no\nLot no. 04 0.11 (low)\nOhio Lumex 18.9% 3 yes\nALSI 9.1% 7 yes\nLot no. 06 0.26 (low)\nOhio Lumex 7.3% 3 yes\nALSI 15.7% 7 yes\nLot no. 38 0.63 (low)\nOhio Lumex 3.5% 7 yes\nALSI 3.8% 7 yes\nLot no. 39 1.24 (medium)\nOhio Lumex 6.5% 7 yes\nALSI 52.9% 7 no\nLot no. 41 1.79 (medium)\nOhio Lumex 17.5% 7 yes\nALSI 30.5% 7 no\nLot no. 43 2.76 (medium)\nOhio Lumex 9.1% 7 yes\nALSI 9.6% 7 yes\nLot no. 56 0.23 (low)\nOhio Lumex 8.0% 7 yes\nALSI 12.6% 7 yes\nLot no. 59 1.71 (medium)\nOhio Lumex 10.2% 7 yes\nALSI 7.9% 7 yes\nCarson River/ Avg. RSD\nOhio Lumex 15.0% yes\nALSI 16.6% yes\nMANUFACTURING SITE\nLot no. 13 5.91 (medium)\nOhio Lumex 51.9% 7 no\nALSI 15.4% 7 yes\nLot no. 17 10.5 (high)\nOhio Lumex 24.2% 3 yes\nALSI 14.6% 7 yes\nLot no. 45 5.44 (medium)\nOhio Lumex 1.6% 7 yes\nALSI 23.4% 6 yes\n\n \n\n45",
    "Page_63": "Table 6-7. Continued\n\n \n\n \n\nSample Lot No. Ohio Lumex Avg. Conc. or Reference RSD Number of wilin 25% RSD Goal?\nand Lab SRM Value Samples\nManufacturing Site/ Avg. RSD\nOhio Lumex 38.0 % no\nALSI 15.0% yes\nSUMMARY STATISTICS\nOverall Avg. RSD\nOhio Lumex 16.1% yes\nALSI 22.3% yes\nField Samples/ Avg. RSD\nOhio Lumex 24.3% yes\nALSI 20.3% yes\nSRMs/ Avg. RSD\nOhio Lumex 8.0% yes\nALSI 24.3% yes\n\n \n\nThe referee laboratory analyzed replicates of all samples\nanalyzed by Ohio Lumex. This was used for purposes of\nprecision comparison to Ohio Lumex. RSD for the vendor\nand the laboratory were calculated individually and shown\nin Table 6-7.\n\nAs noted from Table 6-7, Ohio Lumex precision is similar\no that of the referee laboratory. The single most important\nmeasure of precision provided in Table 6-7, overall\naverage RSD, is 22.3% for the referee laboratory\ncompared to the Ohio Lumex average RSD of 16.1%. The\naboratory and Ohio Lumex RSD are both within the 25%\nRSD objective for precision expected from both analytical\nand sampling variance.\n\nIn addition, field sample precision compared to SRM\nprecision shows that there may be some difference\nbetween these two sample lots; field sample RSD is 20.3%\nor ALSI and 24.3% for Ohio Lumex; SRM RSD is 24.3%\nor ALSI and 8.0% for Ohio Lumex. This is similar to the\nresults for the accuracy comparison. Ohio Lumex appears\no have better precision for the SRM analyses than for the\nield sample analyses. For purposes of this analysis,\nspiked samples are considered the same as field samples\nbecause these were similar field matrices and the resulting\nvariance was expected to be equal to that of field samples.\nThe replicate sample RSDs also confirm the pre-\ndemonstration results, showing that sample\nhomogenization procedures met their originally stated\nobjectives.\n\n \n\n46\n\nThere appears to be no significant site variation between\nOak Ridge, Puget Sound, and the manufacturing site\nsamples. (See Table 6-7 showing average RSDs for each\nof these sample lots. These average RSDs are computed\nusing only the results of the field samples and not the\nSRMs.) The Carson River site had a lower average RSD\nfor both the vendor and the laboratory, but this difference\nmay not be significant because this same result was not\nevident in the data comparisons performed for other data\nsets.\n\nPrecision Summary\n\nThe precision of the Ohio Lumex field instrument is better\nthan the referee laboratory precision. The overall average\nRSD is 22.3% for the referee laboratory, compared to the\nOhio Lumex average RSD of 16.1%. This is primarily\nbecause of the better precision obtained for the SRM\nanalyses by Ohio Lumex. Both the laboratory precision\nand the Ohio Lumex precision goals of 25% overall RSD\nwere achieved.\n\n6.1.4 Time Required\nMeasurement\n\nfor Mercury\n\nDuring the demonstration, the time required for mercury\nmeasurement activities was measured. Specific activities\nthat were timed included: instrument setup, sample\nanalysis, andinstrumentdisassembly. One field technician\nperformed all operations during the demonstration, with the\nexception of instrument setup and tear down, plus a small",
    "Page_64": "amount of sample preparation activities. A second\n\noperator assisted with these items.\n\nSetup and disassemble times were measured one time.\nAnalytical time was measured each day, beginning when\nthe first blank was started, and continuing until the last\nblank was completed atthe end of the day. Any downtime\nwas noted and then subtracted from the total daily\noperational time. The total of the operational time from all\nfour days was divided by the total number of analyses\nperformed. For this calculation, analyses of blanks and\ncalibration standards, and reanalyses of samples were not\nincluded in the total number of samples.\n\nSetup time for the RA-915+/RA-91C consisted of removing\nthe instrument from the shipping container, placement on\na level working surface, establishment of all electrical and\ngas tubing connections, and instrument warm-up. The\ntime required to remove the RA-915+/RA-91C from the\nshipping container could not be measured precisely\nbecause the device was removed from the shipping\ncontainer before the evaluation team could time these\nactivities; however, the vendor did replicate the majority of\nthis process at the request of the evaluator, so that a time\nestimate could be made. Based on these observations, it\nis estimated that one person could remove the device from\nthe shipping container in 15 minutes. Setup time for other\nperipheral devices, such as the computer/monitor and\nanalytical balance, was accomplished during the\ninstrument warm-up time. Leveling of the balance,\ndepending on field conditions, took between 5 and 10\nminutes. Setup of the computer/monitor took less than 5\nminutes.\n\nAfter all devices were setin place, remaining electrical and\ngas flow connections had to be made. The\nRA-915+/RP-91C was connected to a power source and to\nthe com puter/monitor. The balance was also connected to\nthe power source, but not to the computer/monitor. Gas\nconnections had to be made from the auxiliary pump,\nthrough a flip-up flow gauge, and then to the instrument.\nA mercury trap came pre-assembled and already inserted\nin the vent line which was attached to the instrument.\nOverall, the electrical and gas flow connections required 10\nminutes.\n\nAfter initial setup of the RA-915+/RP-91C was complete,\nthe instrument required approximately 45 to 60 minutes to\nwarm to 800°C. It is worth noting that setup of the balance\nand computer/monitor were performed during this time\nperiod.\n\n47\n\nOverall, the time required to remove the instrument from its\nshipping container, setup the device, allow the instrument\nto reach operating temperature, and setup peripheral\ndevices during instrument warm-up is estimated at\napproximately 60 to 75 minutes.\n\nIndividual sample analysis times were not measured for the\nduration of the demonstration. Analysis time was\nestimated by recording start and stop times each day, and\naccounting for any instrument downtime due to operator\nbreaks or device failure and maintenance activities.\nTherefore, the total time for analyses included blanks,\ncalibration standards, and any sample reanalyses;\nhowever, the total number of analyses performed includes\nonly demonstration samples (samples, spikes, and SRMs),\nnot vendor blanks, calibration standards, or reanalyses.\nTable 6-8 presents the time measurements recorded for\neach of the four days of operation of the RA-915+/RP-91C.\nIt should be noted that the second technician was required\napproximately 25% of the time in order to achieve the\nsample throughput observed during the demonstration, and\nthat the times in Table 6-8 are lapse times not labor times.\n\nTable 6-8. Time Measurements for Ohio Lumex\n\nDay Day Day Day Day 4-Day\n\n1 2 3 4 Total\n\nRun Time 195 540 540 0 1,275\n(minutes)\n\n \n\nAnalysis Time Summary\n\nIn total, Ohio Lumex analyzed 197 samples during the\ndemonstration. The turnaround time on individual sample\nanalyses was 1 minute; however, the vendor chose to\nanalyze replicates of virtually everysample. Using the total\nanalytical time reported in Table 6-8 and factoring in the\nsecond analyst (1275 minutes x 1.25 analysts), 8.1 minutes\nper analysis is a better approximation of real world\noperating conditions (assuming that replicate analyses are\nperformed). The vendor claims that 25 samples can be\nprocessed in an hour over an 8-hour day, an average of 2.4\nminutes per sample, if replicates are not performed. Field\nobservations support this claim.\n\nThe number of blanks, standards, and reanalysis of\nsamples outside of the calibration range will vary from site\nto site, depending on project goals (e.g., are “greater than”\nresults acceptable or must all samples be quantified) and\nsite conditions (e.g., high concentration samples or very\nheterogeneous samples). If project goals require all",
    "Page_65": "samples to be quantified, the number of reanalyses and\nblanks required could be higher and, therefore, the time per\nanalysis could be greater. If on the other hand, sample\nresults can be reported as “greater than” values (as was\ngenerally done during the demonstration), then 6.5 minutes\nper analysis is a reasonable average time.\n\nInstrument disassembly was measured from the time that\nthe lastsample or blank analysis ended until the instrument\nwas disassembled and placed in the original shipping\ncontainer. Disassembly involved turning off power,\ndisconnecting the power source and interface cables to the\ncom puter/monitor, and removal of the auxiliary pump unit.\nPackaging involved placing these components in wheeled\nshipping cases. It is estimated that this complete process\nwould take one person approximately 30 minutes to\ncomplete.\n\n6.1.5 Cost\n\nBackground information, assumptions used in the cost\nanalysis, demonstration results, and a cost estimate are\nprovided in Chapter 7.\n\n6.2\n\nThis section discusses the performance results for the\nRA-915+, along with the RP-91C attachment for soils, in\nterms of the secondary objectives described in Section 4.1.\nThese secondary objectives were addressed based on\nobservations of the RA-915+ and RP-91C combination and\ninformation provided by Ohio Lumex.\n\n6.2.1 Ease of Use\n\nDocuments the ease of use, as well as the skills and\ntraining required to properly operate the device.\n\nSecondary Objectives\n\nBased on observations made during the\ndemonstration, the RA-915+/RP-91C_ is\nreasonably easy to operate; lack of automation\nsomewhat impairs the ease of use. Operation\ntechnician with a_ basic\n\nrequires one field\nknowledge of chemistry acquired on the job orin\na university and training on the instrument.\n\n \n\nSix major elements were addressed in evaluating the ease\nof use:\n\n+ Usefulness of Standard Operating Practices (SOPs)\n\n48\n\n* Operator training and experience required\n+ Ease of equipment setup\n\n+ Ease of calibration\n\n+ Ease of sample preparation\n\n+ Ease of measurement\n\nEach of these is described, in sequence, in the following\nparagraphs. Five of the six elements were given a\nsubjective rating - excellent, good, fair, and poor - based on\nobservations made by the instrument evaluator. Operator\ntraining and experience in merely discussed.\n\nThe vendor provided two SOPs, one entitled “RA-915+\nMercury Analyzer” and the other entitled “RP-91C\nAttachment.” These procedures were evaluated during the\ndemonstration.\n\nThe RA-915+ procedure provides the following information:\n+ Comprehensive safety guidelines\n+ Equipment list with corresponding images\n\n+ Equipment application, including applicable media,\ndetection limits, sample parameters, and detection\ntechnique\n\n* Technical specifications and operating conditions\n\n* Design and operation of the analyzer, including a\nschematic\n\n* Description of the appearance and functions of the\nequipment from all angles\n\n+ Pre-operational procedures such as setup and\nselection of operational mode\n\n+ Operational procedures for the display unit and for\nconnection to a personal computer\n\n* Detailed equipment test and maintenance procedures\n+ Troubleshooting guide\n\nThe SOP was well-organized, covered major information\nrequirements, and was easy to understand. The safety\nprecautions were thorough and well-documented. The\nparts and equipment list covered all required parts for use\nof the RA-915+. The table clearly presented various\napplications and related data, including the need for\nancillary equipment for water and soil analyses. Equipment\nspecifications matched those documented during the\ndemonstration. The schematics and discussion of system\ndesign and operational principles were well written. They\nprovided a thorough description of the operational principle\nfor the technology, easily understood by someone\nunfamiliar with the technology. The description of",
    "Page_66": "appearance and functional controls was also useful for\nnovices with the equipment. Similarly, the detailed pre-\noperational procedures were generally clear and\ncomprehensive, allowing an operator with training on the\nbasics of the equipment to setup and operate the RA-915+.\nA step-by-step evaluation of the procedure could not be\nperformed without impacting the evaluation of analytical\nhroughput (see Section 6.1.4). Finally, the troubleshooting\nable was easy to follow; however, there was no opportunity\no evaluate the table, for accuracy or completeness, during\nhe demonstration.\n\nThe SOP for the RP-91C was written in a manner similar\no the SOP for the RA-915+. The RP-91C SOP was\nequally clear and thorough. Adequate detail was provided\nOo assist an inexperienced operator in equipment setup,\ncalibration, operation, troubleshooting, and maintenance.\nThe only maintenance activity that was performed during\nhe demonstration was replacement of the optical lense.\nThe procedure provides adequate information for a\nechnician to perform this maintenance activity.\n\n \n\nThere were two crucial operational elements encountered\nduring the demonstration that were not adequately\naddressed in the RP-91C SOP. The first was the selection\nof sample size such that the results remain within the\ncalibration range. The SOP instructs the user to use a\nsample mass such that the mass of mercury is less than\n1 wg; however, selection of sample size requires an\nestimate of the expected mercury concentration. This\nproblem is not unique to the RA-915+/RP-91C; any AA\ninstrument requires an estimate of sam ple concentration to\nobtain sample results within a specified calibration range.\nSecond, no information was provided on how to handle\nsamples that were outside of the calibration range.\nProcedures implemented during the demonstration\nincluded analyzing a blank sample after a sample was\nabove the calibration range (to purge the system of\nmercury) and reducing sample size on subsequent\nreanalyses (if quantitative results are reported). These\nprocedures were not described in the SOP; however, the\nsoftware provided the following prompt: “OUT OF RANGE”.\nIt is not known whether the analyst is trained to analyze a\nclean-out blank following this prompt. The specific content\nof the training course is not known.\n\nOhio Lumex provides a 1-day training course for an\nadditional cost of $600 to anyone who purchases, rents, or\nleases the RA-915+/RP-91C. The vendor asserts that this\nis a 6-hour, comprehensive course covering software and\nhardware installation, and operational training on use of the\ninstrument for soil analysis. The training course was not\n\n49\n\nevaluated during the demonstration. It may supplement\nthe SOPs. Overall, the SOPs were good, but could use\nadditional detail related to sample size selection and results\noutside of the calibration curve.\n\nOhio Lumex chose to operate the RA-915+/RP-91C with\none chemist during the demonstration. The chemist held\na Ph.D. in chemistry. Ohio Lumex claims that a laboratory\nor field technician with a high school diploma and basic\ncomputer knowledge can operate the equipment after a\n1-day training course on the instrument. Field observations\nsupport this claim. Most operations required either use of\na keyboard or mouse with a Microsoft Windows-based\nsystem. The prompts were clear and easy to understand.\n\nThe operator performed equipment setup with ease. The\nRP-91C connected rapidly and easily to the RA-915+. The\nunit plugged into a power supply and an interface with the\nPC. The external air pump and flow meter (used with the\nRP-91C) were encased in a metal box with a hinged lid.\nThe lid was opened, the flow meter (rotometer) was hinged\nupward into a vertical position, and the pump was\nconnected to the rotometer with plastic tubing that comes\nwith the unit. The self-standing balance was easily setup\nand leveled.\n\nIt was difficult to determine exactly how much time was\nrequired for setup because a second vendor representative\nhelped with setup to expedite the process. Typically, the\ntwo vendor representatives setup the equipment in 5\nminutes (the instrument was already unpacked from its\nshipping case). Field observations indicate that one\nperson could setup all required equipment, starting with\nshipping containers, in approximately 30 minutes, perhaps\nless in some cases. It should be noted that once\ninstrument setup is complete, furnace warm-up requires\n45-60 minutes to reach the operating temperature of 800\n°C. There was no display indicating actual furnace\ntemperature; the operator merely observed the inner lining\nof the furnace. When it achieved a red glow, the furnace\nwas deemed hot enough for operation. Overall, the ease\nof setup was good, with the only drawback being the\nextended warm-up time for the instrument.\n\nCalibration was performed by the operator alone. A blank\nwas analyzed and a 2-point calibration performed in less\nthan five minutes. The RP-91C SOP (p13) recommended\nthree to four calibration points. Calibration consisted of\nweighing the standard(s) and analyzing them according to\nthe steps in the SOP. A calibration curve was plotted and,\nif acceptable, the calibration coefficients were accepted.\nOverall, the ease of calibration was good.",
    "Page_67": "The operator was able to perform sample preparation and\nanalysis on a continuous basis. Sample preparation took\nless than one minute per sample, on average, although\nsome minor assistance was performed by a second vendor\nrepresentative. In general, sample preparation was\nunwieldy, increasing the potential for lost sample or\nweighing errors.\n\nSample preparation consisted of preparing small pieces of\naluminum foil (approximately 5-8 cm squares) for weighing\nsoil samples. Several times during the demonstration, a\nsecond vendor representative assisted with this task. The\nsamples were initially mixed in the original container, using\na clean quartz weigh boat. Approximately one half of the\nsample was transferred to the aluminum foil, which was\nthen placed on the digital balance. The balance was\nzeroed with the sample and foil, which were then removed\nfrom the balance. A small amount of sample was then\ntransferred to a clean, quartz weigh boat. Sample transfer\nwas completed by dipping the quartz cup of the weigh boat\ninto the soil and scooping a small quantity into the bowl.\nEach weigh boat was equipped with an insulated plastic\nhandle to allow safe handling of the weigh boat\nimmediately after heating.\n\nThe balance was placed at ground level, inside a\ncardboard box (a standard file storage box with dimensions\nof 30 cm wide by 40 cm long by 30 cm deep) to shield the\nbalance from wind effects. The balance had a hinged top\ncover with a 5-cm, transparent portal for convenient\nviewing of the sample; however, each time a sample was\ninserted or removed, the lid had to be opened and then\nclosed. The operator sat in a chair almost continuously\nduring the demonstration so as to be able to reach the\nbalance and the sample injection port in alternating steps.\nThe location of the balance on the ground was required\nbecause of the top-opening mechanism on the balance.\nInserting and removing samples through the hinged top\nand the box opening required great care. Each time the\noperator took a short break, it was clear that he was stiff\nfrom working in a sitting position on a continuous basis.\n\nAn aluminum foil square with soil sample was placed on\nthe balance (the balance is not part of the system, but can\nbe provided), the balance was zeroed (tare weight), the\naluminum foil with sample was removed from the balance,\nand asmall amount of the sample was placed in the weigh\nboat. The aluminum foil and residual sample were placed\non the balance again (gross weight). The difference\nbetween the tare weight (zero) and the gross weight (a\nnegative number) was the net weight used for the analysis.\nThis weight was manually calculated and recorded in the\n\n50\n\ninstrument data entry panel using the keyboard. This\noperation was relatively easy to understand and could be\nperformed by a trained technician. However, there were\nopportunities for spilling residual sample after weighing or\nimproperly calculating or entering net weight data. Sample\nweights can be determined by recording a tare weight for\nthe weigh boat, adding sample, and recording a gross\nweight (the difference being the net weight). In this way,\nuse of aluminum foil can be eliminated. The same issues\nremain with manual calculations and data recording.\n\nSample analysis took less than 1 minute per sample.\nBecause of the lack of automation in the process, the\noperator was constantly busy weighing samples, recording\nand entering weights, inserting and removing weigh boats\nfrom the RP-91C, or recording analytical results. It should\nbe noted that the operator always analyzed duplicate\nsamples and, oftentimes, analyzed triplicates to ensure\ngood analytical precision.\n\nAs samples were analyzed, vendor-proprietary software\nscreens allowed the user to track the sample adsorption\ncurve on the screen and know when the analysis was\ncompleted (see Figure 6-3). The software is compatible\nwith Windows 95, 98, or 2000, and can export data to\nMicrosoft Excel. Sample analysis consisted of inserting the\npre-weighed sample boat in the small opening in the\nfurnace, watching the adsorption curve to show the\nanalysis was completed, and removing the sample weigh\nboat. Sample analysis was easy to understand and could\nbe performed by a trained technician.\n\nDuring the demonstration, samples with concentrations\noutside of the equipment calibration range were\nencountered. These samples would result in a peak that\nwas above the top end of the calibration range. The\noperator was required to analyze a blank to demonstrate\nthat excess mercury had been purged from the system; an\n“OUT OF RANGE” screen prompt advised the operator\nthat the sample was not in the calibration range.\n\nThe digital balance was the major peripheral item. The\nvendor will supply a balance, or the user can supply his/her\nown balance. Though the balance is not part of the\nrequired vendor equipment, a balance is a necessary\nperipheral. Therefore, the balance was evaluated during\nthe demonstration. The reader should note that other\nbrands and models of balances may be used and these\nmay not perform in the same manner as the balance used\nduring the demonstration. The balance itself was easy to\nuse, but the lack of an automatic interface with the\nmonitor/software made the overall system more difficult to\noperate and increased the potential for error.",
    "Page_68": "Figure 6-3. RA-915+/RP-91C peak screen.\n\n6.2.2\n\nDocuments potential health and safety concerns\nassociated with operating the device.\n\nHealth and Safety Concerns\n\nNo significant health and safety concerns were\nnoted during the demonstration. The only\npotential health and safety concerns identified\nwere the generation of mercury vapors and the\npotential for burns with careless handling of hot\nThe vendor provides a\n\nquartz sample boats.\nmercury filteras standard equipment; exercising\n\ncaution and good laboratory practices can\nmitigate the potential for burns.\n\n \n\nHealth and safety concerns, including chemical hazards,\nradiation sources, electrical shock, explosion, and\nmechanical hazards were evaluated.\n\n  \n\n0 20 AO BO BO 100 120 140 160 180 260 220 240 260 260 300 320 340 350 380 400 420 440 460 480 500 520 $40 S60 580 600\nTare, se\n\n51\n\nO02\n\n1370\n\n0.00\n\n \n\n(RE e151 >|\n\nNo chemicals were used in the preparation or processing\nof samples, except for analytical standards. During this\ndemonstration, the analytical standards were soil SRMs for\nmercury. These were handled with gloves, and the\noperator wore safety glasses at all times. Such standard\nlaboratory precautions mitigate the potential for dermal\nexposure. Similar procedures were also used for soil\nsamples which contained mercury. Because the RP-91C\nattachment is designed to thermally convert mercury\ncompounds to mercury vapors as part of the analytical\nprocess, and no fume hood was present to exhaust\nmercury vapors after analysis, inhalation of mercury was a\nconcern. The vendor installs a proprietary mercury trap in\nthe exhaust line from the RP-91C attachment.\nMeasurements were taken with a Jerome 431-x gold film\nmercury vapor analyzer manufactured by Arizona\nInstruments Corporation. The instrument has a range of\n0.000 to 0.999 mg/m. In all cases, readings were 0.000\nmg/m®? in the breathing zone of the operator.\n\nIn looking at electrical shock potential, two factors were\nevaluated: 1) obvious areas where electrical wires are",
    "Page_69": "exposed and 2) safety certifications. No obviously exposed\nwires were noted during the demonstration. All\nconnections between equipment were made_ using\nstandard electrical power cords, modem interface lines,\nand 8-pin cords. Power cords were grounded and a surge\nprotector (provided by EPA) was utilized. The RA-915+\nline voltage (110 volts AC) was stepped down to 12 volts\n(DC) at 2.5 amps using a power transformer. The\nRA-915+ was UL, SA, and CE certified, among other\ncertifications marked on the transformer. The balance\nutilized during the demonstration was a KND 1-microgram,\ndigital balance, model FX-320. It operated ona 12-volt DC\n(at 0.3amps) power source that was stepped down from\n110 volts and 7.5 amps. This device had no visible\ncertifications. A standard laptop computer was used\n(Hewlett Packard Pavilion, model HP F145A). This\ncomputer had UL, CE, and numerous other certifications.\n\nNo obvious explosion hazards were noted. The use of\nambient air as a carrier gas eliminates the possibility of\nexplosion associated with the use of oxygen as a carrier\ngas in the presence of ignition sources.\n\nNo serious mechanical hazards were noted during the\ndemonstration. All equipment edges were smooth,\nminimizing any chance of cuts or scrapes. The hinged lid\non the RP-91C pump/rotometer housing presents the\npossibility of a pinch hazard, as would any hinged device;\nhowever, the lid is very light weight, remained opened\nthroughout the demonstration, and is designed to remain\nsecurely in place when the lid is open.\n\n6.2.3 Portability of the Device\n\nDocuments the portability of the device.\n\nThe RA-915+ air analyzer was easily portable,\nalthough the device, even when carried in the\ncanvas sling, was not considered light-weight.\nThe addition of the RP-91C and associated\npump unit preclude this from being a truly field\nportable instrument. The device and\n\nattachments can be transported in carrying\ncases by two people, but must then be setup in\na stationary location. It was easy to setup, but\nthe combined instrument is better characterized\nas mobile rather than field portable.\n\n \n\nThe RA-915+ measured 46 cm (L) by 11 cm (W) by 21 cm\n(H). The weight was reported as 7.5 kg. The RP-91C\nattachment measures 32 cm by 24 cm by 12 cm and\n\n52\n\nweighs 5.5 kg. Also included as a standard feature with\nthe RP-91C were amonitor, keyboard and mouse; and the\npump/rotometer case. All were light weight and easily\nportable, with the pump and rotometer enclosed ina metal\ncarry case with a handle. Remote locations also require\nthe use of a generator or 12-volt battery.\n\nThe RA-915+/RP-91C was not easily portable from the\nstandpoint of being a handheld instrument. Movement and\nsetup of the equipment generally took two people about 10\nminutes, with the equipment already unpacked. It is\nestimated that one person would require approximately 30\nminute to unpack the instrument from the carrying case\nand complete setup. The RA-915+ air analyzer was easily\nportable, although the device, even when carried in the\ncanvas sling, was notlightweight. The addition of the RPD-\n91, pump unit, and battery preclude this from being a truly\nfield portable instrument. The device and attachments can\nbe transported by carrying two containers with handles,\nplus the RP-91C attachment, the monitor/mouse, power\ncords/transformers, and data cables (plus an analytical\nbalance). Even when placed in wheeled shipping\ncontainers, the device is only portable in the sense that it\ncan be managed in a manner similar to wheeled luggage.\nTransport in paved areas is easy; transport up a rocky\nincline would be difficult. The device is, however, easily\ntransportable in any size vehicle, and can be moved to any\nlocation where a vehicle can go. Therefore, it would be\npractical for many field applications. It should not be\ncharacterized as a handheld instrument. During the\ndemonstration, the complete soil analytical unit, including\nthe monitor and air pump, easily fit on a table measuring 30\ninches wide by 72 inches long, with adequate space for\nsample staging and preparation.\n\n \n\nThe balance required a flat, stable surface. Because the\nbalance was top loaded, the vendor chose to place the\nbalance on the ground near the chair in which the operator\nsat. The balance was placed inside of a cardboard box to\neliminate the effects of wind on the enclosed balance. This\nsetup required the operator to repeatedly bend over to tare\nthe sample (on aluminum foil) and again after the analytical\nsample was removed in the sample boat.\n\nThe RA-915+/RP-91C was operated using a 12-volt battery\nduring the Visitors’ Day. The unit appeared to operate well,\nalthough no samples were being processed for evaluation\nand no evaluation was made of the amount of time the\nbattery lasted. The vendor reports a battery life of\napproximately 3.5 hours. Alternatively, a standard\nelectrical source of 110 volts can be utilized. Power can be\nsupplied by any standard 2,000 watt generator.",
    "Page_70": "For the demonstration, the vendor was supplied with a\nfolding table, two chairs, and a tent to provide shelter from\ninclement weather. In addition, one 1-gallon container\neach was provided for waste soil and decontamination\nwater utilized to clean weigh boats. A 2-gallon zip-lock bag\nwas furnished for disposal of used gloves, wipes, and other\nwastes which were contaminated during the demonstration.\nFinally, a large trash bag was supplied for disposal on non-\ncontaminated wastes.\n\n6.2.4\n\nEvaluates the durability of the device based on its\nmaterials of construction and engineering design.\n\nInstrument Durability\n\nThe RA-915+/RP-91C was well designed and\n\nconstructed for durability.\n\n \n\nThe outside of the RA-915+ is constructed of sturdy\naluminum (2 mm thickness) that was painted to prevent\ncorrosion. The exterior of the RP-91C furnace is stainless\nsteel; the interior is quartz. The furnace is covered by a\npainted metal guard to prevent burns. The auxiliary air\npump and rotometer were housed in a sturdy, painted\naluminum box (2 mm thickness). The lid of this container\nwas secured with hinges, and was opened when the\nrotometer was setup for operation. No environmental (e.g.,\ncorrosion) or mechanical (e.g., shear stress or impact)\ntests were performed; however, the outer shell of the\ninstrument was well-designed and constructed, indicating\nthat the device would likely be durable under field\nconditions.\n\nNo evaluation could be made regarding the long-term\ndurability of the furnace, analytical cell, or circuitry.\nExternal visual inspection did not indicate that any\nproblems were likely, although many parts were obscured\nfrom view. The vendor offers a standard 1-year warranty,\nand will provide a 1-year extended warranty and\nmaintenance plan at the owner’s cost. This warranty cost\n$2,400, and covers all parts and labor except consumable\nitems (lamp, rechargeable battery for the RA-915+, and\nfilters). The only mechanical part with the potential to fail\nover time is the air pump. Long term operation could result\nin the need for repair or replacement of the air pump. The\nheating element of the furnace is the other part with some\npotential for long term failure, although it worked properly\n\n53\n\nduring the demonstration. Plastic tubing for the rotometer\nmay also be subject to long term failure due to the effects\nof sun and temperature or mechanical failure. Overall,\nhowever, the design and construction of the instrument\nsupport the vendor claim that this instrument is durable.\nThe vendor asserts that life expectancy of the furnace and\nair pump is 3-5 years with heavy use.\n\nFinally, most of the demonstration was performed during\nrainfall events ranging from steady to torrential. The\ninstrument was located under a tent with side flaps to\nprotect it from rainfall. Even when it was not raining, the\nrelative humidity was high. The high humidity and rainfall\nhad no apparent impact on the reliability of the instrument\noperation.\n\n6.2.5 Availability of Vendor Instruments\nand Supplies\n\nDocuments the availability of the device and spare\nparts.\n\nThe RA-915+/RP-91C is readily available for\nrental, lease, or purchase. Spare parts and\n\nconsumable supplies can be added to the\noriginal instrument order or can be received\n\nwithin 24-48 hours of order placement.\nStandards are readily available from laboratory\nsupply firms or can be acquired through Ohio\nLumex.\n\n \n\nEPA representatives contacted Ohio Lumex regarding the\navailability of the RA-915+/RP-91C and_ supplies.\nAccording to Ohio Lumex, such systems are available\nwithin a few weeks of order placement, but can be\nexpedited. The RA-915+/RP-91C also is available for\nrental or leasing and lead time is subject to availability.\n\nThe instrument comes standard with four quartz-sample\ninjectors; no other parts or consumable supplies are\nprovided standard with the equipment. Spare parts, such\nas the furnace, furnace lenses, the air pump, or additional\nsample injectors, can be ordered individually. These and\nany other parts are available within 24-48 hours.\nStandards can be provided by Ohio Lumex or can be\npurchased from a laboratory supply firm.",
    "Page_71": "Chapter 7\nEconomic Analysis\n\nThe purpose of the economic analysis was to estimate the\ntotal cost of mercury measurement at a hypothetical site.\nThe cost per analysis was estimated; however, because\nthe cost per analysis would decrease as the number of\nsamples analyzed increased, the total capital costwas also\nestimated and reported. Because unit analytical costs are\ndependent upon the total number of analyses, no attempt\nwas made to compare the cost of field analyses with the\nRA-915+/RP-91C to the costs associated with the referee\nlaboratory. “Typical” unit cost results gathered from\nanalytical laboratories were reported to provide a context\nin which to review the RA-915+/RP-91C costs. No attempt\nwas made to make a direct comparison between these\ncosts because of differences in sample throughput,\noverhead factors, total equipment utilization factors, and\nother issues that make a head-to-head comparison\nimpractical.\n\nThis chapter describes the issues and assumptions\ninvolved in the economic analysis, presents the costs\nassociated with field use of the RA-915+/RP-91C, and\npresents a cost summary for a “typical” laboratory\nperforming sample analyses using the reference method.\n\n7.1. Issues and Assumptions\n\nSeveral factors can affect mercury measurement costs.\nWherever possible in this chapter, these factors are\nidentified in such a way that decision-makers can\nindependently complete a project-specific economic\nanalysis. Ohio Lumex offers three options for potential\nRA-915+/RP-91C users: 1) purchase of the instrument, 2)\nweekly rental, and 3) equipment leasing with an option to\npurchase. Because site and user requirements vary\nsignificantly, all three of these options are discussed to\n\n54\n\nprovide each user with the information to make a case-by-\ncase decision.\n\nA more detailed cost analysis was performed on the\nequipment rental option because this case represents the\nmost frequently encountered field scenario. The results of\nthat cost analysis are provided in Section 7.2\n\n7.1.1 Capital Equipment Cost\n\nThe RA-915+/RP-91C comes complete with the analytical\ninstrument (RA-915+), furnace attachment and auxiliary air\npump/flow meter (RP-91C), a set of 4 quartz injection\nspoons with ceramic handles, and software, regardless of\nwhether the instrument is purchased, rented, or leased. An\noptional digital balance is available for purchase, rental, or\nlease from Ohio Lumex, but not included in the base cost\nof any of these three options because the user may provide\nhis/her own balance. Because there is no output signallink\nbetween the balance and the system, any balance can be\nused. A laptop computer with display screen can be\npurchased, rented, or leased from Ohio Lumex or can be\nprovided by the user. A user-supplied printer can also be\nattached to the system using a standard printer cable; no\npurchase, lease, or rental option is available for the printer.\n\nThe cost quoted by Ohio Lumex does not include\npackaging or freight costs to ship the instrument to the user\nlocation. No deposit is required for rental and lease\nagreements. A user manual is provided at no cost. A\n6-hour training session is available for an additional fee.\n\n7.1.2 Cost of Supplies\n\nThe cost of supplies was estimated based on the supplies\nrequired to analyze demonstration samples and\ndiscussions with Ohio Lumex. Requirements vary\ndepending on whether solid or liquid samples are being",
    "Page_72": "analyzed. For purposes of this costestimate, only supplies\nrequired to analyze solid samples are factored into the cost\nestimate because only solid samples were analyzed during\nthe demonstration. Supplies required for liquid samples\nare not noted because a different analytical attachment is\nused. Supplies consisted of consumable items (e.g.,\ncalibration standards, mercury trap) and non-consumables\nthatcould not be returned because they were contaminated\nor the remainder of a set (e.g., quartz injection spoons).\nThe purchase prices and supply sources were obtained\nfrom Ohio Lumex, and confirmed by contacting those\nsources. Because the user cannot return unused or\nremaining portions of supplies, no salvage value was\nincluded in the cost of supplies. PPE supplies were\nassumed to be part of the overall site investigation or\nremediation costs; therefore, no PPE costs were included\nas supplies.\n\n7.1.3 Support Equipment Cost\n\nDuring the demonstration, the RA-915+/RP-91C, air pump,\nlaptop computer, and balance were operated using AC\npower. The costs associated with providing the power\nsupply and electrical energy were not included in the\neconomic analysis; the demonstration site provided AC\npower at no cost. During Visitors’ Day, all of the items\nmentioned were operated using a 12-volt DC battery.\n\nBecause of the large number of samples expected to be\nanalyzed during the demonstration, EPA provided support\nequipment, including tables and chairs for the two field\ntechnician’s comfort. In addition, EPA provided a tent to\nensure that there were no delays in the project due to\ninclement weather. These costs may not be incurred in all\ncases. However, such equipment is frequently needed in\nfield situations, so these costs were included in the overall\ncost analysis.\n\n7.1.4 Labor Cost\n\nThe labor cost was estimated based on the time required\nfor RA-915+/RP-91C setup, sample preparation, sample\nanalysis, summary data preparation, and instrument\npackaging at the end of the day. Setup time covered the\ntime required to take the instrument out of its packaging,\nset up all components, and ready the device for operation.\nHowever, the RA-915+/RP-91C was already removed from\nthe original shipping container. Therefore, this time was\nestimated rather than measured. Sample preparation\ninvolved mixing samples with the injection spoon. Sample\npreparation was generally completed while previous\nsamples were being analyzed. Sample analysis comprised\nthe time required to analyze all samples and submit a data\n\n55\n\nsummary. The data summary was strictly a tabulation of\nresults in whatever form the vendor chose to provide. In\nthis case, the vendor transcribed results from the electronic\ndatabase to the field COC forms (no printer was available\nin the field). The time required to perform all tasks was\nrounded to the nearest hour. However, for the economic\nanalysis, it was assumed that a field technician who had\nworked for a fraction of a day would be paid for an entire 8-\nhour day. Based on this assumption, a daily rate fora field\ntechnician was used in the analysis.\n\nDuring the demonstration, EPA representatives evaluated\nthe skill level required for the field technician to analyze\nand report results for mercury samples. Based on these\nfield observations, a field technician with basic chemistry\nskills acquired on the job or in a university setting, and a\n1-day training course specific to the RA-915+/RP-91C, was\nconsidered qualified to operate the instrument. For the\neconomic analysis, an hourly rate of $15 was used for a\nfield technician. A multiplication factor of 2.5 was applied\nto labor costs to account for overhead costs. Based on this\nhourly rate and multiplication factor, and an 8-hour day, a\ndaily rate of $300 was used for the economic analysis.\nMonthly labor rates are based on the assumption of an\naverage of 21 work days per month. This assumes 365\ndays per year, and non work days totaling 113 days per\nyear (104 weekend days and 9 holidays; vacation days are\ndiscounted assuming vacations will be scheduled around\nshort-term work or staff will be rotated during long\nprojects). Therefore, 252 total annual work days are\nassumed.\n\n7.1.5 Investigation-Derived Waste Disposal\nCost\n\nOhio Lumex was instructed to segregate its waste into\nthree categories during the demonstration: 1) general\ntrash; 2) lightly contaminated PPE and wipes; and\n3) contaminated soil (both analyzed and unanalyzed) and\nother highly contaminated wastes. General trash was not\nincluded as IDW and is not discussed in this document. A\nseparate container was provided for each waste category.\n\nLightly contaminated wastes consisted primarily of used\nsurgical gloves, wipes, and aluminum foil. The surgical\ngloves were discarded for one of three reasons: 1) they\nposed a risk of cross contamination (noticeably soiled),\n2) they posed a potential health and safety risk (holes or\ntears), or 3) the operator needed to perform other tasks or\ntake a break. The rate of waste generation was in excess\nof what would be expected in a typical application of this\ninstrument. In addition, the EPA evaluators occasionally",
    "Page_73": "contributed used gloves to this waste accumulation point.\nWipes were used primarily to clean injection spoons (after\ncooling) between samples. In cases where cross\ncontamination is not a major concern (e.g., field screening\norallsamples are in the same concentration range), lesser\namounts of waste would likely be generated. Aluminum foil\ncontained the soil while it was being weighed. In the case\nof soils, the foil contained virtually no residual soil, and was\ndiscarded in this container. Foil used to weigh wet\nsediments was considered highly contaminated, and was\ndiscarded with the soil.\n\nContaminated soils consisted primarily of soil placed in the\ninjection spoon and then removed because the weight was\nabove the target weight. Soil that was analyzed was also\nplaced in this waste container as a precaution, even though\nitis expected that such soils would be free of mercury after\nbeing heated to high temperatures in the analytical\ninstrument. In some cases, these sample residuals may\nnot need to be handled as hazardous waste.\n\nThe contaminated soil, excess sample material, and lightly\ncontaminated gloves and wipes were considered\nhazardous wastes for purposes of this cost analysis.\n\n7.1.6 Costs Not Included\n\nItems for which costs were not included in the economic\nanalysis are discussed in the following subsections, along\nwith the rationale for exclusion of each.\n\nOversight of Sample Analysis Activities. A typical user\nof the RA-915+/RP-91C would not be required to pay for\ncustomer oversight of sample analysis. EPA\nrepresentatives observed and documented all activities\nassociated with sample analysis during the demonstration.\nCosts for this oversight were not included in the economic\nanalysis because they were project specific. For the same\nreason, costs for EPA oversight of the referee laboratory\nwere also not included in the analysis.\n\nTravel and Per Diem for Field Technician. Field\ntechnicians may be available locally. Because the\navailability of field technicians is primarily a function of the\nlocation of the project site, travel and per diem costs for\nfield technicians were not included in the economic\nanalysis.\n\nSample Collection and Management. Costs for sample\ncollection and management activities, including sample\nhomogenization and labeling, are site specific and,\ntherefore, not included in the economic analysis.\n\n56\n\nFurthermore, these activities were not dependent upon the\nselected reference method or field analytical tool.\nLikewise, sample shipping, COC activities, preservation of\nsamples, and distribution of samples were specific\nrequirements of this project that applied to all vendor\ntechnologies and may vary from site to site. None of these\ncosts was included in the economic analysis.\n\nItems Costing Less than $10. The costs of inexpensive\nitems, such as paper towels, was not included in the\neconomic analysis.\n\nDocumentation Supplies. The costs for digital cameras\nused to document field activities were not included in\nproject costs. These were considered project-specific\ncosts that would not be needed in all cases. In addition,\nthese items can be used for multiple projects. Similarly,\nthe cost of supplies (logbooks, copies, etc.) used to\ndocument field activities was not included in the analysis\nbecause such supplies are project specific.\n\nHealth and Safety Equipment. Costs for rental of the\nmercury vapor analyzer and the purchase of PPE were\nconsidered site specific and, therefore, not included as\ncosts in the economic analysis. Safety glasses and\ndisposable gloves were required for sample handlers and\nwould likely be required in most cases. However, these\ncosts are not specific to any one vendor or technology. As\na result, these costs were not included in the economic\nanalysis.\n\nMobilization and Demobilization. Costs for mobilization\nand demobilization were considered site specific, and not\nfactored into the economic analysis. Mobilization and\ndemobilization costs actually impact laboratory analysis\nmore than field analysis. When a field economic analysis\nis performed, it may be possible to perform a single\nmobilization and demobilization. During cleanup or\nremediation activities, several mobilizations,\ndemobilizations, and associated downtime costs may be\nnecessary when an off-site laboratory is used because of\nthe wait for analytical results.\n\n7.2. RA-915+/RP-91C Costs\n\nThis section presents inform ation on the individual costs of\ncapital equipment, supplies, support equipment, labor, and\nIDW disposal for the RA-915+/RP-91C. Table 7-1\nsummarizes the RA-915+/RP-91C costs.",
    "Page_74": "Table 7-1. Capital Cost Summary for the RA-915+/RP-91C\n\n \n\n \n\nItem Quantity valigsest Total Cost for Selected Project Duration\n\n1-Month 3-Month 6-Month 12-Month 24-Month\nPurchase RA-915+/RP-91C 1 $29,000 $29,000 $29,000 $29,000 $29,000 $29,000\nMonthly Rental of RA-915+/RP-91C 1 $3,500 $3,500 $10,500 $21,000 $42,000 $84,000\nMonthly Lease of RA-915+/RP-91C 1 $3,500 $3,500 $10,500 $21,000 $42,000 $84,000\nPurchase Balance (Optional) * 1 $600 $600 $600 $600 $600 $600\nPurchase Printer (Optional) * 1 $150 $150 $150 $150 $150 $150\n\na A balance is required, but may be provided by the user. A printer is optional; it may also be provided by the user.\n\n7.2.1 Capital Equipment Cost\n\nDuring the demonstration, the RA-915+/RP-91C was\noperated for approximately two and one-half days and was\nused to analyze 197 samples.\n\nFigure 7-1 summarizes the RA-915+/RP-91C capital costs\nfor the three procurement options: rental, lease, and\npurchase. These costs reflect the basic RA-915+/RP-91C\nsystem, with the optional computer. No other options (e.g.,\nbalance or printer) and no supply or shipping costs are\nincluded. As would be expected, this chart clearly shows\nthat either rental or leasing is the most cost-effective option\nfor short-term projects (less than 8 months). When project\nduration (or use on multiple projects) exceeds eight\nmonths, the purchase option is the most cost-effective.\nThese scenarios cover only capital cost, not the cost of\nsupplies, support equipment, labor, and IDW disposal.\n\n100\n\n   \n\nCapital Cost ($1000)\n\nPurchase\n\n12 94\nMonths\n\nFigure 7-1. Capital equipment costs.\n\n57\n\nThe RA-915+/RP-91C, including the auxiliary air pump and\nflow meter, and related electrical connections, sells for\n$29,000. Also included are four quartz injection spoons,\nplastic tubing for air connections, and an_ instruction\nmanual. The portable computer/monitor is not included in\nthe cost, but the software is included. A balance is also\nrequired and can be purchased from Ohio Lumex for $600,\nor rented or leased for $150 per week. However, the user\ncan supply any existing balance. The costs presented in\nFigure 7-1 do notinclude the cost of the balance.\n\n7.2.2 Cost of Supplies\n\nSupplies used during the demonstration included solid\nSRMs and a mercury trap. NIST soil SRMs sell for $250\neach; typically both a high and a low standard will be\nrequired for many applications, for a total cost of $500. If\nsediments are analyzed, a NIST sediment SRM may be\nobtained for $150. No costs for a sediment SRM are\nincluded in this analysis. These standards have a life-\nexpectancy of one to three years (one year is assumed for\nthis cost analysis). A mercury trap was also required\nduring the demonstration and would likely be needed for\nmost field applications. The proprietary trap costs $250\nand comes pre-assembled. The trap is good for\napproximately 1,000 samples. Based on the sample\nthroughput achieved during the demonstration, the trap\nshould last three weeks if running one shift per day and\none week if running three shifts per day.\n\n7.2.3 Support Equipment Cost\n\nOhio Lumex was provided with a 10x10 foot tent for\nprotection from inclement weather during the\ndemonstration. Itwas also provided with one table and two\nchairs for use during sample preparation and analytical\nactivities. The rental cost for the tent (including detachable\nsides, ropes, poles, and pegs) was $270 per week. The\nrental cost for the table and two chairs for one week totaled",
    "Page_75": "$6. Total support equipment costs were $276 per week for\nrental.\n\nFor longer projects, purchase of support equipment should\nbe considered. Two folding chairs would cost\napproximately $40. A 10x10 foot tent would cost between\n$260 and $1,000, depending on the construction materials\nand the need for sidewalls and other accessories (e.g.,\nsand stakes, counter weights, storage bag, etc.). Acost of\n$800 was used for this cost analysis. A folding table would\ncost between $80 and $250, depending on the supplier.\nFor purposes of this cost analysis, $160 was used. Total\npurchase costs for support equipment are estimated at\n$1,000.\n\nThe RA-915+/RP-91C requires an electrical source: either\n110/220 volts 50/60 Hz AC at 1.2 amps or 12 volts DC at\n18 amps. No cost was calculated for the DC electrical\nsource used during the demonstration because any\ninstrument will require a power source. The Ohio Lumex\ninstrument reportedly can be operated on a rechargeable\n12-volt battery for 3.5 hours. (Ohio Lumex, 2003) The\nbattery can be purchased for less than $100. Alternatively,\na standard 2,000 watt generator can be used to power the\ninstrument. The estimated cost for a locally-supplied\ngenerator is $500; Ohio Lumex will also rent a generator\nfor $200 per week, or one can be rented from a local tool\nrental firm.\n\n7.2.4 Labor Cost\n\nOne field technician was required for 3 days during the\ndemonstration to complete sample analyses and prepare\na data summary. Based ona labor rate of $300 per day,\ntotal labor cost for application of the RA-915+/RP-91C was\n$900 for the 2.5-day period (assumes the technician was\npayed for a complete day on the third day). Labor costs\nassume qualified technicians are available locally, and that\nno hotel or per diem costs are applicable. Table 7-2\nsummarizes labor costs for various operational periods.\nThe costs presented do not include supervision and quality\nassurance because these would be associated with the\nuse of any analytical instrument and are a portion of the\noverhead multiplier built into the labor rate.\n\n7.2.5 Investigation-Derived Waste Disposal\nCost\n\nOhio Lumex generated waste personal protective\nequipment, contaminated wipes and aluminum foil, and\nexcess soil waste. The PPE waste was charged to the\noverall project due to project constraints. The minimum\n\n58\n\nwaste volume is a 5-gallon container. Mobilization and\ncontainer drop-off fees were $1,040; disposal of a 5-gallon\nsoil waste container was $400. (This cost was based ona\nlisted waste stream with a hazardous waste number U 151.)\nThe total IDW disposal cost was $1,440. These costs may\nvary significantly from site to site, depending on whether\nthe waste is classified as hazardous or nonhazardous and\nwhether excess sample material requiring disposal is\n\n \n\n \n\n \n\n \n\ngenerated. Table 7-3 presents IDW costs for various\noperational periods, assuming that waste generation rates\nwere. similar to those encountered during the\ndemonstration.\nTable 7-2. Labor Costs\nItem Months\n\n1 3 6 12 24\nTechnician $6,300 $18,900 $37,800 $75,600 $151,200\nSupervisor NA NA NA NA NA\nQuality NA NA NA NA NA\nControl\nTotal $6,300 $18,900 $37,800 $75,600 $151,200\nTable 7-3. IDW Costs\nItem Months\n\n1 3 6 12 24\nDrop Fee $1,040 $3,120 $6,240 $12,480 $24,960\nDisposal $400 $1,200 $2,400 $4,800 $9,600\nTotal $1,440 $4,320 $8,640 $17,280 $34,560\n\n \n\n7.2.6 Summary of RA-915+/RP-91C Costs\n\nThe total cost for performing mercury analysis is\nsummarized in Table 7-4. This table reflects costs for\nprojects ranging from 1-24 months. The rental option was\nused for estimating the equipment cost. Table 7-5\nsummarizes total costs and the percentage of total costs\nfor the actual demonstration.",
    "Page_76": "Table 7-4. Summary of Rental Costs for the RA-915+/RP-91C\n\n \n\n \n\nItem Quantity Unit Unit Months\nCost\n(3) 1 3 6 12 24\n\nCapital Equipment\n\nMonthly Rental 1 NA $3,500 $3,500 $10,500 $21,000 $42,000 $84,000\nSupplies\n\nQuartz Injectors * 1 each $150 $0 $0 $150 $300 $600\n\nSolid SRM ° 2 each $250 $500 $500 $500 $1,000 $1,500\n\nMercury Trap (all components) 1 each NA $65 $250 $500 $1,000 $2,000\nTotal Supply Cost - weceens wenn $565 $750 $1,150 $2,300 $4,100\nSupport Equipment °\n\nTable (optional) - weekly 1 each $5 $20 $60 $120 $160 $160\n\nChairs (optional) - weekly 2 each $1 $10 $25 $40 $40 $40\n\nTent (for inclement weather only) 1 each $270 $800 $800 $800 $800 $800\n- weekly\nTotal Support Equipment Cost eee $830 $885 $960 $1,000 $1,000\nLabor\n\nField Technician (person day) 1 hour $38 $6,300 $18,900 $37,800 $75,600 $151,200\nIDW\n\nDrop Fee NA $1,040 $1,040 $3,120 $6,240 $12,480 $24,960\n\nDisposal NA week $400 $400 $1,200 $2,400 $4,800 $9,600\nTotal IDW Costs - serene neneeeeee $1,440 $4,320 $8,640 $17,280 $34,560\nTotal Cost $18,935 $32,645 $69,715 $138,630 $274,930\n\n \n\na For solid samples and SRMs; a set of 4 comes standard and is assumed to last 2 years, with breakage of one per 6 months\n\nb Only for use with solid samples; assumes two SRMs are required (a low and a high standard) with a life expectancy of 1 year (some standards\nwill have longer shelf lives).\n\nc Rental costs were used through the 3-month period for chairs and the 6-month period forthe table. Purchase costs were used for longer periods.\nPurchase costs for the tent were used for all periods.\n\nd Other than unit costs, all costs are rounded to the nearest $5.\n\ne The instrument is available for weekly rentals at $1,500 per week.\n\n \n\nTable 7-5. RA-915+/RP-91C Costs by Category The cost per analysis based upon 197 samples, when\nCategory Categary Cost Percentage of renting the RA-915+/RP-91C, is $23.44 per sample. The\n($ Total Costs cost per analysis forthe 197 samples, excluding instrument\ncost, is $15.82 per sample.\nInstrument $1,500 32.5%\nSupplies $500 10.8% 7.3. Typical Reference Method Costs\nSupport Equipment $277 6.0% This section presents costs associated with the reference\nmethod used to analyze the demonstration samples for\nLabor $900 19.5% mercury. Costs for other project analyses are not covered.\nIDW Disposal $1,440 31.2% The referee laboratory utilized SW-846 Method 7471B for\nall soil and sediment samples. The referee laboratory\nTotal $4,617 100.0% performed 421 analyses over a 21-day time period.\n\n \n\n59",
    "Page_77": "A typical mercury analysis cost, along with percent\nmoisture for dry-weight calculation, is approximately $35.\nThis cost covers sample management and preparation,\nanalysis, quality assurance, and preparation of a data\npackage. The total cost for 197 samples at $35 would be\n$6,895. This is based on a standard turnaround time of\n21-calendar days. The sample turnaround time from the\n\n60\n\nlaboratory can be reduced to 14, 7, or even fewer calendar\ndays, with a cost multiplier of from 125% to 300%,\ndepending on project needs and laboratory availability.\nThis results in a cost range from $6,895 to $20,685. The\nlaboratory cost does not include sample packaging,\nshipping, or downtime caused to the project while awaiting\nsample results.",
    "Page_78": "Chapter 8\nSummary of Demonstration Results\n\nAs discussed previously in this ITVR, the Ohio Lumex\nRA-915+/RP-91C was evaluated by having the vendor\nanalyze 197 soil and sediment samples. These 197\nsamples consisted of high-, medium-, and _ low-\nconcentration field samples from four sites, SRMs, and\nspiked field samples. Table 8-1 provides a breakdown of\nthe numbers of these samples for each sample type, and\nconcentration range or source. Collectively, these samples\nprovided the different matrices, concentrations, and types\nof mercury needed to perform a comprehensive evaluation\nof the RA-915+/RP-91C.\n\n8.1 Primary Objectives\n\nThe primary objectives of the demonstration were centered\non evaluation of the field instrument and performance in\nrelation to sensitivity, accuracy, precision, time for analysis,\nand cost. Each of these objectives was discussed in detail\nin previous chapters and is summarized in the following\nparagraphs. The overall demonstration results suggest\nthat the experimental design was successful for evaluation\nof the Ohio Lumex RA-915+/RP-91C. Quantitative results\nwere reviewed. The results from this field instrument were\nfound to be comparable to standard analyses performed by\nthe laboratory in terms of precision, and accuracy in\ncomparison to SRMs. Field sample analyses were not\nfound to be comparable, however, to referee laboratory\nresults. The collected data provide evidence to support\nthese statements.\n\nThe two primary sensitivity evaluations performed for this\ndemonstration were the MDL and PQL. Following\nprocedures established in 40 CFR Part 136, the MDL is\nbetween 0.0053 and 0.042 mg/kg based on the results of\nseven replicate analyses for low standards. The equivalent\nMDL for the referee laboratory is 0.0026 mg/kg. The\n\n61\n\ncalculated MDL is only intended as a statical estimation\nand not a true test of instrument sensitivity.\n\nThe low standard calculations using MDL values suggest\nthat a PQL for the Ohio Lumex field instrument may be as\nlow as 0.027mg/kg (5 times the lowest calculated MDL).\nThe referee laboratory PQL confirmed during the\ndemonstration is 0.005 mg/kg with a %D of <10%. The\n%D for the average Ohio Lumex result for a tested sample\nwith a referee laboratory value of 0.06 mg/kg is 0.072\nmg/kg, with a %D of 20%. This was the lowest sample\nconcentration tested during the demonstration thatis close\nto, but not below, the calculated PQL noted above. Both\nthe MDL and PQL were determined for soils and\nsediments.\n\nAccuracy was evaluated by comparison to SRMs and\ncomparison to the referee laboratory analysis for field\nsamples. This included spiked field samples for evaluation\nof additional concentrations not otherwise available. In\nsummary, Ohio Lumex data were within SRM 95%\nprediction intervals 93% of the time, which suggests\nsignificant equivalence to certified standards. The\ncomparison between the Ohio Lumex field data and the\nALSI results, however, suggest that the two data sets are\nnot the same. When a unified hypothesis testis performed\n(which accounts for laboratory bias), this result is\nconfirmed. Ohio Lum ex data were found to be both above\nand below referee laboratory concentrations, therefore\nthere is noimplied or suggested bias. The number of Ohio\nLumex average values less than 30% different from the\nreferee laboratory results or SRM reference values;\nhowever, was 19 of 33 different sample lots. Ohio Lumex\nresults, therefore, can often provide a reasonable estimate\nof accuracy for field determination, and may be affected by\ninterferences notidentified by this demonstration. Because\nthe Ohio Lumex data compare favorably to the SRM",
    "Page_79": "values, the differences between Ohio Lumex and the\nreferee laboratory are likely the result of matrix\ninterferences.\n\nThe precision was determined by analysis of replicate\nsamples. The precision of the Ohio Lumex field instrument\nis better than the referee laboratory precision. The overall\naverage RSD, is 22.3% for the referee laboratory\ncompared to the Ohio Lumex average RSD of 16.1%. This\nis primarily because of the better precision obtained for the\nSRM analyses by Ohio Lumex. Both the laboratory\nprecision and the Ohio Lumex precision goals of 25%\noverall RSD were achieved.\n\nTime measurements were based on the length of time the\noperator spent performing all phases of the analysis,\nincluding setup, calibration, and sample analyses (including\nall reanalysis). Ohio Lumex analyzed 197 samples in\n1,275 minutes times 1.25 analysts over three days, which\naveraged to 8.1 minutes per sample result. Based on this,\nan operator could be expected to analyze 59 samples (8\nhours x 60 minutes + 8.1 minutes/sample) in a 8-hour day.\n\nCost of the Ohio Lumex sample analyses included capital,\nsupplies, labor, support equipment, and waste disposal.\nThe cost per sample was calculated both with and without\nthe cost of the instrument included. This was performed\nbecause the first sample requires that the instrument is\neither purchased or rented, and as the sample number\nincreases, the cost per sample would decrease. A\ncomparison of the field Ohio Lumex cost to off-site\nlaboratory cost was not made. To compare the field and\nlaboratory costs correctly, it would be necessary to include\nthe expense incurred to the project due to waiting for\nanalysis results to return from the laboratory (potentially\nseveral mobilizations and demobilizations, stand-by fees,\nand other aspects associated with field activities).\n\nTable 8-2 summarizes the\nobjectives.\n\nresults of the primary\n\n8.2 Secondary Objectives\n\nTable 8-3 summarizes the results of the secondary\nobjectives.\n\nTable 8-1. Distribution of Samples Prepared for Ohio Lumex and the Referee Laboratory\n\nSite Concentration Range Soil\nCarson River Low (1-500 ppb) 3\n(Subtotal = 62) Mid (0.5-50 ppm) 0\nHigh (50->1,000 ppm) 0\nPuget Sound Low (1 ppb - 10 ppm) 30\n(Subtotal = 67) High (10-500 ppm) 0\nOak Ridge Low (0.1-10 ppm) 10\n(Subtotal = 51) High (10-800 ppm) 3\nManufacturing General (5-1,000 ppm) 10\n(Subtotal = 17)\nSubtotal 56\n\nSample Type\nSediment Spiked Soil SRM\n10 7 7\n0 7 28\n0 0 0\n0 14 13\n3 7 0\n7 7 14\n6 0 4\n0 0 7\n26 42 73\n\n \n\n62",
    "Page_80": "Table 8-2. Summary of RA-915+/RP-91C Results for the Primary Objectives\n\nDemonstration\n\nEvaluation Basis\n\nPerformance Results\n\n \n\nObjective RA-915+/RP-91C Reference Method\nInstrument MDL. Method from 40 CFR Part 136. Between 0.0053 and 0.042 0.0026 mg/kg\nSensitivity mg/kg\nPQL. Lowconcentration SRMs or < 0.06 mg/kg 0.005mg/kg\nsamples.\n\nAccuracy Comparison to SRMs, field, and spiked Ohio Lumex data were within SRM 95% prediction\nsamples covering the entire range of the intervals 93% of the time. 19 of 33 different sample lots\ninstrument calibration. within 30% of referee laboratory value.\n\nPrecision Determined by analysis of replicate samples Ohio Lumex overall average RSD; 16.1%\n\nTime per Analysis\n\nCost\n\nat several concentrations.\n\nTimed daily operations for 2.5 days and\ndivided the total time by the total number of\nanalyses.\n\nCosts were provided by Ohio Lumex and\nindependent suppliers of support equipment\nand supplies. Labor costs were estimated\nbased on a salary survey. IDW costs were\nestimated from the actual costs encountered\nat the Oak Ridge demonstration.\n\nOne technician performed half of the equipment setup\nand demobilization, most sample preparation, and all\ncalibration checks and analyses. Individual analyses\ntook 1 minute each, but the total time per analysis\naveraged approximately 8.1 minutes per sample.\n\nThe cost per analyses based upon 197 samples, when\nrenting the RA-915+/RP-91C, is $23.44 per sample. The\ncost per analyses for the 197 samples, excluding capital\ncost, is $15.82 per sample. The total cost for equipment\nrental and necessary supplies during the demonstration\nis estimated at $4,617. The cost breakout by category is:\ncapital costs, 32.5%; supplies, 10.8%; support\nequipment, 6.0%; labor, 19.5%; and IDW, 31.2%.\n\n \n\n63",
    "Page_81": "Table 8-3. Summary of RA-915+/RP-91C Results for the Secondary Objectives\n\nDemonstration\nObjective\n\nEvaluation Basis\n\nPerformance Results\n\n \n\nEase of Use\n\nHealth and Safety\nConcerns\n\nPortability of the\nDevice\n\nInstrument\nDurability\n\nAvailability of\nVendor\nInstruments and\nSupplies\n\nField observations during the demonstration.\n\nObservation of equipment, operating\nprocedures, and equipment certifications\nduring the demonstration.\n\nReview of device specifications,\nmeasurement of key components, and\nobservation of equipment setup and tear\ndown before, during, and after the\ndemonstration.\n\nObservation of equipment design and\nconstruction, and evaluation of any\nnecessary repairs or instrument downtime\nduring the demonstration.\n\nReview of vendor website and telephone\ncalls to the vendor after the demonstration.\n\n64\n\nThe RA-915+/RP-91C combination is reasonably easy to\noperate; lack of automation somewhat impairs the ease\nof use. Operation requires one field technician with a\nbasic knowledge of chemistry acquired on the job or ina\nuniversity, and training on the instrument.\n\nNo significant health and safety concerns were noted\nduring the demonstration. The only potential health and\nsafety concerns identified were the generation of mercury\nvapors and the potential for bums with careless handling\nof hot quartz sample boats. The vendor provides a\nmercury filter as standard equipment; exercising caution\nand good laboratory practices can mitigate the potential\nfor burns.\n\nThe RA-915+ air analyzer was easily portable, although\nthe device, even when carried in the canvas sling, was\nnot considered light-weight. The addition of the RP-91C\nand associated pump unit preclude this from being a truly\nfield portable instrument. The device and attachments\ncan be transported in carrying cases by two people, but\nmust then be set up in a stationary location. It was easy\nto set up, but the combined instrument is better\ncharacterized as mobile rather than field portable.\n\nThe RA-915+/RP-91C combination was well designed\nand constructed for durability.\n\nThe RA-915+/RP-91C combination is readily available\nfor rental, lease, or purchase. Spare parts and\nconsumable supplies can be added to the original\ninstrument order or can be received within 24-48 hours of\norder placement. Standards are readily available from\nlaboratory supply firms or can be acquired through Ohio\nLumex.",
    "Page_82": "Section 9\nBibliography\n\nAnchor Environmental. 2000. Engineering Design\nReport, Interim Remedial Action Log Pond Cleanup/\nHabitat Restoration Whatcom Waterway Site,\nBellingham, WA. Prepared for Georgia Pacific West,\nInc. by Anchor Environmental, L.L.C., Seattle, WA. July\n31, 2000.\n\nConfidential Manufacturing Site. 2002. Soil Boring Data\nfrom a Remedial Investigation Conducted in 2000.\n\nOhio Lumex, 2001. Portable Zeeman Mercury Anlyzer:\nRA-915+ Analyzer; RP-91 and RP-91C Attachments.\n2001.\n\nRothchild, E.R., R.R. Turner, S.H. Stow, M.A. Bogle, L.K.\nHyder, O.M. Sealand, H.J. Wyrick. 1984. Investigation\nof Subsurface Mercury at the Oak Ridge Y-12 Plant.\nOak Ridge National Laboratory, TN. ORNL/TM-9092.\n\nU.S. Environmental Protection Agency. 1994. Region 9.\nHuman Health Risk Assessment and Remedial\nInvestigation Report - Carson River Mercury Site\n(Revised Draft). December 1994.\n\nU.S. Environmental Protection Agency. 1995.\nContaminants and Remedial Options at Selected\nMetal-Contaminated Sites. July 1995. Washington\nD.C. EPA/540/R-95/512.\n\n65\n\nU.S. Environmental Protection Agency. 1996. Test\nMethods for Evaluating Solid Waste,\nPhysical/Chemical Methods, SW-846 CD ROM, which\ncontains updates for 1986, 1992, 1994, and 1996.\nWashington DC.\n\nU.S. Department of Energy. 1998. Report on the\nRemedial Investigation of the Upper East Fork of\nPoplar Creek Characterization Area at the Oak Ridge\nY-12 Plant, Oak Ridge, TN. DOE/OR/01-1641&D2.\n\nU.S. Environmental Protection Agency. 1998.\nUnpublished. Quality Assurance Project Plan\nRequirements for Applied Research Projects, August\n1998.\n\nU.S. Environmental Protection Agency. 2002a. Region\n9 Internet Web Site, www.epa.gov/region9/index. htm|.\n\nU.S. Environmental Protection\nGuidance on Data Quality Indicators.\nWashington D.C., July 2002.\n\nAgency. 2002b.\nEPA G-5i,\n\nU.S. Environmental Protection Agency. 2003. Field\nDemonstration Quality Assurance Project Plan - Field\nAnalysis of Mercury in Soil and Sediment. August\n2003. Washington D.C., EPA/600/R-03/053.\n\nWilcox, J.W., Chairman. 1983. Mercury at Y-12: A\nSummary of the 1983 UCC-ND Task Force Study.\nReport Y/EX-23, November 1983.\n\nwww.OhioLumex.com, 2003.",
    "Page_83": "Appendix A\nOhio Lumex Comments\n\nAccuracy and Precision\n\nThe accuracy of the instrument was tested in field\nconditions and this may have caused a loss of one sample\nresult data. Also, one sample was entered in the data\nsheet as 0.16 ug/kg instead of 160 ug/kg. Nevertheless,\nthe demonstrated accuracy (95% for SRM) and precision\n(average RSD for reference laboratory was 22.3%, the\naverage RSD for Ohio Lumex was 16.1% or 7.6 % for\nSRM) of the Ohio Lumex instrument was better than\nresults obtained by a reference laboratory.\n\nMethod Detection and Practical Quantitation Limits\n\nThe method detection limits (MDLs) and practical\nquantitation limits (PQLs) determined by the results of\ntesting were obtained for conditions specifically set for the\ninstrument to expand the upper (high concentration) range\nto 200 mg/kg. A simple change of instrument parameters\nwill enable the operator to change the MDL and PQL to\n0.001mg/kg and 0.005mg/kg respectively. A specifically\ndeveloped Pyro 915 attachment for ultralow direct mercury\nmeasurements enables one to achieve MDL/PQL\n0.0001mg/kg and 0.0005 mg/kg.\n\nAutomation\n\nSince the time of the testing, Ohio Lumex has developed\na balance interface to automatically enter sample size into\na computer spread sheet.\n\nAuto Sampler- The turnaround time to analyze an\nindividual sample is 1 minute. 25+ samples can be\nmanually processed in an hour over an 8-hour day, an\naverage of 2.4 minutes persample. The time required only\nto load an auto sampler will be up to 10 minutes per\nsample. Also, addition of the auto sampler will affect the\nreliability and portability of the system.\n\nPortability\n\nThe instrument consist of two modules and can be easily\npacked in one rolling pelican case with total weight of the\nsystem not exceeding 60 pounds. No compressed gases\nare required. Set-up time from unpacking to operation is\nwithin 1 hour. We also have many customers using these\nsettings in the field in remote locations while using portable\npower generators.\n\n \n\n \n\ndiscussed in the body of the ITVR.\n\nThis appendix was written solely by Ohio Lumex. The statements presented in this appendix represent the developer's point of view and\nsummarize the claims made by the developer regarding the RA-915+/RP-91C. Publication of this material does not represent EPA’s approval\nor endorsement of the statements made in this appendix; performance assessment and economic analysis results for the RA-915+/RP-91C are",
    "Page_84": "Appendix B\nStatistical Analysis\n\nTwo separate hypothesis tests were used to compare the\nreferee laboratory samples to the vendor tested samples.\nThis appendix details the equations and information for\nboth of these statistical analyses. For purposes of this\nappendix, we have chosen to call the test comparing\nsample populations using a separate calculation for each\nsample lot the “hypothesis test,” and the statistical\ncomparison of the entire sample set (all 33 separate\nsample lots) analyzed by the vendor and the laboratory the\n“unified hypothesis test,” also known as an “aggregate\nanalysis” for all of the sample lots.\n\nHypothesis Test\n\nA hypothesis test is used to determine if two sample\npopulations are significantly different. The analysis is\nperformed based on standard statistical calculations for\nhypothesis testing. This incorporates a comparison\nbetween the two sample populations assuming a specified\nlevel of significance. For establishing the hypothesis test,\nit was assumed that both sample sets are equal.\nTherefore, if the null hypothesis is rejected, then the\nsample sets are not considered equal. This test was\nperformed on all sample lots analyzed by both Ohio Lumex\nand the referee laboratory. H, and H,, null and alternative\nhypothesis respectively, were tested with a 0.01 level of\nsignificance (LOS). The concern related to this test is that,\nif two sample populations have highly variable data (poor\nprecision), then the null hypothesis may be accepted\nbecause of the test’s inability to exclude poor precision as\na mitigating factor. Highly variable data results in wider\nacceptance windows, and therefore, allows for acceptance\nof the null hypothesis. Conclusions regarding this analysis\nare presented in the main body of the report.\n\nTo determine if the two sample sets are significantly\ndifferent, the absolute value of the difference between the\n\n67\n\nlaboratory average x, and the vendor average x, is\ncompared to a calculated uy. When the absolute value of\nthe difference is greater than wu, then the alternate\nhypothesis is accepted, and the two sets (laboratory and\nvendor) are concluded to be different.\n\nTo calculate y, the variances for the laboratory data set\nand the vendor data set are calculated by dividing their\nstandard deviations by the number of samples in their data\n\n \n\n \n\nset. The effective number of degrees of freedom is then\ncalculated.\n+V,)\nEZ) a fr ay\nWhere:\nf = effective number of degrees of freedom\nVi = variance for the laboratory results\n\nne = number of samples for the laboratory\ndata set\n\nVy = variance for the vendor results\n\nny = number of samples for the vendor data\n\nset.\n\nThe degrees of freedom (f) is used to determine the\nappropriate “t” value and used to calculate y at the 0.01\nlevel of significance using the following:\n\nH= 2 conus v2 + hy",
    "Page_85": "Unified Hypothesis Test\n\nFor a specified vendor, let Y; be the measured Hg\nconcentration for the jf\" replicate of the i” sample for\n/=1,2,...,land/= 1,2,...,J). Let Xj= log(Y;), where log is the\nlogarithm to the base 10. Define xj,, to be the average\nover all log replicates for the i” sample given by:\n\nJ\nX iyg = J yo) log > %%\njel\n\nDenote the estimate of the variance of the log replicates for\nthe i” sample to be:\n\n2\n\nsta [= Uy, -1) 5 > & (ry - Fig)\n\nNow for the reference laboratory, let Yi be the measured\nHg concentration for the i replicate of the i” sample for\n/ =1,2,...,7 and j 1,2,...,J). Denote the reference\nlaboratory quantities X'ip x/, and s” defined in a manner\nsimilar to the corresponding quantities for the vendor.\n\nAssumptions: Assume that the vendor measurements, Yj,\nare independent and identically distributed according to a\nlognormal distribution with parameters uy, and o*. Thatis,\nXj = log(Y;) is distributed according to a normal distribution\nwith expected value y, and variance o*. Further, assume\nthat the reference laboratory measurements, Y'jp are\nindependent and identically distributed according to a\nlognormal distribution with parameters y’, and 0”.\n\nThe null hypothesis to be tested is:\n\nHo: f= B5+6, forsome Sand i=l,...f\n\nagainst the alternative hypothesis that the equality does not\nhold for at least one value of /.\n\nThe null hypothesis H, is rejected for large values of:\n\ni\ny (Fine - ¥'y,,-6) = GA + IP)\n\n2 _ inl\n\nKI 2\n5 root\n\n68\n\nWhere x4 is approximately a chi-square random variable\nwith (I-1) degrees of freedom:\n\nz\n77\" tog y (Tyne ~ Tyo )\n\ni=l\nand\n\nSere)\n\ntel\n\nSG -)eSe)\n\ntel tal\n\nI\nslog > U, -1)+5\" tog\nge il\n\npoot\n\nCritical values for the hypothesis test are the upper\npercentile of the chi-square distribution with (l-1) degrees\nof freedom obtained from a chi-square table.\n\nResults of Unified Hypothesis Test for Ohio Lumex\n\n \n\nSAIC performed a unified hypothesis test analysis to\nassess the comparability of analytical results provided by\nOhio Lumex and those provided by ALSI. Ohio Lumex\nand ALSI both supplied multiple assays on replicates\nderived from a total of 33 different sample lots, be they\nfield materials or reference materials with sample lots 35\nand 55 excluded because these were below the\ninstrument PQL. The Ohio Lumex and ALS! data from\nthese assays formed the basis of this assessment.\n\nThe statistical analysis is based on log-transformed\n(logarithm base 10) data and uses a chi-square test for\nequality of Ohio Lumex and ALSI population means for\ngiven sample lot. Equality of variances is assumed.\n\nInitially, the null hypothesis tested was that, on average,\nOhio Lumex and ALSI would produce the same results\nwithin a given sample lot. This hypothesis is stated as\n\nH49: (Ohio Lumex Lot log mean) = (ALSI Lot log mean)\n\nHio was rejected in that the chi-square statistic was\n130.26, which exceeds the upper 99\" percentile of the\nchi-square distribution with 33 degrees of freedom\nhaving a value of 54.78.\n\nThe null hypothesis was rejected in part because Ohio\nLumex results tended to exceed those from ALSI for the\nsame sample lot. To explore this effect, the null",
    "Page_86": "hypothesis was revised to included a bias term in the\nform of\n\nHy9: (Ohio Lumex Lot log mean) = (ALSI Lot log mean)\n+(delta),\n\nwhere delta is a single value that does not change from\none sample lot to another, unlike the lot log means. Hyo\nwas rejected strongly in that the chi-square statistic was\n101.46, which exceeded the upper 99\" percentile of the\nchi-square distribution with 32 degrees of freedom with a\nvalue of 53.49. In this analysis, delta was estimated to\nbe 0.133 in logarithmic (base 10) space, which indicates\nan average upward bias for Ohio Lumex of 10°'71=1.358\nor about 36%.\n\nFor both hypotheses, the large values of the chi-square\ntest statistics summarize the disagreement between the\nOhio Lumex and ALSI analytical results. Furthermore, a\n\nTable B-1. Unified Hypothesis Test Summary Information\n\nTotal Sample\n\nreview of the statistical analysis details indicates that the\noverall discordance between Ohio Lumex and ALSI\nanalytical results cannot be traced to the disagreement in\nresults for one or two sample lots.\n\nSummary information on these analyses is provided in\nTable B-1. The p-value can be considered as a\nsignificance level. This is a calculated value and usually\nwhen one sets a p-value (e.g., 95% confidence level\nwhich translates to a p-value of 0.05), this value is used\nto test the level of significance for comparison. As noted\nin Table B-1 the p-value is calculated from the test\nstatistics and therefore it can be seen that because the\np-value is so small (< 0.000000) the two sample\npopulations are considered to be non-equivalent and\nhence the large chi-square value.\n\n \n\nHypothesis Lots Excluded Lot DF $001 Delta Chi-square P-value\nHio 33 35, 55 33 0.03967 0.0000 130.26 0.000000\nHon 33 35, 55 32 0.03967 0.1329 101.46 0.000000\n\n69"
}