{
    "Page_1": "NBER WORKING PAPER SERIES\n\nHOW DID COVID-19 AND STABILIZATION POLICIES\nAFFECT SPENDING AND EMPLOY MENT?\nA NEW REAL-TIME ECONOMIC TRACKER BASED ON PRIVATE SECTOR DATA\n\nRaj Chetty\nJohn N. Friedman\nNathaniel Hendren\nMichael Stepner\nThe Opportunity Insights Team\n\nWorking Paper 27431\nhttp://www.nber.org/papers/w2743 1\n\nNATIONAL BUREAU OF ECONOMIC RESEARCH\n1050 Massachusetts Avenue\nCambridge, MA 02138\nJune 2020, Revised November 2020\n\nA previous draft of this paper was circulated under the title “How Did COVID-19 and\nStabilization Policies Affect Spending and Employment? A New Real-Time Economic Tracker\nBased on Private Sector Data.” We thank Gabriel Chodorow-Reich, Emmanuel Farhi, Jason\nFurman, Steven Hamilton, Erik Hurst, Xavier Jaravel, Lawrence Katz, Emmanuel Saez, Ludwig\nStraub, Danny Yagan, and numerous seminar participants for helpful comments. We also thank\nthe corporate partners who provided the underlying data used in the Economic Tracker: Affinity\nSolutions (especially Atul Chadha and Arun Rajagopal), Burning Glass (Anton Libsch and Bledi\nTaska), CoinOut (Jeff Witten), Earnin (Arun Natesan and Ram Palaniappan), Homebase (Ray\nSandza and Andrew Vogeley), Intuit (Christina Foo and Krithika Swaminathan), Kronos (David\nGilbertson), Paychex (Mike Nichols and Shadi Sifain), Womply (Derek Doel and Ryan Thorpe),\nand Zearn (Billy McRae and Shalinee Sharma). We are very grateful to Ryan Rippel of the Gates\nFoundation for his support in launching this project and to Gregory Bruich for early\nconversations that helped spark this work. The work was funded by the Chan-Zuckerberg\nInitiative, Bill & Melinda Gates Foundation, Overdeck Family Foundation, and Andrew and\nMelora Balson. The project was approved under Harvard University IRB 20-0586. The views\nexpressed herein are those of the authors and do not necessarily reflect the views of the National\nBureau of Economic Research.\n\nNBER working papers are circulated for discussion and comment purposes. They have not been\npeer-reviewed or been subject to the review by the NBER Board of Directors that accompanies\nofficial NBER publications.\n\n© 2020 by Raj Chetty, John N. Friedman, Nathaniel Hendren, Michael Stepner, and The\nOpportunity Insights Team. All rights reserved. Short sections of text, not to exceed two\nparagraphs, may be quoted without explicit permission provided that full credit, including ©\nnotice, is given to the source.",
    "Page_2": "How Did COVID-19 and Stabilization Policies Affect Spending and Employment? A New\nReal-Time Economic Tracker Based on Private Sector Data\n\nRaj Chetty, John N. Friedman, Nathaniel Hendren, Michael Stepner, and The Opportunity\nInsights Team\n\nNBER Working Paper No. 27431\n\nJune 2020, Revised November 2020\n\nJEL No. E0,H0JO\n\nABSTRACT\n\nWe build a publicly available database that tracks economic activity at a granular level in real\ntime using anonymized data from private companies. We report daily statistics on consumer\nspending, business revenues, employment rates, and other key indicators disaggregated by ZIP\ncode, industry, income group, and business size. Using these data, we study how COVID-19\naffected the economy by analyzing heterogeneity in its impacts. We first show that high-income\nindividuals reduced spending sharply in mid-March 2020, particularly in areas with high rates of\nCOVID-19 infection and in sectors that require in-person interaction. This reduction in spending\ngreatly reduced the revenues of small businesses in affluent ZIP codes. These businesses laid off\nmany of their employees, leading to widespread job losses especially among low-wage workers\nin affluent areas. High-wage workers experienced a “V-shaped” recession that lasted a few weeks,\nwhereas low-wage workers experienced much larger job losses that persisted for several months.\nBuilding on this diagnostic analysis, we estimate the causal effects of policies aimed at mitigating\nthe adverse impacts of COVID-19. State-ordered reopenings of economies had small impacts on\nspending and employment. Stimulus payments to low-income households increased consumer\nspending sharply, but little of this increased spending flowed to businesses most affected by the\nCOVID-19 shock, dampening its impacts on employment. Paycheck Protection Program loans\nincreased employment at small businesses by only 2%, implying a cost of $377,000 per job\nsaved. These results suggest that traditional macroeconomic tools — stimulating aggregate\ndemand or providing liquidity to businesses — have diminished capacity to restore employment\nwhen consumer spending is constrained by health concerns. During a pandemic, it may be more\nfruitful to mitigate economic hardship through social insurance. More broadly, this analysis\nshows how public statistics constructed from private sector data can support many research and\npolicy analyses without compromising privacy, providing a new tool for empirical\nmacroeconomics.\n\nRaj Chetty Nathaniel Hendren\nDepartment of Economics Harvard University\nHarvard University Department of Economics\nLittauer 321 Littauer Center Room 235\nCambridge, MA 02138 Cambridge, MA 02138\nand NBER\nchetty @ fas.harvard.edu Michael Stepner\n\nHarvard University\nJohn N. Friedman 1280 Massachusetts Avenue\nDepartment of Economics Cambridge, MA 02138\nRobinson Hall stepner@ mit.edu\nBrown University\nProvidence, RI 02912 The Opportunity Insights Team\nand NBER 1280 Massachusetts Avenue\njohn_friedman@ brown.edu Box #201\n\nCambridge, MA 02138\ninfo@opportunityinsights.org\n\nEconomic Tracker and Dowloadable Data is available at www.tracktherecovery.org",
    "Page_3": "I Introduction\n\nSince Kuznets (1941), macroeconomic policy decisions have been made on the basis of publicly\navailable statistics constructed from recurring surveys of households and businesses conducted by\nthe federal government. Although such statistics have great value for understanding total economic\nactivity, they have two limitations. First, survey-based data typically cannot be used to assess\nvariation across geographies or subgroups; due to relatively small sample sizes, most statistics are\ntypically reported only at the national or state level and breakdowns for demographic subgroups or\nsectors are unavailable. Second, such statistics are typically available only at low frequencies, often\nwith a significant time lag. For example, data on consumer spending disaggregated by geography\nare only available for selected large metro areas at a bi-annual level in the Consumer Expenditure\nSurvey (CEX). Because of these limitations, existing publicly available macroeconomic statistics are\ninsufficient to study the sources of economic fluctuations and the causal impacts of macroeconomic\npolicies.\n\nIn this paper, we address these challenges by (1) building a public database that measures\nspending, employment, and other outcomes at a high-frequency, granular level using anonymized\ndata from private companies and (2) demonstrating how this new database can be used to obtain\ninsights into the effects of the coronavirus pandemic (COVID-19) and subsequent stabilization\npolicies in near real-time — within three weeks of the shock or policy change of interest.\n\nWe organize the paper in three parts. First, we describe how we construct statistics on con-\nsumer spending, business revenues, employment rates, job postings, and other key indicators\ndisaggregated by area (ZIP code or county), industry, income level, and business size — by combin-\ning data from credit card processors, payroll firms, and financial services firms. The main challenge\nin using private sector data sources to measure economic activity is a tension between research\nvalue and privacy protection. For research, it is beneficial to use raw, disaggregated data — ideally\ndown to the individual consumer or business level — to maximize precision and flexibility of research\ndesigns. But from a privacy perspective, it is preferable to aggregate and mask data to reduce the\nrisk of disclosure of private information. To balance these conflicting interests, one must construct\nstatistics that are sufficiently aggregated and masked to mitigate privacy concerns yet sufficiently\n\ngranular to support research.!\n\n \n\n1. An alternative approach pursued by several recent studies (summarized at the end of this section) is to use\nconfidential private data sources for research under non-disclosure agreements with companies. Although a valuable\ncomplement to the public data approach we pursue here, the need to acquire data from each company separately\ntypically leads most studies to use one or two datasets and limits the number of researchers who can analyze the data.",
    "Page_4": "We navigate this tradeoff by combining several statistical methods: reporting only changes\nsince January 2020 (rather than raw levels), masking small cells, and pooling data from multiple\ncompanies to comply with regulations governing the disclosure of material non-public information.\nWe then clean the raw data by removing data artifacts (e.g., breaks that arise from changes in\nplatforms) and smoothing seasonal fluctuations. Finally, we address the challenge that statistics\nfrom specific private firms may not be representative of the population in general. To minimize\npotential selection biases, we start by obtaining data from companies that have large samples (e.g.,\nat least one million individuals) and span well-defined sectors or subgroups (e.g., small businesses).\nWe then compare each time series to publicly available benchmarks based on representative surveys\nand use only the series that track publicly available data closely.? After establishing these protocols,\nwe report the final statistics using an automated pipeline that ingests data from businesses and\nreports statistics within a week after the relevant transactions occur.\n\nIn the second part of the paper, we use these new public data to analyze the economic impacts\nof COVID-19. National accounts reveal that GDP fell in the second quarter of 2020 following the\nCOVID-19 shock primarily because of a reduction in consumer spending. We therefore begin by\nexamining the drivers of changes in consumer spending using credit and debit card data. We find\nthat spending fell primarily because high-income households started spending much less. As of\nmid-July, 49% of the reduction in total spending since January came from households in the top\nincome quartile, while 7% came from households in the bottom quartile.’ This is both because\nthe rich account for a larger share of spending to begin with and because they cut spending more\nin percentage terms: top-quartile households spent 13% less as of mid-July than in January 2020,\nwhereas bottom-quartile households spent only 4% less. Spending reductions were concentrated\nin services that require in-person physical interaction, such as hotels and restaurants, consistent\nwith contemporaneous work by Alexander and Karger (2020) and Cox et al. (2020). These findings\n\nsuggest that high-income households reduced spending primarily because of health concerns rather\n\n \n\nOur goal is to assess whether one can produce public statistics that can deliver insights analogous to those obtained\nfrom confidential microdata, thereby expanding the scale and timeliness of empirical macroeconomic research.\n\n2. This benchmarking proves to be quite important in constructing representative series. For example, many\nstudies have used data from Homebase, a company that helps small businesses track their employees’ hours (e.g.,\nBartik et al. 2020, Bartlett and Morse 2020, Granja et al. 2020, Altonji et al. 2020), to study employment in the\nCOVID pandemic. As noted by Bartik et al. (2020), the time series patterns in the Homebase data differ significantly\nfrom representative statistics on small business employment (although the patterns are generally similar for the\nsectors it covers). We therefore turn to other sources of employment data to produce publicly available series that\ntrack representative benchmarks more closely, which are now available for future research.\n\n3. We impute income as the median household income (based on Census data) in the cardholder’s ZIP code. We\nverify the quality of this imputation procedure by showing that our estimates of the gap in spending reductions by\nincome group are aligned with those of Cox et al. (2020), who observe income directly for JPMorgan Chase clients.",
    "Page_5": "than a reduction in income or wealth, perhaps because they were able to self-isolate more easily\nthan lower-income individuals (e.g., by substituting to remote work).\n\nNext, we turn to the impacts of the consumer spending shock on businesses. To do so, we\nexploit geographic variation in the demand shocks businesses face arising from the fact that in-\nperson services are typically produced by small businesses (e.g., restaurants) that serve customers\nin their local area. Small business revenues in the highest-income and highest-rent ZIP codes (e.g.,\nthe Upper East Side of Manhattan) fell by more than 65% between March and mid-April, compared\nwith 30% in the least affluent ZIP codes. These reductions in revenue resulted in a much higher rate\nof small business closure in affluent areas within a given county than in less affluent areas. This was\nparticularly the case for non-tradable goods that require physical interaction — e.g., restaurants and\naccommodation services. Small businesses that provide fewer in-person services — such as financial\nor professional services firms — experienced much smaller losses in revenue even in affluent areas.\n\nAs businesses lost revenue, they passed the shock on to their employees, particularly low-wage\nworkers. Building on results first established using other data sources by Cajner et al. (2020), we\nshow that employment rates fell by 37% around the trough of the COVID recession (April 15,\n2020) for workers with wages rates in the bottom quartile of the pre-COVID wage distribution. By\ncontrast, employment rates fell by 14% for those in the top wage quartile. Employment for high-\nwage workers also rebounded much more quickly: employment levels for workers in the top wage\nquartile were almost back to pre-COVID levels by the end of May, but remained 20% below baseline\n‘or low-wage workers even as of October 2020. The greater persistence of job losses for low-wage\nworkers is not explained purely by sectoral differences. Even in sectors where spending rebounded\no baseline levels, such as retail trade, employment of low-wage workers remained far below baseline\nevels, suggesting that economic activity may have shifted toward modes of production using less\now-wage labor (Jaimovich and Siu 2020).\n\nLow-wage individuals working at small businesses in affluent areas were especially likely to lose\nheir jobs. At small businesses located in the highest-rent ZIP codes, more than 45% of workers were\naid off within two weeks after the COVID crisis began; in the lowest-rent ZIP codes, fewer than\n25% lost their jobs. Job postings also fell much more sharply in more affluent areas, particularly for\npositions requiring less education. As a result, unemployment rates surged even in affluent areas\nhat have typically had relatively low unemployment rates in previous recessions. The impacts\n\non displaced workers persist over time: low-income people working in more affluent ZIP codes\n\n \n\npre-COVID (e.g., Manhattan) remain less likely to be employed months after losing their jobs and",
    "Page_6": "reduce their own spending levels more sharply than their peers working in nearby less affluent areas\n(e.g., the Bronx).\n\nIn summary, the initial impacts of COVID-19 on economic activity were largely driven by a\nreduction in spending by higher-income individuals due to health concerns, which in turn affected\nbusinesses that cater to the rich and ultimately reduced the incomes and expenditure levels of\nlow-wage employees of those businesses. In the third and final part of the paper, we analyze the\nimpacts of three sets of policies that were enacted shortly after the crisis began in an effort to\nbreak this chain of events and mitigate economic losses: state-ordered shutdowns and reopenings,\nstimulus payments to households, and loans to small businesses.*\n\nState-ordered shutdowns and reopenings of economies had modest impacts on economic activity.\nSpending and employment remained well below baseline levels even after reopenings, and trended\nsimilarly in states that reopened earlier relative to comparable states that reopened later. Spending\nand employment also fell well before state-level shutdowns were implemented, consistent with other\nrecent work examining data on hours of work and movement patterns (Bartik et al. 2020, Villas-Boas\net al. 2020). Hence, differences in shutdown orders explain very little of the cross-state variation\nin spending and employment trends, consistent with the findings of Goolsbee and Syverson (2020)\nfrom cell phone location data.\n\nStimulus payments made to households in mid-April 2020 increased spending among low-income\nhouseholds sharply, nearly restoring their spending to pre-COVID levels by late April, consistent\nwith empirical evidence from Baker et al. (2020) and models of consumption that generate excess\nsensitivity (e.g., Kaplan and Violante 2014). However, most of this increase in spending was in\nsectors that require limited physical interaction: purchases of durable goods surged, while con-\nsumption of in-person services increased much less. As a result, little of the increased spending\nflowed to businesses most affected by the COVID-19 shock, potentially limiting the capacity of the\nstimulus to increase economic activity and employment because of diminished multiplier effects (a\nbroken Keynesian cross), as discussed by Guerrieri et al. (2020).\n\nLoans to small businesses as part of the Paycheck Protection Program (PPP) also had small\nimpacts on employment rates. Employment rates at firms with fewer than 500 employees (which\n\nwere eligible for PPP assistance) increased by only 2 percentage points after the PPP was enacted\n\n \n\n4. This set of policies is not exhaustive: a vast set of other policy efforts ranging from changes in monetary policy\nto various state-level programs were also undertaken in response to the crisis. We focus on these three policies because\nthey illustrate the ways in which the data we have assembled here can be used for real-time policy analysis, and we\nhope that future work will use these data to analyze other policies.",
    "Page_7": "relative to larger firms that were ineligible for PPP. Our point estimates imply that the cost per\njob saved by the PPP was $377,000 ($119,000 at the lower bound of the 95% confidence interval).\nContemporaneous studies by Granja et al. (2020), Autor et al. (2020), and Hubbard and Strain\n(2020) reach similar conclusions using other data sources and research designs. The PPP had\nmodest marginal impacts on employment likely because the vast majority of PPP loans went to\ninframarginal firms that were not planning to lay off many workers. As a result, providing liquidity\nto firms is an expensive way to maintain employment rates in the short run, although it remains\npossible that the PPP may have long-term benefits by reducing permanent business closures.\n\nOur findings suggest that economic recovery from a pandemic ultimately requires restoring\nconsumer confidence by addressing health concerns themselves (e.g., Allen et al. 2020, Romer\n2020). Traditional macroeconomic tools — stimulating aggregate demand or providing liquidity to\nbusinesses — have diminished capacity to fully restore employment when demand is constrained\nby health concerns.® In such a setting, it may be especially valuable to provide social insurance\nto reduce hardship for those who have lost their jobs, e.g., via unemployment benefit extensions\n(Guerrieri et al. 2020). In addition, it may be useful to target employment assistance to low-\nincome people who were working in places that suffered the largest job losses (such as affluent,\nurban areas), since geographic disparities in unemployment persist for many years due to limited\nmigration (Blanchard and Katz 1992, Austin, Glaeser, and Summers 2018, Yagan 2019).\n\nOur work builds on two literatures: a longstanding literature on macroeconomic measurement\nand a nascent literature on the economics of pandemics. In the macroeconomic measurement\nliterature, our work is most closely related to recent studies showing that private sector data\nsources can be used to forecast government statistics (e.g., Abraham et al. 2019, Aladangady et\nal. 2019, Ehrlich et al. 2019, Cajner et al. 2019, Gindelsky, Moulton, and Wentland 2019, Dunn,\nHood, and Driessen 2020). In the COVID-19 pandemic literature, several recent papers — whose\nresults we compare to ours in the course of our analysis below — have used confidential private\nsector data to analyze consumer spending (e.g., Baker et al. 2020, Chen, Qian, and Wen 2020, Cox\net al. 2020), business revenues (e.g., Alexander and Karger 2020), and labor market trends (e.g.,\nBartik et al. 2020, Cajner et al. 2020, Kurmann, Lalé, and Ta 2020, Forsythe et al. 2020).\n\nOur paper makes two contributions to these literatures. First, it sheds light on the mechanisms\n\n \n\n5. During the period we study, the federal government injected substantial income into the economy (e.g., increased\nUI benefits and stimulus checks) and the Federal Reserve eased monetary policy significantly. These policies may\nhave averted a Keynesian demand-driven recession on top of the COVID supply shock recession. Our point is not\nthat these policies were ineffective, but rather that the remaining shortfall in spending and employment was driven\nprimarily by health concerns and hence may not have been fixable through conventional macroeconomic tools.",
    "Page_8": "through which pandemics affect economic activity. Other studies of the COVID-19 pandemic have\nfocused on one outcome (e.g., spending or employment or job postings) at broad geographies. By\ncombining data sources on multiple outcomes at the ZIP code level, we exploit local geographic\nvariation to provide an integrated picture of how COVID-19 affected the macroeconomy — from\nchanges in consumer spending to in-person business revenue losses to employment changes and\nimpacts on displaced workers. The heterogeneity in impacts we document across ZIP codes\n\nwhich, to our knowledge, has not been analyzed in prior studies — provides a novel source of\nlocal variation to understand macroeconomic dynamics, similar to the geographic variation widely\nexploited to understand the Great Recession (e.g., Mian and Sufi 2009). In addition, analyzing a\nsuite of outcomes allows us to characterize the impacts of major stabilization policies more fully,\nfrom changes in consumer behavior to impacts on businesses’ employment and hiring decisions.\n\nSecond, and perhaps more importantly, this study opens new approaches to empirical macroe-\nconomics by constructing a new public database of granular macroeconomic statistics. Unlike the\naforementioned studies of COVID-19, which use confidential microdata, the results reported here\nare all produced from what are now publicly available data. Where those studies overlap with ours,\nresults from our public data are very similar to those obtained from their microdata. The capacity\nto use public data substantially expands the number of researchers who can conduct such studies\nand opens many new avenues for policy and research. For instance, policymakers could adjust\npolicies as they observe their impacts on the economy (much as the Paycheck Protection Program\nwas repeatedly adjusted, but without the benefit of evidence on its ongoing impacts). Moreover,\nsuch impacts can be analyzed heterogeneously across areas and subgroups, permitting tailored re-\nsponses by local governments. In this sense, the data assembled here provide a prototype for a\nnew system of real-time, granular national accounts that we hope will be refined in future work,\nmuch as Kuznets (1941) and Summers and Heston (1984, 1991) developed prototypes for national\naccounts that were refined in subsequent work (e.g., Feenstra, Inklaar, and Timmer 2015).\n\nThe paper is organized as follows. The next section describes how we construct the public data\nseries. In Section III, we analyze the effects of COVID-19 on spending, revenue, and employment.\nSection IV analyzes the impacts of policies enacted to mitigate COVID’s impacts. Section V\nconcludes. Technical details are available in an online appendix, and the data used to produce the\n\nresults can be downloaded from this GitHub repository.",
    "Page_9": "II Construction of Public Database\n\nWe use anonymized data from several private companies to construct public indices of con-\nsumer spending, employment, and other outcomes. To systematize our approach and facilitate\ncomparisons between series, we adopt the following set of principles when constructing each series\n(wherever feasible given data availability constraints).\n\nFirst, we remove artifacts in raw data that arise from changes in data providers’ coverage or\nsystems. For instance, firms’ clients often change discretely, sometimes leading to discontinuous\njumps in series, particularly in small cells. We systematically search for large jumps in series (e.g.,\n>80%), study their root causes by consulting with the data provider, and address such discontinu-\nities by imposing continuity using series-specific methods described below. We also winsorize some\noutcomes at the 99th percentile to reduce the influence of outliers when analyzing small cells.\n\nSecond, we smooth low- and high-frequency fluctuations in the data. We address high-frequency\nfluctuations through aggregation, e.g. by reporting 7-day moving averages to smooth fluctuations\nacross days of the week. Certain series — most notably consumer spending and business revenue\n\nexhibit strong lower-frequency seasonal fluctuations that are autocorrelated across years (e.g.,\na surge in spending around the holiday season). Where feasible, we de-seasonalize such series by\nnormalizing each week’s value in 2020 relative to corresponding values for the same week in 2019,\nbut we also report raw values for 2020 for researchers who prefer to make alternative seasonal\nadjustments.\n\nThird, we take a series of steps to protect the confidentiality of businesses and their clients.\nInstead of reporting levels of each series, we report indexed values that show percentage changes\nrelative to mean values in January 2020.6 We suppress small cells and exclude outliers to meet\nprivacy and data protection requirements, with thresholds that vary across datasets as described\nbelow. For data obtained from publicly traded firms — whose ability to disclose data is restricted by\nSecurities and Exchange Commission regulations governing the disclosure of material non-public\ninformation — we combine data from multiple firms so that the statistics we report do not reveal\ninformation about any single company’s activities.”\n\nFinally, we address the challenge that our data sources capture information about the cus-\n\n \n\n6. We always norm after summing to a given cell (e.g. geographic unit, industry, etc.) rather than at the firm or\nindividual level. This dollar-weighted approach overweights bigger firms and higher-income individuals, but leads to\nsmoother series and is arguably more relevant for certain macroeconomic policy questions (e.g., changes in aggregate\nspending).\n\n7. For publicly traded firms, our platform serves as a coordination device that allows multiple firms to pool and\nrelease their data even though each firm faces restrictions that limit its capacity to share its own data publicly.",
    "Page_10": "tomers each company serves rather than the general population. Instead of attempting to adjust\nfor this non-representative sampling, we characterize the portion of the economy that each series\nrepresents by comparing each sample we use to national benchmarks. We explicitly label the sector\nand population subgroup that each series represents and exclude data sources that do not track\nestablished benchmarks for that sector/subgroup closely. We examined several sources of spending,\nrevenue, and employment data in addition to those used in the final analysis below and excluded\nthem because they failed benchmarking tests.\n\nWe release each data series at the highest available frequency using an automated pipeline that\ningests data from data providers, constructs the relevant statistics and conducts quality control\ntests, and outputs the series publicly (see Appendix A for details on the engineering of this pipeline).\nTo limit revisions, we allow for a lag to account for reporting delays (typically one week). Wherever\nfeasible, we disaggregate each series by industrial sector, geography (ZIP, county, or state), and\nincome quartile.\n\nIn the rest of this section we describe each of the series in turn, discussing the raw data sources,\nconstruction of key variables, and cross-sectional comparisons to publicly available benchmarks. We\nbenchmark trends in each series over time to publicly available data in the context of our analysis\nin Section III. All of the data series described below can be freely downloaded from the Economic\n\nTracker website.\n\nII.A Consumer Spending: Affinity Solutions and CoinOut\n\nAffinity Solutions. We measure consumer spending primarily using aggregated and anonymized\ndata on credit and debit card spending collected by Affinity Solutions Inc, a company that aggre-\ngates consumer credit and debit card spending information to support a variety of financial service\nproducts, such as loyalty programs for banks. Affinity Solutions captures nearly 10% of debit\nand credit card spending in the U.S. We obtain raw data from Affinity Solutions disaggregated by\ncounty, ZIP code income quartile, industry and day starting from January 1, 2019. We first remove\ndiscontinuous breaks caused by entry or exit of card providers from the sample (see Appendix B for\ndetails). We then construct daily values of the consumer spending series using a seven-day moving\naverage of the current day and the previous six days of spending.\n\nBecause spending exhibits very large seasonal fluctuations (Appendix Figure la), we seasonally\nadjust our spending series by dividing each week’s 2020 value by its corresponding value from 2019.\n\nWe then index the seasonally-adjusted series relative to pre-COVID-19 spending by dividing each",
    "Page_11": "value by the mean of the seasonally-adjusted average spending level in the first four complete weeks\nof 2020 (January 4-31).\n\nCoinOut Cash Spending Series. A concern with card-based spending measures is that they\nomit cash transactions, which account for 6.3% of consumer spending in the United States (Greene\nand Stavins 2020) and could potentially respond differently to the COVID shock and subsequent\npolicies. To address this concern, we measure cash spending using transaction data from CoinOut,\na company that allows individuals to receive rewards by uploading photos of their receipts to a\nmobile app. We obtain anonymized data from CoinOut beginning January 1, 2018 describing the\ndate and amount of each transaction; the user’s ZIP code; and the date and time the receipt was\nuploaded. We identify cash transactions by searching for the string “cash” in the text of each receipt\nand construct series on the total number and amount of cash transactions by day. The CoinOut\ndata are not disaggregated by industry; however, since cash is almost always used in person, we\nview this series as representing spending on in-person goods (e.g., at grocery stores).\n\nComparison to QSS and MARTS. Total debit and credit card spending in the U.S. was $7.08\ntrillion in 2018 (Board of Governors of the Federal Reserve System 2019), approximately 50%\nof total personal consumption expenditures recorded in national accounts. Appendix Figure 2\ncompares the spending distributions across sectors in the Affinity data to spending captured in\nthe nationally representative Quarterly Services Survey (QSS) and Advance Monthly Retail Trade\nSurvey (MARTS), which together cover 92% of the expenditure-weighted categories in the Affinity\ndata. The Affinity series has broad coverage across industries, but over-represents categories in\nwhich credit and debit cards are used for purchases. In particular, accommodation and food\nservices and clothing constitute a greater share of the card spending data than financial services\nand motor vehicles. We therefore view the Affinity series as providing statistics that are potentially\nrepresentative of total card spending, but not total consumer spending. We assess whether the\nAffinity series accurately captures changes in total card spending in the COVID recession in Section\n\nTILA below.\n\nII.B Small Business Revenue: Womply\n\nWe obtain data on small business transactions and revenues from Womply, a company that aggre-\ngates data from several credit card processors to provide analytical insights to small businesses and\nother clients. In contrast to the Affinity series on consumer spending, which is a cardholder-based\n\npanel covering total spending, Womply is a firm-based panel covering total revenues of small busi-",
    "Page_12": "nesses. The key distinction is that location in Womply data measures the location of the business\nas opposed to the location where the cardholder lives.\n\nWe obtain raw data on small business transactions and revenues from Womply at the ZIP-\nindustry-day level starting from January 1, 2019. After excluding outliers, we aggregate these raw\ndata to form two publicly available series at the county by industry level: one measuring total small\nbusiness revenue and another measuring the number of small businesses open (see Appendix C for\ndetails). For each series, we construct seasonally-adjusted daily values using similar methods to\nthose used to construct the consumer spending series.\n\nComparison to QSS and MARTS. Appendix Figure 2 shows the distribution of revenues ob-\nserved in Womply across industries in comparison to national benchmarks. Womply revenues are\nagain broadly distributed across sectors, particularly those where card use is common. A larger\nshare of the Womply revenue data come from industries that have a larger share of small businesses,\nsuch as food services, professional services, and other services, as one would expect given that the\n\nWomply data only cover small businesses.\n\nII.C Employment: Paychex, Intuit, Earnin, and Kronos\n\nWe combine several data sources to obtain information on employment and earnings: payroll data\nfrom Paychex and Intuit, worker-level data from Earnin, and time sheet data from Kronos. We\ndescribe each of these data sources in turn and then discuss how we combine them to construct\na weekly series that measures private non-farm employment rates in the U.S.° Further details are\nprovided in Appendix D.\n\nPaychex. Paychex provides payroll services to approximately 670,000 small- and medium-sized\nbusinesses across the United States and pays nearly 10% of U.S. private-sector workers (Paychex\n2020). We obtain aggregated weekly data on total employment and payroll earnings for each\ncounty by industry (two-digit NAICS) by 2019 hourly wage quartile by 2019 firm size bin by pay\nfrequency. Hourly wage quartiles are based on fixed thresholds of the hourly wage distribution in\n2019 (<$13.00, $13.00-$18.18, $18.18-29.17, >$29.17). Firm size is measured in Dun & Bradstreet\ndata on employment, broken into a set of broad groups (e.g., 1-49 employees, 50-99 employees,\n100-199 employees, ..., 900-999 employees, >999 employees). We obtain data from Paychex on\nchecks processed by week in each of these groups. We convert these data into an employment series\n\nusing methods analogous to those developed by Cajner et al. (2020); see Appendix D for details.\n\n \n\n8. The private payroll providers from whom we obtain data have limited coverage of government agencies; we\ntherefore do not attempt to measure government employment here.\n\n10",
    "Page_13": "Intuit. Intuit offers payroll services to businesses as part of its Quickbooks program, covering\napproximately one million businesses as of January 2020. Businesses that use Quickbooks tend to be\nvery small (fewer than 20 employees). We obtain anonymized, aggregated data on month-on-month\nand year-on-year changes in total employment (the number of workers paid in the prior month)\nand average earnings at the state and county level by month, based on repeated cross-sections. To\ndevelop a national series, we take population-weighted averages of state changes in each month.\n\nEarnin. Earnin is a financial management application that provides its members with access to\ntheir income as they earn it, in advance of their paychecks. Workers sign up for Earnin individually\nusing a cell phone app, which connects to the bank account in which paychecks are deposited.\nEarnin complements the firm-based payroll datasets discussed above by providing a worker-level\nsample. This yields insight into employment rates at a much wider spectrum of firms — ranging\nfrom the largest firms in the U.S. to small businesses — at the expense of having fewer workers\nper firm. Since employment decisions are highly correlated across workers within firms at business\ncycle frequencies, Earnin’s coverage of a large set of firms proves to be a valuable complement to\nthe firm-based payroll datasets for our analysis. Because its users tend to have lower income levels,\nEarnin primarily provides information on employment for low-wage workers.°\n\nWe obtain anonymized data from Earnin from January 2020 to present at the paycheck level with\ninformation on home ZIP code, workplace ZIP code, unemployment status, wages, and earnings. We\nassign firm sizes to Earnin employers by matching to firm size data obtained from ReferenceUSA,\nand we assign NAICS codes using a custom-built crosswalk constructed by Digital Divide Data. We\nconvert these data into an employment series using an approach similar to that used to construct\nthe Paychex employment series.\n\nKronos. Kronos is a workforce management service used by many firms across the U.S. The\ndata we obtain from Kronos cover approximately 30,000 mid-sized firms which together employed\nabout 3.2 million workers pre-COVID. We obtain anonymized and aggregated weekly data on the\ntotal number of “punches,” representing an employee clocking into work on an electronic time\nsheet. We obtain these data by county, industry, and firm size at the point that the firm entered\nthe Kronos database. The employees in the database are primarily hourly workers who must record\n\ntheir time, and are concentrated in the bottom quartile of the wage distribution: assuming full-time\n\n \n\n9. The median worker in the Earnin sample in January 2020 has an hourly wage rate of $10.80, which falls at\nthe 16th percentile of the national distribution of private sector non-farm workers in January 2020 CPS data. The\ninterquartile range of wages in the Earnin sample is $8.03-$14.33 (corresponding to the 3rd and 40th percentiles of\nthe national distribution).\n\n11",
    "Page_14": "employment, their wage rates translate to average earnings of $24,000 per year (with a 10th-90th\npercentile range of $7,200 to $45,600).\n\nThe Kronos data differ from the other data sources above in that they measure data from\ntime sheets rather than paychecks. The advantage of time sheets is that they provide more timely\ninformation on employment, with a lag of just 2-3 days. The disadvantage of time sheets is that\nthey do not capture total wage employment (e.g., workers may remain on payroll despite clocking\nfewer hours) and, naturally, only provide information for the subset of workers who are required to\nrecord their time.\n\nHomebase. Homebase provides scheduling tools for small businesses (on average, 8.4 employees)\nsuch as restaurants (which comprise 64% of employees for whom sectoral data are available). We\nobtain de-identified individual-level data on days worked and construct an employment series at\nthe industry level. We include Homebase as a point of comparison because it has been widely used\nin other studies of small business employment in the COVID pandemic, but we do not include it\nin our primary employment indices because it does not track benchmarks of overall employment at\nsmall businesses as closely as our other data sources (see Section III.C below).\n\nCombined Employment Series. To protect business privacy and maximize precision, we combine\nthe data sources above to construct our primary employment series (see Appendix D for details).\nBecause Paychex covers all sectors and wage levels, we use Paychex data disaggregated by indus-\ntry, wage quartile and geographic area (county, state and national) as the base for the combined\nemployment series. We then use Earnin and Intuit to refine the series in cells represented by\nthose datasets. As noted above, Earnin best represents lower-wage workers. We therefore combine\nEarnin data with Paychex data to construct employment estimates for the bottom wage quartile.\nNext, we combine Intuit with the Paychex-Earnin data, accounting for the fact that Intuit data\nare available at a lower frequency and are not broken down by wage level or industry. We report\nseven-day moving averages of these series, expressed as a percentage change relative to the first\nfour complete weeks of 2020 (January 4-31). We do not seasonally adjust our employment series\nbecause we have incomplete data in 2019; fortunately, seasonal fluctuations in employment are an\norder-of-magnitude smaller than those in spending (Appendix Figure 1b) and hence are unlikely to\nmaterially affect our results.\n\nThe employment series constructed based on payroll data is generally available only with a one\nmonth lag because people are paid after completing work over multiple prior weeks. To obtain\n\nmore current estimates, we use Kronos time sheet data along with Paychex data from firms with\n\n12",
    "Page_15": "weekly paycycles to forecast employment rates (see Appendix D for the forecasting model).\n\nComparisons to QCEW and OES. Appendix Table 1 compares industry shares in each of the\ndata sources above to nationally representative statistics from the Quarterly Census of Employ-\nment and Wages (QCEW). The Paychex-Earnin combined sample is broadly representative of the\nindustry mix in the U.S. Intuit is concentrated primarily in professional services, construction, other\nservices, and health care and social assistance. Kronos has fairly broad coverage, but over-represents\nthe manufacturing and transportation and warehousing sectors. Homebase covers primarily food\nservices.\n\nIn Appendix Table 2, we assess how these datasets compare to national benchmarks in terms of\nwage rates by comparing median wage rates to nationally representative statistics from the BLS’s\nOccupational Employment Statistics. Median wage rates in Paychex-Earnin combined data closely\nmatch the OES estimates. Average wages in Intuit closely mirror OES estimates in the industries\nthat Intuit covers.\n\nWe conclude based on these comparisons that our combined datasets provide a representative\npicture of private non-farm employment in the United States, and that Earnin provides good\ncoverage of workers at the bottom of the wage distribution, a group of particular interest given\n\ntheir volatile employment rates over the business cycle.\n\nII.D Job Postings: Burning Glass\n\nWe obtain data on job postings from 2007 to present from Burning Glass Technologies. Burning\nGlass aggregates nearly all jobs posted online from approximately 40,000 online job boards in the\nUnited States. Burning Glass then removes duplicate postings across sites and assigns attributes\nincluding geographic locations, required job qualifications, and industry.\n\nWe receive raw data from Burning Glass on job postings disaggregated by industry, week, job\nqualifications and county. Industry is defined using select NAICS supersectors, aggregated from\n2-digit NAICS classification codes. Job qualifications are defined using ONET job zones, which\nclassify jobs into five groups based on the amount of preparation they require. We also obtain\nanalogous data broken down by educational requirements. We report job postings at the weekly\nlevel, expressed as changes in percentage terms relative to the first four complete weeks of 2020.\n\nComparison to JOLTS. Burning Glass data have been used extensively in prior research in\neconomics; for instance, see Hershbein and Kahn (2018) and Deming and Kahn (2018). Carnevale,\n\nJayasundera, and Repnikov (2014) show that the Burning Glass data are reasonably well aligned\n\n13",
    "Page_16": "with government survey-based statistics on job openings and characterize the sample in detail.\nIn Appendix Figure 3, we compare the distribution of industries in the Burning Glass data to\nnationally representative statistics from the Bureau of Labor Statistics’ Job Openings and Labor\nMarket Turnover Survey (JOLTS) in January 2020. In general, Burning Glass is well aligned across\nindustries with JOLTS, with the one exception that it under-covers government jobs. We therefore\n\nview Burning Glass as a sample representative of private sector jobs in the U.S.\nIIE Education: Zearn\n\nZearn is a non-profit math curriculum publisher that combines in-person instruction with digital\nlessons. Zearn was used by approximately 925,000 students in the U.S. in Spring 2020. Many\nschools continued to use Zearn as part of their math curriculum after COVID-19 induced schools\nto shift to remote learning. We obtain data on the number of students using Zearn Math and the\nnumber of lessons they completed at the school-grade-week level (see Appendix E for details).\n\nWe measure online math participation as the number of students using Zearn Math in a given\nweek. We measure student progress in math using the number of lessons completed by students\neach week. After excluding outliers, we aggregate to the county, state, and national level, in each\ncase weighting by the average number of students using the platform at each school during the\nbase period of January 6-February 7, and we normalize relative to this base period to construct the\nindices we report.\n\nComparison to American Community Survey. In Appendix Table 3, we assess the representa-\ntiveness of the Zearn data by comparing the demographic characteristics of the schools for which\nwe obtain Zearn data (based on the ZIP codes in which they are located) to the demographic\ncharacteristics of K-12 students in the U.S. as a whole, as measured in the American Community\nSurvey. The distribution of income, education, and race and ethnicity of the schools in the Zearn\nsample is similar to that in the U.S. as a whole, suggesting that Zearn provides a representative\n\npicture of online learning for students in the U.S.\n\nII.F Public Data Sources: UI Records, COVID-19 Incidence, and Google\nMobility Reports\n\nIn addition to the new private sector data sources described above, we also collect and use three\n\nsets of data from public sources to supplement our analysis: data on unemployment benefit claims\n\nobtained from the Department of Labor and state government agencies; data on COVID-19 cases\n\nand deaths obtained from the New York Times; and data on the amount of time people spend at\n\n14",
    "Page_17": "home vs. other locations obtained from Google’s COVID-19 Community Mobility Reports. Further\n\ndetails on these data sources are provided in Appendix F.\n\nIII Economic Impacts of COVID-19\n\nTo structure our analysis of the economic impacts of COVID-19, we begin from national accounts\ndata. According to the Bureau of Economic Analysis (2020), GDP fell by $1.73 trillion (an annu-\nalized rate of 31.7%) from the first quarter of 2020 to the second quarter of 2020, shown by the\nfirst bar in Figure la. GDP fell primarily because of a reduction in personal consumption expendi-\ntures (consumer spending), which fell by $1.35 trillion. Government purchases and net exports did\nnot change significantly, while private investment fell by $0.47 trillion.!° We therefore begin our\nanalysis by studying the determinants of this sharp reduction in consumer spending. We then turn\nto examine downstream impacts of the reduction in consumer spending on business activity and\nthe labor market. We characterize the dynamics of these outcomes at a daily level from March to\nOctober 2020, the first eight months of the COVID pandemic in the U.S, focusing primarily on two\ncritical periods: the trough of the recession (March 25-April 14) and the initial economic recovery\n\n(July 4-31), after which most outcomes remained relatively stable until October.\n\nIII.A Consumer Spending\n\nWe analyze consumer spending using data on aggregate credit and debit card spending. National\naccounts data show that spending that is well captured on credit and debit cards — essentially all\nspending excluding housing, healthcare, and motor vehicles — fell by approximately $1.03 trillion\nbetween the first quarter of 2020 and the second quarter of 2020, comprising roughly 75% of the\ntotal reduction in personal consumption expenditures.!\"\n\nBenchmarking. We begin by assessing whether our Affinity data track patterns in corresponding\n\nspending categories in the national accounts. Figure 1b plots spending on retail services (excluding\n\nauto-related expenses) and food services in the Affinity data vs. corresponding series from the\n\n \n\n10. Most of the reduction in private investment was driven by a reduction in inventories and equipment investment\nin the transportation and retail sectors, both of which are plausibly a response to reductions in current and anticipated\nconsumer spending. In the first quarter of 2020, consumer spending accounted for an even larger share of the reduction\nin GDP, further supporting the view that the initial shock to the economy came from a reduction in consumer spending\n(Bureau of Economic Analysis 2020).\n\n11. The rest of the reduction is largely accounted for by healthcare expenditures; housing and motor vehicle ex-\npenditures did not change significantly. We view the incorporation of additional private sector data sources to study\nthese other components of spending as an important direction for future work.\n\n15",
    "Page_18": "Advance Monthly Retail Trade Survey (MARTS), one of the main inputs used to construct the\nnational accounts.!? All series are expressed as a percentage change relative to January of each\ncalendar year; each point shows the average level of daily spending in a given month divided by\nspending in January of that year. We do not seasonally adjust spending for this benchmarking\nanalysis because seasonal fluctuations provide useful variation to assess whether the card spending\nseries tracks the MARTS. The Affinity spending series tracks the MARTS closely both before and\nafter the COVID crisis. In particular, both series show a rapid drop in food services spending in\nMarch and April 2020, while total retail spending fluctuates much less. The root-mean-squared-\nerror of the Affinity series relative to the MARTS is small relative to the fluctuations induced by\nCOVID.\n\nFigure 1c plots the change in spending from January to April 2020 in the Affinity spending\nseries against the decline in consumer spending as measured in the MARTS. Despite the fact that\nthe MARTS category definitions are not perfectly aligned with those in the card spending data,\nthe relative declines are generally well aligned across sectors, with a correlation of 0.88. Given that\nAffinity data track the MARTS at the national level quite well, we proceed to use it to disaggregate\nthe national series in several ways to understand why consumer spending fell so sharply.!®\n\nHeterogeneity by Income. We begin by examining spending changes by household income. We\ndo not directly observe cardholders’ incomes in our data; instead, we proxy for cardholders’ incomes\nusing the median household income in the ZIP code in which they live (based on data from the\n2014-18 American Community Survey). ZIP codes are strong predictors of income because of the\ndegree of segregation in most American cities; however, they are not a perfect proxy for income\nand can be prone to bias in certain applications, particularly when studying tail outcomes (Chetty\net al. 2020). To evaluate the accuracy of our ZIP code imputation procedure, we compare our\nestimates to those in contemporaneous work by Cox et al. (2020), who observe cardholder income\ndirectly based on checking account data for clients of JPMorgan Chase. Our estimates are closely\n\naligned with those estimates, suggesting that the ZIP code proxy is reasonably accurate in this\n\n \n\n12. The series are not perfectly comparable because the category definitions differ slightly across the datasets. For\nexample, we observe food and accommodation services combined together in the card data but only food services\nin the MARTS. In addition, the MARTS includes corporate card transactions, whereas we exclude them in order\nto isolate consumer spending. Hence, we would not expect the series to track each other perfectly even if the card\nspending data provided a perfect representation of national spending patterns.\n\n13. Of course, our national benchmarking exercise does not guarantee that our statistics capture economic activity\nin every subgroup accurately. We cannot benchmark most datasets at the local level: this is precisely the value of\nthe private sector data that we introduce here. To assuage concerns about differential selection bias across regions,\nwe show that our main results are obtained in multiple different data sources on different outcomes. It is likely that\nany biases in these data sets due to non-representative sampling are small relative to the scale of changes induced by\nCOVID-19.\n\n16",
    "Page_19": "application.4\n\nFigure 2a plots a seven-day moving average of total daily card spending for households in the\nbottom vs. top quartile of ZIP codes based on median household income.!® The solid line shows\ndata from January to October 2020, while the dashed line shows data for the same days in 2019 as\na reference. Spending fell sharply on March 15, when the National Emergency was declared and\nthe threat of COVID became widely discussed in the United States. Spending fell from $7.9 billion\nper day in February to $5.6 billion per day by the end of March (a 30% reduction) for high-income\nhouseholds; the corresponding change for low-income households was $3.5 billion to $2.8 billion (a\n20% reduction).\n\nBecause high-income households cut spending more in percentage terms and accounted for a\nlarger share of aggregate spending to begin with, they accounted for a much larger share of the\ndecline in total spending in the U.S. than low-income households. In Column 1 of Table la, we\nestimate that as of mid-April, top-quartile households accounted for roughly 41% of the aggregate\nspending decline after the COVID shock, while bottom-quartile households accounted for only 12%\nof the decline.\n\nThis gap in spending patterns by income grew even larger over time. By mid-July, spending\nhad essentially returned to 2019 levels among households in the bottom quartile, whereas spending\namong high-income households remained 13% below baseline levels. These differences persisted\nthrough the first stage of economic recovery to the end of September. This heterogeneity in spending\nchanges by income is larger than that observed in previous recessions (Petev, Pistaferri, and Eksten\n2011, Figure 6) and plays a central role in the downstream impacts of COVID on businesses and\nthe labor market, as we show below.\n\nA potential concern with our card-based estimates of spending changes is bias from substitution\nout of cash purchases; for instance, if individuals sought to use more contactless methods to pay or\nbegan placing more orders online, trends in card spending might exhibit excess volatility relative to\noverall spending. To assess the importance of such substitution, we examine cash purchases using\n\nreceipts data from CoinOut. Appendix Figure 4a plots aggregate cash purchases in the CoinOut\n\n \n\n14. Cox et al. (2020) report an eight percentage point larger decline in spending for the highest income quartile\nrelative to the lowest income quartile in the second week of April. Our estimate of the gap is also eight percentage\npoints at that time, although the levels of the declines in our data are slightly smaller in magnitude for both groups.\n\n15. We estimate total card spending for the U.S. population by inflating the daily spending in the Affinity Solutions\ndata, multiplying by the ratio of January 2020 (or 2019) total spending for components of PCE that are likely\ncaptured in credit/debit card spending (shown in the last bar of Figure la) to the January 2020 (or 2019) total\nspending in the Affinity data.\n\n17",
    "Page_20": "data vs. aggregate card spending at grocery stores over time.!® The time trends are very similar\nbetween the two series (with a signal correlation of 0.9 at the weekly level), showing a sharp spike\nin spending in late March (as households stocked up on groceries), followed by a more sustained\nincrease in spending from the latter half of April. These results — together with the fact that\nour card spending series closely track estimates from the MARTS (Figures 1b and 1c) — indicate\nthat aggregate fluctuations in card spending do not appear to have been offset by opposite-signed\nchanges in cash spending. Rather, households shifted spending similarly across both modes of\npayment. We therefore proceed to focus on card spending in the rest of our analysis given the\nlarger sample sizes and greater granularity of the card spending data.\n\nHeterogeneity Across Sectors. Next, we disaggregate the change in total card spending across\ncategories to understand why households cut spending so rapidly. In particular, we seek to dis-\ntinguish two channels: reductions in spending due to loss of income vs. fears of contracting or\nspreading COVID.\n\nThe left bar in Figure 2b plots the share of the total decline in spending from the pre-COVID\nperiod to mid-April accounted for by various categories. In this and all subsequent figures analyzing\nconsumer spending, we seasonally adjust spending levels by comparing them to 2019 levels in\nthe same week (see Appendix B for details). Consistent with the findings of Cox et al. (2020),\nroughly two-thirds of the reduction in spending came from reduced spending on goods or services\nthat require in-person contact (and thereby carry a risk of COVID infection), such as hotels,\ntransportation, and food services. This is particularly striking given that these goods accounted\nfor only one-third of total spending in January, as shown by the right bar in Figure 2b. Panel B of\nTable 1 shows that these gaps only grew larger as the pandemic progressed, as consumer spending\nincreased above pre-pandemic levels for durable and non-durable goods by mid-July, but remained\nsharply depressed for in-person services.\n\nNext, we zoom in to specific subcategories of spending that differ sharply in the degree to which\nthey require physical interaction in Figure 2c. Seasonally-adjusted spending on luxury goods such\nas installation of home pools and landscaping services — which do not require in-person contact\n\nincreased slightly after the COVID shock. In contrast, spending on restaurants, beauty shops,\nand airlines all plummeted sharply. Consistent with these substitution patterns, online spending\n\nincreased sharply: online purchases increased by 37% from the first to the second quarter of 2020\n\n \n\n16. We focus on grocery spending in the card data because cash spending in CoinOut is concentrated in certain\nsectors such as groceries; unfortunately, we are unable to disaggregate the CoinOut data by sector or align sectoral\ndefinitions more precisely across the datasets.\n\n18",
    "Page_21": "(U.S. Department of Commerce 2020). A conventional reduction in income or wealth would\ntypically reduce spending on all goods as predicted by their Engel curves (income elasticities);\nthe fact that the spending reductions vary so sharply across goods in line with their health risks\nlends further support to the hypothesis that health concerns (either one’s own health or altruistic\nconcerns about others’ health) rather than a lack of purchasing power drove spending reductions.\n\nThese patterns of spending reductions differ sharply from those observed in prior recessions.\nFigure 2d compares the change in spending across categories in national accounts data in the\nCOVID recession and the Great Recession in 2009-10. In the Great Recession, nearly all of the\nreduction in consumer spending came from a reduction in spending on goods; spending on services\nwas almost unchanged. In the COVID recession, 67% of the reduction in total spending came from\na reduction in spending on services, as anticipated by Mathy (2020).\n\nHeterogeneity by COVID Incidence. To further evaluate the role of health concerns, we next\nturn to directly examine the association between incidence of COVID across areas and changes\nin spending from a baseline period prior to the COVID shock (January 4 to January 31, 2020)\nto the trough in consumer spending immediately after the COVID shock (March 25 to April 14,\n2020). Figure 3a presents a binned scatter plot of changes in spending vs. the rate of detected\nCOVID cases by county, separately for low- and high-income counties (median household income\nin the bottom vs. top income quartile). Spending fell more in counties with higher rates of COVID\ninfection in both low- and high-income areas.!?\n\nTo examine the mechanism driving these spending reductions more directly, in Figure 3b, we\npresent a binned scatter plot of the amount of time spent outside home (using anonymized cell phone\ndata from Google) vs. COVID case rates, again separately for low- and high-income counties. In\nboth sets of areas, there is a strong negative relationship: people spent considerably less time\noutside home in areas with higher rates of COVID infection. The reduction in spending on services\nthat require physical, in-person interaction (e.g., restaurants) is mechanically related to this simple\nbut important change in behavior.\n\nFigures 3a-b show that at all levels of COVID infection, higher-income households reduced\nspending and time spent outside more than lower-income households. Figure 3c establishes this\n\npoint more directly by showing that change in time spent outside home falls monotonically with\n\n \n\n17. The relationship shown in Figure 3a also holds in a county-level regression of changes in consumer spending on\nthe logarithm of cases per 100,000 people with controls for household income and state fixed effects (coefficient =\n-2.21, s.e. = 0.30). Note that there was a substantial reduction in spending even in areas without high rates of realized\nCOVID infection, which is consistent with widespread concern about the disease even in areas where outbreaks did\nnot actually occur at high rates.\n\n19",
    "Page_22": "household income across the distribution. These results help explain why the rich reduced spending\nmore, especially on goods that require in-person interaction: high-income people apparently self-\nisolated more, perhaps by working remotely or because they had larger living spaces.\n\nIn sum, disaggregated data on consumer spending reveal that spending in the initial stages of\nthe pandemic fell primarily because of health concerns rather than a loss of current or expected\nincome. Income losses were relatively modest because few high-income individuals lost their jobs\nas we show in Section II.C below — and lower-income households who experienced job loss had their\nincomes more than replaced by supplemental unemployment benefits (Ganong, Noel, and Vavra\n2020), which led unemployed households to increase their spending relative to pre-COVID levels\n(Farrell et al., 2020a).!8 Indeed, national accounts data actually show an increase in total income\nof 13% from March to April 2020. This finding implies that the central channel emphasized in\nKeynesian models that have guided policy responses to prior recessions ~ a fall in aggregate demand\ndue to a lack of purchasing power — was less important in the early stages of the pandemic, partly\nthanks to government policies such as increases in unemployment benefits and easing of monetary\npolicy. Rather, the key driver of residual changes in aggregate spending was a contraction in firms’\nability to supply certain goods, namely services that carry no health risks — consistent with the\nmechanisms emphasized by Eichenbaum, Rebelo, and Trabandt (2020).!\" We now show that this\nsource of spending reductions leads to a novel set of downstream impacts on businesses and the\n\nlabor market, potentially calling for different policy responses than in prior recessions.\nIII.B Business Revenues\n\nHow did reductions in consumer spending affect business activity — whether to remain open, how\n\nmany employees to retain, what wage rates to pay them, how many new people to hire? To analyze\n\n \n\n18. It may be surprising that we do not see a decline in aggregate spending in Figure 2a when supplemental\nunemployment benefits expired at the end of July 2020. Farrell et al. (2020b) estimate that the expiration of\nsupplemental unemployment benefits led to a $96 reduction in weekly spending among unemployed households (16% of\nthe reduction in unemployment benefits). As of the last week of July, federal spending on supplemental unemployment\nbenefits was $15.6 billion (Morath 2020), implying that aggregate spending would decline by roughly $2.5 billion in\nthe week following the expiration of supplemental benefits, about 1.6% of mean weekly card spending in January 2020.\nFrom July to September 2020, the root-mean-squared-error from a regression of total weekly consumer spending on a\nlinear trend is 1.6%. Hence, the aggregate effect of the expiry of supplemental unemployment benefits is small relative\nto typical fluctuations around trend, explaining why the impacts of the expiration of UI benefits are not visible in the\naggregate data shortly after benefits expire. However, as emphasized by Farrell et al. (2020b), households maintained\nconsumption by depleting savings they had built up when receiving supplemental benefits; as they exhaust their\nassets, expenditure could fall more sharply and have a larger impact on aggregate spending.\n\n19. This explanation may appear to be inconsistent with the fact that the Consumer Price Index (CPI) showed little\nincrease in inflation during the pandemic, given that one would expect a supply shock to increase prices. However,\nthe CPI likely understated inflation because it did not capture the extreme shifts in the consumption bundle (Cavallo\n2020) or changes in product variety and promotions offered to consumers (Jaravel and O’Connell 2020) during the\nCOVID crisis.\n\n20",
    "Page_23": "these impacts, we exploit variation in shocks to firms’ revenues across ZIP codes. The motivation\nfor this geographic approach is that spending fell primarily among high-income households in sec-\ntors that require in-person interaction, such as restaurants. Most of these goods are non-tradable\nproducts produced by small local businesses who serve customers in their local area.2° We there-\nfore use differences in average incomes and rents across ZIP codes as a source of variation in the\nmagnitude of the spending shock that small businesses face.?!\n\nBenchmarking. We measure small business revenues using data from Womply, which records\nrevenues from credit card transactions for small businesses (as defined by the Small Business Ad-\nministration). Business revenues in Womply closely track patterns in the Affinity total spending\ndata, especially in sectors with a large share of small businesses, such as food and accommodation\nservices (Appendix Figure 5).??\n\nHeterogeneity Across Areas. We begin our analysis of the Womply data by examining how\nsmall business revenues changed in low- vs. high-income ZIP codes from a baseline period prior to\nthe COVID shock (January 4 to 31, 2020) to the period immediately after the COVID shock prior\nto the stimulus program (March 25 to April 14, 2020).?? Throughout our analysis, we seasonally\nadjust small business revenues using data from 2019 (see Appendix C for details).\n\nFigure 4 maps the change in small business revenue by ZIP code in three large metro areas:\nNew York City, Chicago and San Francisco (analogous ZIP-level maps for other cities are posted\nonline). There is substantial heterogeneity in revenue declines across areas. For example, within\nNew York City average small business revenue declined by more than 73% in the hardest-hit decile\nof ZIP codes, compared to declines of less than 13% in the least affected decile of ZIP codes.?4\n\nIn all three cities, revenue losses were largest in the most affluent parts of the city. For example,\n\nsmall businesses lost 67% of their revenue in the Upper East Side in New York, compared with 45%\n\n \n\n20. For example, 56% of workers in food and accommodation services and retail (two major non-tradeable sectors)\nwork in establishments with fewer than 50 employees.\n\n21. We focus on small businesses because their customers are typically located near the business itself; larger\nbusinesses’ customers (e.g., large retail chains) are more dispersed, making the geographic location of the business\nless relevant. One could also in principle use other groups (e.g., sectors) instead of geography as instruments. We\nfocus primarily on geographic variation because the granularity of the data by ZIP code yields much sharper variation\nthan what is available across sectors and arguably yields comparisons across more similar firms (e.g., restaurants in\ndifferent neighborhoods rather than airlines vs. manufacturing).\n\n22. In sectors that have a bigger share of large businesses — such as retail — the Womply small business series exhibits\na larger decline during the COVID crisis than Affinity (or MARTS). This pattern is precisely as expected given other\nevidence that consumers shifted spending toward large online retailers such as Amazon (Alexander and Karger 2020).\n\n23. We use 2010 Census ZIP Code Tabulation Areas (ZCTAs) to perform all geographic analyses of ZIP-level data.\nThroughout the text, we refer to these areas simply as “ZIP codes”.\n\n24. Very little of this variation is due to sampling error: the reliability of these estimates across ZIP codes within\ncounties is around 0.8, i.e., 80% of the variance within each of these maps is due to signal rather than noise.\n\n21",
    "Page_24": "in the East Bronx; 66% in Lincoln Park vs. 41% in Bronzeville on the South Side of Chicago; and\n84% in Nob Hill vs. 27% in Bayview in San Francisco. Revenue losses were also large in the central\nbusiness districts in each city (lower Manhattan, the Loop in Chicago, the Financial District in San\nFrancisco), likely a direct consequence of the fact that many high-income workers who used to work\nin these areas transitioned to working remotely. But even within predominantly residential areas,\nbusinesses located in more affluent neighborhoods suffered much larger revenue losses, consistent\nwith the heterogeneity in spending reductions observed in the Affinity data.2° More broadly, cities\nthat have experienced the largest declines in small business revenue on average tend to be affluent\ncities — such as New York, San Francisco, and Boston (Appendix Table 4, Appendix Figure 7a).\n\nFigure 5a generalizes these examples by presenting a binned scatter plot of percent changes in\nsmall business revenue vs. median household incomes, by ZIP code across the entire country. We\nobserve larger reductions in revenue at small businesses located in more affluent ZIP codes across\nthe distribution.?® In the richest 5% of ZIP codes, small business revenues fell by 50%, as compared\nwith around 35% in the poorest 5% of ZIP codes, consistent with the differences observed in the\nAffinity consumer spending data across areas.”\n\nAs discussed above, spending fell most sharply not just in high-income areas, but particularly\nin high-income areas with a high rate of COVID infection. Data on COVID case rates are not\navailable at the ZIP code level; however, one well established predictor of the rate of spread of\nCOVID is population density: the infection spreads more rapidly in dense areas. Figure 5b shows\nthat small business revenues fell more heavily in more densely populated ZIP codes.\n\nFigure 5c combines the income and population density mechanisms by plotting revenue changes\nvs. median rents (for a two bedroom apartment) by ZIP code. Rents are a simple measure of the\naffluence of an area that combine income and population density: the highest rent ZIP codes tend\n\nto be high-income, dense areas such as Manhattan. Figure 5c shows a steep gradient of revenue\n\n \n\n25. We find a similar pattern when controlling for differences in industry mix across areas; for instance, the maps\nlook very similar when we focus solely on small businesses in food and accommodation services (Appendix Figure 6).\n\n26. One may be concerned that some of this correlation is driven by high-income households relocating to second\nhomes, leading to shifting of small business revenue to other areas rather than a reduction in total revenue. While a\nsignificant number of households own second homes in certain areas (e.g., the most affluent parts of New York), the\nfraction of households moving to second homes is negligible in most areas, particularly those with rents below the\n95th percentile of the distribution, and hence plays a small role in explaining these results.\n\n27. Of course, households do not restrict their spending solely to businesses in their own ZIP code. An alternative\nway to establish this result at a broader geography is to relate small business revenue changes to differences in income\ndistributions across counties. Counties with larger top 1% income shares experienced larger losses of small business\nrevenue (Appendix Figure 8a). Poverty rates are not strongly associated with revenue losses at the county level\n(Appendix Figure 8b), showing that it is the presence of the rich in particular (as opposed to the middle class) that\nis most predictive of economic impacts on local businesses.\n\n22",
    "Page_25": "changes with respect to rents: revenues fell by less than 30% in the lowest-rent ZIP codes, compared\nwith more than 50% in the highest-rent ZIP codes. This relationship is essentially unchanged when\nwe compare ZIP codes within the same county by regressing revenue changes on rent with county\nfixed effects (Table 2, Column 2).?8 It also remains similar when controlling for the (pre-COVID)\ndensity of high-wage workers in a ZIP code to account for differences that may arise from shifts\nto remote work in business districts (Table 2, Column 3). Furthermore, these spatial differences\npersisted even as the economy began to recover. In July, small business revenue was still around\n25% below its January level in the highest-rent ZIP codes, but only around 5% below the January\nlevel in the lowest-rent ZIP codes (Appendix Figure 9a).\n\nIn Figure 5d, we examine heterogeneity in this relationship across sectors that require different\nlevels of physical interaction: food and accommodation services and retail trade (which largely\nrequire in-person interaction) vs. finance and professional services (which largely can be conducted\nremotely). Revenues fell much more sharply for food and retail in higher-rent areas; in contrast,\nthere was essentially no relationship between rents and revenue changes for finance and professional\nservices. These findings show that businesses that cater in person to the rich were those that lost\nthe most revenue.\n\nAs a result of this sharp loss in revenues, small businesses in high-rent areas were much more\nlikely to close entirely. We measure closure in the Womply data as reporting zero credit card\nrevenue for three days in a row, and seasonally adjust rates of business closure using 2019 data (see\nAppendix B for details). Appendix Figure 8c shows that 40% of small businesses in the highest-\nrent ZIP codes closed, compared with 25% in the lowest-rent ZIP codes. The extensive margin of\nbusiness closure accounts for most of the decline in total revenues.\n\nBecause businesses located in high-rent areas lost more revenue in percentage terms and ac-\ncounted for a greater share of total revenue to begin with, they accounted for most of the aggregate\nloss in small business revenue. Almost half of the total loss in small business revenues came from\nbusinesses located in the top-quartile of ZIP codes by rent; less than 15% of the revenue loss came\nfrom businesses located in the bottom quartile. Next, we examine how the incidence of this shock\n\nis passed on to their employees.\n\n \n\n28. The relationship between higher local rents and larger revenue losses at small businesses is not driven by variation\nbetween rural and urban areas, since this pattern is unchanged within counties.\n\n23",
    "Page_26": "IlIl.C Employment Rates\n\nWe study employment impacts using data from payroll companies. We begin by benchmarking\nthese data sources to employment statistics from nationally representative surveys conducted by\nthe Bureau of Labor Statistics and then disaggregate the data by wage level and geography to\nanalyze how the shock in consumer spending and business revenue affected employment rates.\n\nBenchmarking. Figure 6a plots employment rates from the nationally representative Current\nEmployment Statistics (a survey of businesses) and Current Population Survey (a survey of house-\nholds) for all workers alongside our combined Paychex-Intuit-Earnin employment series, constructed\nas described in Section II.C. Our payroll-based series is broadly aligned with the survey-based mea-\nsures, generally falling between estimates obtained from the two surveys.\n\nFigure 6b examines how our series performs in matching national statistics on trends across\nsectors. For illustration, we focus on two sectors that experienced very different trajectories: food\nservices, where employment fell heavily, and professional services, where it did not. In both cases,\nour Paychex-Intuit-Earnin series closely tracks data from the CES. Appendix Figure 10d shows\nmore generally that changes in employment rates across sectors (two-digit NAICS) are very closely\naligned in our series and the CES, with a correlation of 0.95.\n\nFor comparison, we also examine trends in employment based on data from Homebase, a dataset\nthat has been used to examine employment trends in the COVID recession in many studies. Home-\nbase exhibits a much larger decline in employment than the other series (56% at the trough vs. 15%\nin the CES). This is primarily because half of the individuals in the Homebase data work in the\nfood services sector, which suffered particularly large employment losses as noted above; however,\neven within food services, Homebase exhibits a larger decline in employment at the trough (64%)\nrelative to the CES (47%), as shown in Figure 6b, and thus has a higher RMSE. Because Homebase\ndoes not track overall national benchmarks on employment very closely, we do not use it for the\nanalysis that follows, although we note that it exhibits qualitative patterns similar to the other\nseries within food services.\n\nIn Appendix Figures 10a-b, we compare trends by wage quartile in our data with estimates based\non the Current Population Survey and estimates in Cajner et al. (2020), who report employment\nchanges by wage quintile using data from ADP in the initial weeks after the COVID shock. We\nfind broadly similar trends in all three datasets. We also examine employment changes by state\n\nand find that in almost all states (excluding North Dakota and Hawaii), employment changes from\n\n24",
    "Page_27": "January-April in our combined series align very closely with changes in the CES, with an overall\ncorrelation of 0.99 (Appendix Figure 10c).\n\nBased on these benchmarking exercises, we conclude that our combined employment series\nprovides a good representation of employment rates across sectors, wage groups, and geographic\nareas.\n\nHeterogeneity by Wage Rates. Figure 7a plots the combined employment series by wage quartile.\nTo construct this figure, we first construct hourly wage quartiles based on fixed thresholds of the\nhourly wage distribution in 2019 (<$13.00, $13.00-$18.18, $18.18-29.17, >$29.17). The solid lines\nplot total employment (based on repeated daily cross-sections) in each of these bins relative to the\nJanuary baseline, based on the combined Paychex-Intuit-Earnin data. Consistent with the findings\nof Cajner et al. (2020) in prior work using ADP data, we find sharp heterogeneity in job losses by\nwage rate. Employment rates fell by 37% around the trough of the recession (April 15) for workers\nin the bottom wage quartile (i.e., the total number of jobs paying <$13/hour was 37% lower as of\nApril 15 than in January). By contrast, employment rates fell by only 14% for those in the top\nwage quartile as of April 15.\n\nHigh-wage workers not only were less likely to lose their jobs to begin with, but also experienced\na much more rapid recovery. By late May, employment for high-wage workers had returned nearly\nto the pre-COVID baseline. But employment rates for low-wage workers remained roughly 20%\nbelow baseline levels even as of mid-September. Using time sheet data from Kronos, and payroll\ndata from firms with weekly paycycles in Paychex — both of which are available with a shorter\nlag than payroll-based employment data containing all paycycles — we construct a prediction of\nemployment rates up to October 14 as described in Section II.C (shown by the dashed lines in\nFigure 7a). These predictions suggest that the rate of recovery remained slow for low-wage workers\nin October.\n\nIn sum, COVID induced a short-term “V-shaped” recession for high-wage workers in terms of\nemployment opportunities, but led to a much deeper and more prolonged recession for lower-wage\nworkers. Why did employment trajectories for low-wage workers differ so sharply from those for\nhigh-wage workers? One potential explanation is that low-wage workers work in different sectors\nor areas that may have experienced larger reductions in consumer demand. We evaluate this hy-\npothesis in Figure 7b by plotting employment for workers in the bottom wage quartile, reweighting\nthe series to match baseline employment shares by county and industry (2 digit NAICS) in the top\n\nwage quartile. This reweighting closes very little of the gap between the two series, showing that\n\n25",
    "Page_28": "differences in industry and location do not explain the differences in employment trajectories. Fig-\nure 7c provides a specific illustration of this result by showing trends in employment and spending\nin the retail trade sector. Total retail spending was nearly 10% higher as of July 31 relative to\nthe pre-COVID baseline. Employment of high-wage workers was comparable to baseline levels, yet\nemployment of low-wage workers was still down by over 15%.\n\nOne explanation for these patterns is that firms have shifted their production processes to use\nmore technology or find other efficiencies (Lazear, Shaw, and Stanton 2016) and economic activity\nmay have shifted toward these more efficient firms. For example, retail spending may have shifted\ntoward online retailers and larger firms that use more capital (or imports) than low-wage labor in\nthe United States to produce goods. Such shifts could reduce demand for routine occupations more\npermanently — a phenomenon documented in previous recessions by Jaimovich and Siu (2020).\nThese results raise the possibility of a “jobless recovery” absent efforts to help workers who have\nbeen displaced from their prior jobs (Berger 2012).\n\nHeterogeneity Across Areas. To shed further light on why employment rates for low-wage\nworkers fell so much, we next turn to examine geographic heterogeneity in employment losses, in\nconnection to the heterogeneity in spending changes and business revenue losses examined above.\nWe begin by using the Earnin data — which is available at the ZIP code level — to analyze hetero-\ngeneity across the ZIP codes where people work (not necessarily where they live). Figure 8 maps\nchanges in employment rates from January to the trough in mid-April for low-wage workers at\nsmall- and mid-size businesses (fewer than 500 employees) by ZIP code in New York, Chicago and\nSan Francisco (analogous ZIP-level maps for other cities are posted online).?9 The patterns closely\nmirror those observed for business revenues above. Employment rates for low-wage workers fell by\nmore than 70% in the most affluent areas of these cities, as compared with 30% in the least afflu-\nent areas. We observe very similar spatial patterns when examining variation across commuting\nzones (aggregates of counties) at the national level using the combined Paychex-Intuit-Earnin data\n(Appendix Figure 7b).\n\nFigure 9a presents a binned scatter plot of changes in low-wage employment rates (from January\nto the mid-April trough) vs. median rents in the employer’s ZIP code, by firm size. Employment\n\nrates fell much more at businesses located in high-rent areas than low-rent areas in all groups,\n\n \n\n29. We focus on small and mid-size businesses here because, as noted above, larger firms are more likely to serve\nmarkets extending well beyond the ZIP code in which they are located. Additionally, very large firms exhibit\nsignificantly smaller declines in employment (Appendix Figure 11). Because employment fell more slowly after the\ninitial shock to consumer spending and business revenue, we use a slightly later period — from April 8-28 — to analyze\nthe trough in employment than the March 25-April 14 period we used to study changes in spending and revenue.\n\n26",
    "Page_29": "supporting the view that the sharp reductions in business revenue in affluent areas induced firms\nto lay off low-wage workers. As employment recovered in the months after April 2020, the spatial\ndifferences observed in Figure 9 persisted. In July, low-wage employment was approximately 15%\nbelow baseline levels in low-rent ZIP codes, but remained 30% below baseline in the highest-rent\nZIP codes (Appendix Figure 9b).\n\nWe observe a similar gradient with respect to local rents for workers at very large firms: from\n25% in the lowest-rent ZIPs to over 35% in the highest-rent ZIPs. This presumably reflects that\nfact that multi-establishment firms such as Starbucks faced larger revenue losses at stores located\nin more affluent neighborhoods for the reasons documented above, which in turns induced them\nto reduce employment in those areas more heavily. While there is a similar gradient with respect\nto rent levels, the overall level of employment losses for workers at large firms was lower than at\nsmaller firms. This may be because large firms lost less revenue as a result of the COVID shock\ngiven their line of business (e.g., fast food vs. sit-down restaurants) or had a greater ability to\nsubstitute to other modes of business (delivery, online retail).°°\n\nTable 2b presents a set of regression estimates quantifying these impacts. Low-wage workers\nconsistently faced larger employment losses in higher-rent ZIP codes, even when comparing ZIP\ncodes within the same county (Column 2) and controlling for the density of high-wage workers in\nthe ZIP code (Column 3).*!\n\nJob Postings. Prior work suggests that the labor market impacts of the recession may depend\nas much upon job postings as they do on the rate of initial layoffs (e.g., Diamond and Blanchard\n1989, Elsby, Michaels, and Ratner 2015). We therefore now turn to examine how the spending\nshocks and revenue losses have affected job postings using data from Burning Glass, building on\nprior work by Forsythe et al. (2020). We conduct this analysis at the county level, pooling firms\nof all sizes and sectors because workers can substitute across firms and areas when searching for a\nnew job, making it less relevant which exact firm or ZIP code they work in.\n\nFigure 9b presents a binned scatter plot of the change in job postings between January and\nthe April trough vs. median rents by county for jobs that require minimal education. We find a\n\npattern similar to what we find with current employment: job postings with minimal educational\n\n \n\n30. We cannot measure changes in revenue by establishment for large firms because the Womply data on revenues\nonly cover small businesses.\n\n31. Employment in the combined Paychex-Intuit-Earnin data is only available at the county level. We see a similar\npattern when regressing Paychex-Intuit-Earnin employment changes for low-wage workers on rent at the county level\n(coefficient = -8.69% per thousand dollars, s.e. = 1.09% per thousand dollars), although the magnitude of the gradient\nis attenuated as expected given the coarser geographic measures.\n\n27",
    "Page_30": "requirements fell much more sharply (by approximately 30%) in high-rent areas than for workers\nin lower-rent areas. Hence, low-wage workers in such areas were not only more likely to have lost\ntheir jobs to begin with, they also had poorer prospects of finding a new job. Figure 9c replicates\nFigure 9b for job postings that require higher levels of education. For this group, which is much\nmore likely to be employed in tradable sectors that are less influenced by local conditions (e.g.,\nfinance or professional services), there was no relationship between local rents and the change in\njob postings, consistent with our findings above in Figure 5d.\n\nComparison to Great Recession. The geographic pattern of job losses in the COVID recession\ndiffered sharply from that in the Great Recession. Using employment data from the Bureau of\nLabor Statistics, Figure 10 shows that counties in the bottom quartile of the household median\nincome distribution accounted for 30% of job losses in the Great Recession (from 2007-2010), while\nthose in the top quartile accounted for less than 20% of job losses. By contrast, in the COVID\nrecession (from January to April 2020), counties in the top quartile accounted for a larger share of\njob losses than counties in the bottom quartile.??\n\nBecause job losses were concentrated in more affluent areas, UI claims were almost equally likely\nto come from high- and low-income counties in the COVID recession. For example, 16% of the\nlabor force in Santa Clara county in California — the highest income county on the West Coast\n\nclaimed UI between March 15 and May 2. This claim rate is identical to that in Fresno CA, a\nlow-income county in California’s Central Valley. Unemployment rates reached 10% regularly in\nFresno in prior recessions, but such rates are unprecedented in Santa Clara.\n\nIn the Great Recession, the areas of the country that experienced the largest increases in\nunemployment took many years to recover because workers did not move to find new jobs, and\njob vacancies remained depressed in hard-hit areas well after the national recession ended (Yagan\n2019). Appendix Figure 9c shows early signs of a similar pattern in this recession: job postings\nremained significantly lower in high-rent counties than in low-rent counties even at the end of July.\nThese findings suggest that the recovery for low-wage workers may take longer in richer areas in\n\nthe COVID recession.\n\n \n\n32. The increase in unemployment rates between February and April 2020 (11%) was only two-thirds as large as\nthe decrease in employment (16%). The difference was due to a 5% decline in the labor force: many people lost their\njobs but were not actively searching for a new job in the midst of the pandemic (Coibion, Gorodnichenko, and Weber\n2020). In the three prior recessions, the labor force continued to grow by 0.3% to 0.8% annually. We therefore focus\non the decline in employment rates to obtain comparable statistics on job loss across recessions.\n\n28",
    "Page_31": "III.D Impacts on Displaced Workers\n\nThe analysis in the last section focused on changes in employment rates for workers by location\nin repeated cross-sections, showing for example that low-wage employment rates fell sharply in\nManhattan relative to the Bronx. We close our analysis by examining how the COVID shock\naffected workers’ employment and consumption trajectories longitudinally, tracking workers who\nlost their jobs and examining whether they were able to find employment elsewhere as the economy\nrecovered. Did people who worked in Manhattan pre-COVID remain out of work and have lower\nspending levels than comparable workers in the Bronx (who were less likely to lose their jobs)? Or\ndid they find jobs elsewhere, so that the initial incidence of the shock was effectively shared across\nworkers over time, as one would expect in a frictionless labor market?\n\nThe traditional approach to studying displacement effects is to compare the employment tra-\njectories of displaced vs. comparable non-displaced workers in individual-level panel data (e.g.,\nJacobson, LaLonde, and Sullivan 1993, Sullivan and Wachter 2009). Here, we implement such an\nanalysis using the aggregated employment data from Earnin that we have made publicly available.\nTo do so, we track employment rates by workers’ ZIP code of residence; since relatively few peo-\nple moved during the pandemic (Pew Research Center 2020), this effectively provides a panel of\nemployment rates for a given set of workers. We then use data from the Census LEHD Origin-\nDestination Employment Statistics (LODES) database, which provides information on the matrix\nof residential ZIP by work ZIP for low-income workers in the U.S. in 2017, to compute the average\nworkplace median rent level for each residential ZIP.\n\nFigure 11a presents a binned scatter plot of changes in low-income employment by home (resi-\ndential) ZIP code vs. average workplace rent. This figure shows that low-income individuals who\nwere working in high-rent areas pre-COVID were much less likely to be employed after the shock\nhit in April — consistent with our findings above. Strikingly, these employment losses then persisted\nover time with no convergence over time in employment rates for workers who lived in different\nareas. Figure 11b plots employment trends for low-wage workers living in low-income ZIP codes, by\nthe average workplace rent. As of April 15, employment fell for workers in high-workplace-rent (top\nquartile) ZIP codes by 45%, whereas employment fell by 32% among workers in low workplace rent\n(bottom quartile) ZIP codes. This gap in employment rates persisted for several months; in mid-\nJuly, employment in high workplace rent ZIP codes was around 33% below baseline levels, whereas\n\nemployment in low workplace rent ZIP codes was 17% below baseline levels. More broadly, across\n\n29",
    "Page_32": "the entire distribution of workplace rents, the slope of the relationship between employment rates\nand workplace rents was almost the same in July as in April (Appendix Figure 9d). These gaps\nin employment persist even when comparing workers who live in the same county: adding county\nfixed effects to a regression of changes in employment (as of July) on ZIP workplace increases the\nslope coefficient from -15%/$1000 (s.e. = 0.7%) to -33.3%/$1000 (s.e. = 3.6%).°3\n\nThese results show that the spatial patterns in the maps in Figure 8 are driven not by peo-\nple switching from working in high-rent areas to low-rent areas, but rather by persistently lower\nemployment rates for those who happened to be working in high-rent areas pre-COVID. A worker\nworking at a restaurant in Manhattan remains less likely to be employed months later than a\nworker in the Bronx. One explanation for this lack of re-equilibration even within labor markets is\nthat, unlike in prior recoveries, many workers may have simply returned to their previous jobs as\nthe economy recovered rather than shifting to new jobs. Given the high levels of churn typically\nobserved in low-wage labor markets, one would expect greater convergence in employment rates\nacross workers with different initial conditions over time. Still, this evidence suggests that there\nare significant frictions within labor markets that contributed to persistent impacts of COVID on\nlow-wage workers who happened to work in areas and sectors where demand fell sharply.\n\nFinally, we analyze how these differential shocks to employment affected the consumption of\ndisplaced low-wage workers. Returning to the card spending data from Affinity Solutions, we ask\nwhether low-income individuals working in high-rent ZIP codes reduce spending more than those\nworking in low-rent ZIP codes. Figure 11c replicates Figure 1la using spending changes on the y\naxis, restricting to households living in low-income ZIPs.?4 Low-income individuals living in areas\nwhere people tend to work in high-rent ZIP codes cut spending by 40% on average from January\nto April 2020, compared with 25% for those living in areas where people tend to work in low-rent\nZIPs. The relationship remains similar when we compare ZIP codes within the same county and\ncontrol for rents in the home (residential) ZIP code (Appendix Table 5).\n\nIn sum, reductions in spending by high-income households due to concerns about COVID\n\ninfection led to persistent negative impacts on employment and spending for low-income workers\n\n \n\n33. In the Earnin microdata, we find similar results even when comparing workers employed at the same firm (e.g.,\na chain restaurant): people working in high-rent ZIP codes in January remained less likely to have a job (anywhere)\nin July than their co-workers working in a different establishment of the same firm in lower-rent ZIP codes.\n\n34. We restrict this figure to households living in low-income ZIPs because we cannot disaggregate the Affinity\ndata by individual-level income. Since the Earnin data already represent only low-income workers, we do not restrict\nto low-income ZIPs in the employment analysis above; however, the patterns are very similar when restricting to\nlow-income ZIPs in the Earnin data.\n\n30",
    "Page_33": "working in affluent areas.®°\n\nIV Evaluation of Policy Responses to COVID-19\n\nWe have seen that a chain of events led to substantial employment losses following the COVID-19\nshock: (1) reductions in spending by high-income individuals due to health concerns, (2) revenue\nlosses for businesses catering to those customers, and (3) persistent employment losses for low-\nincome workers working at those businesses. We now turn to study what type of policies can\nmitigate the economic impacts of the pandemic, focusing in particular on increasing employment\namong low-income workers. We study three sets of policies that targeted different points of the\neconomic chain: (1) state-ordered business reopenings that removed barriers to economic activity;\n(2) stimulus payments to households, which aimed to spur consumer spending and thereby increase\n\nemployment; and (3) loans to small businesses, which provided liquidity to keep workers on payroll.\n\nIV.A  State-Ordered Reopenings\n\nOne direct approach to changing consumer spending and employment is via executive orders. Many\nstates enacted stay-at-home orders and shutdowns of businesses in an effort to limit the spread of\nCOVID infection and later reopened their economies by removing these restrictions. We begin by\nexamining how such executive orders affect economic activity, exploiting variation across states in\nthe timing of shutdowns and reopenings. Throughout this section, we define the reopening date to\nbe the day that a state began the reopening process (see Appendix G for details). In most states,\nreopening was a gradual process in which certain industries and types of businesses opened before\nothers, but there was a lot of heterogeneity across states in the precise form that the reopening\nook. Our estimates should therefore be viewed as an assessment of the average impact of typical\nreopening efforts on aggregate economic activity; we defer a more detailed analysis of how different\npes of reopenings affected different sectors (which can be undertaken with the data we have made\npublicly available) to future work.\n\nWe begin with a case study comparing Colorado and New Mexico that is representative of our\noroader findings. These two states both issued stay-at-home orders during the final week of March\nNew Mexico on March 24, Colorado on March 26). Colorado then partially reopened its economy,\n\npermitting retail and personal service businesses to open to the public, on May 1, while New Mexico\n\n \n\n35. In future work, this source of geographic variation in displacement rates could potentially be used to study\n\n \n\nurther downstream impacts on a range of other financial and economic outcomes, as in Mian and Sufi (2009).\n\n31",
    "Page_34": "did not reopen until two weeks later, on May 16. Figure 12a plots consumer spending (using the\nAffinity Solutions data) in Colorado and New Mexico. Spending evolved nearly identically in\nthese two states: in particular, there is no evidence that the earlier reopening in Colorado boosted\nspending during the two intervening weeks before New Mexico reopened.\n\nFigure 12b generalizes the case study in Figure 12a by studying partial reopenings in the five\nstates that issued such orders on or before April 27. For each reopening date (of which there are\nthree: April 20, 24, and 27), we compare the trajectory of spending in treated states to a group of\ncontrol states that had not reopened at the time that the treated state reopened. We select at least\nthree control states (listed in Appendix Table 6) for each of the reopening dates by matching on\npre-period levels of spending (relative to January) during the three weeks prior to reopening. We\nthen calculate unweighted means of the outcome variables in the control and treatment states to\nconstruct the two series for each reopening date. Finally, we pool these three event studies together\n(redefining calendar time as time relative to the reopening date) to create Figure 12b.\n\nAs in the case study of Colorado vs. New Mexico, the trajectories of spending in the treated\nstates almost exactly mirror those in the control states. We formalize the estimate from this design\nusing a difference-in-differences (DD) design that compares the two weeks before the reopening in\nthe treated states and two weeks after. We estimate that reopenings led to a 1.43 percentage point\nincrease in spending. This DD estimate also appears in Table 3, Column 1. Column 2 replicates that\nspecification, but focuses on reopenings where we can go out three weeks after the event before\ncontrol states begin to reopen; the DD estimate is unchanged with this wider window, at 1.37\npercentage points. Figure 12c shows that we also find little impact of reopenings on employment\n(using the Paychex-Intuit-Earnin data). Finally, Figure 12d shows (using data from Womply) that\nthere was a 3.27 percentage point increase in the fraction of small businesses open after states\nallowed businesses to reopen — confirming that state orders did have some mechanical impact on\nthe fraction of businesses that were open. However, this mechanical effect does not appear to\ntranslate to noticeable impacts on total employment or spending.\n\nIn line with these small treatment effect estimates, reopenings accounted for a relatively small\nshare of the overall variation in economic conditions across states. To demonstrate this, we first\ncalculate the actual variance in spending levels and other outcomes across states. We then coun-\nterfactually add our estimated effect of reopening to all states that were not yet open as of May 18,\nand recalculate the variance. Figure 12e then plots 1 minus the ratio of the counterfactual variance\n\nto the actual variance, which is a measure of the importance of early reopenings in explaining the\n\n32",
    "Page_35": "variation in economic activity observed on May 18. These ratios are very low, showing that early\nreopenings did not play an important role in explaining why some states had stronger employment\ntrajectories than others.°° These results are consistent with the findings of other contemporaneous\nstudies showing that little of the state-level variation in employment, job vacancies, or time spent\noutside home is related to state-level stay-at-home orders or business closures (Bartik et al. 2020,\nForsythe et al. 2020, Goolsbee and Syverson 2020, Lin and Meissner 2020, Villas-Boas et al. 2020).\n\nWhy did these reopenings have so little immediate impact on economic activity? The evidence\nin Section HI suggests that health concerns among consumers were the primary driver of the\nsharp decline in economic activity in March and April. Consistent with that evidence, spending fell\nsharply in most states before formal state closures (Appendix Figure 12). If individuals’ own health\nconcerns are the core driver of reductions in spending during pandemics, governments may have\nlimited capacity to mechanically restore economic activity through reopenings if those reopenings\n\nare not interpreted by consumers as a signal of reduced health risks.?7\n\nIV.B_ Stimulus Payments to Households\n\nThe Coronavirus Aid, Relief, and Economic Security (CARES) Act made direct payments to nearly\n160 million people, totaling $267 billion as of May 31, 2020. Individuals earning less than $75,000\nreceived a stimulus payment of $1,200; married couples earning less than $150,000 received a\npayment of $2,400; and households received an additional $500 for each dependent they claimed.\nThese payments were reduced at higher levels of income and phased out entirely for households with\nincomes above $99,000 (for single filers without children) or $198,000 (for married couples without\nchildren). IRS statistics show that 72% of stimulus payments made in April were direct-deposited\non exactly April 15, 2020, while some households received payments on April 14 (Bureau of the\nFiscal Service 2020). The goal of these stimulus payments was to increase consumer spending and\nrestore employment. Was the stimulus effective in achieving these goals?\n\nImpacts on Consumer Spending. We estimate the causal effect of the stimulus payments using\na regression discontinuity design. Figures 13a-b plot raw daily card spending levels relative to\n\nJanuary for low-income (bottom income quartile ZIP codes) and high-income households (top\n\n \n\n36. We emphasize that these results apply to average employment rates and are thus not inconsistent with evidence\nof modest impacts in specific subsectors, particularly at higher wage levels, as identified e.g., by Cajner et al. (2020).\n\n37. In this vein, we stress that our research design only identifies the impacts of individual states opening earlier vs.\nlater; if one state’s actions impact behavior in other states (e.g., by shaping perceptions about health risks), the total\nimpacts of shutdowns or reopenings at a national level could be larger. Moreover, these conclusions only apply to\nthe initial stages of the pandemic that we study here. If health concerns diminish over time (e.g., due to quarantine\nfatigue), government restrictions could have larger effects on economic activity.\n\n33",
    "Page_36": "income quartile ZIP codes) for the month of April. To reduce cyclical patterns, we residualize daily\nspending levels with respect to day-of-week and first-day-of-month fixed effects, estimated using\ndata for the period January 1, 2019 to May 10, 2019.\n\nSpending levels jumped sharply from April 13th to 15th. Fitting linear control functions to the\npoints on either side of April 15, we estimate that spending levels rose discontinuously on April 15 by\n25 pp for low-income households and 8 pp in high-income households.*® Both effects are statistically\nsignificantly different from 0, as well as from each other.®? Panel A of Table 4 shows that these\nregression discontinuity estimates remain similar under varying bandwidths. These findings are\nconsistent with contemporaneous work by Baker et al. (2020) and Karger and Rajan (2020), who use\nindividual transaction data on incomes and spending patterns of approximately 15,000 primarily\nlow-income individuals to estimate a large and immediate effect of receiving a stimulus check\non spending, especially among low-income households. Together, these results provide empirical\nsupport for models that generate excess sensitivity of consumption to anticipated temporary income\nshocks (e.g., Campbell and Mankiw 1989, Kaplan and Violante 2014).\n\nIn Figures 13c-d, we investigate the composition of goods on which households spent their\nstimulus checks. We pool all households in these figures to maximize precision. Spending on\ndurable goods rose by 21 percentage points following the arrival of the stimulus payments and\nfurther increased thereafter, rising well above pre-crisis levels. But spending on in-person services\nrose by only 7 percentage points, remaining more than 50% below pre-crisis levels. Durable goods\naccounted for 44% of the recovery in spending levels from the beginning to the end of April, while\nin-person services accounted for just 18% of the recovery (Appendix Figure 13). The stimulus thus\nincreased the overall level of spending, but did not channel money back to the businesses that\nlost the most revenue due to the COVID shock. These findings provide empirical evidence for the\n“broken Keynesian cross” mechanism established in the Guerrieri et al. (2020)’s model, where funds\nare not recirculated back to the sectors shut down by the pandemic, diminishing multiplier effects.\n\nImpacts on Business Revenue Across Areas. Next, we investigate how the stimulus affected\nbusiness revenues. In particular, did the businesses that lost the most revenue — those in high-rent\n\nareas — gain business as as result of the stimulus? Figures 14a and 14b replicate the analysis above\n\n \n\n38. We omit the partially treated date of April 14 (denoted by a hollow dot) when estimating this RD specification\nsince a small fraction of stimulus payments arrived on that day.\n\n39. We expect the stimulus program to have a smaller impact on high-income households for three reasons. First,\nlower-income households simply received more money than high-income households. Second, low-income households\nspent half as much as high-income households prior to the COVID shock (Figure 2a), and hence one would expect a\nlarger impact on their spending levels as a percentage of baseline spending. Finally, many studies have found higher\nmarginal propensities to consume (MPCs) among lower-income households, who are often more liquidity constrained.\n\n34",
    "Page_37": "using Womply data on small business revenues as the outcome, separately for lowest-rent-quartile\nand highest-rent-quartile ZIP codes. We see a sharp increase of 18 percentage points in revenues in\nsmall businesses in low-rent neighborhoods exactly at the time when households received stimulus\npayments. In contrast, Panel B shows a small, statistically insignificant increase in revenues of 1\npercentage point for small businesses in high-rent areas.\n\nThis geographic heterogeneity illustrates another important dimension in which the stimulus\ndid not channel money back to the business that lost the most revenue from the COVID shock.\nIn fact, the stimulus actually amplified the difference in small business revenue losses rather than\nnarrowing it across areas. Those in low-rent areas have nearly returned to pre-crisis levels following\nthe stimulus payments, while those in high-rent areas remained more than 20% down relative to\nJanuary levels (Figure 14c, blue lines). Panel B of Table 4 shows these regression discontinuity\nestimates remain similar under varying bandwidths.\n\nImpacts on Employment. Finally, we investigate whether the increase in spending induced by\nthe stimulus increased employment rates, as one would expect in a traditional Keynesian stimulus.\nHere, we do not use the RD design as we do not expect employment to respond immediately to\nincreased spending. Instead, we analyze the evolution of employment of low-wage workers in the\nEarnin data in low- vs. high-rent ZIP codes over time in Figure 14c (orange lines). In high-rent\nareas, low-wage employment remained 45% below pre-COVID levels as of the end of April — perhaps\nnot surprisingly, since revenues have not recovered significantly there. But even in low rent areas,\nemployment has recovered only partially, despite the fact that small business revenues have reverted\nto pre-COVID baseline levels. This result echoes the divergence between employment and revenue\nat the sectoral level documented above in Figure 7c and again raises the specter of a jobless recovery\nfor low-wage workers.\n\nIn summary, the stimulus substantially increased total consumer spending but did not directly\nundo the initial spending reductions by returning money back to the businesses that lost the most\nrevenue. This empirical impact contrasts with theoretical motivations for stimulus in response\nto shocks. In particular, Farhi and Werning (2016) show that optimal macroprudential policy\ninvolves a stimulus that increases spending in sectors and areas whose demand is depressed. In a\nfrictionless model where businesses and workers could costlessly reallocate their capital and labor\nto other sectors, the reallocation of spending across sectors and areas might have no consequence\nfor employment levels. But if workers’ ability to switch jobs is constrained — e.g., because of job-\n\nspecific skills that limit switching across industries or costs that limit moving across geographic\n\n35",
    "Page_38": "areas, as suggested by Yagan (2019) — the ability of the stimulus to foster a uniform recovery in\nemployment to pre-COVID levels is likely to be hampered, perhaps explaining why employment\n\nlevels remained well below baseline even as total spending recovered after April 15.\nIV.C_ Loans to Small Businesses\n\nWe now evaluate the Paycheck Protection Program (PPP), which sought to reduce employment\nlosses by providing financial support to small businesses. Congress appropriated nearly $350 billion\nfor loans to small businesses in an initial tranche paid beginning on April 3, followed by another\n$175 billion in a second round beginning on April 27. The program offered loan forgiveness for\nbusinesses that maintained sufficiently high employment (relative to pre-crisis levels).\n\nAccording to the House Committee on Small Business (2020), the stated primary purpose of\nthe PPP was to encourage businesses to maintain employment even as they lost revenue. The\nSmall Business Administration (2020a) emphasized the employment impacts of the PPP as a key\nmeasure of the program’s success, noting that the PPP “ensure[d] that over approximately 50\nmillion hardworking Americans stay[ed] connected to their jobs” based on self-reports of the number\nof jobs retained by firms that received PPP assistance.\n\nHere, we study the marginal impacts of the PPP on employment directly using payroll data,\nexploiting the fact that eligibility for the PPP depended on business size. Firms with fewer than\n500 employees before the COVID crisis qualified for PPP loans, while those with more than 500\nemployees generally did not. One important exception to this rule was the food services industry,\nwhich was treated differently because of the prevalence of franchises. We therefore omit the food\nservices sector from the analysis that follows./°\n\nWe estimate the causal effect of the PPP on employment rates at small businesses using a\ndifference-in-differences research design, comparing trends in employment for firms below the 500\nemployee cutoff (the treated group) vs. those above the 500 employee cutoff (the control group)\n\nbefore vs. after April 3, when the PPP program began.‘!\n\nFigure 15a plots the average change\nin employment rates (inferred from payroll deposits) relative to January for firms in the Paychex-\n\nEarnin data employing 100-500 employees, which were eligible for PPP loans, vs. firms employing\n\n \n\n40. The remaining exceptions to this rule affect relatively few workers: omitting food services, more than 90% of\nemployees work at firms that face the 500 employee threshold for eligibility.\n\n41. Firms with more than 500 employees were still eligible for the Employee Retention Credit (ERC), which gave all\nfirms that lost more than 50% of their revenue a tax credit worth up to $5,000 per employee if they did not take up the\nPPP. While data on ERC takeup are unavailable, fewer than 10% of CFOs of large firms report revenue losses larger\nthan 25% (PwC 2020), suggesting that the vast majority of firms with more than 500 employees were not eligible for\nthe ERC and hence serve as a valid counterfactual for employment in the absence of government assistance.\n\n36",
    "Page_39": "501-800 employees, which were generally ineligible for PPP loans.4? To adjust for the fact that\nindustry composition varies across firms of different sizes, we reweight by two-digit NAICS code\nso that the distribution of industries in the below-500 and above-500 employee groups match the\noverall distribution of industries in January 2020 when computing mean employment rates by firm\nsize. We also residualize employment rates by county x wage quartile x week fixed effects, to\naccount for the differential time patterns of employment rates by county and wage quartile shown\nin Section HI.C.\n\nBefore April 3, trends in employment were similar among eligible vs. ineligible firms, showing\nthat larger businesses provide a good counterfactual for employment trends one would have observed\nin smaller firms absent the PPP program (conditional on the reweighting and controls described\nabove). After April 3, employment continued to follow a similar trajectory in the treated (<500\nemployees) and control (>500 employees) groups, with at most a relative increase of 2 pp in the\ntreated group until August, after which employment rates in the two groups are essentially identical\nagain. These findings imply that the PPP program had little marginal impact on employment at\nsmall businesses under the identification assumption that employment trends in the two groups\nwould have remained similar absent the PPP.\n\nFigure 15b plots the change in employment from January 4-January 31 to June 1-June 23 by\nfirm size bin. The decline in employment is quite similar across firm sizes, and is not markedly\nsmaller for firms below the 500 employee eligibility threshold.4? Appendix Figure 14 shows that we\nobtain very similar results in the Earnin data alone.“4\n\nIn Table 5, we quantify the impacts of the PPP using OLS regressions of the form:\n\nEmPseqit = Yegt + OEligible, + yPost-PPP; + BppEligible, - Post-PPP; + Eseqit, (1)\n\n \n\nwhere Emp,.gi, is the change in employment within each firm size category s x county c x wage\nquartile g x 2-digit NAICS industry 7 on week ¢ cell, relative to January 4-January 31, Eligible,\nis an indicator variable for whether firm size is 500 or fewer employees in the pre-COVID period,\nPost-PPP; is an indicator variable for the date being on or after 3 April 2020, and acgt represents\na county-week-wage quartile fixed effect. We estimate this regression on the sample of firms with\n\n100-800 employees using data from March 11 to August 15. We focus on employment impacts up\n\n \n\n42. Since Intuit consists primarily of firms with fewer than 20 employees, we omit it from this analysis.\n\n43. Because of differences in the measurement of firm sizes in our data and the SBA data used to determine PPP\neligibility (see below), there is no sharp discontinuity in eligibility at the 500 cutoff. Hence, we do not interpret this\nplot using an RD design, but rather view it as showing that our estimates are insensitive to the bandwidth used to\ndefine the treatment and control groups in the DD analysis.\n\n44. Our data use agreements do not permit us to report results based solely on Paychex data.\n\n \n\n37",
    "Page_40": "to August 15 because Figure 15a suggests that employment rates in the two groups converged after\nearly August (extending the estimation window would only further reduce the estimated impacts\nof the PPP). We reweight by two-digit NAICS code so that the distributions of industries in the\nbelow-500 and above-500 employee groups both match the overall distribution of industries in\nJanuary 2020. We cluster standard errors at the county-by-industry-by-firm-size level to permit\ncorrelation in errors across firms and over time within counties and estimate the regression using\nOLS, weighting by the total number of employees in the cell from January 4-31, 2020.\n\nColumn 1 presents the baseline estimate obtained from regression equation (1) of Bpp = 1.78\n(s.e. = 1.99), an estimate that matches the figure plotted in Figure 15a and is similar to that\nobtained in confidential ADP data in contemporaneous work by Autor et al. (2020). The mean\ndecline in employment among firms in the control group to August 15 was 18.7%, implying that\nthe PPP saved 9.1% of the jobs that would otherwise have been lost between April and August\n2020. In Column 2, we reduce the bandwidth to focus more narrowly around the 500-employee size\nthreshold; the estimates remains statistically indistinguishable from that in Column 1. Columns\n3 and 4 replicate the specification in Column 1, using data from Earnin and Kronos, respectively.\nThe estimates from these data sources (which apply to workers in the bottom wage quartile) are\nsimilar to our baseline estimate.\n\nOur difference-in-differences research design identifies the causal effect of the PPP on eligible\nfirms under the assumption that the PPP did not have a causal effect on employment at PPP-\nineligible firms. It is possible that the PPP reduced employment at ineligible firms (relative to\nthe no-PPP counterfactual) through an employment substitution channel: ineligible firms might\nhave hired workers laid off from eligible firms in the absence of the PPP. In the presence of such\nsubstitution, our DD estimate would overstate the causal effect of the PPP on employment at\nsmall businesses, providing an upper bound for its partial equilibrium impact (ignoring general\nequilibrium effects that may have influenced consumer demand and employment at all firms).\n\nMeasurement Error in Firm Sizes. Our measures of firm size — which are based on employment\nlevels in 2018 from the ReferenceUSA database for the Earnin sample and employment levels in 2019\nfrom Dun & Bradstreet data for the Paychex sample — do not correspond perfectly to the measures\nused by the Small Business Administration to determine PPP eligibility. Such measurement error\nin firm size attenuates the estimates of 8pp obtained from (1) relative to the true causal effect of\nPPP eligibility because some of the firms classified as having more than 500 employees may have\n\nactually received PPP (and vice versa). We estimate the degree of this attenuation bias by matching\n\n38",
    "Page_41": "our data on firm sizes to data publicly released by the Small Business Administration (SBA) on\na selected set of PPP recipients and assessing the extent to which firms are misclassified around\nthe threshold. We estimate that our reduced-form estimates are attenuated by 35% based on this\nmatched data (see Appendix D for details). Under standard assumptions required to obtain a local\naverage treatment effect in the presence of non-compliance — no direct effect of being classified as\nhaving more than 500 workers independent of the PPP and a monotonic treatment effect — we can\nestimate the LATE of the PPP on employment rates by multiplying the raw estimates reported in\nTable 1 by 1.35 (Angrist, Imbens, and Rubin 1996). This gives us a final preferred point estimate\n\nfor the effect of PPP eligibility on employment of 2.41 percentage points.\n\n \n\nCosts Per Job Saved. Using SUSB data, we calculate that approximately 53.6 million workers\nwork at firms eligible for PPP assistance, excluding firms in NAICS 72 (for details, see Appendix\nD). Under the assumption that the PPP’s effects on firms with between 100 and 500 employees\nwere the same in percentage terms as the PPP’s effects on all eligible firms, our baseline estimates\nin the combined Paychex-Earnin data (Column 1 of Table 5), adjusted for attenuation bias, imply\nthat the PPP saved 0.02 x 53.6M = 1.29 million jobs from April through August 15.4° Given a\ntotal expenditure on the PPP program of $486 billion through August 8 (excluding firms in food\nservices), this translates to an average cost per job saved (over the five months between April and\nAugust) of $377,000. Even at the upper bound of the 95% confidence interval for employment\nimpact, we estimate a cost per job saved of $119,000. For comparison, mean annual earnings for\nworkers at PPP-cligible firms are only $45,000.\n\nWhy did the PPP have relatively small effects on employment rates despite having a very high\ntakeup rate among small businesses? One potential explanation is that the loans were taken by\nfirms that did not intend to layoff many employees to begin with, i.e. firms that were inframarginal\nrecipients of loans. Consistent with this hypothesis, Granja et al. (2020) show that states and con-\ngressional districts that experienced more job losses prior to April 3 actually received fewer PPP\nloans. Moreover, PPP loans also were not distributed to the industries most likely to experience\njob losses from the COVID crisis. For example, firms in the professional, scientific, and technical\nservices industry received a greater share of the PPP loans than accommodation and food services\n(SBA 2020). Yet accommodation and food services accounted for half of the total decline in employ-\n\nment between February and March (prior to PPP enactment) in BLS statistics, while employment\n\n \n\n45. If the treatment effect of the PPP program on food services were the same in percentage terms as in other\nsectors, we estimate the PPP saved a total of 1.51 million jobs.\n\n39",
    "Page_42": "in professional, scientific and technical services accounted for less than 5% of the decline.\nAlthough the PPP had modest impacts on employment, it may have had other benefits, such as\n\nreducing the rate of business closures. As emphasized by Hubbard and Strain (2020), if the costs\n\nof closing and restarting businesses are sufficiently large, the PPP may have still have significant\n\nbenefits over time — an important question for future research.\n\nV_ Conclusion\n\nTransactional data held by private companies have great potential for measuring economic activity,\nbut to date have been accessible only through contracts to work with confidential microdata. In\nthis paper, we have constructed a public database to measure economic activity at a high-frequency,\ngranular level using data from private companies. By aggregating and masking the underlying micro\ndata, we construct series that can be released publicly without disclosing sensitive information, yet\nare well suited to answer a variety of research questions.\n\nWe apply these new data to analyze the economic impacts of COVID-19. We find that COVID-\n19 induced high-income households to self-isolate and sharply reduce spending in sectors that require\nphysical interaction. This spending shock in turn led to losses in business revenue and layoffs of\nlow-income workers at firms that cater to high-income consumers. Because the root cause of the\nshock was self-isolation driven by health concerns, there was limited capacity to restore economic\nactivity without addressing the virus itself, at least in the initial months after the pandemic began\nin mid-March. In particular, state-ordered reopenings of economies had only modest impacts on\neconomic activity; stimulus checks increased spending particularly among low-income households,\nbut very little of the additional spending flows to the businesses most affected by COVID; and loans\nto small businesses had little impact on employment rates. Our analysis therefore suggests that\nthe most effective approach to mitigating economic hardship in the midst of a pandemic may be to\nprovide benefits to those who have lost their incomes to mitigate consumption losses, while investing\nin public health measures to restore consumer confidence and ultimately increase spending.\n\nWe focused in this paper on the short-run economic consequences of COVID-19. However, such\nshocks can also have long-lasting scarring effects. Private sector data can be useful in measuring\nthese impacts as well. To illustrate, Figure 16 plots weekly student progress (lessons completed)\non Zearn, an online math platform used by nearly one million elementary school students as part\nof their regular school curriculum. Children in high-income areas temporarily learned less on this\n\nplatform when the COVID crisis hit and schools shifted to remote instruction, but soon recovered\n\n40",
    "Page_43": "to baseline levels. By contrast, children in lower-income areas remained 50% below baseline levels\nthrough the end of the school year. Although this platform captures only one aspect of education,\nthese findings raise the concern that pandemics may amplify inequality in the long-run by hindering\nhuman capital development especially for lower-income children.\n\nBeyond its implications for the economics of pandemics, our analysis demonstrates two ways\nin which the public database constructed here provides a new tool for empirical macroeconomics.\nFirst, the data can be used to learn rapidly from sub-national heterogeneity, as different places,\nsectors, and subgroups are often hit by different shocks and pursue different local policy responses.\nAnalyzing such heterogeneity can permit rapid diagnosis of the root factors underlying an economic\ncrisis. Second, the data permit rapid policy evaluation — often within three weeks of implementation\n\nopening a path to fine-tuning policy responses in an evidence-based manner.\n\nThe advantage of constructing a public database to conduct such analyses rather than working\ndirectly with the confidential data held by private sector firms is that it permits a much broader\nrange of work along these lines. For example, the data are now being used by local policymakers to\ninform local policy responses and forecast tax revenue impacts (e.g., Maine, Missouri, Kansas, and\nTexas). They are also being used by Congressional staff to design federal policies, e.g. predicting\nthe impacts and costs of policies targeted based on business revenue losses (RESTART Act 2020).\nAnd they are being used by other researchers to analyze a broad range of issues: constructing price\nindices that account for changes in consumption bundles (Cavallo 2020), analyzing the effects of\npolitical views on economic outcomes (Makridis and Hartley 2020), estimating the effects of the\nPPP on smaller firms’ employment decisions (Granja et al. 2020), and estimating the impacts of\nunemployment benefits on aggregate spending (Casado et al. 2020).\n\nOver the 20th century, the Bureau of Economic Analysis built on a prototype developed by\nKuznets (1941) to institute surveys of businesses and households that form the basis for today’s\nNational Income and Product Accounts. The database built here can be viewed as a prototype\nfor a system of granular, real time national accounts built using transactional private sector data.\nEven this first prototype yields insights that cannot be obtained from existing data, suggesting that\na broader, more refined platform that aggregates data from private companies has great potential\n\nfor improving our understanding of economic activity and policymaking going forward.*®\n\n \n\n46. We view such data as a complement to rather than replacement for survey-based national accounts. Data from\nrepresentative surveys will remain essential to obtain consistent statistics on national aggregates and to benchmark\nprivate sector data sources; private sector data serve to increase granularity and precision.\n\n41",
    "Page_44": "References\n\nAbraham, Katharine G, Ron S Jarmin, Brian Moyer, and Matthew D Shapiro (ed.) 2019. Big Data\nfor 21st Century Economic Statistics. NBER Book Series Studies in Income / Wealth.\n\nAladangady, Aditya, Shifrah Aron-Dine, Wendy Dunn, Laura Feiveson, Paul Lengermann, and\nClaudia Sahm. 2019. “From Transactions Data to Economic Statistics: Constructing Real-time,\nHigh-frequency, Geographic Measures of Consumer Spending.” NBER Working Paper No.\n26253 (September). https: //doi.org/10.3386/w26253. http: //www-nber.org/papers/w26253.\n\nAlexander, Diane, and Ezra Karger. 2020. “Do stay-at-home orders cause people to stay at home?\nEffects of stay-at-home orders on consumer behavior.” Federal Reserve Bank of Chicago Work-\ning Paper No. 2020-12 (April). https: / / doi.org /10.21033 / wp- 2020-12. https: // www.\nchicagofed.org/publications/working-papers/2020/2020-12.\n\nAllen, Danielle, Sharon Block, Joshua Cohen, Peter Eckersley, and Meredith Rosenthal. 2020.\n“Roadmap to Pandemic Resilience: Massive Scale Testing, Tracing, and Supported Isolation\n(TTSI) as the Path to Pandemic Resilience for a Free Society.” Edmond J. Safra Center For\nEthics At Harvard University.\n\nAltonji, Joseph, Zara Contractor, Lucas Finamor, Ryan Haygood, Ilse Lindenlaub, Costas Meghir,\n\n \n\nCormac O’Dea, Dana Scott, Liana Wang, and Ebonya Washington. 2020. “Employment Effects\n\nof Unemployment Insurance Generosity During the Pandemic.” Yale University Manuscript.\n\n \n\n \n\nAngrist, Joshua D, Guido W Imbens, and Donald B Rubin. 1996. “Identification of causal effects\nusing instrumental variables.” Journal of the American statistical Association 91 (434): 444\n455.\n\nAustin, Benjamin A, Edward L Glaeser, and Lawrence H Summers. 2018. “Jobs for the Heartland:\nPlace-based policies in 21st century America.” NBER Working Paper No. 24548 (April). https:\n//www.nber.org/papers/w24548.\n\n \n\nAutor, David, David Cho, Leland D Crane, Mita Goldar, Byron Lutz, Joshua Montes, William\nB Peterman, David Ratner, Daniel Villar, and Ahu Yildirmaz. 2020. An Evaluation of the\n\nPaycheck Protection Program Using Administrative Payroll Microdata. Technical report.\n\nBaker, Scott R, R. A Farrokhnia, Steffen Meyer, Michaela Pagel, and Constantine” Yannelis. 2020.\n“Income, Liquidity, and the Consumption Response to the 2020 Economic Stimulus Payments.”\nNBER Working Paper No. 27097.\n\nBartik, Alexander W., Marianne Bertrand, Feng Lin, Jesse Rothstein, and Matt Unrath. 2020.\n“Measuring the labor market at the onset of the COVID-19 crisis.” Brookings Papers on\nEconomic Activity (June). https://www.brookings.edu/wp-content /uploads/2020/06/Bartik-\n\net-al-conference-draft.pdf.\n\n42",
    "Page_45": "Bartlett, Robert P, and Adair Morse. 2020. “Small Business Survival Capabilities and Policy Ef\nfectiveness: Evidence from Oakland.” NBER Working Paper No. 27629.\n\nBennet, M. 2020. “S 3814-RESTART Act.” Senate - Finance Committee.\n\nBerger, David. 2012. “Countercyclical restructuring and jobless recoveries.”\n\nBlanchard, Olivier, and Lawrence Katz. 1992. “Regional Evolutions.” Brookings Papers on Eco-\nnomic Activity 1992 (1): 1-61.\n\nBoard of Governors of the Federal Reserve System. 2019. The 2019 Federal Reserve Payments\nStudy.\n\nBureau of the Fiscal Service. 2020. Daily Treasury Statement: Issues: Current and Archive.\n\nCajner, Tomaz, Leland D Crane, Ryan A Decker, Adrian Hamins-Puertolas, and Christopher Kurz.\n2019. Improving the Accuracy of Economic Measurement with Multiple Data Sources: The Case\n\nof Payroll Employment Data. Technical report. National Bureau of Economic Research.\n\nCajner, Tomaz, Leland D. Crane, Ryan A. Decker, John Grigsby, Adrian Hamins-Puertolas, Erik\nHurst, Christopher Kurz, and Ahu Yildirmaz. 2020. “The U.S. Labor Market during the Be-\n\nginning of the Pandemic Recession.” Working Paper (May).\n\nCampbell, John Y, and N Gregory Mankiw. 1989. “Consumption, income, and interest rates: Rein-\n\nterpreting the time series evidence.” NBER Macroeconomics Annual 4:185-216.\n\nCarnevale, Anthony P, Tamara Jayasundera, and Dmitri Repnikov. 2014. “Understanding online\njob ads data.” Georgetown University, Center on Education and the Workforce, Technical\n\nReport (April).\nCasado, Miguel Garza, Britta Glennon, Julia Lane, David McQuown, Daniel Rich, and Bruce A\nWeinberg. 2020. “The Effect of Fiscal Stimulus: Evidence from COVID-19.”\n\nCavallo, Alberto. 2020. “Inflation with Covid Consumption Baskets.”\n\nChen, Haiqiang, Wenlan Qian, and Qiang Wen. 2020. “The Impact of the COVID-19 Pandemic\non Consumption: Learning from High Frequency Transaction Data.” Working Paper (April).\nhttps: //doi.org/http://dx.doi.org/10.2139/ssrn.3568574. https: //ssrn.com/abstract=3568574.\n\nChetty, Raj, John N Friedman, Emmanuel Saez, Nicholas Turner, and Danny Yagan. 2020. “In-\ncome Segregation and Intergenerational Mobility Across Colleges in the United States.” The\n\nQuarterly Journal of Economics.\n\nChetty, Raj, Nathaniel Hendren, Patrick Kline, and Emmanuel Saez. 2014. “Where is the Land\nof Opportunity? The Geography of Intergenerational Mobility in the United States.” The\nQuarterly Journal of Economics 129 (4): 1553-1623.\n\n43",
    "Page_46": "Coibion, Olivier, Yuriy Gorodnichenko, and Michael Weber. 2020. Labor Markets During the COVID-\n\n19 Crisis: A Preliminary View. Technical report. National Bureau of Economic Research.\n\nCox, Natalie, Peter Ganong, Pascal Noel, Joseph Vavra, Arlene Wong, Diana Farrell, and Fiona\nGreig. 2020. “Initial impacts of the pandemic on consumer behavior: Evidence from linked\n\nincome, spending, and savings data.” Brookings Papers on Economic Activity.\n\nDeming, David, and Lisa B. Kahn. 2018. “Skill Requirements across Firms and Labor Markets:\nEvidence from Job Postings for Professionals.” Journal of Labor Economics 36 (51): S337\n$369. https: //doi.org/10.1086/694106. https: //doi-org/10.1086/694106.\n\nDiamond, Peter, and OJ Blanchard. 1989. “The beveridge curve.” Brookings Papers on Economic\nActivity 1:1-76.\n\nDunn, Abe, Kyle Hood, and Alexander Driessen. 2020. “Measuring the Effects of the COVID-19\nPandemic on Consumer Spending Using Card Transaction Data.” National Bureau of Economic\n\nResearch.\n\nEhrlich, Gabriel, John Haltiwanger, Ron Jarmin, David Johnson, and Matthew D Shapiro. 2019.\n“Re-engineering Key National Economic Indicators.” In Big Data for 21st Century Economic\n\nStatistics. University of Chicago Press.\n\nEichenbaum, Martin 5, Sergio Rebelo, and Mathias Trabandt. 2020. The Macroeconomics of Epi-\n\ndemics. Technical report. National Bureau of Economic Research.\n\nElsby, Michael WL, Ryan Michaels, and David Ratner. 2015. “The Beveridge curve: A survey.”\nJournal of Economic Literature 53 (3): 571-630.\n\nFarhi, Emmanuel, and Ivan Werning. 2016. “A theory of macroprudential policies in the presence\nof nominal rigidities.” Econometrica 84 (5): 1645-1704.\n\nFarrell, Diana, Peter Ganong, Fiona Greig, Max Liebeskind, Pascal Noel, Daniel Sullivan, and\nJoseph Vavra. 2020b. The Unemployment Benefit Boost. Technical report. JPMorgan Chase\nInstitute.\n\nFarrell, Diana, Peter Ganong, Fiona Greig, Max Liebeskind, Pascal Noel, and Joseph Vavra. 2020a.\nConsumption Effects of Unemployment Insurance during the COVID-19 Pandemic. Technical\nreport. JPMorgan Chase Institute.\n\nFeenstra, Robert C, Robert Inklaar, and Marcel P Timmer. 2015. “The next generation of the Penn\nWorld Table.” American Economic Review 105 (10): 3150-82.\n\nForsythe, Eliza, Lisa B Kahn, Fabian Lange, and David Wiczer. 2020. “Labor demand in the time\nof COVID-19: Evidence from vacancy postings and UI claims.” Journal of Public Economics\n189:104238.\n\n44",
    "Page_47": "Ganong, Peter, Pascal J Noel, and Joseph S Vavra. 2020. US Unemployment Insurance Replacement\n\nRates During the Pandemic. Technical report. National Bureau of Economic Research.\n\nGindelsky, Marina, Jeremy Moulton, and Scott A Wentland. 2019. “Valuing housing services in\nthe era of big data: A user cost approach leveraging Zillow microdata.” In Big Data for 21st\n\nCentury Economic Statistics. University of Chicago Press.\n\nGoolsbee, Austan, and Chad Syverson. 2020. Fear, Lockdown, and Diversion: Comparing Drivers\nof Pandemic Economic Decline 2020. Working Paper, Working Paper Series 27432. National\n\nBureau of Economic Research, June. http://www.nber.org/papers/w27339.\n\nGranja, Joao, Christos Makridis, Constantine Yannelis, and Eric Zwick. 2020. “Did the Paycheck\nProtection Program Hit the Target?” NBER Working Paper No. 27095 (May). https: //doi.\norg/10.3386/w27095. http://www-.nber.org/papers/w27095.\n\nGreene, Claire, and Joanna Stavins. 2020. 2019 Diary of Consumer Payment Choice. Technical\n\nreport. Federal Reserve Bank of Atlanta.\n\nGuerrieri, Veronica, Guido Lorenzoni, Ludwig Straub, and Ivan Werning. 2020. Macroeconomic\nImplications of COVID-19: Can Negative Supply Shocks Cause Demand Shortages? Working\nPaper, Working Paper Series 26918. National Bureau of Economic Research, April. https:\n//doi.org/10.3386/w26918. http://www.nber.org/papers/w26918.\n\nHershbein, Brad, and Lisa B. Kahn. 2018. “Do Recessions Accelerate Routine-Biased Technological\nChange? Evidence from Vacancy Postings.” American Economic Review 108, no. 7 (July):\n1737-72. https: //doi.org/10.1257 /aer.20161570. https: //www.aeaweb.org /articles?id=10.\n1257/aer.20161570.\n\nHouse Committee on Small Business. 2020. Oversight of the Small Business Administration and\nDepartment of Treasury Pandemic Programs: Hearing Before The House Committee on Small\n\nBusiness, 116th Cong. (Testimony of Steven Mnuchin).\n\nHubbard, Glenn, and Michael R Strain. 2020. “Has the Paycheck Protection Program Succeeded?”\n\nBrookings Institution.\n\nJacobson, Louis $, Robert J LaLonde, and Daniel G Sullivan. 1993. “Earnings Losses of Displaced\n\nWorkers.” The American Economic Review, 685-709.\n\nJaimovich, Nir, and Henry E Siu. 2020. “Job polarization and jobless recoveries.” Review of Eco-\nnomics and Statistics 102 (1): 129-147.\n\nJaravel, Xavier, and Martin O’Connell. 2020. “Real-time price indices: Inflation spike and falling\n\nproduct variety during the Great Lockdown.” Journal of Public Economics 191.\n\nKaplan, Greg, and Giovanni L Violante. 2014. “A model of the consumption response to fiscal\n\nstimulus payments.” Econometrica 82 (4): 1199-1239.\n\n45",
    "Page_48": "Karger, Ezra, and Aastha Rajan. 2020. “Heterogeneity in the Marginal Propensity to Consume:\nEvidence from Covid-19 Stimulus Payments.” FRB of Chicago Working Paper.\n\nKurmann, André, Etienne Lalé, and Lien Ta. 2020. “The Impact of COVID-19 on U.S. Employment\nand Hours: Real-Time Estimates with Homebase Data” (May). http: //www.andrekurmann.\n\ncom/hb_covid.\n\nKuznets, Simon. 1941. National Income and Its Composition, 1919-1938. New York: National Bu-\n\nreau of Economic Research.\n\nLazear, Edward P., Kathryn L. Shaw, and Christopher Stanton. 2016. “Making Do with Less:\nWorking Harder during Recessions.” Journal of Labor Economics 34 (S1): $333-S360. https:\n//doi.org/10.1086/682406. eprint: https: //doi.org/10.1086/682406. https: //doi.org/10.1086/\n682406.\n\nLin, Zhixian, and Christopher M Meissner. 2020. “Health vs. Wealth? Public Health Policies and\nthe Economy During Covid-19.” NBER Working Paper No. 27099 (May). https://doi.org/10.\n3386/w27099. http://www-nber.org/papers/w27099.\n\nMakridis, Christos, and Jonathan Hartley. 2020. “The Cost of Covid-19: A Rough Estimate of the\n2020 US GDP Impact.”\n\nMathy, Gabriel. 2020. The COVID-19 Epidemic will be the First Services Recession and it Could\nbe a Bad One.\n\nMian, Atif, and Amir Sufi. 2009. “The consequences of mortgage credit expansion: Evidence from\nthe US mortgage default crisis.” The Quarterly Journal of Economics 124 (4): 1449-1496.\n\nMorath, Eric. 2020. “Federal Government Sent Workers Nearly 250Billionin600-a-Week Jobless\nAid.” The Wall Street Journal.\n\nPaychex. 2020. Small Business Employment Watch. https: / / www .paychex.com /employment-\nwatch/#!/, April.\n\nPetev, Ivaylo, Luigi Pistaferri, and Itay Saporta Eksten. 2011. Consumption and the Great Reces-\n\nsion: An analysis of trends, perceptions, and distributional effects.\n\nPew Research Center. 2020. 2020 Pew Research Center’s American Trends Panel Wave 68 June\n2020 Final Topline.\n\nPwC. 2020. PwC US CFO Pulse Survey. Technical report. June. https://www.pwe.com/us/en/\n\nlibrary /covid-19/pwe-covid-19-cfo-pulse-survey.html.\n\nRomer, Paul. 2020. “Roadmap to Responsibly Reopen America.” roadmap.paulromer.net, http:\n\n//roadmap.paulromer.net.\n\n46",
    "Page_49": "Small Business Administration. 2020a. Joint Statement by SBA Administrator Jovita Carranza and\nU.S. Treasury Secretary Steven T. Mnuchin Regarding Enactment of the Paycheck Protection\nProgram Flexibility Act.\n\n \n\n. 2020b. Paycheck Protection Program (PPP) Report. Technical report. May. https://www.\nsba.gov/document/report--paycheck- protection-program-ppp-report.\n\nSullivan, Daniel, and Till von Wachter. 2009. “Job Displacement and Mortality: An Analysis Using\nAdministrative Data.” The Quarterly Journal of Economics 124 (3): 1265-1306.\n\nSummers, Robert, and Alan Heston. 1984. “Improved International Comparisons of Real Product\nand its Composition: 1950-1980.” Review of Income and Wealth 30 (2): 207-219.\n\n. 1991. “The Penn World Table (Mark 5): an expanded set of international comparisons,\n1950-1988.” The Quarterly Journal of Economics 106 (2): 327-368.\n\n \n\nU.S. Bureau of Economic Analysis. 2020. National Income and Product Accounts. Data retrieved\n\nfrom U.S. Bureau of Economic Analysis, National Income and Product Accounts.\n\nU.S. Department of Commerce. 2020. U.S. Census Bureau News (Tuesday, 18 August, 2020). Tech-\n\nnical report.\n\nVillas-Boas, Sofia B, James Sears, Miguel Villas-Boas, and Vasco Villas-Boas. 2020. “Are We #Stay-\ningHome to Flatten the Curve?” UC Berkeley: Department of Agricultural and Resource Eco-\nnomics CUDARE Working Papers (April). https://escholarship.org/uc/item/5h97n884.\n\nYagan, Danny. 2019. “Employment Hysteresis from the Great Recession.” Journal of Political\nEconomy 127 (5): 2505-2558.\n\n47",
    "Page_50": "Online Appendix\n\nA Automated Data Processing Pipeline\n\nThis appendix describes the automated pipeline we built to ingest raw data, process it to construct\naggregate statistics, and then release those statistics publicly. This automated pipeline allows us to\ntypically post updated statistics within one business day of receiving the raw data. By automating\nthe data processing to the extent possible, we aim to post data as close to real-time as possible,\nwhile maintaining the quality of the data and minimizing the manual upkeep required. The primary\nsource of lags in the posted data is therefore driven by lags in the underlying data generating\nprocesses: for example, card transactions can take up to a week to settle and employment income\nis typically paid in bi-weekly or monthly payrolls. We summarize our data engineering methods\nhere for those who may be interested in setting up similar infrastructure in other contexts.\n\nStep 1: Data Ingestion. In order to flexibly accommodate diverse data sources, with varying\nsecure file transfer methods and update frequencies, we operate a server in the cloud that pulls up-\ndated data from each source on a regular interval. We receive data updates from private companies\non a daily, weekly or monthly cadence. Many companies have unique policies and requirements for\nsecuring data transfers, so we write scripts to intake this data using a variety of secure file transfer\nservices (e.g. Amazon S3 buckets and SFTP servers). We also download or scrape a variety of\npublicly available statistics from the web, such as unemployment insurance claims and COVID-19\ncase counts.\n\nThree main challenges arise when handling this large volume of frequently updated data: storing,\nsyncing, and version controlling the data we receive. We store all the raw data we receive as flat\nfiles in a data lake (an Amazon $3 bucket). We use object storage rather than a database or a\nmore customized storage service (such as Git LFS) to minimize storage costs while maximizing our\nflexibility to ingest incoming data which arrives in numerous formats that may change over time.\nWe version control each snapshot of the data we download within the same Git repository that\nstores our code using a tool called DVC (“Data Version Control”). DVC creates a pointer to a hash\nof the raw data for each data file or folder (in other words, a shortcut to the files in the data lake),\nwhich we version control in Git and update every time new data is downloaded. This associates\neach snapshot of data with the code that existed at the time it was processed, and allows us to\neasily roll back our code and data simultaneously to any prior state. DVC also facilitates syncing\n\nthe raw data from the data lake by efficiently downloading the data that is associated with each\n\n48",
    "Page_51": "pointer in the Git repository.\n\nStep 2: Data Processing. For each dataset, we have an automated pipeline of programs that\nprocess and transform the raw data into the public datasets that we post online. We use an\nautomated build tool to organize and execute this collection of programs. We mostly process the\ndata using Stata and execute our automated builds within Stata using the -project- command\ndeveloped by Robert Picard.\n\nThis data processing step generates two outputs: (1) a set of CSV files that contain all the data\nto be posted publicly and (2) a quality control report. The quality control report is a document\nthat allows analysts to quickly assess any notable deviations in the data and determine whether\nthe updated data require further review before being publicly released. Each report flags three\ntypes of changes that would require manual review: revisions made to previously posted data, large\ndeviations in newly reported data, or newly missing data. The report also contains a series of tables\nand figures that preview the data and highlight any changes in the newly processed data.\n\nEach time new data is ingested, the data processing step is run automatically. If it runs to\ncompletion, a Git pull request is generated with DVC pointers to the newly updated raw data\nalongside a link to the quality control report. If the data processing fails (for example, because\nthe structure of the raw data has changed), an error report is generated. At this point, we pause\nand perform a manual review before posting the new data online. If the data processing failed or\nif any changes were detected in the quality control report that require further review, we manually\ninvestigate and write new code as needed, then re-process the data and inspect the updated quality\ncontrol report before proceeding.\n\nAfter reviewing and approving the quality control report, we merge the Git pull request con-\ntaining the new data, which automatically triggers the final Data Release step. This manual review\nand approval is therefore the only manual step in the data processing pipeline.\n\nStep 3: Data Release. Once the processed data is ready for release, our scripts automatically\npost the updated data to two public destinations. First, we sync the updated data into the database\npowering our online data visualization website built by DarkHorse Analytics (www.tracktherecovery.org).\nWhile doing so, we also update the “last updated” and “next expected update” dates on the web-\nsite. Second, we upload the CSV files containing all the updated data to our “data downloads”\npage. The updated visualizations and data downloads are then both immediately available for\n\npublic use.\n\n49",
    "Page_52": "B_ Consumer Spending Series Construction\n\nThis appendix provides greater detail on the construction of the consumer spending series using\nthe Affinity Solutions data.\n\nStructure of Raw Data. We receive data from Affinity Solutions in cells corresponding to the\nintersection of (i) county by (ii) income quartile by (iii) industry by (iv) day and week, where\ncells where fewer than five unique cards transacted are masked. Income quartile is assigned based\non ZIP code of residence using 2014-2018 ACS estimates of median household income. We use\npopulation weights when defining quartile thresholds so that each income quartile includes the\nsame number of individuals. ZIP code income quartile and county are both determined by the\ncardholder’s residence. We crosswalk from ZIP codes to counties using the geographic definitions\ndescribed in Appendix G to aggregate the series to the county and state levels.\n\nWe adjust the raw data we receive from Affinity Solutions to address three challenges: (1)\nchanges in the customer base over time, (2) a data quality issue which creates spurious increases\nin consumer spending, and (3) seasonal fluctuations.\n\nChanging Customer Base. The raw Affinity data have discontinuous breaks caused by entry\nor exit of card providers from the sample. We identify these sudden changes systematically by\nregressing the number of transacting cards at a weekly level on the date separately for each year-\nby-county, and then implementing a Supremum Wald test for a structural break at an unknown\nbreak point.\n\n950 counties have a structural break where the p-value of the test is less than 5 x 1078. For\ncounties with only one break below this threshold, we correct our estimates as follows. We first\ncompute the state-level week-to-week percent change in spending excluding all counties with a\nstructural break (using the national series for DC and states for which all counties have a structural\nbreak). If we identify a structural break in week t, we impute spending levels in weeks t — 1, t, and\nt+1, as we cannot ascertain the precise date when the structural break occurred (e.g., it may have\noccurred on the 2nd day of week t—1 or the 6th day of week t). When there is a change in coverage\nwe adjust the series to be in line with the lower level of coverage. For example, suppose a county\nhas n active cards up until week t, when the number of cards in the county increases to 3n. In\nweek t — 2, the county would have a level of n cards, its reported value. In week t — 1, if counties in\nthe rest of the state had a 5% increase in the number of cards, we would impute the county with a\n\nbreak to have a level of 1.05n cards. In week t, if counties in the rest of the state had a 10% increase\n\n50",
    "Page_53": "in the number of cards, we would impute t to have a level of (1.10) x (1.05n) = 1.155n. Likewise, if\ncounties in the rest of the state had an 8% decrease in the number of cards in week t + 1, we would\nimpute t+1 to have a level of (0.92) x (1.155n) = 1.0626n. At this point, state-level fluctuations no\nlonger impact the series, and we use the reported percent change each week to adjust this number\nfor card coverage. We omit 98 counties with multiple structural breaks from our series. We do not\nremove any counties where the structural break occurred between March 10th and March 31st of\n2020 because the consumer spending response to the COVID-19 was so strong that in many places\nit could be classified as a structural break. For the week around Christmas, we impute the number\nof cards by averaging the preceding and succeeding week, since holiday spending spikes are also\nsometimes classified as a structural break.\n\nWe implement a structural-break correction for three counties: Philadelphia County, Pennsylva-\nnia (county FIPS of 42101); Washington, District of Columbia (11001); Jefferson County, Kentucky\n(21111). For Philadelphia and Washington, we implement a correction by estimating a regression\ndiscontinuity at the date of the break, and then adding the RD estimate to the series prior to the\nstructural break. The structural break in Jefferson county occurs on January 7th of 2020, and so\nthere are not enough days on the left-hand side to implement the RD correction. Consequently, we\nassign the January 7th value to each day between January lst and January 6th.\n\nSpurious Changes in Consumer Spending. There is an implausibly large spike in consumer\nspending between January 15th, 2019 and January 17th, 2019 that is not found in other data\nseries. This spike in national consumer spending is not driven by specific regions nor sectors. We\ntreat this spike as a data quality issue, and respond by replacing each impacted day with the average\nspending on t— 7, + 7, and t+ 14, where t is the impacted day. A similar problem arises in the\n“Accommodations and Food Services” sector in Richmond City County, Virginia where spending\nincreases by over 80 times on May 23rd, 2019 relative to to nearby days. We implement a similar\nprocedure replacing the impacted day with the average spending on t— 14, t—7,t+7, andt+14,\nwhere t is the impacted day.\n\nSeasonal Adjustment. We seasonally adjust the data by calculating, for each week and day, the\nyear-on-year change relative to the 2019 value. We norm February 29, 2020 (a Saturday) relative\nto the average of February 23 and March 2, 2019 (both Saturdays). Labor day in 2019 fell one week\nearlier than in 2020, so we adjust the week of labor day, as well as the two weeks before, based on\nthe same week in 2019 relative to Labor Day rather than the week number in the year.\n\nDefinition of Categories of Goods. In parts of our analysis, we distinguish between four cat-\n\n51",
    "Page_54": "egories of goods and services: durable goods; non-durable goods; remote services; and in-person\nservices. We define durable goods as the following MCC groups: motor vehicles, sporting and hobby\ngoods, home improvement centers, consumer electronics, and telecommunications equipment. Non-\ndurable goods include wholesale trade, agriculture, forestry and hunting, general merchandise, ap-\nparel and accessories, health and personal care stores, and grocery stores. Remote services include\nutilities, professional/scientific services, public administration, administration and waste services,\ninformation, construction, education, and finance and insurance. In-person services include real\nestate and leasing, recreation, health care services, transportation and warehousing services, and\n\naccommodation and food services, as well as barber shops, spas, and assorted other services.\n\nC_ Small Business Revenue and Small Businesses Open Series Construction\n\nThis appendix details our methodology for constructing the Small Business Revenue and Small\nBusinesses Open series, using data from Womply.\n\nInitial Construction. We receive Womply data on total revenue and number of open businesses\nat the date x ZIP code x firm category level. The Womply data are limited to small businesses,\ndefined as businesses with annual revenue below Small Business Administration thresholds.\n\nTo reduce the influence of outliers, firms outside twice the interquartile range of firm annual\nrevenue within this sample are excluded and the sample is further limited to firms with 30 or\nmore transactions in a quarter and more than one transaction in 2 out of the 3 months. We\nconvert Womply’s firm categories to two-digit NAICS codes using an internally generated Womply\ncategory-NAICS crosswalk, and then aggregate to NAICS supersectors. We measure small business\nrevenue as the sum of all credits (generally purchases) minus debits (generally returns). We define\nsmall businesses as being open on a given day if they have at least one transaction in the previous\nthree days.\n\nWe crosswalk from ZIP codes to counties using the geographic definitions described in Appendix\nG to aggregate the series to the county and state levels. We then collapse the Womply data\nto aggregate spending and total small businesses open within each day x NAICS supersector x\ngeography x ZIP income quartile, creating ZIP income quartiles as described in Appendix B. We\ntake a seven-day look-back moving average of each series, and norm each series relative to its\naverage level over the period January 4-31. We then seasonally adjust the data by following the\n\nprocedure described in Appendix B.\n\n52",
    "Page_55": "Masking. To preserve the privacy of firms in the data and to avoid displaying noisy estimates for\nsmall cells, we mask Womply series that report less than $250,000 in total revenue during the base\nperiod of January 4-31. In addition, Womply adds merchants and an imputed revenue quantity\nsuch that every cell with 1 or 2 merchants has no fewer than 3 merchants. This imputation has the\nresult of dampening the effect of any declines that would otherwise place the number of merchants\nin a cell at 1 or 2, lowering the effect of any increase from 1 or 2 merchants to 3 merchants, and\nenhancing the effect of any increase from 0 merchants to 1 or 2 merchants. We minimize the impact\nof this masking by processing data at the highest level of aggregation available. When possible, we\ncorrect for this imputation by comparing similar datasets.\n\nAnomalous Data. Our quality-control process checks for anomalous variations in the Womply\nraw data. There are several cases of single-day spikes of positive or negative revenue within a given\nfirm category x ZIP code. We treat these cases as outliers, and replace the revenue value with the\nrevenue for the same category x ZIP code from the previous week, unless that is also an outlier or\na holiday, in which case we substitute zero revenue.‘”\n\nDelayed Processing of Payments. Due to differences in the speed at which data providers share\ntheir data with Womply, data for the most recent dates as of a given data refresh are typically\nincomplete. If left unaddressed, there would appear to be a decline in small business revenue and\nsmall businesses open in the most recent data. We generally receive Womply’s data a week after\nthe reported transactions. As a conservative approach, we exclude the four most recent days in the\n\ndata we publish.\n\nD_ Employment Series Construction\n\nThis appendix provides further details on how we construct various employment series analyzed in\nthe paper.\n\nPaychex Employment Series. We receive Paychex data at the county x industry x 2019 hourly\nwage quartile x 2019 firm size bin x pay frequency x week of payroll processing level. Salaried\nemployees’ wages are translated to hourly wages by dividing weekly pay by 40 hours. Since we seek\nto measure private sector employment, we exclude workers employed in public administration and\n\nthose with an unclassified industry (which each represent 0.8% of workers as of January 2020). We\n\n \n\n47. More generally, negative revenue may appear in the Womply data due to returns and refunds. There are a\nnumber of cases of observed negative revenue, especially during March 2020, due to consumers seeking returns or\nrefunds on certain products. We include these cases in the Womply series, but exclude large single-day occurrences\nof negative revenue.\n\n53",
    "Page_56": "restrict the sample to workers with weekly, bi-weekly, semi-monthly or monthly pay frequencies;\nthese workers represent over 99% of employees in the Paychex data.\n\nWe begin by creating a daily series of paychecks processed on each date by linearly interpolating\ndaily values between each week in each county x 2-digit NAICS code x 2019 hourly wage quartile\nx 2019 firm size bin x pay frequency cell. In order to construct a series of employment as of each\ndate, rather than paychecks being processed as of each date, we take two steps.\n\nFirst, we construct a series of pay periods ending as of each date. We take a separate approach\nfor paychecks following regular weekly cycles (i.e. weekly and bi-weekly paychecks) and for pay-\nchecks following a cycle based on fixed calendar dates (i.e. semi-monthly and monthly paychecks).\nFor weekly and bi-weekly payfrequencies, we use data provided by Paychex on the distribution of the\nnumber of days between a worker’s pay date and the last date in the worker’s pay period (i.e., date\nat which payroll is processed — last date in pay period), for weekly and bi-weekly payfrequencies,\nto distribute paychecks to the last date of the corresponding pay period, treating the distribution\nof (date at which payroll is processed — last date in pay period) as constant across geographies and\nNAICS codes. For monthly and semi-monthly payfrequencies, where cycles regularly occur on fixed\ncalendar dates (e.g. the 15th and 30th of each month for semi-monthly paycycles), we assume that\nthe last date within each pay period is the closest preceding calendar date that is the 15th or the\n30th day of the month (semi-monthly paycycles) or the 30th day of the month (monthly paycycles).\nIn each case, we interpolate values around public holidays.\n\nSecond, to construct a series of employment as of each date, we record a worker as being\nemployed for the full duration of the paycycle up until the last date in their pay period, under the\nassumption that workers are employed for each day during their pay period. We then collapse the\ndata to the level of county x industry x 2019 hourly wage quartile x 2019 firm size x pay x date.\n\nFinally, we take steps to prevent the introduction of new Paychex clients from artificially creating\nbreaks in the employment series at smaller levels of geography. We begin by calculating the share\nof employment in January 2020 accounted for by each industry x firm size bin within each county x\nwage quartile cell. Next, we calculate the change in employment relative to January for each county\nx wage quartile x industry x firm size bin, and multiply this change by the share of total employment\nin the corresponding county x wage quartile cell, creating an employee-weighted employment series\nfor each county x wage quartile x industry x firm size bin cell. We denote a county x wage quartile\nx industry x firm size bin cell as an “influential cell” if the county contains 100 or fewer than unique\n\ncounty x quartile x industry x firm size bin cells, and the cell accounts for over 10% of employment\n\n54",
    "Page_57": "in the corresponding quartile x wage quartile at any date in 2020, or if the county contains greater\nthan 100 unique county x wage quartile x industry x firm size bin cells, and the cell accounts for\nover 5% of employment in the county x wage quartile at any date in 2020. We drop influential\ncells that record a change in employment relative to January 2020 of at least +50% on any date,\non the basis that such a trend likely arises due to changes in Paychex’s client base rather than true\nemployment changes. Around 4% of county x wage quartile x industry x firm size bin cells are\naffected by this procedure.\n\nEarnin Employment Series. We obtain anonymized microdata at the worker level from Earnin.\nWe construct our analysis sample by restricting the sample to workers who are paid on a weekly\nor bi-weekly paycycle; these categories account for 92% of paychecks. We also restrict the sample\nto workers who are active Earnin users, with non-missing earnings and hours worked over the last\n28 days. Next, we exclude workers whose reported income over the prior 28 days is greater than\n$50,000/13 (corresponding to an income of greater than $50,000 annually).\n\nWe then restrict the sample to workers who are in paid employment. Users may continue to use\nEarnin after they have been laid off; we exclude payments which Earnin classifies as unemployment\npayments, either based on the user’s registration with Earnin as being unemployed, or based on\nthe string description of the transaction. Where a user has previously been unemployed, but stops\nreceiving unemployment checks after a certain date, we treat the user as having been re-employed\nif they receive a payment amount of $200 within the two weeks following their last unemployment\ncheck. Using this approach, we find that 90% of Earnin users are re-employed within fourteen days\nof receiving their last unemployment check.\n\nWe use external data sources to gather further information on firm size and industry. To\nobtain information on industry, we use a custom-built crosswalk created by Digital Divide Data\nwhich contains NAICS codes for each employer in the Earnin data with more than ten Earnin\nusers. To obtain information on firm size, we crosswalk Earnin employers to ReferenceUSA data at\nthe firm location level by spatially matching Earnin employers to ReferenceUSA firms. We begin\nby geocoding Earnin addresses to obtain latitudes and longitudes for each Earnin employer. We\nthen remove common prefixes and suffixes of firm names, such as “inc” and “associated”. Next,\nwe compute the trigram similarities between firm names for all Earnin and ReferenceUSA firms\nwithin twenty-five miles of another. We then select one “match” for each Earnin firm within the\nReferenceUSA data, among the subset of firms within one mile. We first match Earnin employers\n\nto ReferenceUSA firms if the firms are within one mile of one another, and share the same firm\n\n55",
    "Page_58": "name. Second, where no such match is available, we choose the geographically closest firm (up to a\ndistance of one mile) among all firms with string similarities of over 0.6. Third, where no such match\nis available, we match an Earnin employer to the ReferenceUSA employer within twenty-five miles\nwith the highest trigram string similarity, provided that the match has a trigram string similarity of\n0.9. We then compute the modal parent-firm match in the ReferenceUSA data for each parent-firm\ngrouping in Earnin. Where at least 80% of locations within a parent-firm grouping in Earnin are\nmatched to a single parent-firm grouping in the ReferenceUSA data, we impute that parent-firm\no every Earnin location. In total, we match around 70% of Earnin employers to ReferenceUSA\nfirms.\n\nEarnin data are observed at the ZIP code level. We crosswalk from ZIP codes to counties using\nhe geographic definitions described in Appendix G to aggregate the series to the county and state\nevels.\n\nWe construct an employment series in the Earnin data from our analysis sample as follows. In\nhe paycheck-level data, we observe the worker’s paycycle frequency. As in the Paychex data, we\nuse paycycle frequency to construct an employment series by assuming that workers are employed\nhroughout the full duration of their paycycle. That is, we assume that a worker paid every two\n\nweeks has been fully employed for the two weeks prior to receiving their paycheck. To account for\n\n \n\nhe delay in receipt of paychecks, we shift the Earnin series back by one week. We then take the\ncount of employed individuals across the Earnin sample as our measure of employment. We take\na 7-day moving average to form our Earnin employment series, and express the series as a change\nrelative to January 4-31.\n\nComparison of Construction of Earnin and Paychex Employment Series to Cajner et al. (2020)\nADP Series. In both the Earnin and Paychex datasets, we construct daily employment series using\ndata on paychecks. Our treatment of paycheck data is similar to the treatment of paycheck data in\nCajner et al. (2020), who estimate employment based on paycheck deposits using firm-level data\nfrom ADP. Cajner et al. (2020) define employment within a week as the count of paychecks that are\nprocessed during that week. For businesses which do not process payroll every week (e.g. businesses\nwhose workers are paid every two weeks), Cajner et al. (2020) impute the count of paychecks in the\n“missing” week using the number of paychecks in the next period in which the businesses processes\npayroll.\n\nBecause the Earnin data are available at the worker level, we do not observe whether a business\n\nas a whole does not process payroll every week. However, under the assumption that all workers\n\n56",
    "Page_59": "within a business are paid on the same paycycle, our worker-level approach of distributing paychecks\nuniformly over the paycycle matches the approach in Cajner et al. (2020) of imputing employment\nbased on the next week in which paychecks are observed. The two primary differences between our\ntreatment of paycycles and the treatment in Cajner et al. (2020) are that we use a 7-day moving\naverage, whereas Cajner et al. (2020) use a 14-day moving average, and that we treat that the last\ndate of the employment period as seven days prior to the receipt of the paycheck, whereas Cajner\net al. (2020) observe the pay period directly. The seven-day lag accounts for delays between the\nend of a worker’s pay period, which is the event observed in Cajner et al. (2020), and the date on\nwhich paychecks are received by workers, which is the event observed in the Earnin data.\n\nBecause the Paychex data are not available at the firm level, we are not able to directly imple-\nment the approach in Cajner et al. (2020) of imputing employment using the count of paychecks in\nthe “missing” week for firms that do not process payroll on a weekly basis. Instead, we make the\nconceptually similar assumption that workers are employed throughout the full duration of their\npaycycle, such that we can infer the full set of dates on which an individual worked by observing\nthe last date of each of their pay periods and their pay frequency. Under the assumptions that all\nworkers within a given firm are paid according to the same paycycle, our approach of inferring em-\nployment based on last date of pay period matches the approach in Cajner et al. (2020) of imputing\nemployment based on the next week in which paychecks are observed. A further difference is that\npay period is observed in Cajner et al. (2020); by contrast, in the Paychex data, pay periods are\nimputed using payroll processing date and the distribution of (payroll processing date — last date\nin pay period). Finally, Cajner et al. (2020) use a 14-day moving average, whereas we use a 7-day\nmoving average.\n\nCombined Employment Series. We combine Paychex, Earnin, and Intuit data to construct our\nprimary employment series. Because Paychex covers all sectors and wage levels fairly comprehen-\nsively, we use it as the base for the combined employment series. We then use Earnin and Intuit\nto refine the series in cells represented by those datasets.\n\nBecause Earnin best represents workers in the bottom wage quartile, we combine Earnin data\nwith Paychex data to construct employment estimates for the bottom wage quartile. To do so,\nwe first calculate total employment levels within each two-digit NAICS code by firm size by geog-\nraphy cell by summing employment levels for bottom-wage-quartile Paychex workers and Earnin\n\nworkers. We place the majority of the weight on Paychex, with greater weight on Earnin in geo-\n\n \n\n48. We convert the weekly Paychex data to daily measures of employment by assuming that employment is constant\n\n57",
    "Page_60": "graphic areas and in NAICS codes where it has greater coverage; the exact weights are undisclosed\nto protect privacy. These combined Paychex-Earnin values are used to assess the effects of the Pay-\ncheck Protection Program. In order to create the other analysis datasets, we then collapse across\nfirm sizes and compute mean levels of employment for bottom-wage-quartile workers by geography\nby taking a weighted average of the NAICS-by-geography combined estimates, weighting by the\nJanuary Paychex NAICS shares for bottom-wage-quartile workers in each geography.\n\nNext, we combine Intuit with the Paychex-Earnin data. Intuit provides us with overall national\nindustry shares as of 2019, but does not release data broken down by wage level or industry. We\ntherefore must effectively impute the Intuit data to wage-industry cells in order to combine it with\nthe Paychex data. To do so, we assume that any differences in employment between Intuit and\nPaychex are constant (in percentage terms, relative to the January baseline) by industry and wage\nquartiles within a given geography and month. We reweight the Paychex data to match the national\nIntuit industry distribution and compute the percentage difference between the employment decline\nin the reweighted Paychex data and the Intuit data in each geography-month cell. We then apply\nthis correction factor to each wage-industry cell in the Paychex data to obtain imputed values by\nwage and industry for the relevant industries covered by Intuit. For instance, if Intuit exhibits\na 5% larger employment decline than the reweighted Paychex series in Manhattan in April, we\nwould impute a value for each wage-by-industry cell covered in the Intuit data that is 1.05 times\nthe decline observed in Paychex for that cell. When constructing the series that we use to analyze\nthe effects of the Paycheck Protection Program, we exclude the Intuit data, since Intuit primarily\nconsists of small firms.\n\nFinally, we take a weighted average of the Paychex data and the imputed Intuit data in each\nindustry to compute the final combined series. We place the majority of the weight on Paychex, with\ngreater weight on Intuit in sectors where it has greater coverage; the exact weights are undisclosed\nto protect privacy.\n\nThe preceding steps yield combined data at the industry by wage quartile for each geography\n(county, state, and national). We construct aggregate estimates across industries, wage quartiles,\n\nand overall by aggregating these estimates using Paychex January employment weights.*? We\n\n \n\nwithin each week.\n\n49. In a few cases, Earnin and Intuit data do not provide coverage for a given geographical region or industry;\nwe suppress such cells. We also suppress cells in which Paychex records less than an average of 100 total monthly\nemployees in the second half of 2019 at the industry by geography or income quartile by geography level. When\naggregating employment series to the geographical level without breakdowns by industry or wage quartile, however,\nwe use data from all cells, without masking.\n\n58",
    "Page_61": "report seven-day moving averages of these series, expressed as a percentage change relative to\nJanuary 4-31. We construct a series for average total earnings analogously, using total earnings\ninstead of total employment.\n\nTo construct employment predictions for the most recent weeks, we regress the combined em-\nployment series for each quartile of workers on the Kronos series for the same week, the correspond-\ning quartile of the Paychex weekly series for the same week, as well as the three prior weeks of\nPaychex weekly data. We then use these regression coefficients combined with the most recent Kro-\nnos and Paychex weekly data to create a series of predicted employment rates for workers in each\nwage quartile. Appendix Figure 15 assesses the accuracy of this forecasting approach by comparing\nout-of-sample predictions of employment to realized employment trends. Predicted employment is\ngenerally similar to realized employment for both high-wage (top quartile) and low-wage (bottom\nquartile) workers.\n\nZIP Code-Level Low-Income Employment Series. As ZIP code is not observed in Paychex\nand Intuit, we separately construct ZIP code-level employment using the Earnin data only. We\nconstruct our analysis sample as above. To account for the noisier data at the ZIP code-level, we\nnorm the ZIP code-level changes relative to a pre-period of January 5 - March 7. We suppress\nestimates for ZIP codes with fewer than 100 worker-days observed over this period.\n\nAssessing Mismeasurement of Firm Sizes using SBA data. We assess the degree of misclassifi-\ncation of PPP eligibility in our sample by merging publicly available data on PPP recipients from\nthe SBA to data on firm sizes from both ReferenceUSA and Dun & Bradstreet, which form our\nmeasures of firm size in the Earnin and Paychex data, respectively. To construct SBA data on\nPPP recipients, we restrict attention to firms receiving loans of at least $150,000, as the names and\naddresses of these firms are publicly available from the SBA. We first geocode addresses recorded in\nSBA, ReferenceUSA, and Dun & Bradstreet data to obtain a latitude and longitude for each firm.\nWe then compute the trigram similarities between firm names for all SBA and ReferenceUSA firms,\nand all SBA and Dun & Bradstreet firms within twenty-five miles of another. We then select one\n“match” for each PPP recipient from both the ReferenceUSA and Dun & Bradstreet data, among\nthe subset of firms within twenty-five miles, following the procedure described above in our merge\nof Earnin data to ReferenceUSA data. For firms with loans of above $150,000, exact loan size is\nnot observed; we impute loan size as the midpoint of loan range.\n\nWe use the merged SBA-ReferenceUSA and SBA-Dun & Bradstreet data to estimate the first-\n\nstage of our difference-in-differences design, i.e. how much more PPP assistance firms classified\n\n59",
    "Page_62": "as having 100-500 employees in our sample received relative to those classified as having more\nthan 500-800 employees. To do so, we stack the datasets and use the same weights used when\nconstructing the combined employment series. The SBA released firm names and ZIP codes of\nPPP recipients receiving over $150,000 in loans, which represent 72.8% of total PPP expenditure.\nOf the roughly 660,000 PPP recipients of these loans, we merge around 60% of firms and 62% of\ntotal expenditure to firm size data. In this matched subset, we find that mean PPP expenditure\nper worker is $2,303 for firms we classify as having 100-500 employees and $586 per worker for\nfirms with 500-800 employees (excluding firms in the food services industry). Given that we match\nonly 62% of the publicly available PPP expenditure to our data and the publicly available data\n\ncovers only 73% of total PPP expenditure, this implies that firms measured as having 100-500\n$2,303\n0.62x0.73\n\nwith 500-800 employees received att = $1,290 in PPP assistance per worker.” We calculate\n\nemployees in our sample received = $5,090 of PPP assistance per worker, while firms\nthat PPP assistance to eligible firms with between 100 and 500 employees (excluding NAICS 72)\nis $5,092 per worker on average.°! Hence, firms with 501-800 workers in the ReferenceUSA-Dun\n\n& Bradstreet data (the control group) were effectively treated at an intensity of eee = 25.3%,\n\n \n\nwhereas firms with 100-500 workers in the ReferenceUSA-Dun & Bradstreet data (the treatment\n\ngroup) were treated at an intensity of 3003 = 100%.\n\n \n\nInflating our baseline reduced-form estimates by any = 1.35 yields estimates of the treat-\nment effect of PPP eligibility adjusted for attenuation bias due to mismeasurement of firm size.\n\nCalculating PPP Expenditures Per Worker. Using Statistics of U.S. Businesses (SUSB) data,\nwe calculate that approximately 62.4 million workers work at firms eligible for PPP assistance (53.7\nmillion workers excluding those in the food services industry, NAICS 72). To compute total PPP\nexpenditure, we first use publicly released data on loan recipients to calculate that 92.1% of total\nPPP expenditure was received by non-NAICS 72 firms. We then multiply this share by total PPP\n\nexpenditure as of August 8 to reach an estimate of $486 billion in non-NAICS 72 firms.\n\n \n\n50. This calculation assumes that the degree of misclassification of eligibility among identifiable PPP recipients\nmatches the degree of misclassification of eligibility in the broader ReferenceUSA sample.\n\n51. To compute this statistic, we first calculate the share of total loan amounts received by non-NAICS 72 firms\nin the publicly released SBA data. We begin by imputing precise loan amount as the midpoint of minimum and\nmaximum of loan range, where precise loan amount is not released. We then calculate the share of loans in firms\nwith firm size between 100 and 500, in NAICS codes other than NAICS 72, under the assumption that our merge\nrate is constant by firm size. Using this approach, we calculate that 13.1% of PPP loan spending was allocated to\nnon-NAICS 72 firms with between 100 and 500 employees. We then rescale the total PPP expenditure to the end of\nJune, $521 billion, by 0.131 to arrive at an estimate of $69.22 billion in PPP loan spending to non-NAICS 72 firms\nwith 100-500 employees. Finally, we divide $69.22 billion by the number of workers at non-NAICS 72 firms with\n100-500 employees to arrive at an estimate of loan spending per worker.\n\n60",
    "Page_63": "E Educational Progress Data Construction\n\nIn this appendix, we provide additional details about how we define Zearn indices of math progress\nand engagement.\n\nMasking. The data we obtain are masked such that any county with fewer than two districts,\nfewer than three schools, or fewer than 50 students on average using Zearn Math during the pre-\nperiod of January 6 to February 7 is excluded. We fill in these masked county statistics with the\ncommuting zone mean whenever possible. We winsorize values reflecting an increase of greater than\n300% at the school level. We exclude schools which did not have at least 5 students using Zearn\nMath for at least one week from January 6 to February 7.\n\nSchool Breaks. To reduce the effects of school breaks, we replace the value of any week for a\ngiven school that reflects a 50% decrease (increase) greater than the week before or after it with\n\nthe mean value for the three relevant weeks.\n\nF Public Data Sources\n\nThis appendix provides further details on our use of public data sources on unemployment benefits,\nCOVID-19 incidence, and mobility measures.\n\nUnemployment Benefit Claims. We collect county-level data by week on unemployment insur-\nance claims starting in January 2020 from state government agencies since no weekly, county-level\nnational data exist. Location is defined as the county where the filer resides. We use the initial\nclaims reported by states, which sometimes vary in their exact definitions (e.g., including or exclud-\ning certain federal programs). In some cases, states only publish monthly data. For these cases,\nwe impute the weekly values from the monthly values using the distribution of the weekly state\nclaims data from the Department of Labor (described below). We construct an unemployment\nclaims rate by dividing the total number of claims filed by the 2019 Bureau of Labor Statistics\nlabor force estimates. Note that county-level data are available for 22 states, including the District\nof Columbia.\n\nWe also report weekly unemployment insurance claims at the state level from the Office of\nUnemployment Insurance at the Department of Labor. Here, location is defined as the state liable\nfor the benefits payment, regardless of the filer’s residence. We report both new unemployment\nclaims and total employment claims. Total claims are the count of new claims plus the count of\n\npeople receiving unemployment insurance benefits in the same period of eligibility as when they\n\n61",
    "Page_64": "last received the benefits.\n\nCOVID-19 Data. We report the number of new COVID-19 cases and deaths each day using\npublicly available data from the New York Times available at the county, state and national level.®?\nWe also report daily state-level data on the number of tests performed per day per 100,000 people\nfrom the COVID Tracking Project.°? For each measure - cases, deaths, and tests — we report two\ndaily series per 100,000 people: a seven-day moving average of new daily totals and a cumulative\ntotal through the given date. We manually review any spikes in cases, tests, or deaths that are\nlarger than 25%. If news reports suggest that the spike is a reporting artifact, we smooth the data\nby imputing a value for the day of the spike using the growth rate in the outcome on the prior day,\nunless there was also a spike on that day.\n\nGoogle Mobility Reports. We use data from Google’s COVID-19 Community Mobility Reports to\nconstruct measures of daily time spent at parks, retail and recreation, grocery, transit locations, and\nworkplaces.>4 We report these values as changes relative to the median value for the corresponding\nday of the week during the five-week period from January 3rd - February 6, 2020. Details on place\ntypes and additional information about data collection is available from Google. We use these raw\nseries to form a measure of time spent outside home as follows. We first use the American Time\nUse survey to measure the mean time spent inside home (excluding time asleep) and outside home\nin January 2018 for each day of the week. We then multiply time spent inside home in January\nwith Google’s percent change in time spent at residential locations to get an estimate of time spent\ninside the home for each date. The remainder of waking hours in the day provides an estimate\nfor time spent outside the home, which we report as changes relative to the mean values for the\ncorresponding day of the week in January 2020. Finally, we report each series as a seven-day moving\n\naverage.\n\nG Dates and Geographic Definitions\n\nIn this appendix, we provide additional details about how we define key dates and geographic units\n\nused in our analysis.\n\n \n\n52. See the New York Times data description for a complete discussion of methodology and definitions. Because\nthe New York Times groups all New York City counties as one entity, we instead use case and death data from New\nYork City Department of Health data for counties in New York City.\n\n53. We use the Census Bureau’s 2019 population estimates to define population when normalizing by 100,000 people.\nWe suppress data where new counts are negative due to adjustments in official statistics.\n\n54. Google Mobility trends may not precisely reflect time spent at locations, but rather “show how visits and length\nof stay at different places change compared to a baseline.” We call this “time spent at a location” for brevity.\n\n62",
    "Page_65": "Key Dates for COVID-19 Crisis. The Economic Tracker includes information about key dates\nrelevant for understanding the impacts of the COVID-19 crisis. At the national level, we focus on\n\nthree key dates:\ne First U.S. COVID-19 Case: 1/20/2020\ne National Emergency Declared: 3/13/2020\ne CARES Act Signed in to Law: 3/27/2020\nAt the state level we collect information on the following events:\n\ne Schools closed statewide: Sourced from COVID-19 Impact: School Status Updates by MCH\nStrategic Data, available here. Compiled from public federal, state and local school informa-\n\ntion and media updates.\n\ne Nonessential businesses closed: Sourced from the Institute for Health Metrics and Evalua-\ntion state-level data (available here), who define a non-essential business closure order as:\n“Only locally defined ’essential services’ are in operation. Typically, this results in closure\nof public spaces such as stadiums, cinemas, shopping malls, museums, and playgrounds. It\nalso includes restrictions on bars and restaurants (they may provide take-away and delivery\nservices only), closure of general retail stores, and services (like nail salons, hair salons, and\nbarber shops) where appropriate social distancing measures are not practical. There is an\n\nenforceable consequence for non-compliance such as fines or prosecution.”\n\ne Stay-at-home order goes into effect: Sourced and verified from the New York Times reopening\ndata, available here, and hand-collection from local news and government sources where\n\nneeded.\n\ne Stay-at-home order ends: Sourced and verified from the New York Times reopening data,\navailable here, and hand-collection from local news and government sources where needed.\nDefined as the date at which the state government lifted or eased executive action or other\npolicies instructing residents to stay home. We code “regional” and “statewide” expiry of\nstay-at-home orders separately. A “regional” expiration of a stay-at-home orders occurs\nwhen a stay-at-home order expires in one region within a state, but not everywhere within\n\nthe state. A “statewide” expiration of a stay-at-home order occurs when a stay-at-home order\n\n63",
    "Page_66": "first expired throughout a whole state, either due to a statewide change in policy, or due to\n\nthe stay-at-home order in each county having expired.\n\ne Partial business reopening: Sourced and verified from the New York Times reopening data,\navailable here, and hand-collection from local news and government sources where needed.\nDefined as the date at which the state government allowed the first set of major industries to\nreopen (non-essential retail or manufacturing in nearly every case). Deviations from the New\nYork Times reopening data are deliberate and usually involve our regional classification or\nour inclusion of manufacturing. A “regional” reopening occurs when businesses are allowed\nto reopen in one region within a state, but not everywhere within the state. A “statewide”\nreopening occurs when businesses are allowed to reopen throughout a whole state, either due\n\nto a statewide change in policy, or due to restrictions being eased in each individual county.\n\nGeographic Definitions. For many of the series we convert from counties to metros and ZIP codes\nto counties. We use the HUD-USPS ZIP code Crosswalk Files to convert from ZIP code to county.\nWhen a ZIP code corresponds to multiple counties, we assign the entity to the county with the\nhighest business ratio, as defined by HUD-USPS ZIP Crosswalk. We generate metro values for a\nselection of large cities using a custom metro-county crosswalk, available in Appendix Table 7. We\nassigned metros to counties and ensured that a significant portion of the county population was\nin the metro of interest. Some large metros share a county, in this case the smaller metro was\nsubsumed into the larger metro. We use the Uniform Data Systems (UDS) Mapper to crosswalk\n\nfrom ZIP codes to ZCTAs.\n\n64",
    "Page_67": "Table 1\n\nChanges in Consumer Spending on Debit and Credit Cards by Sector and Income Quartile\n\nChange in Consumer Debit and Credit Card Spending Per Day\nRelative to January 4-31 2020 ($ Billions)\n\nLevel of Consumer Spending\n\nDep. Var.:\nPer Day ($ Billions)\n\n \n\nChange as of April 8-14 Change as of June 8-14 Change as of July 8-14 Level as of January 4-31 2020\n\n@)\n\nPanel A: Card Spending by Income Quartile\n\n(2)\n\n(3)\n\n(4)\n\n \n\n \n\n \n\n \n\nPooled, All Income Quartiles -$7.5 -$3.1 -$3.1 $22.0\nBottom Quartile -$0.9 -$0.2 -$0.3 $3.3\n(12.5%) (6.8%) (8.5%) (15.2%)\nSecond Quartile -$1.5 -$0.6 -$0.6 $4.9\n(20.1%) (17.5%) (19.4%) (22.4%)\nThird Quartile -$2.0 -$0.8 -$0.8 $6.0\n(26.6%) (26.6%) (26.8%) (27.1%)\nTop Quartile -$3.1 -$1.5 -$1.4 $7.8\n(40.9%) (49.1%) (45.3%) (35.3%)\nPanel B: Card Spending by Sector\nDurable Goods -$0.8 +$1.0 +$0.9 $4.9\n(10.6%) (-42.5%) (-45.6%) (22.7%)\nNon-Durable Goods -$0.6 +$0.1 +$0.2 $4.9\n(8.0%) (-3.0%) (-9.9%) (22.3%)\nRemote Services -$1.2 -$0.2 -$0.2 $4.5\n(15.0%) (6.9%) (11.5%) (20.4%)\nIn-Person Services -$5.1 -$2.9 -$3.0 $6.9\n(65.1%) (127.3%) (156.1%) (31.8%)\nPanel C: In-Person Services Sub-Sector Decomposition\nHotels & Food -$2.0 -$1.1 -$1.2 $2.6\n(38.3%) (39.6%) (38.6%) (37.6%)\nTransportation -$1.5 -$1.1 -$1.1 $1.7\n(29.4%) (37.3%) (36.2%) (25.0%)\nHealth Care -$0.5 -$0.1 -$0.2 $0.9\n(10.0%) (3.9%) (4.8%) (12.3%)\nRecreation -$0.4 -$0.3 -$0.3 $0.5\n(8.4%) (11.3%) (10.9%) (7.3%)\nOther In-Person Services -$0.7 -$0.2 -$0.3 $1.2\n(13.9%) (8.0%) (9.4%) (17.8%)\n\n \n\n \n\nNotes: This table describes how national consumer spending on credit and debit cards changes over time, relative to its level in January 2020. To compute these changes, we\nbegin by calculating total daily spending in the Affinity Solutions data for each day in 2019 and 2020. We then inflate these numbers to estimate total card spending for the\nfull U.S. population by multiplying by the ratio of January 2020 (or 2019) total spending for components of PCE that are likely captured in credit/debit card spending\n(shown in the last bar of Figure la) to the January 2020 (or 2019) total spending in the Affinity data. In Column (1), we calculate the change in card spending as ((Spending\nfor April 8 through April 14 2020) - (Spending for April 8 through April 14 2019)) - (Spending for January 4 through January 31 2020) - (Spending for January 4 - January\n31 2019)). Columns (2) and (3) replicate Column (1) for the June 8-14 and July 8-14 periods respectively, instead of April 8-14. Column (4) shows mean daily national\nspending over the period of January 4-31 2020. Panel A shows changes in total spending for the full sample and separately by income quartile, imputed using median\nhousehold income within the cardholder's residential ZIP code in the 2014-2018 ACS. The share of the national decline accounted for by each quartile is shown in parentheses\nin each row. The declines in card spending among bottom-quartile and top-quartile ZIP codes in Panel A Columns (1) and (2) appear in the annotations on Figure 2a. Panel\nB replicates Panel A, disaggregating by categories of goods instead of income quartiles. For definitions of these categories, see Appendix B. The shares of the total change in\nconsumer spending summed across these four categories in Panel B do not necessarily add up to 100% because of spending on uncategorized goods or services. Panel C\n\ndisaggregates the change in consumer spending within in-person services across five sub-categories, which add up to 100% of in-person services. Data source: Affinity Solutions.",
    "Page_68": "Table 2\n\nAssociation Between Rent and Changes in Business Revenue and Employment, by ZIP Code\n\n \n\nPanel A: Business Revenue\n\nDep. Var.: Change in Small Business Revenue (%)\n\n(1) (2) (3)\n\nMedian 2BR Rent (per -13.47 -14.00 -10.55\nthousand dollars) (0.35) (0.67) (0.69)\nLog of Density of High -2.26\nWage Workers (0.12)\nCounty FEs xX xX\n\nObservations 18378 18378 17159\n\nPanel B: Low-Wage Employment\nDep. Var.: Change in Low-Wage Employment at Small Businesses (%)\n\n(1) (2) (3)\n\nMedian 2BR Rent (per -13.93 -9.70 -6.89\nthousand dollars) (0.53) (0.95) (0.99)\nLog of Density of High -1.80\nWage Workers (0.18)\nCounty FEs xX xX\n\nObservations 15685 15685 14502\n\nNotes: This table presents estimates from population-weighted OLS regressions at the ZIP-code level, regressing percentage\nchanges in small business revenue (using Womply data) and small business low-wage employment (using Earnin data) on\naverage median two-bedroom rent within the ZIP-code (as measured in the 2014-2018 ACS). Standard errors are reported in\nparentheses. The dependent variable is scaled from 0 to 100, so that, for example, the coefficient of -13.47 in the first row of\nColumn (1), Panel A implies that a $1000 increase in monthly two-bedroom rent is associated with a 13.47 percentage point\nlarger decline in total revenue relative to the January level. The dependent variable in Panel A is the change in small business\nrevenue between January 4-31 and March 25-April 14. The dependent variable in Panel B is the change in low-wage\nemployment at small businesses between January 4-31 and April 8-28, defining small businesses as firms with fewer than 500\nemployees. In both panels, the dependent variable is winsorized at the 99th percentile of the (population-weighted) ZIP-level\ndistribution. Column (1) shows the baseline regression without any controls: this specification corresponds to the estimated\nslope coefficient and standard error reported in Figure 5c (small business revenue) and Figure 9a (low-wage employment at\nsmall businesses). Column (2) adds county fixed effects and Column (3) further adds the log of the density of high wage\nworkers as a control (which is observed using the Census LODES for 92% of ZIP codes representing 99% of the U.S.\npopulation). Data sources: Panel A: Womply; Panel B: Earnin.",
    "Page_69": "Table 3\nCausal Effects of Re-Openings on Economic Activity: Event Study Estimates\n\n \n\n \n\n \n\nLow-Wage High-Wage Small Businesses Time Spent Outside\nSpending (%) Employment (%)\nDep. Var.: Employment (%) Employment (%) Open (%) Home (%)\n(1) (2) (3) (4) (5) (6) (7) (8) (9) (10)\nDD Estimate of — 1.43 1.37 0.65 1.04 -0.30 1.26 3.27 4.44 0.76 0.92\nEffect of Reopening: (0.51) — (0.53) (0.51) — (0.97) (0.85) (0.88) (1.26) (1.85) (0.56) (0.98)\nState-Week Observations: 200 312 208 258 248 248 244 324 112 138\nAnalysis Window (weeks\n2 3 2 3 2 2 2 3 2 3\non either side of\nMean Decline in Outcome\n-28.2 -18.3 -29.2 -10.5 -40.5 -21.1\n\n(Jan-April):\n\nNotes: This table estimates the effects of state reopenings on various outcomes using an event study design based on states that reopened non-essential businesses between April 20 and\nApril 27. Each state that reopens is matched to multiple control states (listed in Appendix Table 6) that did not reopen within the subsequent 3 weeks but had similar trends of the\noutcome variable during the weeks preceding the reopening. We construct the control group separately for each re-opening day and then stack the resulting event studies to align the\nevents. All estimates are from OLS regressions at the State x Week level of the change in the outcome variable relative to January on an indicator variable for the state being a state that\nreopened, an indicator variable for the date being after the reopening date, and the interaction between these two variables. We report the coefficient and standard error on the interaction\nterm, which we refer to as the difference-in-difference (DD) estimate of the effect of reopening. Standard errors are clustered at the state level and reported in parentheses. The dependent\nvariable is rescaled to be in percentage terms such that, for example, the first row of Column (1) indicates that the difference-in-difference estimate for the effect of reopening on consumer\nspending over a two-week horizon is a 1.45 percentage point increase in consumer spending. The third row indicates the \"Analysis Window\" used in the regression: for example, the sample\nin column (1) is restricted to the two weeks before and after the date of reopening, whereas the sample in column (2) is restricted to the three weeks before and after the date of reopening.\nThe last row shows the mean decline in the outcome variable across states from the period January 4-31 to the period March 25-April 14 — except in columns (7) and (8) which use\nJanuary 4-31 instead of January 4-31 as the January reference period, and columns (9) and (10) which use January 3-February 6 as the January reference period. Column (1) shows the\nestimated effect of reopening on consumer spending using data from Affinity Solutions. Consumer spending is expressed as a percentage change relative to its level over the period January\n4-31, and seasonally adjusted using 2019 data. Columns (3) and (4) replicate columns (1) and (2) using changes in employment as the dependent variable. Employment is calculated using\nPaychex-Intuit-Earnin data and expressed as a percentage change relative to its level over the period January 4-31. Columns (5) and (6) replicate column (3) for employment in the\nbottom wage quartile and top wage quartile respectively. Columns (7) and (8) replicate columns (1) and (2) respectively using number of small businesses open as the dependent variable,\ncalculated using Womply data and expressed as a percentage change relative to its level over the period January 4-31. Columns (9) and (10) replicate columns (1) and (2) respectively\nusing time spent away from home as the dependent variable, calculated using Google Mobility data and expressed as a percentage change relative to its level over the period January 3-\nFebruary 6. Columns (1), (3), and (7) correspond to the specifications displayed in Figures 12B, 12C, and 12D respectively. Data sources: Affinity Solutions, Paychex, Intuit, Earnin,\nWomply, Google.",
    "Page_70": "Table 4\n\nCausal Effect of Stimulus Payments on Spending and Small Business Revenue:\n\nRegression Discontinuity Estimates\n\n \n\n \n\nPanel A: Impact of Stimulus Payments on Consumer Spending\n\n \n\nDep. Var.: Change in Consumer Spending (%)\nBottom Income Quartile ZIP Codes Top Income Quartile ZIP Codes\n\n(1) (2) (3) (4)\n\nRD Effect of 25.15 36.97 8.45 15.83\nStimulus: (7.15) (9.81) (3.83) (5.14)\nWindow: April 1 - April 30 April 7 - April 21 April 1 - April 30 April 7 - April 21\n\nPanel B: Impact of Stimulus Payments on Small] Business Revenue\n\n \n\nDep. Var.: Change in Small Business Revenue (%)\nBottom Rent Quartile ZIP Codes Top Rent Quartile ZIP Codes\n(1) (2) (3) (4)\n\n \n\nRD Effect: of 17.92 20.83 1.20 -7.54\nStimulus: (9.59) (16.76) (6.27) (10.45)\nWindow: April 1 - April 30 April 7 - April 21 April 1 - April 30 April 7 - April 21\n\n \n\n \n\nNotes: This table shows regression discontinuity estimates of changes in spending and business revenue around the date of stimulus\npayments on April 15, 2020. Panel A shows estimated effects of stimulus payments on consumer spending. To construct the estimates, we\nfirst express consumer spending on each day as a percentage change relative to mean daily consumer spending over the period January 4-31\nin the corresponding calendar year. We then residualize these daily percentage changes with respect to day of week and first day of the\nmonth fixed effects, which we estimate using data from January 1, 2019, to May 10, 2019. We then compute OLS regressions of the\nresidualized outcome variable on an indicator variable for the date being on or after April 15 2020, using a linear control function before\nand after April 15, and excluding the partially treated date of April 14. The first row shows the coefficient on the indicator variable for the\ndate being on or after April 15, which we refer to as the RD effect of stimulus; standard errors are reported in parentheses. The dependent\nvariable is scaled as a percentage change from January so that, for example, the first row of Column (1) indicates that stimulus payments\nincreased consumer spending by 25.15 percentage points in bottom income quartile ZIP codes relative to the January 2020 level of\nspending. In columns (1) and (2), we compute daily changes in spending restricted to cardholders in ZIP codes in the bottom quartile of the\ndistribution of ZIP code median household income (based on data from the 2014-2018 ACS). Columns (3) and (4) replicate columns (1) and\n(2), computing daily changes in spending restricted to cardholders living in the top income quartile of ZIP codes. The coefficient and\nstandard error in columns (1) and (3) of Panel A correspond to the specifications displayed in Figures 13b and 13c. Panel B shows\n\nregression discontinuity estimates for the effect of stimulus payments on small business revenue using data from Womply. We first express\n\n \n\nsmall business revenue on each day relative to mean daily small business revenue over the period January 4-31 of the corresponding year.\nWe then residualize daily changes in small business revenue as in Panel A, and compute OLS regressions as in Panel A. Columns (1) and\n(2) restrict to ZIP codes in the bottom quartile of the distribution of ZIP code median rent for a two bedroom apartment (based on data\nfrom the 2014-2018 ACS). Columns (3) and (4) restrict to businesses in the top rent quartile ZIP codes. The coefficient and standard error\nin columns (1) and (3) of Panel B correspond to the specifications displayed in Figures 14a and 14b. In both panels, columns (1) and (3)\ninclude all of April 2020 in the regression specification, while columns (2) and (4) restrict to a narrower bandwidth, within one week on\n\neither side of the stimulus payment date. Data sources: Panel A: Affinity Solutions; Panel B: Womply.",
    "Page_71": "Table 5\n\nCausal Effect of Paycheck Protection Program on Employment: Difference-in-Difference Estimates\n\nDep. Var.: Change in Employment (%)\nCombined Paychex and Earnin Data Earnin Data Kronos Data\n(1) (2) (3) (4)\nBaseline Estimate Smaller Bandwidth Baseline Estimate Baseline Estimate\n\n(100-800 Employees) (300-700 Employees) (100-800 Employees) (100-800 Employees)\n\nDD Estimate 1.78 1.62 1.01 -0.22\n(1.99) (2.68) (0.94) (2.11)\n\n \n\nNotes: This table shows difference-in-difference (DD) estimates of the effect of PPP eligibility (defined as the parent firm having 500 or\nfewer employees) on employment. The outcome variable is employment at the county x 2-digit NAICS x income quartile x PPP\neligibility x week level, excluding the Accommodations and Food Services Sector (NAICS 72), expressed as a percentage change relative\nto a pre-period of January 4-31, 2020. Columns (1) and (2) present regressions in combined Paychex-Earnin data. In the baseline\nestimate in column (1), which corresponds to the difference-in-difference estimate in Figure 15a, we begin by restricting to firms with\nbetween 100 and 800 employees. We then reweight firms on 2-digit NAICS codes such that the (worker-weighted) distribution of 2-digit\nNAICS codes within Paychex firms in each size bin matches the national distribution of 2-digit NAICS codes among Paychex firms in\nthe period January 4-31 2020. We do the same for Earnin firms. Next, to combine the datasets, we reweight such that the (worker-\nweighted) share of each dataset is constant in each firm size bin. We then sum employment across datasets at the county x 2-digit\nNAICS x income quartile x eligibility x week level. Finally, we report estimates from regression equation (1): an OLS regression of\nchanges in employment on county x worker income quartile x week fixed effects, an indicator for PPP eligibility (firm size <500\nemployees), an indicator for dates after April 3, and an interaction term between PPP eligibility and the date being after April 3 (the\nDD estimate). The sample for this regression is limited to weeks ending between March 11 and August 15; we restrict the sample to\nthese weeks because Figure 15a indicates that there is little evidence of a persistent effect on employment for businesses that were\neligible for PPP assistance after mid-August. The DD estimate is the coefficient on the interaction term for PPP eligibility and the date\nbeing after April 3. We cluster standard errors (reported in parentheses) at the county x industry level, and winsorize the dependent\nvariable at the 99th percentile (weighted by reweighted employment over the period January 4-31). Column (2) replicates Column (1),\nrestricting to firms with between 300 and 700 employees. Columns (3) and (4) replicate Column (1) in the Earnin data alone and the\nKronos data alone, respectively. Column (3) corresponds to the specification for the Earnin-only difference-in-difference estimate reported\nin Appendix Figure 15a. As we treat all Earnin workers as belonging to the first quartile, Column (3) uses county x week fixed effects,\n\nrather than county x worker income quartile x week fixed effects. Data sources: Paychex, Earnin, Kronos.",
    "Page_72": "Appendix Table 1\nIndustry Employment Shares Across Datasets\n\n \n\nQCEW Industry Shares (%) Shares in Private Datasets (%)\nQCEW All QCEW Small\nEstablishments Establishments Paychex + Earnin Intuit Kronos Homebase\nNAICS Code NAICS Description (1) (2) (3) (4) (5) (6)\n11 Agriculture, Forestry, Fishing and Hunting 0.84 1.04 0.61 0.83\n21 Mining, Quarrying, and Oil and Gas Extraction 0.55 0.43 0.21 0.08\n22 Utilities 0.44 0.29 0.17 0.17 0.79\n23 Construction 5.72 7.62 6.35 7.32 1.13\n31-33 Manufacturing 10.27 5.16 8.48 2.24 22.14\n42 Wholesale Trade 4.72 5.99 5.78 1.66\n44-45 Retail Trade 12.48 14.06 8.32 4.65 3.72 11.28\n48-49 Transportation and Warehousing 4.30 2.82 2.26 1.58 10.39 0.87\n51 Information 2.29 1.64 1.63 0.94\n52 Finance and Insurance 4.83 4.60 3.57 1.72 5.88\n53, Real Estate and Rental and Leasing 1.71 2.90 3.08 1.85\n54 Professional, Scientific, and Technical Services 7.63 8.97 12.12 11.84 2.78\n55 Management of Companies and Enterprises 1.93 0.79 0.45 0.15\n56 Administrative Support 7.25 5.30 6.61 5.00\n61 Educational Services 2.39 1.53 2.43 1.18 1.11 3.62\n62 Health Care and Social Assistance 16.16 13.16 15.21 5.71 22.71 5.34\n71 Arts, Entertainment, and Recreation 1.78 1.64 2.17 1.30 1.77 2.07\n72 Accommodation and Food Services 11.04 15.60 11.09 2.61 10.20 49.17\n81 Other Services (except Public Administration) 3.57 6.21 8.74 5.96 1.83\n99 Unclassified 0.11 0.24 0.72 43.2 20.15 23.04\n\nNotes: This table compares the industry (2-digit NAICS) composition of four private employment-based datasets to the Quarterly Census of Employment and Wages (QCEW), an administrative dataset covering the near-universe of firms in the United States. Each\ncolumn displays the share of employees (in percentage terms) in the given dataset who work in the specified sector. Column (1) displays the industry composition of the QCEW in the first quarter of 2020. Column (2) replicates column (1) restricting to small establishments,\ndefined as establishments with fewer than 50 employees. Column (3) shows the industry composition of Paychex-Earnin data in January 2020. To construct Column (3), we first separately calculate the number of employees in each 2-digit NAICS code in Paychex and\nEarnin as the number of worker-days in each 2-digit NAICS code. We then calculate combined Paychex-Earnin employment in each 2-digit NAICS code as a weighted sum of Paychex and Earnin, where the weights are undisclosed to meet privacy protection requirements.\nColumn (4) shows the industry composition of Intuit data in January 2020. Column (5) shows the industry composition of Kronos in January 2020, constructed by calculating the total number of \"punches\" (i.e. worker-days) in each 2-digit NAICS code. Column (6) shows\nthe industry composition of Homebase in January 2020. To construct Column (6), we crosswalk Homebase industry classifications to 2-digit NAICS codes and calculate the number of unique employee x employer pairs with a positive number of recorded hours in January\n\n2020 in each 2-digit NAICS code. Where a dataset has no coverage in a given NAICS code, we present the employment share in that dataset as blank. Data sources: Homebase, Paychex, Earnin, Kronos, Intuit.",
    "Page_73": "Appendix Table 2\n\nHourly Pre Tax Wage Rates By Industry Across Datasets\n\n \n\nNAICS Code\n11\n21\n22\n23\n\n31-33\n42\n44-45\n48-49\n51\n52\n53\n54\n55\n56\n61\n62\n71\n72\n81\n\nNAICS Description\nAgriculture, Forestry, Fishing and Hunting\nMining, Quarrying, and Oil and Gas Extraction\nUtilities\nConstruction\nManufacturing\nWholesale Trade\nRetail Trade\nTransportation and Warehousing\nInformation\nFinance and Insurance\nReal Estate and Rental and Leasing\nProfessional, Scientific, and Technical Services\nManagement of Companies and Enterprises\nAdministrative Support\nEducational Services\nHealth Care and Social Assistance\nArts, Entertainment, and Recreation\nAccommodation and Food Services\nOther Services (except Public Administration)\nAll\nIndustry-Weighted Average of BLS Mean Wages\n\nOccupational Employment\nStatistics (OES)\n\nMean in Private Datasets\n\n \n\nMay 2019 OES\n(1)\n\nHomebase\n\n(2)\n\nPaychex - Earnin\n\n(3)\n\nIntuit\n\n(4)\n\n \n\n$16.35\n$32.15\n$39.80\n$27.87\n$26.48\n$28.85\n$17.02\n$24.33\n$39.07\n$36.73\n$24.98\n$41.83\n$42.59\n$20.50\n$28.34\n$26.98\n$19.18\n$13.65\n$21.58\n$25.72\n\n$12.47\n$14.63\n\n$14.20\n\n$12.57\n$15.87\n$12.26\n$11.11\n$14.80\n$12.11\n$17.24\n\n$20.63\n$32.89\n$33.18\n$28.74\n$25.44\n$27.34\n$21.07\n$24.62\n$32.78\n$32.82\n$25.66\n$34.37\n$24.06\n$23.51\n$24.78\n$25.47\n$22.47\n$16.62\n$22.50\n$25.34\n$26.00\n\n$26.27\n$27.79\n\nNotes: This table compares mean wages in private sector datasets to mean wages in Occupational Employment Statistics (OES) data, within each two-digit NAICS code. Column (1) reports mean wages in each NAICS\n\ncode in May 2019 OES data. We inflate these wages to 2020 dollars using the BLS Consumer Price Index. Column (2) reports mean wages in Homebase in January 2020. In Homebase data, mean wages are measured as pre-\n\ntax wages recorded by the employer. Mean wages are computed weighting by worker-days, excluding workers whose reported mean wage is zero. Column (3) reports mean wages in combined Paychex-Earnin data in January\n\n2020. We first compute mean wages separately in Paychex and Earnin data as mean wages in January 2020, weighting by number of worker-days. In Paychex, wages are measured as pre-tax wages recorded by the\n\nemployer. In Earnin, wages are post-tax wages recorded in payroll deposits. We then take a weighted mean of Paychex and Earnin wages within each industry, where the weights are not disclosed to meet business privacy\n\nrequirements. Column (4) shows mean wages in Intuit in January 2020. As we do not observe wages within each industry in Intuit data, we report only the average wage across all industries. Observed wages in Intuit data\n\nrepresented pre-tax wages as recorded by the employer. The last row of Columns (2) - (4) displays BLS mean wages, reweighted to match the 2-digit NAICS composition within each private sector dataset (as constructed in\n\nAppendix Table 1). Data sources: Earnin, Homebase, Paychex, Intuit.",
    "Page_74": "Appendix Table 3\n\nDemographic Characteristics of Zearn Users\n\n \n\nZearn Users U.S. Population\n\n(1) (2)\n\n \n\nPanel A: Income\n\nZIP Median Household Income\n\n25th Percentile 43,355 45,655\n\nMedian 54,941 57,869\n\n75th Percentile 71,485 77,014\nNumber of ZIP codes 6,529 33,253\nNumber of People 925,978 322,586,624\n\nPanel B: School Demographics\nShare of Black Students\n\n25th Percentile 1.2% 1.5%\nMedian 5.2% 5.8%\n75th Percentile 21.3% 19.1%\n\nShare of Hispanic Students\n\n25th Percentile 4.3% 5.6%\nMedian 11.4% 15.0%\n75th Percentile 33.5% 40.6%\n\nShare of Students Receiving FRPL\n\n25th Percentile 35.7% 28.2%\n\nMedian 56.9% 50.1%\n\n75th Percentile 80.4% 74.8%\nNumber of Schools 11,400 88,459\nNumber of Students 887,592 49,038,524\n\n‘Notes: This table reports demographic characteristics for Zearn schools vs. the U.S. population. Panel A compares\nincome characteristics of ZIP codes in which Zearn schools are located vs. all ZIP codes. We define Zearn to have\ncoverage in a ZIP code if at least five students at schools located in the ZIP code used Zearn over the period January\n6-February 7. Column (1) shows income characteristics of ZIP codes in which Zearn schools are located. The first\nhree rows in Panel A display the 25th percentile, median, and 75th percentile of ZIP-level median household income\nin ZIP codes in which Zearn has coverage. Household income percentiles are calculated using the 2014-2018 median\n10usehold income in each school's ZIP code, as measured in the ACS. The fourth and fifth rows of Panel A display\nhe number of ZIP codes in which Zearn has coverage, and the number of students using Zearn in those ZIP codes.\nColumn (2) replicates Column (1) using all ZIP codes in the U.S. The fourth and fifth rows of Column (2) display the\notal number of ZIP codes in the U.S. and the total population of the U.S., respectively. Panel B compares the\ndemographic composition of Zearn schools vs. the demographic composition of all U.S. schools. We calculate the\ndemographic characteristics in Panel B using school-level data from the Common Core data set constructed by MDR\nEducation, a private education data firm. The first three rows of Panel B, Column (1) show the 25th percentile,\nmedian, and 75th percentile of share of Black students among schools with coverage in Zearn. Rows 4-6 and 7-9 of\nPanel B replicate Rows 1-3 using the share of Hispanic students and the share of students receiving free or reduced\n\nrice lunch meals. Row 10 of Panel B displays the number of Zearn schools matched to the Common Core data, and\n\n \n\nhe number of students in those schools, respectively. Column (2) replicates Column (1) using data for all U.S.\n\nschools, rather than restricting to Zearn schools. Data source: Zearn.",
    "Page_75": "Appendix Table 4\nCities with Largest Small Business Revenue Losses Following COVID Shock\nCity State Change in Small Bus. Revenue\n\n(1) (2) (3)\n\nNew Orleans Louisiana -77%\nWashington District of Columbia -74%\nSan Francisco California -69%\nNew York City New York -68%\nBoston Massachusetts -65%\nHonolulu Hawaii -65%\nCharlotte North Carolina -64%\nPhiladelphia Pennsylvania -63%\nSan Jose California -62%\nBaltimore Maryland -59%\n\n \n\nNotes: This table shows the ten cities with the largest small business revenue declines as measured in the\nWomply data (among the fifty largest cities in the U.S.). Columns (1) and (2) display the name of the city and\nthe state in which it is located. Column (3) shows the decline in small business revenue, computed as the change\nin net small business revenue in Womply data between January 4-31 2020 and March 25 2020-April 14 2020,\n\nseasonally adjusted using 2019 values of net revenue. Data source: Womply.",
    "Page_76": "Appendix Table 5\nAssociation Between Changes in Consumer Spending in ZIP Code and Workplace Rent\n\n \n\nDep. Var.: Change in Consumer Spending (%)\n(1) (2) (3)\n\n \n\nMean Workplace 2BR Rent -12.61 -9.55 -16.49\n(per thousand dollars) (0.69) (1.47) (4.38)\nMedian Home 2BR Rent -4,80\n\n(per thousand dollars) (1.93)\n\nControls:\n\nCounty Fixed Effects xX\nObservations 8837 6624 8837\n\n \n\nNotes: This table shows OLS regressions of average percentage changes in consumer spending by ZIP code (using\ndata from Affinity Solutions) on average workplace ZIP code median two-bedroom rent. Standard errors are\nreported in parentheses. In each regression, we restrict the sample to ZIP codes in the bottom quartile of median\nhousehold income. We compute ZIP-level changes in consumer spending in the Affinity data as the percentage\nchange in seasonally-adjusted spending from the period January 4-31 to the period March 25-April 14, winsorizing\nat the 99th percentile of (population-weighted) ZIP-level changes in employment. We construct the average\nworkplace rent variable by combining data on the matrix of home residence by workplace ZIP codes taken from\nCensus’ LEHD Origin-Destination Employment Statistics (LODES) for low-income workers (workers earning below\n$1,250 per month) with data on median two bedroom monthly rents from the 2014-2018 ACS. In particular, we\nassign median rents from the ACS to each ZIP code of workplace in the LODES data and then compute mean\nworkplace rent in each home ZIP code, weighting by the number of low-wage jobs in each workplace ZIP code. The\ndependent variable is scaled from 0 to 100 and the independent variable is expressed in thousands such that, for\nexample, the coefficient of -12.61 in Column (1) implies that a $1000 increase in monthly workplace rent is\nassociated with a 12.61% larger drop in total spending. Column (1) shows the baseline regression without any\ncontrols. This specification corresponds with the slope coefficient and standard error in Figure 11c. Column (2)\n\nadds median home two bedroom rent. Column (3) adds county fixed effects. Data source: Affinity Solutions.",
    "Page_77": "Appendix Table 6\n\nList of Partial Re-Openings and Control States for Event Study\n\nConsumer Spending Controls\nDate States that Re-Opened (1)\n\nCalifornia, Connecticut, Delaware,\nFlorida, Hawaii, Illinois, Indiana,\nLouisiana, Maryland, Massachusetts,\nMissouri, Nebraska, New Jersey, New\n\nApril 20th, 2020 South Carolina\n\nMexico, New York, Oregon,\nPennsylvania, South Dakota, Virginia,\n\nWashington, Wisconsin\n\nCalifornia, Connecticut, Delaware,\nFlorida, Illinois, Indiana, Louisiana,\n\nMaryland, Massachusetts, Missouri,\nApril 24th, 2020 Alaska, Georgia\nNebraska, New Jersey, New Mexico,\n\nNew York, Pennsylvania, South Dakota,\n\nVirginia, Washington, Wisconsin\n\nIllinois, Nebraska, New Jersey,\n\n \n\nApril 27th, 2020 Minnesota, Mississi\nPennsylvania, Virginia\n\nEmployment Controls Small Businesses Open Controls Mobility Controls\n\n(2) (3) (4)\nCalifornia, Connecticut, Delaware, District\n\nCalifornia, Connecticut, Delaware, District Of Columbia, Florida, Hawaii, Illinois,\n\nOf Columbia, Florida, Illinois, Indiana, Indiana, Louisiana, Maryland, Massachusetts,\nIndiana, Missouri, Nebraska, New\n\nLouisiana, Maryland, Missouri, Nebraska, Missouri, Nebraska, New Jersey, New\nMexico, Oregon, South Dakota\n\nNew Mexico, Oregon, Pennsylvania, South Mexico, New York, Oregon, Pennsylvania,\n\nDakota, Virginia, Washington, Wisconsin South Dakota, Virginia, Washington,\n\nWisconsin\n\nCalifornia, Connecticut, Delaware, District\n\nCalifornia, Connecticut, Delaware, District\n\nOf Columbia, Florida, Illinois, Indiana,\nOf Columbia, Florida, Illinois, Indiana, Delaware, Indiana, Louisiana,\nLouisiana, Maryland, Massachusetts, .\nLouisiana, Maryland, Missouri, Nebraska, Missouri, Nebraska, New Mexico,\n\nMissouri, Nebraska, New Jersey, New\n\nNew Mexico, Pennsylvania, South Dakota, South Dakota, Virginia, Wisconsin\nMexico, New York, Pennsylvania, South\n\nVirginia, Washington, Wisconsin\nDakota, Virginia, Washington, Wisconsin\n\nCalifornia, Connecticut, Delaware, District California, Connecticut, Delaware, District .\nDelaware, Illinois, Nebraska, New\nOf Columbia, Illinois, Maryland, Nebraska, | Of Columbia, Illinois, Maryland, Nebraska,\n\nNew Mexico, New York, Pennsylvania, South\n\nMexico, Pennsylvania, South Dakota,\nNew Mexico, South Dakota, Virginia,\nVirginia, Wisconsin\n\nWashington, Wisconsin Dakota, Virginia, Washington, Wisconsin\n\nNotes: This table lists the treatment and control states for the analysis of state reopenings in Figures 12b-d and Table 3. Column (1) displays the control states that are compared to the treatment states in the two-week event horizon\n\nin the event study of consumer spending (as measured in the Affinity data) described in Figure 12b-d and Table 3; for details, see notes to Figure 12b-d and Table 3. Column (2) replicates Column (1) for employment (as measured in\n\nthe Paychex-Intuit-Earnin data). Column (3) replicates Column (1) for number of small businesses open (as measured in the Womply data). Column (4) replicates Column (1) for time away from home (as measured in the Google\n\nMobility data).",
    "Page_78": "Appendix Table 7\nCity to County Crosswalk\n\n \n\nCity Name\n\nAlbuquerque\nAtlanta\nAustin\nBakersfield\nBaltimore\nBoise\n\nBoston\nCharlotte\nChicago\nCleveland\nColorado Springs\nColumbus\nDallas\n\nDenver\n\nDetroit\n\nEl Paso\n\nFort Worth\nFresno\nHonolulu\nHouston\nIndianapolis\nJacksonville\nKansas City\nLas Vegas\n\nLos Angeles\nLouisville\nMemphis\nMiami\nMilwaukee\nMinneapolis\nNashville\n\nNew Orleans\nNew York City\nNew York City\nNew York City\nNew York City\nNew York City\nOakland\nOklahoma City\nOmaha\nPhiladelphia\nPhoenix\nPortland\nRaleigh\nSacramento\nSalt Lake City\n\nSan Antonio\n\n \n\nSan Diego\n\nSan Francisco\nSan Jose\nSeattle\n\nTampa\nTucson\n\nTulsa\n\nVirginia Beach\nWashington\nWichita\n\nState Name\n\nNew Mexico\nGeorgia\nTexas\nCalifornia\nMaryland\nIdaho\nMassachusetts\nNorth Carolina\nIllinois\nOhio\nColorado\nOhio\nTexas\nColorado\nMichigan\nTexas\nTexas\nCalifornia\nHawaii\nTexas\nIndiana\nFlorida\nMissouri\nNevada\nCalifornia\nKentucky\nTennessee\nFlorida\nWisconsin\nMinnesota\nTennessee\nLouisiana\nNew York\nNew York\nNew York\nNew York\nNew York\nCalifornia\nOklahoma\nNebraska\n\nPennsylvania\n\n \n\nArizona\nOregon\nNorth Carolina\nCalifornia\nUtah\n\nTexas\nCalifornia\nCalifornia\nCalifornia\nWashington\nFlorida\nArizona\nOklahoma\n\nVirginia\n\nDistrict of Columbia\n\nKansas\n\nCounty\n\nBernalillo\nFulton\nTravis\nKern\nBaltimore\nAda\n\nSuffolk\nMecklenburg\nCook\nCuyahoga\nEl Paso\nFranklin\nDallas\nDenver\nWayne\n\nEl Paso\nTarrant\nFresno\nHonolulu\nHarris\nMarion\nDuval\nJackson\nClark\n\nLos Angeles\nJefferson\nShelby\nDade\nMilwaukee\nHennepin\nDavidson\nOrleans\nBronx\nKings\n\nNew York\nQueens\nRichmond\nAlameda\nOklahoma\nDouglas\nPhiladelphia\nMaricopa\nMultnomah\nWake\nSacramento\nSalt Lake\nBexar\n\nSan Diego\nSan Francisco\nSanta Clara\nKing\nHillsborough\nPima\n\nTulsa\nVirginia Beach City\n\nDistrict Of Columbia\n\nSedgwick\n\nCounty FIPS Code\n\n35001\n13121\n48453\n\n6029\n24005\n1600\n25025\n37119\n1703\n39035\n\n804\n39049\n48113\n\n803\n26163\n4814\n48439\n\n6019\n15003\n48201\n18097\n12031\n29095\n32003\n\n6037\n21111\n47157\n12086\n55079\n27053\n47037\n2207\n36005\n36047\n3606\n3608\n36085\n\n600\n40109\n31055\n4210\n\n4013\n4105\n37183\n\n6067\n49035\n48029\n\n6073\n\n6075\n\n6085\n53033\n12057\n\n4019\n40143\n51810\n11001\n20173\n\n \n\n \n\nNotes: This table shows our metro area (city) to county crosswalk. We assigned metros to counties and ensured that a\n\nsignificant portion of the county population was in the metro of interest. Some large metros share a county; in this case\n\nthe smaller metro was subsumed into the larger metro.",
    "Page_79": "FIGURE 1: Consumer Spending in National Accounts vs. Credit and Debit Card Data\n\nA. National Accounts: Changes in GDP and its Components\n\n$0.04T $0.05T\n\nS\ng\n8\n&\nn\nCc\n2\nS\ng\ns\ng\nG\n\nE\n\n£\na\na\nOo\now\n\nns of chained 2012 dollars)\n\n \n\n \n\n \n\n \n\n \n\nGross Private Govt. Net Personal Credit Card\nDomestic Domestic Expend, Exports Consumption Spending\nProduct —_Investment Expend. (PCE) in PCE\nB. Retail and Food Services in Affinity Solutions Data vs. Advance C. Consumer Spending in Affinity Data vs. Advance Monthly Retail\nMonthly Retail Trade Survey Trade Survey Estimates in April 2020, by Industry\n\n  \n     \n  \n \n\nHome Improvement Centers,\n\n‘*® A Grocery and Food Stores\nSporting Goods and Hobby,\nGeneral Merchandise Stores\n\n-50%4 Apparel and Accessorie;\n.\n\n-100% Correlation Coef. 0.88\n-100% -50% o% 50%\nChange in Advance Monthly Retail Trade Survey Revenue (%)\nfrom January to April 2020\n\n \n\n \n\n  \n\nJul 2019 Oct 2019 Jan 2020 Api Jul 2020 Oct 2020\nNotes: This figure compares changes in consumer spending measured in Affinity Solutions data on debit and credit card\nexpenditures to the National Income and Product Accounts (NIPA) data and Advance Monthly Retail Trade Survey (MARTS)\ndata. Panel A examines the change in GDP from Q1-2020 to Q2-2020 using NIPA data (Tables 1.1.2, 1.1.6 and 2.3.2 from\nthe Second Estimate of 2nd Quarter 2020 Gross Domestic Product, released on August 27 2020). The first bar shows the\nseasonally-adjusted change in real GDP (-$1.73T). In parentheses under the first bar we report the compound annual growth\nrate corresponding to this one-quarter change in real GDP (-31.7%). Bars two through five show the contribution to the\nchange in real GDP of its components, estimated using NIPA Table 1.1.2. The final bar shows the contribution of components\nof Personal Consumption Expenditures (PCE) that are likely to be captured in credit card spending (-$1.03T), estimated\nusing NIPA Table 2.3.2. This includes all components of PCE except for motor vehicles and parts, housing and utilities,\nhealth care, and the final consumption expenditures of nonprofit institutions serving households. This bar indicates total\nspending (including spending in other modes of payment, e.g. cash) in categories of goods and services which are likely to\nbe well-represented in card spending data, rather than total card spending itself. Panel B reports changes in average daily\nspending for each month in the Affinity Solutions credit and debit card data and the Advance Monthly Retail Trade Survey\n(MARTS). The retail series in Panel B restricts to retail trade sectors (NAICS 44-45) excluding motor vehicles (NAICS 441)\nand gas (NAICS 447). The MARTS series is constructed by dividing the total spending in each category by the number of\ndays in that month, and then indexing the average daily spending to January of the corresponding year. The Affinity series\nis constructed by taking the monthly average of the seven-day moving average series indexed to January of the respective\nyear. We also report the root mean squared error (RMSE) corresponding to the difference between indexed MARTS monthly\nspending and indexed Affinity monthly spending. Panel C displays a scatter plot of changes in spending at the three-digit\nNAICS code level between January and April 2020 in the Affinity data vs. the MARTS data, restricting to industries where\nthe industry definitions in the Affinity Solutions data align closely with a three-digit NAICS code surveyed in the MARTS.\nWe report the correlation between changes in the Affinity and MARTS data, weighted by total MARTS spending in January\n2020. Data source: Affinity Solutions.",
    "Page_80": "FIGURE 2: Changes in Consumer Spending During the COVID Crisis\n\nA. Spending Changes by Income Quartile: 2019 vs. 2020 B. Spending Changes by Sector\n\n$-3,1 Bill\n10 (41% otagg.\n\nSpendin\njen) . a ”\n- NL Mansa sone Maes tem ‘\n\nfen fy Sl\n\n  \n \n  \n\n100%\n\nDurable Goods\n\nDurable Goods.\n\nRES. ERS\n\n% 0\n\nSpenaing ‘Spending Decline) 75%:\necline}\n\n-0.9 Bilion\n(12% of Aag\nSpending Decline) 50%.\n\n‘ LN\n§22 pion $40.1 Billion\n% of A\n\nCredit and Debit Card Spending\nPer Day ($ Billions)\n\n \n\n  \n\n \n\n \n\n \n\n \n\n \n\nSonica? teary\n2 spending Decline) 25% np.\nSennces: (33%)\nFebl Marl Aprl Mayl Junl Jull Augl Sepl Oct1\n0%:\n=~ 2019 Top Income Quartile 2020 Top Income Quartile 1 ane Mazeageia) Share of Pre-COVID Spending\n-~ 2019 Bottom Income Quartile 2020 Bottom Income Quartile\nC. Spending Changes by Category D. Spending Changes by Sector: COVID vs Great Recession\n\n75%\n\n \n\n \n\n25% g\nAtHome\n> Swim Pools @8\n= o Landscaping £2\nZo 0% and Hort. Serv. ae\n2 S 50%\n38 ae 50%\non All Consumer 3's\nDE -25% Spending 2 §\ng2 of\nEs Se\n55 “5\n22 S2 25%\nSo -50% as\nOs Restaurants and ‘52\n£ s Eating Places os\noe £9\n5 -75% os\n& Airlines a 0%\nBarbers and Durables Non-Durables Services\n-100% Beauty Shops\n\n \n\nFeb4 Feb18  Mar3 Mari? Marat Apr14  Apr28 GE Great Recession [NN COVID-19\n\nNotes: This figure disaggregates spending changes by income and sector using debit and credit card data from Affinity\nSolutions. Panel A plots a weekly series of average daily consumer spending, separately for cardholders residing in ZIP codes\nin the top and bottom (population-weighted) quartiles of median household income (measured using the 2014-2018 ACS). We\ninflate the spending observed in Affinity data to estimate total spending for the full U.S. population by multiplying by the\nratio of January 2020 (or 2019) total spending for components of PCE that are likely captured in credit/debit card spending\n(described in the notes to Figure 1) to the January 2020 (or 2019) total spending in the Affinity data. The annotations in Panel\nA display the change in spending during the periods of April 8-14, July 8-14 and Sept 28-Oct 4 respectively (calculated as\ndescribed in Table 1). Panel B disaggregates seasonally-adjusted spending changes (left bar) and pre-COVID levels (right bar)\nby sector. In the left bar of Panel B, the total decline being decomposed is defined as ((Spending in March 25 through April\n14 2020) - (Spending in March 25 through April 14 2019)) - ((Spending in January 4 through January 31 2020) - (Spending\nin January 4 through January 31 2019)). The right bar of Panel B shows the sectoral shares of spending during January 4-31\n2020. See Appendix B for the definitions of these sectors. Panel C compares seasonally-adjusted trends in weekly consumer\nspending for five specific categories of goods and pooled consumer spending. Panel D decomposes the change in personal\nconsumption expenditures (PCE) in the Great Recession and the COVID-19 Recession using NIPA Table 2.3.6U. PCE is\ndefined here as the sum of services, durables and non-durables in seasonally adjusted, chained (2012) dollars. The peak to\ntrough declines are calculated from December 2007 to June 2009 for the Great Recession and from January 2020 to April 2020\nfor the COVID-19 Recession. Data source: Affinity Solutions.",
    "Page_81": "FIGURE 3: Association Between COVID-19 Incidence, Spending, and Time Away From Home\n\nA. Change in Consumer Spending vs. COVID Case Rate, by County B. Change in Time Spent Away From Home vs. COVID Case Rate, by\nCounty\n\n-20%\n\n   \n\nLow-Income Counties (1)\nSlope = -2.24 (s.e. = 0.29)\n\n   \n\n  \n\nLow-Income Counties (1)\nSlope = -2.05 (s.e. = 0.60)\n\n   \n\n.\nHigh-Income Counties (4) High-Income Counties (Q4)\n\nlope = -1.87 (s.e. = 0.23)\n\n \n\n \n\n-40% © Slope = -1.07 (s.e. = 0.54) -35%\n5 20 150 1100 5 20 150 1100\nCounty-level COVID-19 Cases Per 100,000 People (Log Scale) County-level COVID-19 Cases Per 100,000 People (Log Scale)\n\nC. Change in Time Spent Away From Home vs. Median Income, by\nCounty\n\n-15%\n\n-20%\n\n-25%\n\n-30%\n\n  \n\nSlope = -0.21%/$1000 (s.e. = 0.01)\n\n-35%\n40,000 60,000 80,000 100,000\nMedian Household Income in 2014-2018 ($)\n\n \n\nNotes: This figure presents three county-level binned scatter plots. To construct each binned scatter plot, we divide the\ndata into twenty equal-sized bins, ranking by the x-axis variable and weighting by the county’s population, and plot the\n(population-weighted) means of the y-axis and x-axis variables within each bin. Panel A presents the change in seasonally-\nadjusted consumer spending from the base period (Jan 4-31) to the three-week period of March 25-April 14. Panel B presents\nthe change in time spent away from home from the base period (Jan 3-Feb 6) to the three-week period of March 25-April\n14. We exclude weekends when calculating the change in time spent outside home. In both Panels A and B, the x-axis\nvariable is the logarithm of the county’s mean daily cumulative COVID case rate per capita over the period March 25-April\n14. These panels plot values separately for counties in the top and bottom quartiles of median household income (measured\nusing population-weighted 2014-2018 ACS data). Panel C replicates Panel B with county median household income on the\nx-axis (measured in 2014-2018 ACS data). Data sources: Affinity Solutions, Google Community Mobility Reports.",
    "Page_82": "FIGURE 4: Changes in Small Business Revenues by ZIP Code\n\nA. New York B. Chicago\n\nChange in Small R : Change in Small\n\nBusiness Revenue a PTO Business Revenue\n\nfrom Jan to Apr 2020 y from Jan to Apr 2020\n<-73.0% <-63.1%\n-73.0% to-645% [Hon 5 i 63.1% to 54.5%\n64.5% 10 -58.5% % D> ‘ j Park | 54.5% to 50.2%\n58.5% 10 -54.0% / 50.2% t0 -46.1%\n54.0% to -48.5% > i Park 46.1% to -41.9%\n48.5% to 427% 41.9% to -38.6%\n42.7% 10 -36.4% . & ee | -38.6% to -35.3%\n196.4% 10-262% 5 y : ; 35.3% to -29.6%\n“26.2% to -13.1% j Y 29.6% to -17.6%\n>A3.1% ot “ : iq a / > 17.6%\n\n \n\nLeatiet | @ Magbox\n\nC. San Francisco\n\n     \n \n\nVatiejo\n\nChange in Small\nBusiness Revenue\nfrom Jan to Apr 2020\n\n<-17.2%\n\nTT.2% to 66.7%\n68.7% to 61.1%\n81.1% to -56.0%\n-56.0% to -51.8%\n51.8% to -47.6%\n47.6% to -44.4%\n\n-44.4% to -39.3%\n-39.3% to -24.6%\nBezsoe\n\nNotes: This figure plots seasonally-adjusted changes in small business revenue by ZIP code in the MSAs corresponding to New\nYork-Newark-Jersey City, NY-NJ-PA (Panel A), Chicago-Naperville-Elgin, IL-IN-WI (Panel B), and San Francisco-Oakland-\nHayward, CA (Panel C). The changes are measured during March 25 to April 14 relative to the period from January 4 to\nJanuary 31. We seasonally-adjust revenue in each week by dividing the indexed value relative to January for that week in\n2020 by the corresponding indexed value from 2019. We calculate the signal-to-noise ratio by regressing seasonally-adjusted\nnormalized weekly revenue on an indicator variable for whether the week is after March 9, 2020, within each ZIP code,\ndenoting the coefficient and standard error on this indicator variable in each ZIP code as 8, and SE-, respectively. We then\ncalculate the signal-to-noise ratio as 1 — oO SE?/ n)/var(8z). The signal variance to total variance ratios for the panels are 0.79\n(New York), 0.78 (Chicago), and 0.78 (San Francisco). These maps must be printed in color to be interpretable; dark red\ncolors represent areas with larger revenue declines, while dark blue colors represent areas with smaller declines. Data source:\nWomply.",
    "Page_83": "FIGURE 5: Changes in Small Business Revenues vs. ZIP Code Characteristics\nA. Median Income B. Population Density\n-20%\n\n-30%\n\n&\n\n10 April 2020\n\n40%\n\n-50%\n\n   \n\n60%-| Slope = -0.13%/$1000 (s.e. = 0.01)\n\n25,000 50,000 75,000 100,000 125,000 150,000\nMedian Household Income in 2014-2018 ($)\n\n-60% | Slope = -2.77% (s.e. = 0.08)\n\n20 100 400 1,600 6,400 25,600\nPopulation Density: Inhabitants per Square Mile in 2014-2018 (Log Scale)\n\n \n\n \n\n \n\nC. Median Two Bedroom Rent D. Median Two Bedroom Rent: In-Person vs. Teleworkable\n. o% © Slope 232¥est000 (we = 250)\n& .\no 7 : ~\nZo . 10% : °\nLN -30%\nes -20%\nge\nBS -40% -30%\na\n\n-40%\n\n   \n\n-50%\n\nfrom January to April 2020\n\n  \n\n-50%\n\nChange in Small Business Revenue (%)\n\nChange\n\nFood and Accommodation Services and Retail Trade\nSlope = -13.02%/$1000 (s.e. = 0.93)\n\n60% | Slope = -13.47%/$1000 (s.e. = 0.35) 60%\n\n400 1,000 1,600 2,200 400 1,000 1,600 2,200\nMedian Two Bedroom Monthly Rent in 2014-2018 ($) Median Two Bedroom Monthly Rent in 2014-2018 ($)\n\n \n\n \n\nNotes: This figure presents binned scatter plots showing the relationship between changes in seasonally-adjusted small business\nrevenue in Womply data vs. various ZIP code-level characteristics. The binned scatter plots are constructed as described\nin Figure 3. In each panel, the changes in small business revenue are measured during March 25 to April 14 relative to the\nperiod from January 4 to January 31 and seasonally adjusted as defined in Figure 4, winsorizing at the 99th percentile of\nthe (population-weighted) ZIP-level distribution. We exclude data from ZIP codes in which changes are larger than 200%\nor where the variance of normalized revenue exceeds 900%. We also exclude ZIP code-by-industry cells with average weekly\nrevenue of less than $4,250 during the base period of January 4 to January 31. In Panel A, the x-axis variable is median\nhousehold income at the ZIP code level from the 2014-2018 ACS. In Panel B, the x-axis variable is the logarithm of the number\nof ZIP code inhabitants per square mile in the 2014-18 ACS. In Panel C, the x-axis variable is the ZIP code median rent for a\ntwo-bedroom apartment in the 2014-2018 ACS. Panel D replicates Panel C for two distinct sectors: in-person services defined\nas the combination of Food and Accommodation (NAICS 72) and Retail Trade (NAICS 44 and 45), and teleworkable services\ndefined as Finance and Professional Services (NAICS 52 and NAICS 54). Data source: Womply.",
    "Page_84": "FIGURE 6: Changes in Employment Rates Over Time\n\nA. Pooling All Industries\n\n   \n\n \n\n      \n\n \n\nApr 15 Sep 15,\n0%\nfg\n9\n2° -5%\n2 >\nEs\n22 10%\nQo\nES\nule\n& 9\nag ~15%\n26\noo .\n5 ow -20% —®— _Paychex-Intuit-Earnin\n—-@-- CES\n—e— cps RMSE CES: 3.67 p.p.\nRMSE CPS: 1.43 p.p.y\nT T T T T T T T T T\nJan Feb Mar Apr May Jun Jul Aug Sep Oct\nB. Accommodation and Food Services vs. Professional Services\n_ Apr 15, Sep 15,\nSS 0% -4\ne 8 es eetenienl =@ '\n2 >\nSS -20%\nos °\na c\nS |\nle\n9\nEo 40%\na2\ncs RMSE Accom. and Food: 5.24 p.p. \\\n=~ -60% RMSE Professional: 2.35 p.p. \\\n5O RMSE Homebase Accom. and Food: 6.71 p.p. |\nT T T T T T T T T 1\nJan Feb Mar Apr May Jun Jul Aug Sep Oct\n\n—®— Paychex-Intuit-Earnin Accom. & Food Services —@ - Paychex-Intuit-Earnin Professional Services\n—®— CES Accom. & Food Services —@-- CES Professional Services\n—@— Homebase Food Services\n\nNotes: This figure compares employment changes relative to January 2020 within various datasets. The combined Paychex-\nIntuit-Earnin data covers private non-farm employment in the United States, constructed as described in Section H.C. We\nplot the values of the combined Paychex-Intuit-Earnin employment series as of the 15th of each month, relative to the period\nJanuary 4-31. The Current Employment Statistics (CES) and the Current Population Survey (CPS) data are available monthly,\nso we plot changes in each month relative to January 2020. The CES is a monthly survey of firms at the establishment level.\nThe CPS is a monthly survey of households, which we then adjust to match a payroll definition of employment by accounting\nfor multiple jobholders. The CES reports employment for the pay period including the 12th of each month, and the CPS\nis fielded during the week of the 19th of each month. In Panel B, we present employment series restricted to two specific\nsectors: Accommodation and Food Services (NAICS sector 72) and Professional and Business Services (NAICS supersector\n60). Panel B also presents employment changes measured in the Homebase data at small businesses in Accommodation and\nFood Services (NAICS sector 72). Data sources: Paychex, Intuit, Earnin, Homebase.",
    "Page_85": "FIGURE 7: Changes in Employment by Wage Quartile\n\nA. Changes in Employment by Wage Quartile\n\n    \n   \n\n  \n  \n\n \n\n \n\n \n \n\n \n\n \n\n \n\n \n\nApr 15, Sep15 Oct 14\n1%\n1 1 | 0%\n09 1 100-1) _1-0:1m)\n° ' an! 2%\n1 le 10.5\n1 3% een)\ng 100m | oe\n= 109 1 -8% = (2.4m)\nER “10% Ie |\nee \\\nSG I\n2 2 1-20% |\nos 16.3m)_| poe\nES 10% WPS); -20%\nule 1 (63m)\nlo 1 I\no2 I |\n2s 1 i\nag 1 I\nG% -30% | — Top Wage Quartile 829) 1 \\\ntot cutie (510-20) tt\n— Second Quartile ($13-18) ! |\no, | —— Bottom Wage Quartile (<$13) | 1 I\n-40% I I L\n1 1 T 1 T 1 r 1 1 i T\nJan1  Feb1— Mar Apr1 = May1 Jun Jul4 Augi Sep1  Oct1_ — Nov\nB. Changes in Employment by Wage Quartile, Reweighting Across C. Changes in Employment by Wage Quartile and Consumer\nIndustries and Areas Spending, Retail Trade\n0% 20%\n=\ng 10% 8.0%\nES omy g\neg” 0.3%\naS § 0% | Mayes | -- - pI -----5 =~ ~~ -5 = =~ - 5-—— ==\n55 =\nos 5\nas >\nE> -20% 2 -10%\nwig 4 @\n< 2\nos 3 16.9%\nSs 3-209\nes 2 -20%\n5X -30% 2\nTop Wage Quartile S -30% Consumer Spending\n_. Bottom Wage Quartile, Reweighted &\nto Match Top Quartile on County x Industry Employment: Top Wage Quartile\n—— atom Wage Quartile\n40% it 1ge Quarti 40% Employment: Bottom Wage Quartile\n\n \n\nFeb15 Mar 15 AprtS = May 15 Jun 15 Jul 15 Aug 15 Sep 15 Feb 15 Mar 15 Apr 15 May 15 Jun 15 Jul 15 Aug 15 Sep 15\n\nNotes: This figure plots changes in employment by wage quartile relative to January 4-31 2020. In each panel, we show a daily\nseries of private non-farm employment constructed by combining Paychex, Intuit and Earnin data, as described in Section\nII.C. We separate the sample into wage quartiles based on fixed thresholds of the 2019 hourly wage distribution. In Panel\nA, the solid portion of each line represents the combined Paychex-Intuit-Earnin data, while the dashed portion of the line is\nforecasted using Kronos data and Paychex data from firms with weekly paycycles. To construct this forecast, we regress the\ncombined Paychex-Intuit-Earnin series on the de-seasonalized Kronos series for the same date (t), the Paychex weekly series\nfor the same date (t), and the Paychex weekly series for three prior weeks (t — 7), (f — 14), (t — 21). We then use the resulting\ncoefficients to predict the value of combined Paychex-Intuit-Earnin employment before the combined data is available. In\nPanel B, we reweight Paychex-Intuit-Earnin data to examine whether differences in employment trends between the top and\nbottom wage quartile are explained by differences in industry and geographic composition. We restrict the sample in Panel\nB to county x industry (2-digit NAICS) cells which have nonzero first-quartile and fourth-quartile employment in the period\nJanuary 4-31 2020; this sample restriction excludes 0.9% of worker-days from the sample. We then calculate the daily change\nin employment since January 4-31 2020 in each county x industry x income quartile cell, winsorizing at the 99th percentile\n(weighted by total employment in the period January 4-31 2020). For the top and bottom wage quartiles, we estimate overall\ndaily employment by taking the weighted mean of employment changes in every county x industry cell, weighting by the level\nof employment in January 4-31. These series are similar but not identical to Panel A because of the sample restriction and\nwinsorization. Finally, we estimate bottom quartile employment reweighted to match the industry and geographic composition\nof top quartile employment by performing the same procedure, but weighting bottom quartile employment changes by top\nquartile employment levels in January 4-31 in each cell. In Panel C, we restrict to the retail trade sector (NAICS 44-45) and\npresent the change relative to January 4-31 in the Paychex-Intuit-Earnin employment series and the Affinity consumer card\nspending series. Data sources: Paychex, Intuit, Earnin, Kronos, Affinity Solutions.",
    "Page_86": "FIGURE 8: Changes in Low-Wage Employment Rates by ZIP Code\n\nA. New York B. Chicago\n\n‘Change in Low-Wage\nEmployment at Small\nBusinesses from\nJan to Apr 2020\n<-50.4%\n89.4% to 51.0%\n51.0% to 48.7%\n46.7% to 43.0%\n43.0% to 38.5%\n38.5% to 33.4%\n33.4% to -28.9%\n28.9% 10 23.0%\n23.0% 10-13.2%\n13.2%\nNo Data\n\n29.3% 10-13.3%\n\n213.3%\n\n  \n\nC. San Francisco\n\n‘Change in Low-Wage\nEmployment at Smail\nBusinesses from\nJan to Apr 2020\n< 822%\n82.2% 10 68.0%\n68.0% to -$8.7%\n58.7% to 54.1%\n54.1% to 46.5%\n46.5% 0-41.8%\n41.8% to 26.7%\n36.7% to 30.0%\n30.0% 10-18.1%\n> 18.1%\nNo Data\n\n \n\nNotes: This figure replicates Figure 4 using Earnin data on changes in employment among low-wage workers, plotted by\nemployer ZIP code. We focus on small and medium-sized businesses, defined as firms with at most 500 employees, measured\nusing linked data from ReferenceUSA. For users whose employer cannot be linked to ReferenceUSA data on firm sizes, we\nrestrict to users whose employer is in the fourth decile or below of firms in the Earnin data, in terms of number of Earnin\nusers working for the firm; the median firm size for the fourth decile of Earnin employers is roughly 300 employees (among\nemployers matched to ReferenceUSA data). We measure the change in employment as total average weekly employment\nduring the period of April 8-28 divided by total average weekly employment in the period of January 4-31, 2020. We calculate\nthe signal-to-noise ratios as in Figure 4; these ratios are 0.79 in New York, 0.59 in Chicago, and 0.67 in San Francisco. These\nmaps must be printed in color to be interpretable; dark red colors represent areas with larger employment declines, while dark\nblue colors represent areas with smaller declines. Data source: Earnin.",
    "Page_87": "FIGURE 9: Changes in Employment Rates and Job Postings vs. Rent\n\nA. Low-Wage Employment vs. Median Rent, by ZIP\n\n  \n\n-20%\nso tee\ncs\nEN -30%\n=\n52\n39\nE>\nwg e\nc3 -40%\nos Large Businesses (10,000+ Employees)\nee Slope = -9.58%/$1000 (s.e. = 0.65)\nOo\n6e\n‘4. Simall Businesses (<500 Employees)\n50% Slope = -13.93%/$1000 (s.e. = 0.53)\n\nMedium Businesses (500-9,999 Employees)\n@ — Slope = -14.64%/$1000 (s.e. = 0.91)\n\n500 1000 1500 2000 2500\nMedian Two Bedroom Monthly Rent in 2014-2018 ($)\n\n \n\nB. Job Postings for Low-Education Workers vs. Median Rent, by C. Job Postings for High-Education Workers vs. Median Rent, by\nCounty County\n\n0%\n\n \n\n  \n\nsg 9\noa -10%\nas\nst\n$5\nZe\nao -20%\nBe ° .\n3& . °\nc2 o—* 2 nee e .\nos\nQe -30% . .\nPe 0 °\n£8 . . .\n5£\n-40%\n\nSlope = -21.02%/$1000 (s.e. = 1.21) Slope = -1.61%/$1000 (s.e. = 0.93)\n\n \n\n \n\n500 1000 1500 2000\n\n500 1000 1500\nMedian Two Bedroom Monthly Rent in 2014-2018 ($)\n\nMedian Two Bedroom Monthly Rent in 2014-2018 ($)\n\nNotes: This figure shows binned scatter plots of the relationship between median rents and changes in employment rates\n(Panel A) or changes in job postings (Panels B and C). The binned scatter plots are constructed as described in Figure 3. In\neach panel, the x-axis variable is the median rent (within a county or ZIP code) for a two-bedroom apartment in the 2014-2018\nACS. Panel A presents the change in employment rates among low-income workers from January 4-31 to April 8-28 2020,\nmeasured by employer ZIP code separately by firm size in Earnin data linked to ReferenceUSA firm sizes. We winsorize at\nthe 99th percentile of (population-weighted) ZIP-level changes in employment for each firm size category. Panel B presents\nthe county-level change in job postings for workers with minimal or some education from January 8-28 to March 25-April 14\n2020 in the Burning Glass data. Panel C replicates Panel B with job postings for workers with moderate, considerable, or\nextensive education. To construct Panels B and C, we compute the change in job posts in each county x worker education\ncell and winsorize at the 99th percentile of (population-weighted) county-level changes in employment within each education\ngroup. Solid lines are best-fit lines estimated using OLS, except in Panel B, where we use a lowess fit. Each panel also displays\nthe slope coefficient and standard error of the corresponding linear OLS regression. Data sources: Earnin, Burning Glass\nTechnologies.\n\n2000",
    "Page_88": "FIGURE 10: Geography of Employment Losses in the Great Recession vs. COVID Recession\n\n30%\n\n20%\n\n10%\n\nShare of Employment Changes (%)\n\n  \n  \n\n0%\n2007 to 2010\nEmployment Loss\n\nJan to Apr 2020 Week 11 to Week 14 2020\nEmployment Loss UI Claims\n\n     \n\nQuartile of County Median Income\n\nHE cotton = EN Second I Third EE Top\n\nNotes: This figure displays the share of job losses occurring in low vs. high income counties during the Great Recession and\nthe COVID Recession. We split counties into (population-weighted) quartiles by median household income in the 2006 ACS\nfor the Great Recession (Panel A) and the 2014-2018 ACS for the COVID Recession (Panels B and C). To construct the\nfirst set of four bars, we use BLS data to measure the share of the national employment losses from 2007 and 2010 occurring\nwithin counties in each quartile of median household income. The second set of bars replicates the first set of bars using\nthe employment losses from January 2020 to April 2020. The third set of bars reports the share of total initial UI claims\nwithin each county income quartile between March 15 (the first week of COVID-related UI claims) and April 12, 2020. In this\nthird set of bars, we only include counties within states that issue weekly reports of county-level UI claims data; these states\ncomprise 53% of the U.S. population.",
    "Page_89": "FIGURE 11: Changes in Employment and Consumer Spending for Low-Income Households vs.\nWorkplace Rent\n\n     \n\n \n\nA. Change in Low-Income Employment vs. Workplace Rent B. Trends in Low-Income Employment by Workplace Rent Quartile\n-25% ow\n£8 20% -10%\n28\nos\nES\nBL -35% -20%\nue\n£2\nad -30%\n3s ;\nBE 40%\nb=\n-40%\n-45% .\n° Slope =-13.32%/$1000 (s.e. = 0.50) ° -* Q1 Workplace Rent\n5q0,| ® Q4 Workplace Rent\n600 800 1,000 1,200 1,400 1,600 1,800 -50%\n\n \n\nAverage Two Bedroom Monthly Rent in 2014-2018 in Workplace ZIP ($)\n\n   \n\nC. Change in Spending Among Low-Income Households vs.\nWorkplace Rent\n\n-20%\n\n-25%\n\n-30%\n\n-35%\n\nChange in Consumer Spending (%)\nfrom January to April 2020\n\n \n\n~40% | Slope =-12.61%/$1000 (s.e. = 0.69) .\n\n600 800 1000 1200 1400 1600 1800\nAverage Two Bedroom Monthly Rent in 2014-2018 in Workplace ZIP ($)\n\nNotes: This figure compares changes in low-income employment (Panels A and B) and seasonally-adjusted consumer spending\n(Panel C) by home ZIP code to average rent in the workplace ZIP codes of low-income workers who live in each home ZIP code.\nWe construct the average workplace rent for each home ZIP code in two steps. First we measure the distribution of workplace\nZIP codes for low-income workers (earning below $1,250 per month) using the matrix of home ZIP codes by workplace ZIP\ncodes in the Census LEHD Origin-Destination Employment Statistics (LODES). Then, for each home ZIP code, we use these\ndistributions to construct a weighted mean over the median rent of a two-bedroom apartment in workplace ZIP codes (measured\nin the 2014-2018 ACS), weighting by the share of low-income workers in each workplace ZIP code. Panel A presents the change\nin employment rates among low-income workers from January 4-31 to April 8-28 2020, measured by home ZIP code in Earnin\ndata, winsorizing at the 99th percentile of (population-weighted) ZIP-level changes in employment. Panel B uses the same\nEarnin data on employment rates by home ZIP code to present the trends over time in employment of low-income workers\nrelative to the base period of January 4-31, separately for home ZIP codes in the top and bottom (population-weighted)\nquartiles of workplace rent. Panel C replicates Panel A using the change in seasonally-adjusted consumer spending from\nJanuary 4-31 to March 25-April 14, measured by home ZIP code in the Affinity Solutions data and restricted to ZIP codes\nin the bottom quartile of the household income distribution. The binned scatter plots in Panels A and C are constructed as\ndescribed in Figure 3. Data sources: Earnin, Affinity Solutions.",
    "Page_90": "FIGURE 12: Effects of Reopenings on Economic Activity: Event Studies\n\nA. Case Study: Colorado vs New Mexico B. Re-Opened States vs. Control States: Consumer Spending\n\n \n \n  \n \n\nNew Mexico ; Colorado New Mexico Begins\n\nGloag | iSosing i Betopsaing\n/\n\nColorado Begins,\nRe-Opening,\n\n \n\n    \n\n2020\n\n10%\n\n \n\n2\n\n      \n \n\nChange in Consumer Spendini\n\n—+— Control States\n—*— Opening States\n\n-30%\n\n  \n\n(\n1\n'\n'\n'\n+ New Mexico\n40 40 to 0 0 2\nDays Relative to Re-opening\nDithin-Dif Estimate: +1.43p.p. (6. = 051)\n\n. Re-Opened States vs. Control States: Small Businesses Open\n\n \n   \n\n         \n\nAart une\n\n  \n\nFebt Feb 15 Mar 14 AIS May May23\n\n5\n\nC. Re-Opened States vs. Control States: Employment\n\n    \n\n \n\n  \n\n   \n   \n\n‘Opening 0\n0%: ' = '\n1 < '\ns \\ 5 \\\nBe ' B. \\\n= I c i\n58 ' g '\ngg 10% ' é \\\nBs | 3 |\nES ' a '\nBe I 2 i\n2 20% - — :\nH 2\nae ' ® \\\n\\ 2 \\\n-30% | —*— Control States ! Ego] —2— Control states -\n—+*— Opening States i Oo “0%) __.__ Opening States 1\n\n-80 -60 do 20 0 20 80 60 4p 20 0 20\n\nDays Relative to Re-opening Days Relative to Re-opening\nDift.n-Dif Estimate: +0.65p p. (s.e. = 0.51) Dift.in-Diff Estimate: +3.27p.p. (se. = 1.26)\n\nE. Variance Explained by Reopenings\n\n15%\n\n \n\n0% [ | i\n\nSpending Employment Businesses Open\n\nNotes: This figure analyzes the causal effects of state reopenings. Panel A presents a time series plot of the change in\nseasonally-adjusted consumer spending relative to the base period of January 4-31 for New Mexico and Colorado. Colorado\npartially reopened non-essential businesses on May 1, while New Mexico did not do so until May 16. Panel B presents an event\nstudy plot of the same outcome variable, showing average spending changes in five states (SC, AK, GA, MN and MS) that\npartially reopened non-essential businesses between April 20 and April 27. Each reopening state is matched to multiple control\nstates (listed in Appendix Table 6) that did not reopen within the subsequent 3 weeks but had similar trends of the outcome\nvariable during the weeks preceding the reopening. We construct the control group separately for each reopening day and\nthen stack the resulting event studies to align the events. Panel C replicates Panel B with the change in employment relative\nto January 4-31 measured using combined Paychex-Intuit-Earnin data (as described in Section II.C). Panel D replicates Panel\nB with the seasonally-adjusted change in small businesses open measured using Womply data. In Panels B to D, we report\nthe coefficient from a difference-in-differences regression comparing treated vs. untreated states in the two weeks following vs.\nthe two weeks prior to the partial reopening (also reported in Table 3). Panel E reports the share of variance in outcomes\nexplained by reopenings as of May 18. To estimate these variance shares, we first calculate the variance of each outcome across\nstates on May 18, 2020. Then, we add the difference-in-difference estimate for the effect of reopening on a given outcome\nto all states not open on May 18 (adding only half of the effect if the state opened between May 11 and May 18). We then\nrecalculate the variance in this counterfactual in which all states had reopened. The share of variance explained by reopenings\nfor each outcome is defined as 1-(counterfactual variance/actual variance). Data sources: Affinity Solutions, Paychex, Intuit,\nEarnin, Womply.",
    "Page_91": "FIGURE 13: Effect of Stimulus Payments on Consumer Spending: Regression Discontinuity\nEstimates\n\nA. Spending in Lowest Income Quartile ZIP Codes B. Spending in Highest Income Quartile ZIP Codes\n\n   \n\n   \n\n \n\n'\n\\\n\\\n\\\n'\n\\\ngg ioe\nBS 0% | ..\na @ 2s\n83 | . “ye\n8 \\\nos\na0 . '\nS* -30% . |\n© | RD Estimate of Stimulus Impac\n-40% | 2.2% (s1e.= 7.2%\nApri ‘Apr 8 ‘Apr 15 ‘Apr 22 ‘Apr 29 Apr Apr 8 Apr 15 Apr 22 Apr 29\nC. Durable Goods Spending D. In-Person Services Spending\n\n   \n\nImpact:\n\n \n\nApr 1 Apr 8 Apr 15 Apr 22 Apr 29\n\nNotes: This figure analyzes the effect of the CARES Act stimulus payments deposited on April 15, 2020 on card spending by\nplotting daily spending levels in the Affinity data for the month of April. In each panel, we first calculate spending on each\nday relative to mean spending over January 4-31, and then residualize daily spending with respect to day of week and first of\nthe month fixed effects, which we estimate using data from January 1 2019 to May 10 2019. Each panel reports regression\ndiscontinuity estimates of the jump in spending on April 15, using a linear control function before and after April 15 (shown\nby the solid best fit lines), excluding the partially treated day of April 14, shown by the hollow point and demarcated by the\ndashed vertical line. Panel A restricts the sample to cardholders living in ZIP codes in the lowest quartile of (population-\nweighted) median household income measured using the 2014-2018 ACS. Panel B restricts the sample to cardholders in highest\nincome quartile ZIP codes. Panels C and D pool all cardholders and restrict to spending on durable goods (Panel C) and\nin-person services (Panel D), as defined in Appendix B. Data source: Affinity Solutions.",
    "Page_92": "FIGURE 14: Effects of Stimulus Payments on Business Revenue and Employment\n\n \n\n \n\nA. Small Business Revenue in Lowest Rent Quartile ZIP Codes B. Small Business Revenue in Highest Rent Quartile ZIP Codes\n\\ \\\n10% ie 10; \\\ng . °¢\noO 0% ' © 0% '\n© °\nZo le a '\n28-10 6 eB 0 |\nos oe! . . as 1\nBS -20%40 . | . . BE 20 !\n55 fee ioe . 22\nSs —w 2° 2 gs \\\nao 0% . ; . Bg 2% . ee ° .\n= = .\noo e 1 1 *\nEZ 20% . ° 7\n53“ aa : —*\nse 1 le 6 .\na 0% ' \\\n2 \\ \\\n5 \\ \\ . .\n5 -00% ' 0% ° '\n| RD Estimate of Stimulus Impact | RD Estimate of Stimulus Impact:\n| 17.92% (s.¢.= 9.59%) | 1.20% (s.e.= 6.27%)\napr t Apr 8 pris Apr 22 ‘Apr 29 Aprt ‘Apr 8 Aprts Apr 22 ‘Apr 29\n\nC. Small Business Revenue and Worker Employment\nby ZIP Code Rent Quartile\n\n20% +\n\n0% +\n\n \n\n-20% 4\n\n-40% 4\n\nChange Relative to January 2020 (%)\n\n \n\n \n\n \n\nJan1S  Feb1 Feb15 Mart Mar15 = Apri. Apr1S = May1 May15 = Jun Jun 15\n\n \n\n \n\nBottom Wage Quartile Employment in Botlom Rent Quartle ZIPs ‘Small Bus. Revenue in Bottom Rent Quartle ZIPs\n\naaa Bottom Wage Quartile Employment in Top Rent Quartle ZIPs = = = = Small Bus. Revenue in Top Rent Quartile ZIPs\n\nNotes: This figure analyzes the effect of the CARES Act stimulus payments deposited on April 15, 2020 on small business\nrevenues and low-wage employment. In Panels A and B, we first calculate small business revenue on each day relative to mean\nspending over January 4-31, and then residualize daily revenue with respect to day of week and first of the month fixed effects,\nwhich we estimate using data from January 1 2019 to May 10 2019. Panels A and B report regression discontinuity estimates\nof the jump in spending on April 15, using a linear control function before and after April 15 (shown by the solid best fit lines),\nexcluding the partially treated day of April 14, shown by the hollow point and demarcated by the dashed vertical line. Panel\nA restricts the sample to businesses in ZIP codes in the lowest quartile of (population-weighted) median two-bedroom rent\nmeasured using the 2014-2018 ACS. Panel B restricts the sample to cardholders in highest rent quartile ZIP codes. Panel C\nplots the 7-day moving average of the changes in seasonally-adjusted small business revenue from Womply data and low-income\nemployment at small businesses from Earnin data. The employment data is restricted to businesses whose parent firm has at\nmost 500 employees (measured in ReferenceUSA data linked to Earnin data). Data sources: Womply, Earnin.",
    "Page_93": "FIGURE 15: Effects of Paycheck Protection Program on Employment\n\nA. Change in Employment by PPP Eligibility, All Industries Excl. Food Services\n\n    \n     \n   \n\n;PPP Program Begins jEstimated Effect to August 15:\n0% (April 3 11.78 p.p. (s.e. = 1.99 p.p.)\n| |\n| |\n| |\n| |\nZo 5% I I\nzo ' |\na ! 1\nSS -10% |\n22 |\nes I\nue 1\n<2 -15% ; \\\n2s \\ 501-800 Employees\noo\nco |\nO- -20%\n' | 100-500 Employees\n| |\n-25% I |\nt\n\n \n\nT T T T T T T\nFeb15 Mar15 Apr15 May15 Jun15 Jul15 Aug15 Sep 15\n\nB. Change in Employment by Firm Size, All Industries Excl. Food Services\n\n \n\n-10% |\n°\n|\nsO ° ° ° |\nSL e\nes 1°\nBo -20% e\nes i\ns3 i\naes | °\neS i\nWig |\nc2 i\n& I\nSS -30% |\nGE I\nse |\noO I\n|\n|\n|\n-40% |\n0 100 200 300 400 500 600 700 800\nFirm Size\n\nNotes: This figure analyzes the effects of the Paycheck Protection Program on employment using the threshold in eligibility at\n500 employees. We pool all industries except Accommodation and Food Services (NAICS 72), which was subject to different\neligibility rules (discussed in Section IV.C). Panel A compares employment trends measured in Paychex and Earnin data among\nfirms with 100-500 employees (generally eligible for PPP loans) to firms with 501-800 employees (generally ineligible for PPP\nloans). To construct these employment trends, we begin by calculating weekly employment changes relative to January 4-31\n2020 disaggregated by data source, county, industry (2-digit NAICS), wage quartile and firm size bin. We reweight these cells\nso that the composition in each firm size bin matches the pooled distribution of industry and data source over the period\nJanuary 4-31 2020. We plot the “control” series (firms with 501-800 employees) directly as the mean weekly value of the\nreweighted employment series. We plot the “treated” series (firms with 100-500 employees) as the sum of the control series\nand the weekly difference between control and treated firms after residualizing on interacted county and wage quartile fixed\neffects. For visual clarity, we recenter each series so the mean change in employment is 0% over the pre-period (February 12\nto March 18). The difference between these two series corresponds to the regression estimate in Column 1 of Table 5, which is\nalso reported in the figure. Panel B presents a binned scatter plot of changes in reweighted employment (defined as in Panel\nA) from January 4-31 to June 1-23 vs. firm size. To construct changes in employment by firm size, we first classify firms in\nbins of size 50 according to their parent employer size. Then we calculate the mean change in employment among firms in\neach bin and plot this mean change against the midpoint in each bin. Data sources: Paychex, Earnin.",
    "Page_94": "FIGURE 16: Effects of COVID on Educational Progress by Income Group\n\n20% 4\n\n0% 5\n\n-20% +\n\n-40% 4\n\n   \n   \n\n—e— Top Income Quartile\n——*— Middle Income Quartiles\n—+— Bottom Income Quartile\n\nChange in Math Lessons Completed (%)\nRelative to January 2020\n\n-60% 4\n\n \n\n \n\nT T T T T T T T T\nJan 8 Jan 22 Feb 5 Feb 19 Mar 4 Mar 18 Apr 1 Apr 15 Apr 29\n\nNotes: This figure plots a time series of students’ educational progress on the Zearn Math online platform, splitting schools\ninto quartiles based on the share of students eligible for Free and Reduced Price Lunch. We measure educational progress as\nthe number of accomplishment badges earned in Zearn Math in each week, relative to the mean value of badges earned during\nthe reference period of January 6 to February 7 2020. The sample is restricted to classes with more than 10 students using\nZearn during the reference period and at least five users in every week during the reference period. We measure the share of\nstudents eligible for Free and Reduced Price Lunch in each school using demographic data from the Common Core data set\nfrom MDR Education, a private education data firm. Data source: Zearn.",
    "Page_95": "APPENDIX FIGURE 1: Seasonal Fluctuations in Consumer Spending vs. Employment\n\nA. Seasonal Fluctuations in Consumer Spending in MARTS Data\n\n40%\n20%\n\n0%\n\nChange in Spending (%)\nRelative to January\n\n—+4— No Seasonal Adjustment\n20% —e— With Seasonal Adjustment RMSE: 13.25 p.p.\n-20%\n\n \n\n2010 2011 2012 2013 2014 2015 2016 2017 2018 2019\n\nB. Seasonal Fluctuations in Employment in CES Data\n\n40%\n\n20%\n\noe | at et ai les lish unter punts yuinits units urate\n\nChange in Employment (%)\nRelative to January\n\n—+4— No Seasonal Adjustment\n20% —e— With Seasonal Adjustment RMSE: 2.00 p.p.\n-20%\n\n \n\n2010 2011 2012 2013 2014 2015 2016 2017 2018 2019\n\nNotes: This figure compares seasonal fluctuations in Advance Monthly Retail Trade Survey (MARTS) data on consumer\nspending on retail sales and food services (excluding motor vehicle and gas) vs. Current Employment Statistics (CES) data\non private sector non-farm employment. Panel A shows seasonal fluctuations in consumer spending in MARTS data. The\nseries marked in triangles shows trends in consumer spending without seasonal adjustment, expressed as percentage changes\nin consumer spending in each month relative to January of the same year. The series marked in circles shows trends in\nconsumer spending, as seasonally adjusted by the U.S. Census Bureau, expressed as percentage changes in consumer spending\nin each month relative to January of the same year. The annotation in the lower right hand corner displays the RMSE for\n\nthe difference between the two series, expressed in percentage terms. Panel B replicates Panel A using CES data on private\nsector, non-farm employment.",
    "Page_96": "APPENDIX FIGURE 2: Industry Shares of Consumer Spending and Business Revenues Across\nDatasets\n\nA. Compared to QSS B. Compared to MARTS\n\nFinance & Insurance Motor Vehicles\n\nHealth & Soc. Assist. Nonstore Retailers\n\nProf. Services Food & Beverage\n\nInformation Food Service\n. General Merchandise\nAdmin Support\nGas Stations\nTrans. & Warehousing\nHealth & Personal Care\nRental & Leasing\nBuilding Material\nUtilities .\nClothing\n\nOther Services\nMiscellaneous\n\nArts, Entmt., & Rec Furniture\n\nME oss\nEE Atinity Electronics\n\nAccom. & Food Services\n\nia\n\n \n\n \n\nEducation Fe Womply Sporting & Hobby\nTo\n0% 10% 20% 30% 0% 10% 20% 30%\nPercent of Total Service Revenue in Q1 2020 (%) Percent of Total Retail and Food Service Revenue in January 2020 (%)\n\nNotes: This figure compares the industry composition of spending in private sector datasets to the industry composition\nof spending in representative survey datasets. Panel A shows the NAICS two-digit industry mix for transactions in the\nAffinity Solutions and Womply datasets compared with the Quarterly Services Survey (QSS), a survey dataset providing\ntimely estimates of revenue and expenses for selected service industries. Subsetting to the industries in the QSS, each bar\nrepresents the share of revenue in the specified sector during Q1 2020. We construct spending and revenue shares for the\nAffinity Solutions and Womply datasets (respectively) by aggregating card transactions in Q1 2020, using the merchant to\nclassify the purchase by sector. Panel B shows the NAICS three-digit industry mix for the same two sector private datasets\ncompared with the Advance Monthly Retail Trade Survey (MARTS), another survey dataset which provides current estimates\nof sales at retail and food services stores across the United States. Subsetting to the industries in the MARTS, each bar\nrepresents the share of revenue in the specified sector during January 2020. We construct revenue shares for the private\ndatasets, Affinity and Womply, by aggregating firm revenue (from card transactions) in January 2020. Data sources: Affinity\nSolutions, Womply.",
    "Page_97": "APPENDIX FIGURE 3: Industry Shares of Job Postings in Burning Glass and Job Openings in\nJob Openings and Labor Turnover Survey (JOLTS)\n\n25%\n\nN\n\n3S\n\nxs\n1\n\n=\n\na\n\nss\n1\n\n10%-4\n\n5% +\n\nIndustry Share of JOLTS Job\nOpenings in January 2020 (%)\n\n \n\n \n\n0% 4 Corr. = 0.91\nT T T T T T\n0% 5% 10% 15% 20% 25%\nIndustry Share of Burning Glass\nJob Postings in January 2020 (%)\n\n \n\nNotes: This figure presents a scatter plot showing the industry share of each 2-digit NAICS code of job postings in the Job\nOpenings and Labor Turnover Survey (JOLTS) data in January 2020 vs. the corresponding industry share in job postings\nin Burning Glass data in January 2020. The solid line is a 45 degree line. The annotation in the bottom right corner of the\npanel displays the correlation between 2-digit NAICS industry shares in the JOLTS vs. Burning Glass data in January 2020,\nexcluding NAICS 92 (Public Administration), and weighting according to total job openings in each NAICS code in JOLTS\nin January 2020. Data source: Burning Glass.",
    "Page_98": "APPENDIX FIGURE 4: Cash Spending in CoinOut Transactions Data vs. Card Spending\n\n80%\n\n60% Signal Correlation Affinity Grocery\n© vs. CoinOut National Series: 0.9\n\n40%\n\n20%\n\n0%\n\nChange in Consumer Spending (%)\nRelative to January 2020\n\n \n\n-20%\nJan 1 Feb 1 Mar 1 Apr 1 May 1 Jun 1\n\n \n\n \n\n \n\nCoinOut Total Spending Affinity Grocery Spending\n\nNotes: This figure compares 7-day moving averages of national trends in cash transactions in CoinOut data vs. card spending\non groceries in Affinity Solutions data between January 1 2020 and June 1 2020. The signal correlation between the two\ndatasets at the national level is 0.90 at the weekly level. We compute this correlation by collapsing both datasets to the\nnational weekly level, where values in each week are expressed as the percentage change from the January average. To adjust\nfor measurement error at the weekly level, we calculate the series-specific reliability as the week-on-week correlation within\neach dataset. We then divide the raw weekly correlation between datasets by the square root of the product of the reliabilities\nto get the signal correlation. Data sources: CoinOut, Affinity Solutions.",
    "Page_99": "APPENDIX FIGURE 5: Small Business Revenue Changes vs. Consumer Spending Changes\n\nA. Retail Services (Excluding Auto and Gas)\n\n \n\n \n\n \n\n \n\n80%\nJ 60%\n>\na\n2 40%\n@\ngs\n2\n2 20%\nS\n®\nx 0%\nDa\ne\n£\nO -20%\nSpending (Affinity Solutions)\n“40% Small Business Revenue (Womply) RMSE: 13.83 p.p.\ntt ot tt oo tt\nJan 4 Apr 4 Jul 4 Oct 1 Jan 1 Apr 4 Jul\n2019 2019 2019 2019 2020 2020 2020\nB. Food Services and Accommodation\n40%\nJ 20%\n2\na\n2 0%\n@\ngs\n2\n© -20%\n5\n®\n© -40%\naD\n<\na\n=\nO -60%\nSpending (Affinity Solutions)\nSmall Business Revenue (Womply)\n-80% ( RMSE: 5.22 p.p.\nTt\nJan 4 Apr 1 Jul 4 Oct 1 Jan 1 Apr 1 Jul 4\n2019 2019 2019 2019 2020 2020 2020\n\nNotes: This figure compares seven-day moving averages of total consumer spending (from Affinity Solutions data) and small\nbusiness revenue (from Womply data) for the period January 1 2019 to June 30 2020. Each series is expressed as a percentage\nchange relative to the January 4-31 level in each calendar year. We do not seasonally adjust spending or small business revenue\nin this figure because seasonal fluctuations provide useful variation to assess whether the consumer spending series tracks the\nsmall business revenue series. Following the sectors defined in the Advance Monthly Retail Trade Survey (MARTS), Panel A\nrestricts to specifically retail trade sectors (NAICS code 44-45) excluding motor vehicles (NAICS code 441) and gas (NAICS\ncode 447), and Panel B restricts specifically to food services and accommodation (NAICS code 72). The bottom right corner of\n\neach panel displays the root mean squared error (RMSE) corresponding to the difference between the two lines. Data sources:\nAffinity Solutions, Womply.",
    "Page_100": "APPENDIX FIGURE 6: Changes in Small Business Revenues by ZIP Code for Food and\nAccommodation Service Businesses\n\nA. New York City B. Chicago\n\n   \n  \n \n\nSa\nChange in Revenue for\n\nChange in Revenue for\n\n‘Accommodations and ‘Accommodations and\n\nFood Services Food Services\n\nfrom Jan to Apr 2020 from Jan to Apr 2020\n<-84.2% <-77.1%\n84.2% to -77.0% -T7.1% 0 -69.2%\n-T7.0% to -70.9% 69.2% to 64.8%\n-70.9% to -64.9% 64.8% 0 -59.0%\n64.9% to 59.0% -58,0% to 55.4%\n-59.0% to -51.6% “55.4% to -49.7%\n51.6% to 44.6% 49.7% to -41.1%\n44.6% to -34.3% 41.1% 10 -34.7%\n234.3% to -19.9% 34.7% to -25.8%\n> 19.9% > 25.8%\nNo Data No Data\n\nLeatiet | © Mapbox\n\n \n\nC. San Francisco\n\n  \n\nValtejo\n\nChange in Revenue for\n\nAccommodations and\n\nFood Services\n\nfrom Jan to Apr 2020\n<-90.8%\n-90.8% to -84.3%\n84.3% to -79.9%\n-79.9% to -75.6%\n-78.6% to -70.7%\n-70.7% t0 65.7%\n85.7% to 58.9%\n~58.9% to -51.1%\n-51.1% to -43.0%\n> 43.0%\nNo Data\n\nNotes: This figure replicates Figure 4 for small businesses in the food and accommodation service sector (NAICS 72), showing\nthe change in revenue levels by ZIP code from January 4-31 to March 25-April 14. For further details, see the notes to Figure\n4. The signal variance to total variance ratios for the panels are 0.83 (New York), 0.88 (Chicago), and 0.69 (San Francisco).\n\nData source: Womply.",
    "Page_101": "APPENDIX FIGURE 7: National Maps of Changes in Small Business Revenues and Low-Income\nEmployment\n\nA. Changes in Small Business Revenues, by County\n\nChange in Small\nBusiness Revenue\nfrom Jan to Apr 2020\n< -53%\n\n-53% to -46%\n-46% to -42%\n-42% to -38%\n-38% to -35%\n-35% to -31%\n-31% to -26%\n-26% to -21%\n-21% to -10%\n\n> -10%\n\nNo Data\n\n \n\nLeaflet | © Mapbox\n\nB. Changes in Low-Wage Employment, by CZ\n\nChange in Low-Wage\nEmployment from\nJan to Apr 2020\n\n< -50%\n\n-50% to -44%\n-44% to -39%\n-39% to -33%\n-33% to -30%\n-30% to -25%\n-25% to -20%\n-20% to -13%\n-13% to -3%\n\n> -3%\n\nNo Data\n\n \n\nLeaflet | © Mapbox\n\nNotes: This figure presents national maps of changes in small business revenues (Panel A) and low-income employment (Panel\nB). Panel A replicates Figure 4 for the entire United States instead of a single MSA, showing the change in small business\nrevenue from January 4-31 to March 25-April 14 in each county (rather than ZIP code, as in Figure 4). See the notes to\nFigure 4 for further details. Panel B replicates Figure 8 at the commuting zone (CZ) level for the entire United States instead\nof a single MSA, showing the change in employment from January 4-31 to April 8-28 in the Paychex-Intuit-Earnin combined\ndata on employment in the bottom wage quartile (rather than Earnin data alone, as in Figure 8) in each CZ (rather than ZIP\ncode, as in Figure 8). See the notes to Figure 8 for further details. Data sources: Panel A: Womply; Panel B: Paychex, Intuit,\nEarnin.",
    "Page_102": "APPENDIX FIGURE 8: Changes in Small Business Outcomes vs. ZIP and County\nCharacteristics\n\nA. Changes in Small Business Revenue vs. Income Share of Top 1% B. Changes in Small Business Revenue vs. Share of Population\nof Income Distribution, by County Below Poverty Line, by County\n\n-30% -30%\n-40%\n\n40% .\n\n-50%\n\n  \n\nChange in Small Business Revenue (%)\nfrom January to April 2020\n.\n.\n.\n.\n\n“60% | Slope = -0.63% (s.¢. = 0.08) “60% | Slope = 0.24% (s.¢. = 0.04)\n\n \n\n \n\n5 10 15 20 25 30 5 10 15 20 25\nTop 1% Income Share (%) Share of the Population Below the Poverty Line in 2014-2018 (%)\n\nC. Changes in Small Businesses Open vs. Rent, by ZIP\n\n20%\n\n-30%\n\n~40%\n\nfrom January to April 2020\n\n \n\nChange in Small Businesses Open (%)\n\nSlope = -8.26%/$1000 (s.e. = 0.28)\n\n500 1,000 1,500 2,000\nMedian Two Bedroom Monthly Rent in 2014-2018 ($)\n\n-50%\n\n \n\nNotes: This figure shows the association between ZIP- or county-level characteristics and changes in small business outcomes\nbetween January 4-31 and March 25-April 14 2020, as measured in Womply data. The binned scatter plots are constructed\nas described in the notes to Figure 3. Panels A-B replicate Figure 5 but compare the declines in small business revenue with\nvarious measures of the distribution of income at the county level. Panel A presents a binned scatter plot of changes in small\nbusiness revenue vs. the income share of the top 1% of the income distribution within each county, as constructed using the\ndistribution of parent incomes in Chetty et al. (2014). The top 1% of the income distribution is defined using the distribution\nof incomes within each county, rather than the national income distribution. Panel B presents a binned scatter plot of changes\nin small business revenue vs. the share of the county population with incomes below the poverty line in the 2014-2018 ACS.\nPanel C replicates Figure 5c using the change in the number of small businesses open, rather than the change in small business\nrevenue, as the outcome variable. See notes to Figure 5 for details. Data source: Womply.",
    "Page_103": "Change in Small Business Revenue (%)\n\n \n\n \n\nRelative to January 2020\n.\n\n \n\nJe in Job Postings (%)\n\nAPPENDIX FIGURE 9: Changes in Small Business Revenue, Employment, and Job Postings\nFrom January to July vs. Rent\n\nA. Change in Small Business Revenue vs. Median Rent, by ZIP B. Change in Low-Income Employment vs. Median Rent, by ZIP\n\n0%\n\n  \n      \n \n\nChange from Jan-Jul +\nSlope = -13.12%/$1000 2\n(2. = 0.57)\n\n°\n\n \n \n  \n\n°\n\n-20% Change from Jan-Jul\nSlope = -9.67%/$1000\n\n(se. = 0.49)\n\n      \n \n\n \n    \n    \n \n\nChange from Jan-Apr\nSlope = -13.47%/$1000\n(se. = 0.35)\n\n-40% .\nChange from Jan-Apr\nSlope = -11.99%/$1000\n\n° (8.2. = 0.41)\n\n \n\n-60%\n\n \n\n \n\na\nS4\ns\n\n1000 1500 2000 500 4000 1500 2000\nMedian Two Bedroom Monthly Rent in 2014-2018 ($) Median Two Bedroom Monthly Rent in 2014-2018 ($)\nC. Change in Job Postings for Low-Education Workers vs. Median D. Change in Low-Income Employment vs. Workplace Rent, by ZIP\n\nRent, by County\n\n20%\n\n0%\n\n  \n\n  \n    \n   \n  \n\n-10%\nChange from Jan-Jul\nSlope = -14.82%/$1000\n(se. = 0.67)\n\nChange from Jan-Jul\nSlope = -26.44%/$1000\n\n(se. = 1.40) 20%\n\n-30%\n\n \n\n40%\n\n \n\n \n\n40% Change from Jan-Apr Change from Jan-Apr\nSlope = -21.02%/$1000 Slope = -13.32%/$1000 .\n(e.= 1.21) (Se. = 0.50)\n-50%\n600 1,000 1,400 1,800\n500 4000 1500 2000\n\nAverage Two Bedroom Monthly Rent in 2014-2018 in Workplace ZIP ($)\nMedian Two Bedroom Monthly Rent in 2014-2018 ($)\n\nNotes: This figure presents binned scatter plots showing the association between changes in various economic measures vs.\nZIP- and county-level median rent levels, contrasting the patterns in April vs. July 2020. See the notes to Figure 3 for more\ndetails on the construction of binned scatter plots. Panel A replicates Figure 5c, adding a second series showing ZIP-level\nchanges in small business revenue from January to July 4-31 2020 vs. ZIP median rent. Panel B replicates Figure 9a, pooling\nall firm sizes, and then adding a second series showing ZIP-level changes in low-income employment (from Earnin) from\nJanuary to July 4-31 2020 vs. ZIP median rent. Panel C replicates Figure 9b, adding a second series showing county-level\nchanges in job postings from January to July 4-31 2020 vs. county median rent. Panel D replicates Figure lla, adding a\nsecond series showing ZIP-level changes in low-income employment (from Earnin) from January to July 4-31 vs. workplace\nrent in ZIP. See the notes to Figure 11 for more details on the construction of workplace rent in ZIP. Data sources: Panel A:\nWomply; Panel B: Earnin; Panel C: Burning Glass; Panel D: Earnin.",
    "Page_104": "Change in Employment (%)\n\n \n\nAPPENDIX FIGURE 10: Employment in Paychex-Intuit-Earnin Data vs. ADP, CPS, and CES\n\n    \n \n\n \n\n \n\n     \n\n \n\n \n\n \n\nA. Trends in Employment Rates by Income Quartile: B. Change in Employment Rates to April by Income Quartile:\nPaychex-Intuit-Earnin vs. ADP. Paychex-Intuit-Earnin vs. ADP vs. CPS\naor 15! Sep 151 0%\n\\ 1\n9 \\\n0% ! J\n'\nI H Eg -10%\nss\n1 1 EN\n— een . i gS\n—a + I BQ 20%\n— a i It £2\n-e- Appar ! I BS -30%\n-e- a2 i I gE\n' 1 Ee\n-e- a3 I I o-\n-e- a4 H », EE) Paychex-Intuit-Earnin\n40% {°° \\ “0% lm A0P\nJan15 Feb15 Mar15 Apr15 May 15 Jun1S Jul15 Aug 15 Sep 1 Mumm crs\nai a2 a3 a4\nC. Change in Employment Rates to April by State: D. Change in Employment Rates to April by 2-Digit NAICS Code:\nPaychex-Intuit-Earnin vs. CES Paychex-Intuit-Earnin vs. CES\n0% 0%\nSeq ~10%\n-10% cos\nEEN\nSLE -20%\nZee\nBae\nS -20% EES 209\nS zu s 6\n8 gc8\n2 £s2\n8 388 oy\ns 40%\n5 30% o55\n-50%\n-40% Corr. = 0.99 e Corr. = 0.95\n-20% 15% -10% 5% -50% -40% -30% -20% -10% 0%\nCES Change in Employment (%) CES Change in Employment (%)\nfrom January to April 2020 from January to April 2020\n\nNotes: This figure benchmarks the Paychex-Intuit-Earnin combined employment series to the Current Population Survey\n(CPS), the Current Employment Statistics (CES), and estimates based on ADP data in Cajner et al. (2020). Panel A shows\nemployment trends in the Paychex-Intuit-Earnin combined data (solid series) and ADP data (dotted series), cut by income\nquartile (combined Paychex-Intuit-Earnin data) or income quintile (ADP data). The Paychex-Intuit-Earnin series is expressed\nas a percentage change relative to January 4-31 2020. The ADP series (from Cajner et al. 2020) is expressed as a percentage\nchange relative to February 15 2020. Panel B shows changes in employment from January to April 2020, cut by income\nquartile, in the Paychex-Intuit-Earnin combined, ADP, and CPS datasets. In the combined Paychex-Intuit-Earnin data, we\nexpress the change in employment relative to January 4-31 2020. The ADP series in Cajner et al. (2020) is expressed as\na percentage change relative to February 15 2020. The CPS series is expressed as a percentage change relative to January\n2020. Panel C shows a scatter plot of changes in employment in Paychex-Intuit-Earnin combined data between January 4-31\nand April 15 vs. changes in CES employment between January and April, by state. We exclude Hawaii and North Dakota,\nwhere Paychex-Intuit-Earnin data have poor coverage. Panel D shows a scatter plot of changes in employment in Paychex-\nIntuit-Earnin combined data between January 4-31 and April 15 vs. changes in CES employment between January and April,\nby two-digit NAICS code. In Panels C and D, the bottom right corner displays the correlation between the data points in\neach graph, weighted by state population (Panel C) and CES employment in each NAICS code (Panel D), respectively. Data\nsources: Paychex, Intuit, Earnin.",
    "Page_105": "APPENDIX FIGURE 11: Changes in Low-Wage Employment by Firm Size\n\n-20% 4\n\n-30%7\n\n40% 70\n\nChange in Employment (%)\nfrom January to April 2020\n\n \n\n-50% 4 : :\nT T T\n10 100 1,000 10,000 100,000 1,000,000\nParent Firm Size (Log Scale)\n\nNotes: This figure displays a binned scatter plot of average percent declines in employment in the Earnin data at firms of\ndifferent sizes. Binned scatter plots are constructed as described in notes to Figure 3. We calculate the change in employment\nfrom the period January 4-31 2020 to the period April 8-28 2020, and weight the binned scatter plot by employment in each\nfirm over the period January 4-31 2020. We estimate the size of firms by matching Earnin employer names and locations to\nemployer names and locations in ReferenceUSA data. Data source: Earnin.",
    "Page_106": "APPENDIX FIGURE 12: Event Studies of Consumer Spending Around State-Ordered Business\nClosures\n\n20 Early | Late |\nClosings ! Closings '\n\n°\n\n  \n\nChange in Consumer Spending (%)\nrelative to January 2020\niN)\nOo\n\n-60\n\nT T T T T\nFebruary 1 February 15 February 29 March 14 March 28, April 14\n\n \n\n-e Early (Mar 19 - 24) Closers ~-® Late (Mar 24-Apr6) Closers -® Non-Closers\n\nNotes: This figure displays trends in seasonally-adjusted consumer spending in the Affinity Solutions data, pooling states\nby the date on which a state-wide order closed non-essential businesses. States are aggregated into three groups: “Early”\n(state-wide closure order issued between March 19 and March 24), “Late” (state-wide closure order issued between March 30\nand April 6), and “Non-Closers” (no state-wide closure order issued by April 6). Dashed lines denote the first date on which\nstate-wide orders closing non-essential businesses were issued by “Early Closers” (March 19) and “Late Closers” (March 30).\nData source: Affinity Solutions.",
    "Page_107": "APPENDIX FIGURE 13: Effects of Stimulus Payments on Composition of Consumer Spending\n\n \n\n \n\n100% 4 i\nDurable Goods |\n23% Durable Goods: Durable Goods |\ni oo i Durable Goods\n\n75% + ! ee\n1\n1\n1\n1\n1\n50% + i\n1\n1\n1\n1\n25% 4 i\n1\n1\n1\n1\n0% 4 |\n\nJanuary Pre-Stimulus Post-Stimulus Share of Recovery\n\nNotes: This figure presents statistics on the distribution of card spending across categories during various periods. The first\nbar replicates the right bar in Figure 2b, showing the composition of the level of spending for the period January 4-31 2020.\nThe second and third bars replicate this distribution for the post-COVID, pre-stimulus period (March 25-April 14) and the\npost-COVID, post-stimulus period (April 29-May 5), respectively. The fourth bar replicates the left bar in Figure 2b, except\ndecomposing the change during the recovery (the pre-stimulus to post-stimulus periods) rather than the decline. We define\neach spending category using Merchant Category Codes (MCCs), see Appendix B for details. Data source: Affinity Solutions.",
    "Page_108": "APPENDIX FIGURE 14: Effect of Paycheck Protection Program on Employment in Earnin Data\n\nA. Change in Employment by PPP Eligibility, All Industries Excl. Food Services\n\n    \n\n0%\n\n-10%\n\n-20%\n\n-30%\n\nChange in Employment (%)\nRelative to January 2020\n\n-40%\n\n-50%\n\nPPP Program Begins Estimated Effect to August 15:\n'April 3 11.01 p.p. (s.e. = 0.94 p.p.)\n\nI\nI\nI\nI\nI\nI\nI\nI\nI\nI\nI\nI\n\\ 100-500 Employees\n|\n\n  \n\n501-800 Employees\n\n \n\nT T T T T T T\nFeb15 Mar15 Apr15 May15 Jun15 Jul15 Aug15 Sep 15\n\nB. Change in Employment by Firm Size, All Industries Excl. Food Services\n\n-20%\n\n-30%\n\n-40%\n\nChange in Employment (%)\nfrom January to June 2020\n\n-50%\n\n \n\n100 200 300 400 500 600 700 800\nFirm Size\n\nNotes: This figure replicates Figure 15, using Earnin data rather than combined Paychex-Earnin data. For details, see notes\n\nto Figure 15. Data source: Earnin.",
    "Page_109": "APPENDIX FIGURE 15: Out-Of-Sample Fit of Advance Employment Series\n\n0%\n£9\n=S -10%\noO\nEe2\n>So\n82\noa\nE\nGe -20%\nSo\no2\n23\noo 0,\nfod -30%\n-40%\n0%\nSo\nZS -10%\noO\nEe2\ns\nQo\nE\nGg -20%\nSo\no2\n26\nSe -30%\n-40%\n\nNotes: This figure compares out-of-sample predictions for employment to realized employment series. We construct predicted\nvalues for Paychex-Intuit-Earnin employment using Kronos data and Paychex data for firms with weekly paycycles; see notes\nto Figure 7 for details. Panel A compares out-of-sample predictions to realized values from June 16-July 15 2020. Panel B\ncompares the out-of-sample prediction to realized values from July 16-August 15 2020. The root mean squared error (RMSE)\nfor the difference between the prediction model and the true values across the top, middle, and bottom quartiles in the first\ntesting period is 0.946 percentage points, while the RMSE across the top, middle, and bottom quartiles in the second testing\n\n     \n \n\nA. Testing Period: June 16 - July 15\n\n-2%\n<— Actual\n\nQ4 Data\n\n1\nTraining Period: | Testing Period!\n\n|\n|\n|\n|\n|\n|\n|\nI.\n| -20%\n\n—— Actual\nQ1 Data\n\nPaychex-Intuit-Eamin Data\nfor Bottom Wage Quartile\n\nQ1 Prediction\n\nPaychex-Intuit-Earnin Data\nfor Top Wage Quartile\n\nQ4 Prediction\n\n \n\nMar 1\n\n    \n \n \n\nMay1 Jun1 Jul? Aug 1\n\nApr 1\n\nB. Testing Period: July 16 - August 15\n\n   \n \n\nTraining Period: Testing Period\n\n19%\n\nSep 1\n\nOct 1\n\n-19%\n\n<—— Actual\n\nQ1 Data\n\nPaychex-Intuit-Eamin Data\nfor Bottom Wage Quartile\n\nQ1 Prediction\nPaychex-Intuit-Earin Data\nQ4 Prediction\n\n \n\nMar 1\n\nApr1 May1 Jun1 Jul? Aug\n\nperiod is 0.042 percentage points. Data sources: Paychex, Intuit, Earnin, Kronos.\n\nSep 1\n\nOct 1"
}